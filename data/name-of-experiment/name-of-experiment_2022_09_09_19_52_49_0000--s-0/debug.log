2022-09-09 19:53:03.481721 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 0 finished
----------------------------------  --------------
epoch                                  0
replay_buffer/size                  2000
trainer/num train calls             1000
trainer/QF1 Loss                       3.94174
trainer/QF2 Loss                       3.94255
trainer/Policy Loss                   -1.9925
trainer/Q1 Predictions Mean            0.000151529
trainer/Q1 Predictions Std             0.000228239
trainer/Q1 Predictions Max             0.000679763
trainer/Q1 Predictions Min            -0.000531779
trainer/Q2 Predictions Mean           -5.63871e-05
trainer/Q2 Predictions Std             0.000174974
trainer/Q2 Predictions Max             0.000346887
trainer/Q2 Predictions Min            -0.000484205
trainer/Q Targets Mean                 1.94309
trainer/Q Targets Std                  0.40832
trainer/Q Targets Max                  2.70474
trainer/Q Targets Min                  0.853453
trainer/Log Pis Mean                  -1.9926
trainer/Log Pis Std                    0.392346
trainer/Log Pis Max                   -1.00451
trainer/Log Pis Min                   -2.91689
trainer/policy/mean Mean               2.30164e-05
trainer/policy/mean Std                0.00010287
trainer/policy/mean Max                0.000234463
trainer/policy/mean Min               -0.000197066
trainer/policy/normal/std Mean         0.999973
trainer/policy/normal/std Std          0.000353458
trainer/policy/normal/std Max          1.00052
trainer/policy/normal/std Min          0.999443
trainer/policy/normal/log_std Mean    -2.73504e-05
trainer/policy/normal/log_std Std      0.00035348
trainer/policy/normal/log_std Max      0.000518069
trainer/policy/normal/log_std Min     -0.000557339
trainer/Alpha                          1
trainer/Alpha Loss                    -0
expl/num steps total                2000
expl/num paths total                  20
expl/path length Mean                 76.9231
expl/path length Std                  68.4987
expl/path length Max                 219
expl/path length Min                   1
expl/Rewards Mean                      0.012
expl/Rewards Std                       0.108885
expl/Rewards Max                       1
expl/Rewards Min                       0
expl/Returns Mean                      0.923077
expl/Returns Std                       0.266469
expl/Returns Max                       1
expl/Returns Min                       0
expl/Actions Mean                     -0.0225748
expl/Actions Std                       0.630821
expl/Actions Max                       0.997862
expl/Actions Min                      -0.997226
expl/Num Paths                        13
expl/Average Returns                   0.923077
eval/num steps total                5000
eval/num paths total                   5
eval/path length Mean               1000
eval/path length Std                   0
eval/path length Max                1000
eval/path length Min                1000
eval/Rewards Mean                      0
eval/Rewards Std                       0
eval/Rewards Max                       0
eval/Rewards Min                       0
eval/Returns Mean                      0
eval/Returns Std                       0
eval/Returns Max                       0
eval/Returns Min                       0
eval/Actions Mean                      5.36414e-05
eval/Actions Std                       7.14094e-05
eval/Actions Max                       0.00017729
eval/Actions Min                      -0.00014062
eval/Num Paths                         5
eval/Average Returns                   0
time/data storing (s)                  0.00342657
time/evaluation sampling (s)           1.27794
time/exploration sampling (s)          0.328954
time/logging (s)                       0.00884813
time/sac training (s)                 11.6879
time/saving (s)                        0.00473613
time/training (s)                      2.789e-05
time/epoch (s)                        13.3118
time/total (s)                        13.5579
Epoch                                  0
----------------------------------  --------------
2022-09-09 19:53:16.570212 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 1 finished
----------------------------------  --------------
epoch                                   1
replay_buffer/size                   3000
trainer/num train calls              2000
trainer/QF1 Loss                        0.053863
trainer/QF2 Loss                        0.05487
trainer/Policy Loss                    -8.65523
trainer/Q1 Predictions Mean             7.15275
trainer/Q1 Predictions Std              0.582554
trainer/Q1 Predictions Max              8.52325
trainer/Q1 Predictions Min              6.06481
trainer/Q2 Predictions Mean             7.15553
trainer/Q2 Predictions Std              0.585204
trainer/Q2 Predictions Max              8.51642
trainer/Q2 Predictions Min              6.06056
trainer/Q Targets Mean                  7.11351
trainer/Q Targets Std                   0.432134
trainer/Q Targets Max                   8.52015
trainer/Q Targets Min                   6.25866
trainer/Log Pis Mean                   -2.05389
trainer/Log Pis Std                     0.280882
trainer/Log Pis Max                    -1.0487
trainer/Log Pis Min                    -3.06221
trainer/policy/mean Mean               -0.0126601
trainer/policy/mean Std                 0.0979944
trainer/policy/mean Max                 0.178636
trainer/policy/mean Min                -0.211859
trainer/policy/normal/std Mean          0.898272
trainer/policy/normal/std Std           0.0221595
trainer/policy/normal/std Max           0.942304
trainer/policy/normal/std Min           0.850946
trainer/policy/normal/log_std Mean     -0.10759
trainer/policy/normal/log_std Std       0.0248227
trainer/policy/normal/log_std Max      -0.0594271
trainer/policy/normal/log_std Min      -0.161407
trainer/Alpha                           0.740725
trainer/Alpha Loss                     -1.5168
expl/num steps total                 3000
expl/num paths total                   22
expl/path length Mean                 500
expl/path length Std                  488
expl/path length Max                  988
expl/path length Min                   12
expl/Rewards Mean                       0.001
expl/Rewards Std                        0.031607
expl/Rewards Max                        1
expl/Rewards Min                        0
expl/Returns Mean                       0.5
expl/Returns Std                        0.5
expl/Returns Max                        1
expl/Returns Min                        0
expl/Actions Mean                      -0.022396
expl/Actions Std                        0.600402
expl/Actions Max                        0.995545
expl/Actions Min                       -0.995445
expl/Num Paths                          2
expl/Average Returns                    0.5
eval/num steps total                10000
eval/num paths total                   10
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                      -0.0282052
eval/Actions Std                        0.116026
eval/Actions Max                        0.178951
eval/Actions Min                       -0.210661
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00529192
time/evaluation sampling (s)            0.938899
time/exploration sampling (s)           0.351257
time/logging (s)                        0.00924489
time/sac training (s)                  11.5319
time/saving (s)                         0.00510739
time/training (s)                       3.311e-05
time/epoch (s)                         12.8417
time/total (s)                         26.636
Epoch                                   1
----------------------------------  --------------
2022-09-09 19:53:30.165227 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 2 finished
----------------------------------  --------------
epoch                                   2
replay_buffer/size                   4000
trainer/num train calls              3000
trainer/QF1 Loss                        0.0622704
trainer/QF2 Loss                        0.0627535
trainer/Policy Loss                   -13.3
trainer/Q1 Predictions Mean            12.1767
trainer/Q1 Predictions Std              0.907688
trainer/Q1 Predictions Max             13.5521
trainer/Q1 Predictions Min              9.55639
trainer/Q2 Predictions Mean            12.1747
trainer/Q2 Predictions Std              0.907086
trainer/Q2 Predictions Max             13.5362
trainer/Q2 Predictions Min              9.56065
trainer/Q Targets Mean                 12.289
trainer/Q Targets Std                   0.766325
trainer/Q Targets Max                  13.3735
trainer/Q Targets Min                  10.2428
trainer/Log Pis Mean                   -1.96084
trainer/Log Pis Std                     0.46372
trainer/Log Pis Max                    -0.66401
trainer/Log Pis Min                    -3.31396
trainer/policy/mean Mean               -0.0172653
trainer/policy/mean Std                 0.196621
trainer/policy/mean Max                 0.481538
trainer/policy/mean Min                -0.405751
trainer/policy/normal/std Mean          0.902694
trainer/policy/normal/std Std           0.0154195
trainer/policy/normal/std Max           0.950704
trainer/policy/normal/std Min           0.864605
trainer/policy/normal/log_std Mean     -0.102517
trainer/policy/normal/log_std Std       0.0170442
trainer/policy/normal/log_std Max      -0.0505526
trainer/policy/normal/log_std Min      -0.145482
trainer/Alpha                           0.549368
trainer/Alpha Loss                     -2.97148
expl/num steps total                 4000
expl/num paths total                   23
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                      -0.00445484
expl/Actions Std                        0.607925
expl/Actions Max                        0.995813
expl/Actions Min                       -0.998066
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                15000
eval/num paths total                   15
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                       0.052532
eval/Actions Std                        0.202538
eval/Actions Max                        0.477997
eval/Actions Min                       -0.234559
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00372981
time/evaluation sampling (s)            0.936209
time/exploration sampling (s)           0.303164
time/logging (s)                        0.0118589
time/sac training (s)                  12.0423
time/saving (s)                         0.00447006
time/training (s)                       2.177e-05
time/epoch (s)                         13.3017
time/total (s)                         40.2208
Epoch                                   2
----------------------------------  --------------
2022-09-09 19:53:42.714359 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 3 finished
----------------------------------  --------------
epoch                                   3
replay_buffer/size                   5000
trainer/num train calls              4000
trainer/QF1 Loss                        0.568665
trainer/QF2 Loss                        0.570835
trainer/Policy Loss                   -17.3687
trainer/Q1 Predictions Mean            16.5942
trainer/Q1 Predictions Std              1.61953
trainer/Q1 Predictions Max             19.7044
trainer/Q1 Predictions Min             11.2443
trainer/Q2 Predictions Mean            16.5957
trainer/Q2 Predictions Std              1.61903
trainer/Q2 Predictions Max             19.6543
trainer/Q2 Predictions Min             11.2761
trainer/Q Targets Mean                 16.4248
trainer/Q Targets Std                   1.61796
trainer/Q Targets Max                  19.1107
trainer/Q Targets Min                   1
trainer/Log Pis Mean                   -1.68501
trainer/Log Pis Std                     0.891065
trainer/Log Pis Max                     0.599299
trainer/Log Pis Min                    -3.85466
trainer/policy/mean Mean               -0.0170735
trainer/policy/mean Std                 0.36654
trainer/policy/mean Max                 0.792524
trainer/policy/mean Min                -0.707814
trainer/policy/normal/std Mean          0.891067
trainer/policy/normal/std Std           0.0461936
trainer/policy/normal/std Max           1.00861
trainer/policy/normal/std Min           0.751996
trainer/policy/normal/log_std Mean     -0.116708
trainer/policy/normal/log_std Std       0.0526671
trainer/policy/normal/log_std Max       0.00857587
trainer/policy/normal/log_std Min      -0.285024
trainer/Alpha                           0.408938
trainer/Alpha Loss                     -4.1893
expl/num steps total                 5000
expl/num paths total                   24
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                       0.0620205
expl/Actions Std                        0.638598
expl/Actions Max                        0.999207
expl/Actions Min                       -0.998928
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                20000
eval/num paths total                   20
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                       0.307706
eval/Actions Std                        0.319598
eval/Actions Max                        0.675182
eval/Actions Min                       -0.590896
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00331761
time/evaluation sampling (s)            0.94489
time/exploration sampling (s)           0.304995
time/logging (s)                        0.00916842
time/sac training (s)                  11.0605
time/saving (s)                         0.00340021
time/training (s)                       2.766e-05
time/epoch (s)                         12.3263
time/total (s)                         52.7579
Epoch                                   3
----------------------------------  --------------
2022-09-09 19:53:55.748868 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 4 finished
----------------------------------  --------------
epoch                                   4
replay_buffer/size                   6000
trainer/num train calls              5000
trainer/QF1 Loss                        0.205741
trainer/QF2 Loss                        0.207989
trainer/Policy Loss                   -20.241
trainer/Q1 Predictions Mean            19.5691
trainer/Q1 Predictions Std              1.9688
trainer/Q1 Predictions Max             23.4975
trainer/Q1 Predictions Min             13.3863
trainer/Q2 Predictions Mean            19.5716
trainer/Q2 Predictions Std              1.9683
trainer/Q2 Predictions Max             23.5045
trainer/Q2 Predictions Min             13.451
trainer/Q Targets Mean                 19.4857
trainer/Q Targets Std                   1.62968
trainer/Q Targets Max                  22.5656
trainer/Q Targets Min                  14.0293
trainer/Log Pis Mean                   -1.48423
trainer/Log Pis Std                     1.04933
trainer/Log Pis Max                     1.1138
trainer/Log Pis Min                    -4.14127
trainer/policy/mean Mean               -0.136923
trainer/policy/mean Std                 0.394422
trainer/policy/mean Max                 0.877069
trainer/policy/mean Min                -0.856286
trainer/policy/normal/std Mean          0.908988
trainer/policy/normal/std Std           0.0688152
trainer/policy/normal/std Max           1.01591
trainer/policy/normal/std Min           0.708621
trainer/policy/normal/log_std Mean     -0.098465
trainer/policy/normal/log_std Std       0.0792029
trainer/policy/normal/log_std Max       0.0157884
trainer/policy/normal/log_std Min      -0.344434
trainer/Alpha                           0.305689
trainer/Alpha Loss                     -5.31465
expl/num steps total                 6000
expl/num paths total                   25
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                      -0.344499
expl/Actions Std                        0.576401
expl/Actions Max                        0.995042
expl/Actions Min                       -0.999187
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                25000
eval/num paths total                   25
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                       0.107385
eval/Actions Std                        0.534488
eval/Actions Max                        0.80538
eval/Actions Min                       -0.845515
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00336336
time/evaluation sampling (s)            0.929663
time/exploration sampling (s)           0.305152
time/logging (s)                        0.00894115
time/sac training (s)                  11.5191
time/saving (s)                         0.00346827
time/training (s)                       2.405e-05
time/epoch (s)                         12.7697
time/total (s)                         65.7816
Epoch                                   4
----------------------------------  --------------
2022-09-09 19:54:08.394128 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 5 finished
----------------------------------  --------------
epoch                                   5
replay_buffer/size                   7000
trainer/num train calls              6000
trainer/QF1 Loss                        0.78112
trainer/QF2 Loss                        0.784545
trainer/Policy Loss                   -21.8762
trainer/Q1 Predictions Mean            21.3428
trainer/Q1 Predictions Std              2.06309
trainer/Q1 Predictions Max             26.0545
trainer/Q1 Predictions Min             13.7352
trainer/Q2 Predictions Mean            21.3489
trainer/Q2 Predictions Std              2.06356
trainer/Q2 Predictions Max             26.0284
trainer/Q2 Predictions Min             13.7632
trainer/Q Targets Mean                 21.2205
trainer/Q Targets Std                   2.19661
trainer/Q Targets Max                  24.9703
trainer/Q Targets Min                   1
trainer/Log Pis Mean                   -1.18095
trainer/Log Pis Std                     1.13573
trainer/Log Pis Max                     1.5666
trainer/Log Pis Min                    -4.79508
trainer/policy/mean Mean               -0.0441933
trainer/policy/mean Std                 0.462678
trainer/policy/mean Max                 0.881474
trainer/policy/mean Min                -0.892891
trainer/policy/normal/std Mean          0.917242
trainer/policy/normal/std Std           0.0971458
trainer/policy/normal/std Max           1.11001
trainer/policy/normal/std Min           0.664152
trainer/policy/normal/log_std Mean     -0.0923815
trainer/policy/normal/log_std Std       0.111494
trainer/policy/normal/log_std Max       0.104372
trainer/policy/normal/log_std Min      -0.409245
trainer/Alpha                           0.229179
trainer/Alpha Loss                     -6.15958
expl/num steps total                 7000
expl/num paths total                   26
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                       0.163386
expl/Actions Std                        0.651137
expl/Actions Max                        0.998413
expl/Actions Min                       -0.998811
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                30000
eval/num paths total                   30
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                       0.295547
eval/Actions Std                        0.422222
eval/Actions Max                        0.875832
eval/Actions Min                       -0.856292
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00341239
time/evaluation sampling (s)            0.937701
time/exploration sampling (s)           0.328228
time/logging (s)                        0.00977799
time/sac training (s)                  11.1302
time/saving (s)                         0.00335335
time/training (s)                       2.066e-05
time/epoch (s)                         12.4127
time/total (s)                         78.4183
Epoch                                   5
----------------------------------  --------------
2022-09-09 19:54:21.590521 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 6 finished
----------------------------------  --------------
epoch                                   6
replay_buffer/size                   8000
trainer/num train calls              7000
trainer/QF1 Loss                        0.863235
trainer/QF2 Loss                        0.864802
trainer/Policy Loss                   -22.6518
trainer/Q1 Predictions Mean            22.2172
trainer/Q1 Predictions Std              1.93923
trainer/Q1 Predictions Max             25.9266
trainer/Q1 Predictions Min             15.0198
trainer/Q2 Predictions Mean            22.2166
trainer/Q2 Predictions Std              1.93631
trainer/Q2 Predictions Max             25.9804
trainer/Q2 Predictions Min             15.0457
trainer/Q Targets Mean                 22.0961
trainer/Q Targets Std                   2.18673
trainer/Q Targets Max                  25.6264
trainer/Q Targets Min                   1
trainer/Log Pis Mean                   -1.04077
trainer/Log Pis Std                     1.33271
trainer/Log Pis Max                     1.55503
trainer/Log Pis Min                    -6.27716
trainer/policy/mean Mean               -0.0961754
trainer/policy/mean Std                 0.487074
trainer/policy/mean Max                 0.93343
trainer/policy/mean Min                -0.917523
trainer/policy/normal/std Mean          0.921499
trainer/policy/normal/std Std           0.126557
trainer/policy/normal/std Max           1.16815
trainer/policy/normal/std Min           0.608976
trainer/policy/normal/log_std Mean     -0.0917128
trainer/policy/normal/log_std Std       0.143315
trainer/policy/normal/log_std Max       0.155422
trainer/policy/normal/log_std Min      -0.495976
trainer/Alpha                           0.171766
trainer/Alpha Loss                     -7.1183
expl/num steps total                 8000
expl/num paths total                   27
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                      -0.139751
expl/Actions Std                        0.648953
expl/Actions Max                        0.999634
expl/Actions Min                       -0.999314
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                35000
eval/num paths total                   35
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                       0.0285808
eval/Actions Std                        0.409267
eval/Actions Max                        0.90339
eval/Actions Min                       -0.893188
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.0033684
time/evaluation sampling (s)            0.93314
time/exploration sampling (s)           0.343508
time/logging (s)                        0.00946304
time/sac training (s)                  11.6326
time/saving (s)                         0.00344186
time/training (s)                       2.825e-05
time/epoch (s)                         12.9256
time/total (s)                         91.6036
Epoch                                   6
----------------------------------  --------------
2022-09-09 19:54:35.000061 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 7 finished
----------------------------------  --------------
epoch                                   7
replay_buffer/size                   9000
trainer/num train calls              8000
trainer/QF1 Loss                        2.62986
trainer/QF2 Loss                        2.62436
trainer/Policy Loss                   -22.9081
trainer/Q1 Predictions Mean            22.5464
trainer/Q1 Predictions Std              1.97211
trainer/Q1 Predictions Max             26.5927
trainer/Q1 Predictions Min             14.8528
trainer/Q2 Predictions Mean            22.5364
trainer/Q2 Predictions Std              1.96318
trainer/Q2 Predictions Max             26.6235
trainer/Q2 Predictions Min             14.8778
trainer/Q Targets Mean                 22.4362
trainer/Q Targets Std                   2.8763
trainer/Q Targets Max                  26.1567
trainer/Q Targets Min                   1
trainer/Log Pis Mean                   -0.917664
trainer/Log Pis Std                     1.22868
trainer/Log Pis Max                     1.82436
trainer/Log Pis Min                    -3.99751
trainer/policy/mean Mean               -0.038268
trainer/policy/mean Std                 0.509145
trainer/policy/mean Max                 0.937958
trainer/policy/mean Min                -0.927753
trainer/policy/normal/std Mean          0.92784
trainer/policy/normal/std Std           0.143111
trainer/policy/normal/std Max           1.17473
trainer/policy/normal/std Min           0.572741
trainer/policy/normal/log_std Mean     -0.088041
trainer/policy/normal/log_std Std       0.166486
trainer/policy/normal/log_std Max       0.161038
trainer/policy/normal/log_std Min      -0.557322
trainer/Alpha                           0.129
trainer/Alpha Loss                     -8.02316
expl/num steps total                 9000
expl/num paths total                   28
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                       0.199314
expl/Actions Std                        0.689756
expl/Actions Max                        0.998296
expl/Actions Min                       -0.997657
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                40000
eval/num paths total                   40
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                      -0.0415114
eval/Actions Std                        0.365431
eval/Actions Max                        0.445151
eval/Actions Min                       -0.914432
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00339064
time/evaluation sampling (s)            0.95042
time/exploration sampling (s)           0.351449
time/logging (s)                        0.00953681
time/sac training (s)                  11.8067
time/saving (s)                         0.00359938
time/training (s)                       1.989e-05
time/epoch (s)                         13.1252
time/total (s)                        105.001
Epoch                                   7
----------------------------------  --------------
2022-09-09 19:54:48.348030 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 8 finished
----------------------------------  --------------
epoch                                   8
replay_buffer/size                  10000
trainer/num train calls              9000
trainer/QF1 Loss                        0.990021
trainer/QF2 Loss                        0.999547
trainer/Policy Loss                   -23.4218
trainer/Q1 Predictions Mean            23.144
trainer/Q1 Predictions Std              1.86287
trainer/Q1 Predictions Max             26.4982
trainer/Q1 Predictions Min             16.2457
trainer/Q2 Predictions Mean            23.1471
trainer/Q2 Predictions Std              1.86739
trainer/Q2 Predictions Max             26.4798
trainer/Q2 Predictions Min             16.2881
trainer/Q Targets Mean                 23.0352
trainer/Q Targets Std                   2.18409
trainer/Q Targets Max                  26.4395
trainer/Q Targets Min                   1
trainer/Log Pis Mean                   -0.579302
trainer/Log Pis Std                     1.47462
trainer/Log Pis Max                     2.39623
trainer/Log Pis Min                    -6.55062
trainer/policy/mean Mean               -0.0750199
trainer/policy/mean Std                 0.552411
trainer/policy/mean Max                 0.963307
trainer/policy/mean Min                -0.950652
trainer/policy/normal/std Mean          0.863246
trainer/policy/normal/std Std           0.143955
trainer/policy/normal/std Max           1.15762
trainer/policy/normal/std Min           0.515645
trainer/policy/normal/log_std Mean     -0.162387
trainer/policy/normal/log_std Std       0.179753
trainer/policy/normal/log_std Max       0.146367
trainer/policy/normal/log_std Min      -0.662336
trainer/Alpha                           0.0973619
trainer/Alpha Loss                     -8.33734
expl/num steps total                10000
expl/num paths total                   29
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                      -0.288522
expl/Actions Std                        0.642171
expl/Actions Max                        0.996888
expl/Actions Min                       -0.998444
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                45000
eval/num paths total                   45
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                      -0.195422
eval/Actions Std                        0.487028
eval/Actions Max                        0.918363
eval/Actions Min                       -0.932027
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00332203
time/evaluation sampling (s)            0.962267
time/exploration sampling (s)           0.313099
time/logging (s)                        0.00956028
time/sac training (s)                  11.7832
time/saving (s)                         0.00367464
time/training (s)                       2.131e-05
time/epoch (s)                         13.0751
time/total (s)                        118.338
Epoch                                   8
----------------------------------  --------------
2022-09-09 19:55:00.898012 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 9 finished
----------------------------------  --------------
epoch                                   9
replay_buffer/size                  11000
trainer/num train calls             10000
trainer/QF1 Loss                        1.7104
trainer/QF2 Loss                        1.68704
trainer/Policy Loss                   -23.3906
trainer/Q1 Predictions Mean            23.147
trainer/Q1 Predictions Std              1.84948
trainer/Q1 Predictions Max             26.05
trainer/Q1 Predictions Min             15.5702
trainer/Q2 Predictions Mean            23.1404
trainer/Q2 Predictions Std              1.85197
trainer/Q2 Predictions Max             26.0142
trainer/Q2 Predictions Min             15.4422
trainer/Q Targets Mean                 23.0182
trainer/Q Targets Std                   2.55902
trainer/Q Targets Max                  25.9068
trainer/Q Targets Min                   1
trainer/Log Pis Mean                   -0.755855
trainer/Log Pis Std                     1.27049
trainer/Log Pis Max                     2.10945
trainer/Log Pis Min                    -5.7249
trainer/policy/mean Mean               -0.0819965
trainer/policy/mean Std                 0.529302
trainer/policy/mean Max                 0.96211
trainer/policy/mean Min                -0.936944
trainer/policy/normal/std Mean          0.809174
trainer/policy/normal/std Std           0.185271
trainer/policy/normal/std Max           1.19801
trainer/policy/normal/std Min           0.36766
trainer/policy/normal/log_std Mean     -0.239873
trainer/policy/normal/log_std Std       0.242092
trainer/policy/normal/log_std Max       0.180664
trainer/policy/normal/log_std Min      -1.0006
trainer/Alpha                           0.0731181
trainer/Alpha Loss                     -9.82411
expl/num steps total                11000
expl/num paths total                   30
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                      -0.219402
expl/Actions Std                        0.602392
expl/Actions Max                        0.996038
expl/Actions Min                       -0.995795
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                50000
eval/num paths total                   50
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                       0.0301328
eval/Actions Std                        0.465882
eval/Actions Max                        0.926064
eval/Actions Min                       -0.94231
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00503231
time/evaluation sampling (s)            0.940847
time/exploration sampling (s)           0.2924
time/logging (s)                        0.00905271
time/sac training (s)                  11.0514
time/saving (s)                         0.00362123
time/training (s)                       1.978e-05
time/epoch (s)                         12.3024
time/total (s)                        130.878
Epoch                                   9
----------------------------------  --------------
2022-09-09 19:55:13.798808 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 10 finished
----------------------------------  --------------
epoch                                  10
replay_buffer/size                  12000
trainer/num train calls             11000
trainer/QF1 Loss                        0.0515719
trainer/QF2 Loss                        0.0491557
trainer/Policy Loss                   -23.2178
trainer/Q1 Predictions Mean            23.0696
trainer/Q1 Predictions Std              1.66971
trainer/Q1 Predictions Max             25.6937
trainer/Q1 Predictions Min             16.2001
trainer/Q2 Predictions Mean            23.079
trainer/Q2 Predictions Std              1.66912
trainer/Q2 Predictions Max             25.6447
trainer/Q2 Predictions Min             16.2114
trainer/Q Targets Mean                 23.1529
trainer/Q Targets Std                   1.6146
trainer/Q Targets Max                  25.7809
trainer/Q Targets Min                  16.6951
trainer/Log Pis Mean                   -0.536841
trainer/Log Pis Std                     1.49023
trainer/Log Pis Max                     2.94665
trainer/Log Pis Min                    -4.89426
trainer/policy/mean Mean               -0.183412
trainer/policy/mean Std                 0.521931
trainer/policy/mean Max                 0.965729
trainer/policy/mean Min                -0.965201
trainer/policy/normal/std Mean          0.777935
trainer/policy/normal/std Std           0.22917
trainer/policy/normal/std Max           1.24213
trainer/policy/normal/std Min           0.291478
trainer/policy/normal/log_std Mean     -0.301451
trainer/policy/normal/log_std Std       0.33041
trainer/policy/normal/log_std Max       0.216829
trainer/policy/normal/log_std Min      -1.23279
trainer/Alpha                           0.0551912
trainer/Alpha Loss                    -10.2461
expl/num steps total                12000
expl/num paths total                   31
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                      -0.258804
expl/Actions Std                        0.562608
expl/Actions Max                        0.993988
expl/Actions Min                       -0.999449
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                55000
eval/num paths total                   55
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                      -0.0317074
eval/Actions Std                        0.487095
eval/Actions Max                        0.930916
eval/Actions Min                       -0.958222
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00335519
time/evaluation sampling (s)            0.983864
time/exploration sampling (s)           0.340833
time/logging (s)                        0.00902106
time/sac training (s)                  11.3002
time/saving (s)                         0.00328826
time/training (s)                       1.993e-05
time/epoch (s)                         12.6406
time/total (s)                        143.769
Epoch                                  10
----------------------------------  --------------
2022-09-09 19:55:26.683209 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 11 finished
----------------------------------  --------------
epoch                                  11
replay_buffer/size                  13000
trainer/num train calls             12000
trainer/QF1 Loss                        0.0599292
trainer/QF2 Loss                        0.0592564
trainer/Policy Loss                   -22.9532
trainer/Q1 Predictions Mean            22.7938
trainer/Q1 Predictions Std              1.46022
trainer/Q1 Predictions Max             25.584
trainer/Q1 Predictions Min             17.3944
trainer/Q2 Predictions Mean            22.7873
trainer/Q2 Predictions Std              1.45735
trainer/Q2 Predictions Max             25.5647
trainer/Q2 Predictions Min             17.312
trainer/Q Targets Mean                 22.7272
trainer/Q Targets Std                   1.3605
trainer/Q Targets Max                  25.4157
trainer/Q Targets Min                  17.4266
trainer/Log Pis Mean                   -0.313718
trainer/Log Pis Std                     1.47688
trainer/Log Pis Max                     4.37228
trainer/Log Pis Min                    -5.08233
trainer/policy/mean Mean               -0.123715
trainer/policy/mean Std                 0.552101
trainer/policy/mean Max                 0.986762
trainer/policy/mean Min                -0.957912
trainer/policy/normal/std Mean          0.749629
trainer/policy/normal/std Std           0.239538
trainer/policy/normal/std Max           1.2617
trainer/policy/normal/std Min           0.268165
trainer/policy/normal/log_std Mean     -0.347139
trainer/policy/normal/log_std Std       0.358484
trainer/policy/normal/log_std Max       0.232464
trainer/policy/normal/log_std Min      -1.31615
trainer/Alpha                           0.0414626
trainer/Alpha Loss                    -10.5474
expl/num steps total                13000
expl/num paths total                   32
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                       0.201993
expl/Actions Std                        0.688361
expl/Actions Max                        0.998865
expl/Actions Min                       -0.99935
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                60000
eval/num paths total                   60
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                      -0.303115
eval/Actions Std                        0.48555
eval/Actions Max                        0.925756
eval/Actions Min                       -0.943212
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00359537
time/evaluation sampling (s)            0.935301
time/exploration sampling (s)           0.319294
time/logging (s)                        0.00914041
time/sac training (s)                  11.3536
time/saving (s)                         0.00332426
time/training (s)                       1.969e-05
time/epoch (s)                         12.6242
time/total (s)                        156.643
Epoch                                  11
----------------------------------  --------------
2022-09-09 19:55:39.446470 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 12 finished
----------------------------------  --------------
epoch                                  12
replay_buffer/size                  14000
trainer/num train calls             13000
trainer/QF1 Loss                        0.0632654
trainer/QF2 Loss                        0.0562677
trainer/Policy Loss                   -22.2192
trainer/Q1 Predictions Mean            22.0964
trainer/Q1 Predictions Std              1.42723
trainer/Q1 Predictions Max             24.812
trainer/Q1 Predictions Min             15.8064
trainer/Q2 Predictions Mean            22.1061
trainer/Q2 Predictions Std              1.42369
trainer/Q2 Predictions Max             24.7426
trainer/Q2 Predictions Min             15.9086
trainer/Q Targets Mean                 22.2205
trainer/Q Targets Std                   1.37761
trainer/Q Targets Max                  24.9879
trainer/Q Targets Min                  16.1222
trainer/Log Pis Mean                    0.0857781
trainer/Log Pis Std                     1.75398
trainer/Log Pis Max                     4.63721
trainer/Log Pis Min                    -6.14158
trainer/policy/mean Mean               -0.093238
trainer/policy/mean Std                 0.61877
trainer/policy/mean Max                 0.976724
trainer/policy/mean Min                -0.980636
trainer/policy/normal/std Mean          0.71183
trainer/policy/normal/std Std           0.255167
trainer/policy/normal/std Max           1.32482
trainer/policy/normal/std Min           0.230183
trainer/policy/normal/log_std Mean     -0.414056
trainer/policy/normal/log_std Std       0.403107
trainer/policy/normal/log_std Max       0.281279
trainer/policy/normal/log_std Min      -1.46888
trainer/Alpha                           0.0313246
trainer/Alpha Loss                    -10.093
expl/num steps total                14000
expl/num paths total                   33
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                       0.226566
expl/Actions Std                        0.618343
expl/Actions Max                        0.999623
expl/Actions Min                       -0.998547
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                65000
eval/num paths total                   65
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                       0.125663
eval/Actions Std                        0.481035
eval/Actions Max                        0.928973
eval/Actions Min                       -0.95163
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00331416
time/evaluation sampling (s)            0.940089
time/exploration sampling (s)           0.338119
time/logging (s)                        0.00916486
time/sac training (s)                  11.2275
time/saving (s)                         0.00333278
time/training (s)                       1.958e-05
time/epoch (s)                         12.5216
time/total (s)                        169.397
Epoch                                  12
----------------------------------  --------------
2022-09-09 19:55:51.823813 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 13 finished
----------------------------------  --------------
epoch                                  13
replay_buffer/size                  15000
trainer/num train calls             14000
trainer/QF1 Loss                        0.724696
trainer/QF2 Loss                        0.732606
trainer/Policy Loss                   -21.9223
trainer/Q1 Predictions Mean            21.8458
trainer/Q1 Predictions Std              1.39636
trainer/Q1 Predictions Max             23.919
trainer/Q1 Predictions Min             14.2412
trainer/Q2 Predictions Mean            21.8383
trainer/Q2 Predictions Std              1.38772
trainer/Q2 Predictions Max             23.8545
trainer/Q2 Predictions Min             14.3031
trainer/Q Targets Mean                 21.8248
trainer/Q Targets Std                   1.79956
trainer/Q Targets Max                  23.8459
trainer/Q Targets Min                   1
trainer/Log Pis Mean                    0.0989492
trainer/Log Pis Std                     1.77866
trainer/Log Pis Max                     5.31771
trainer/Log Pis Min                    -5.29608
trainer/policy/mean Mean                0.0195162
trainer/policy/mean Std                 0.624696
trainer/policy/mean Max                 0.996677
trainer/policy/mean Min                -0.990718
trainer/policy/normal/std Mean          0.778479
trainer/policy/normal/std Std           0.300973
trainer/policy/normal/std Max           1.51336
trainer/policy/normal/std Min           0.154975
trainer/policy/normal/log_std Mean     -0.33779
trainer/policy/normal/log_std Std       0.441686
trainer/policy/normal/log_std Max       0.41433
trainer/policy/normal/log_std Min      -1.86449
trainer/Alpha                           0.0237636
trainer/Alpha Loss                    -10.8488
expl/num steps total                15000
expl/num paths total                   34
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                       0.298706
expl/Actions Std                        0.616742
expl/Actions Max                        0.999958
expl/Actions Min                       -0.999946
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                70000
eval/num paths total                   70
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                       0.0564018
eval/Actions Std                        0.508141
eval/Actions Max                        0.990792
eval/Actions Min                       -0.933275
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00510056
time/evaluation sampling (s)            0.932213
time/exploration sampling (s)           0.316991
time/logging (s)                        0.00980618
time/sac training (s)                  10.873
time/saving (s)                         0.00331559
time/training (s)                       2.009e-05
time/epoch (s)                         12.1405
time/total (s)                        181.766
Epoch                                  13
----------------------------------  --------------
2022-09-09 19:56:04.139022 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 14 finished
----------------------------------  --------------
epoch                                  14
replay_buffer/size                  16000
trainer/num train calls             15000
trainer/QF1 Loss                        0.0398213
trainer/QF2 Loss                        0.039524
trainer/Policy Loss                   -21.2356
trainer/Q1 Predictions Mean            21.1436
trainer/Q1 Predictions Std              1.43642
trainer/Q1 Predictions Max             23.2051
trainer/Q1 Predictions Min             14.9892
trainer/Q2 Predictions Mean            21.1298
trainer/Q2 Predictions Std              1.42977
trainer/Q2 Predictions Max             23.1924
trainer/Q2 Predictions Min             15.1256
trainer/Q Targets Mean                 21.1228
trainer/Q Targets Std                   1.33997
trainer/Q Targets Max                  23.0313
trainer/Q Targets Min                  15.4378
trainer/Log Pis Mean                    1.03933
trainer/Log Pis Std                     1.84938
trainer/Log Pis Max                     5.707
trainer/Log Pis Min                    -3.4554
trainer/policy/mean Mean                0.130066
trainer/policy/mean Std                 0.6598
trainer/policy/mean Max                 0.999585
trainer/policy/mean Min                -0.981065
trainer/policy/normal/std Mean          0.707779
trainer/policy/normal/std Std           0.322992
trainer/policy/normal/std Max           1.6503
trainer/policy/normal/std Min           0.176948
trainer/policy/normal/log_std Mean     -0.461769
trainer/policy/normal/log_std Std       0.501552
trainer/policy/normal/log_std Max       0.500954
trainer/policy/normal/log_std Min      -1.7319
trainer/Alpha                           0.0181314
trainer/Alpha Loss                     -7.8625
expl/num steps total                16000
expl/num paths total                   35
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                      -0.397874
expl/Actions Std                        0.686164
expl/Actions Max                        0.998723
expl/Actions Min                       -0.999191
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                75000
eval/num paths total                   75
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                       0.25392
eval/Actions Std                        0.501945
eval/Actions Max                        0.991267
eval/Actions Min                       -0.965953
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00494983
time/evaluation sampling (s)            0.931015
time/exploration sampling (s)           0.308109
time/logging (s)                        0.0095078
time/sac training (s)                  10.8208
time/saving (s)                         0.00360282
time/training (s)                       1.895e-05
time/epoch (s)                         12.078
time/total (s)                        194.072
Epoch                                  14
----------------------------------  --------------
2022-09-09 19:56:16.816578 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 15 finished
----------------------------------  --------------
epoch                                  15
replay_buffer/size                  17000
trainer/num train calls             16000
trainer/QF1 Loss                        0.0291967
trainer/QF2 Loss                        0.0275062
trainer/Policy Loss                   -20.7109
trainer/Q1 Predictions Mean            20.6604
trainer/Q1 Predictions Std              1.06393
trainer/Q1 Predictions Max             22.1776
trainer/Q1 Predictions Min             15.7091
trainer/Q2 Predictions Mean            20.6424
trainer/Q2 Predictions Std              1.06947
trainer/Q2 Predictions Max             22.1458
trainer/Q2 Predictions Min             15.7397
trainer/Q Targets Mean                 20.6608
trainer/Q Targets Std                   1.00358
trainer/Q Targets Max                  22.0718
trainer/Q Targets Min                  16.2162
trainer/Log Pis Mean                    1.17162
trainer/Log Pis Std                     1.96877
trainer/Log Pis Max                     7.22367
trainer/Log Pis Min                    -4.07402
trainer/policy/mean Mean                0.00382724
trainer/policy/mean Std                 0.68908
trainer/policy/mean Max                 0.996044
trainer/policy/mean Min                -0.991405
trainer/policy/normal/std Mean          0.719996
trainer/policy/normal/std Std           0.386451
trainer/policy/normal/std Max           1.79388
trainer/policy/normal/std Min           0.0971033
trainer/policy/normal/log_std Mean     -0.496571
trainer/policy/normal/log_std Std       0.615532
trainer/policy/normal/log_std Max       0.584379
trainer/policy/normal/log_std Min      -2.33198
trainer/Alpha                           0.0140544
trainer/Alpha Loss                     -7.79771
expl/num steps total                17000
expl/num paths total                   36
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                       0.13536
expl/Actions Std                        0.724312
expl/Actions Max                        0.999711
expl/Actions Min                       -0.999985
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                80000
eval/num paths total                   80
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                      -0.0903143
eval/Actions Std                        0.783655
eval/Actions Max                        0.99428
eval/Actions Min                       -0.966032
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00357316
time/evaluation sampling (s)            0.928305
time/exploration sampling (s)           0.299045
time/logging (s)                        0.00960282
time/sac training (s)                  11.1794
time/saving (s)                         0.00480187
time/training (s)                       2.603e-05
time/epoch (s)                         12.4248
time/total (s)                        206.74
Epoch                                  15
----------------------------------  --------------
2022-09-09 19:56:29.549725 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 16 finished
----------------------------------  --------------
epoch                                  16
replay_buffer/size                  18000
trainer/num train calls             17000
trainer/QF1 Loss                        0.0288467
trainer/QF2 Loss                        0.0279892
trainer/Policy Loss                   -19.9294
trainer/Q1 Predictions Mean            19.8356
trainer/Q1 Predictions Std              1.16318
trainer/Q1 Predictions Max             21.2758
trainer/Q1 Predictions Min             14.0419
trainer/Q2 Predictions Mean            19.8405
trainer/Q2 Predictions Std              1.14514
trainer/Q2 Predictions Max             21.2415
trainer/Q2 Predictions Min             14.0032
trainer/Q Targets Mean                 19.8644
trainer/Q Targets Std                   1.08533
trainer/Q Targets Max                  21.3448
trainer/Q Targets Min                  14.1545
trainer/Log Pis Mean                    1.27167
trainer/Log Pis Std                     1.79853
trainer/Log Pis Max                     5.67395
trainer/Log Pis Min                    -3.09714
trainer/policy/mean Mean                0.0118483
trainer/policy/mean Std                 0.609214
trainer/policy/mean Max                 0.997828
trainer/policy/mean Min                -0.983183
trainer/policy/normal/std Mean          0.621
trainer/policy/normal/std Std           0.408884
trainer/policy/normal/std Max           1.68766
trainer/policy/normal/std Min           0.0731985
trainer/policy/normal/log_std Mean     -0.750979
trainer/policy/normal/log_std Std       0.81278
trainer/policy/normal/log_std Max       0.523342
trainer/policy/normal/log_std Min      -2.61458
trainer/Alpha                           0.0109233
trainer/Alpha Loss                     -7.80664
expl/num steps total                18000
expl/num paths total                   37
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                       0.0480865
expl/Actions Std                        0.534009
expl/Actions Max                        0.999998
expl/Actions Min                       -0.99992
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                85000
eval/num paths total                   85
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                       0.0370099
eval/Actions Std                        0.591974
eval/Actions Max                        0.997935
eval/Actions Min                       -0.981217
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00332122
time/evaluation sampling (s)            0.961973
time/exploration sampling (s)           0.298722
time/logging (s)                        0.00925834
time/sac training (s)                  11.1876
time/saving (s)                         0.00342786
time/training (s)                       1.995e-05
time/epoch (s)                         12.4643
time/total (s)                        219.463
Epoch                                  16
----------------------------------  --------------
2022-09-09 19:56:42.105749 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 17 finished
----------------------------------  --------------
epoch                                  17
replay_buffer/size                  19000
trainer/num train calls             18000
trainer/QF1 Loss                        0.0241728
trainer/QF2 Loss                        0.0287859
trainer/Policy Loss                   -19.43
trainer/Q1 Predictions Mean            19.3768
trainer/Q1 Predictions Std              0.894679
trainer/Q1 Predictions Max             20.6704
trainer/Q1 Predictions Min             14.2304
trainer/Q2 Predictions Mean            19.3957
trainer/Q2 Predictions Std              0.889462
trainer/Q2 Predictions Max             20.6365
trainer/Q2 Predictions Min             14.3878
trainer/Q Targets Mean                 19.3253
trainer/Q Targets Std                   0.832458
trainer/Q Targets Max                  20.5316
trainer/Q Targets Min                  14.2755
trainer/Log Pis Mean                    1.81794
trainer/Log Pis Std                     2.09409
trainer/Log Pis Max                     6.96579
trainer/Log Pis Min                    -3.35048
trainer/policy/mean Mean                0.0741665
trainer/policy/mean Std                 0.638033
trainer/policy/mean Max                 0.995089
trainer/policy/mean Min                -0.99173
trainer/policy/normal/std Mean          0.601294
trainer/policy/normal/std Std           0.405744
trainer/policy/normal/std Max           1.90067
trainer/policy/normal/std Min           0.0577304
trainer/policy/normal/log_std Mean     -0.796636
trainer/policy/normal/log_std Std       0.834363
trainer/policy/normal/log_std Max       0.642206
trainer/policy/normal/log_std Min      -2.85197
trainer/Alpha                           0.00881905
trainer/Alpha Loss                     -5.59215
expl/num steps total                19000
expl/num paths total                   38
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                       0.103859
expl/Actions Std                        0.584318
expl/Actions Max                        0.999188
expl/Actions Min                       -0.999737
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                90000
eval/num paths total                   90
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                       0.0649661
eval/Actions Std                        0.677615
eval/Actions Max                        0.979333
eval/Actions Min                       -0.955629
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.0032839
time/evaluation sampling (s)            0.938331
time/exploration sampling (s)           0.292945
time/logging (s)                        0.0100827
time/sac training (s)                  11.0605
time/saving (s)                         0.00483176
time/training (s)                       2.676e-05
time/epoch (s)                         12.31
time/total (s)                        232.011
Epoch                                  17
----------------------------------  --------------
2022-09-09 19:56:54.880264 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 18 finished
----------------------------------  --------------
epoch                                  18
replay_buffer/size                  20000
trainer/num train calls             19000
trainer/QF1 Loss                        0.0217589
trainer/QF2 Loss                        0.025545
trainer/Policy Loss                   -18.7045
trainer/Q1 Predictions Mean            18.6512
trainer/Q1 Predictions Std              0.784681
trainer/Q1 Predictions Max             19.8033
trainer/Q1 Predictions Min             14.3665
trainer/Q2 Predictions Mean            18.6564
trainer/Q2 Predictions Std              0.794743
trainer/Q2 Predictions Max             19.8578
trainer/Q2 Predictions Min             14.1389
trainer/Q Targets Mean                 18.6471
trainer/Q Targets Std                   0.735735
trainer/Q Targets Max                  19.8758
trainer/Q Targets Min                  14.9018
trainer/Log Pis Mean                    2.22743
trainer/Log Pis Std                     2.15081
trainer/Log Pis Max                     8.12183
trainer/Log Pis Min                    -3.52429
trainer/policy/mean Mean                0.0192877
trainer/policy/mean Std                 0.705829
trainer/policy/mean Max                 0.997642
trainer/policy/mean Min                -0.99101
trainer/policy/normal/std Mean          0.542581
trainer/policy/normal/std Std           0.382566
trainer/policy/normal/std Max           1.62625
trainer/policy/normal/std Min           0.0527927
trainer/policy/normal/log_std Mean     -0.92234
trainer/policy/normal/log_std Std       0.864961
trainer/policy/normal/log_std Max       0.486276
trainer/policy/normal/log_std Min      -2.94138
trainer/Alpha                           0.00753423
trainer/Alpha Loss                     -3.77658
expl/num steps total                20000
expl/num paths total                   39
expl/path length Mean                1000
expl/path length Std                    0
expl/path length Max                 1000
expl/path length Min                 1000
expl/Rewards Mean                       0
expl/Rewards Std                        0
expl/Rewards Max                        0
expl/Rewards Min                        0
expl/Returns Mean                       0
expl/Returns Std                        0
expl/Returns Max                        0
expl/Returns Min                        0
expl/Actions Mean                       0.2478
expl/Actions Std                        0.642928
expl/Actions Max                        0.999371
expl/Actions Min                       -0.999268
expl/Num Paths                          1
expl/Average Returns                    0
eval/num steps total                95000
eval/num paths total                   95
eval/path length Mean                1000
eval/path length Std                    0
eval/path length Max                 1000
eval/path length Min                 1000
eval/Rewards Mean                       0
eval/Rewards Std                        0
eval/Rewards Max                        0
eval/Rewards Min                        0
eval/Returns Mean                       0
eval/Returns Std                        0
eval/Returns Max                        0
eval/Returns Min                        0
eval/Actions Mean                      -0.0184726
eval/Actions Std                        0.73843
eval/Actions Max                        0.985591
eval/Actions Min                       -0.967842
eval/Num Paths                          5
eval/Average Returns                    0
time/data storing (s)                   0.00506431
time/evaluation sampling (s)            0.933183
time/exploration sampling (s)           0.314985
time/logging (s)                        0.00938986
time/sac training (s)                  11.2553
time/saving (s)                         0.00441537
time/training (s)                       2.811e-05
time/epoch (s)                         12.5224
time/total (s)                        244.775
Epoch                                  18
----------------------------------  --------------
2022-09-09 19:57:07.771834 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 19 finished
----------------------------------  ---------------
epoch                                   19
replay_buffer/size                   21000
trainer/num train calls              20000
trainer/QF1 Loss                         0.0172835
trainer/QF2 Loss                         0.0199774
trainer/Policy Loss                    -18.033
trainer/Q1 Predictions Mean             17.9543
trainer/Q1 Predictions Std               0.978273
trainer/Q1 Predictions Max              19.1604
trainer/Q1 Predictions Min              13.4028
trainer/Q2 Predictions Mean             17.9522
trainer/Q2 Predictions Std               0.985795
trainer/Q2 Predictions Max              19.2015
trainer/Q2 Predictions Min              13.4521
trainer/Q Targets Mean                  17.9374
trainer/Q Targets Std                    0.90686
trainer/Q Targets Max                   19.0976
trainer/Q Targets Min                   13.7838
trainer/Log Pis Mean                     2.92902
trainer/Log Pis Std                      2.05179
trainer/Log Pis Max                      8.15073
trainer/Log Pis Min                     -2.65443
trainer/policy/mean Mean                 0.037366
trainer/policy/mean Std                  0.695772
trainer/policy/mean Max                  0.998567
trainer/policy/mean Min                 -0.991498
trainer/policy/normal/std Mean           0.541293
trainer/policy/normal/std Std            0.397319
trainer/policy/normal/std Max            1.93984
trainer/policy/normal/std Min            0.0404703
trainer/policy/normal/log_std Mean      -0.95346
trainer/policy/normal/log_std Std        0.924078
trainer/policy/normal/log_std Max        0.662605
trainer/policy/normal/log_std Min       -3.20719
trainer/Alpha                            0.00676606
trainer/Alpha Loss                      -0.354614
expl/num steps total                 21000
expl/num paths total                    40
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.14334
expl/Actions Std                         0.481877
expl/Actions Max                         0.999195
expl/Actions Min                        -0.996498
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                100000
eval/num paths total                   100
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0381539
eval/Actions Std                         0.575798
eval/Actions Max                         0.991383
eval/Actions Min                        -0.97103
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00334669
time/evaluation sampling (s)             0.933707
time/exploration sampling (s)            0.314769
time/logging (s)                         0.00921378
time/sac training (s)                   11.3595
time/saving (s)                          0.00479841
time/training (s)                        2.402e-05
time/epoch (s)                          12.6254
time/total (s)                         257.657
Epoch                                   19
----------------------------------  ---------------
2022-09-09 19:57:20.402981 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 20 finished
----------------------------------  ---------------
epoch                                   20
replay_buffer/size                   22000
trainer/num train calls              21000
trainer/QF1 Loss                         0.0152125
trainer/QF2 Loss                         0.0156727
trainer/Policy Loss                    -17.632
trainer/Q1 Predictions Mean             17.5819
trainer/Q1 Predictions Std               0.666214
trainer/Q1 Predictions Max              18.5055
trainer/Q1 Predictions Min              13.7799
trainer/Q2 Predictions Mean             17.5869
trainer/Q2 Predictions Std               0.675391
trainer/Q2 Predictions Max              18.5292
trainer/Q2 Predictions Min              13.6589
trainer/Q Targets Mean                  17.5605
trainer/Q Targets Std                    0.645498
trainer/Q Targets Max                   18.4331
trainer/Q Targets Min                   13.932
trainer/Log Pis Mean                     3.16196
trainer/Log Pis Std                      2.13317
trainer/Log Pis Max                      8.24122
trainer/Log Pis Min                     -2.90607
trainer/policy/mean Mean                -0.0705771
trainer/policy/mean Std                  0.741586
trainer/policy/mean Max                  0.998351
trainer/policy/mean Min                 -0.986711
trainer/policy/normal/std Mean           0.528761
trainer/policy/normal/std Std            0.357754
trainer/policy/normal/std Max            1.80828
trainer/policy/normal/std Min            0.0451612
trainer/policy/normal/log_std Mean      -0.894419
trainer/policy/normal/log_std Std        0.793277
trainer/policy/normal/log_std Max        0.592374
trainer/policy/normal/log_std Min       -3.09752
trainer/Alpha                            0.00691834
trainer/Alpha Loss                       0.805533
expl/num steps total                 22000
expl/num paths total                    41
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.178863
expl/Actions Std                         0.847999
expl/Actions Max                         0.999383
expl/Actions Min                        -0.997315
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                105000
eval/num paths total                   105
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0739069
eval/Actions Std                         0.593243
eval/Actions Max                         0.99339
eval/Actions Min                        -0.98156
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00493471
time/evaluation sampling (s)             0.937265
time/exploration sampling (s)            0.30474
time/logging (s)                         0.0107773
time/sac training (s)                   11.1217
time/saving (s)                          0.00337265
time/training (s)                        2.092e-05
time/epoch (s)                          12.3828
time/total (s)                         270.28
Epoch                                   20
----------------------------------  ---------------
2022-09-09 19:57:33.469678 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 21 finished
----------------------------------  ---------------
epoch                                   21
replay_buffer/size                   23000
trainer/num train calls              22000
trainer/QF1 Loss                         0.0157756
trainer/QF2 Loss                         0.0146553
trainer/Policy Loss                    -17.0786
trainer/Q1 Predictions Mean             17.0425
trainer/Q1 Predictions Std               0.686392
trainer/Q1 Predictions Max              17.8182
trainer/Q1 Predictions Min              13.4829
trainer/Q2 Predictions Mean             17.0215
trainer/Q2 Predictions Std               0.682332
trainer/Q2 Predictions Max              17.8283
trainer/Q2 Predictions Min              13.5778
trainer/Q Targets Mean                  16.9916
trainer/Q Targets Std                    0.633284
trainer/Q Targets Max                   17.7065
trainer/Q Targets Min                   14.0104
trainer/Log Pis Mean                     3.3047
trainer/Log Pis Std                      2.09199
trainer/Log Pis Max                      8.21096
trainer/Log Pis Min                     -4.95219
trainer/policy/mean Mean                -0.324681
trainer/policy/mean Std                  0.662806
trainer/policy/mean Max                  0.994051
trainer/policy/mean Min                 -0.989451
trainer/policy/normal/std Mean           0.489129
trainer/policy/normal/std Std            0.40695
trainer/policy/normal/std Max            1.88918
trainer/policy/normal/std Min            0.0333479
trainer/policy/normal/log_std Mean      -1.10145
trainer/policy/normal/log_std Std        0.961847
trainer/policy/normal/log_std Max        0.63614
trainer/policy/normal/log_std Min       -3.40076
trainer/Alpha                            0.00620317
trainer/Alpha Loss                       1.54867
expl/num steps total                 23000
expl/num paths total                    42
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.180425
expl/Actions Std                         0.768789
expl/Actions Max                         0.989145
expl/Actions Min                        -0.999141
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                110000
eval/num paths total                   110
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.151086
eval/Actions Std                         0.409669
eval/Actions Max                         0.989467
eval/Actions Min                        -0.982051
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00484731
time/evaluation sampling (s)             0.928231
time/exploration sampling (s)            0.285543
time/logging (s)                         0.00944323
time/sac training (s)                   11.5368
time/saving (s)                          0.00331517
time/training (s)                        2.049e-05
time/epoch (s)                          12.7682
time/total (s)                         283.334
Epoch                                   21
----------------------------------  ---------------
2022-09-09 19:57:46.491681 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 22 finished
----------------------------------  ---------------
epoch                                   22
replay_buffer/size                   24000
trainer/num train calls              23000
trainer/QF1 Loss                         0.0345577
trainer/QF2 Loss                         0.019838
trainer/Policy Loss                    -16.4719
trainer/Q1 Predictions Mean             16.4141
trainer/Q1 Predictions Std               0.708473
trainer/Q1 Predictions Max              17.3569
trainer/Q1 Predictions Min              13.2162
trainer/Q2 Predictions Mean             16.392
trainer/Q2 Predictions Std               0.683158
trainer/Q2 Predictions Max              17.2265
trainer/Q2 Predictions Min              13.1622
trainer/Q Targets Mean                  16.4618
trainer/Q Targets Std                    0.642854
trainer/Q Targets Max                   17.3287
trainer/Q Targets Min                   13.0222
trainer/Log Pis Mean                     3.21229
trainer/Log Pis Std                      2.18651
trainer/Log Pis Max                      8.25897
trainer/Log Pis Min                     -3.71012
trainer/policy/mean Mean                -0.308251
trainer/policy/mean Std                  0.636474
trainer/policy/mean Max                  0.99747
trainer/policy/mean Min                 -0.98806
trainer/policy/normal/std Mean           0.46944
trainer/policy/normal/std Std            0.356824
trainer/policy/normal/std Max            1.9006
trainer/policy/normal/std Min            0.034476
trainer/policy/normal/log_std Mean      -1.098
trainer/policy/normal/log_std Std        0.920491
trainer/policy/normal/log_std Max        0.64217
trainer/policy/normal/log_std Min       -3.36749
trainer/Alpha                            0.00711276
trainer/Alpha Loss                       1.04997
expl/num steps total                 24000
expl/num paths total                    43
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.197674
expl/Actions Std                         0.384829
expl/Actions Max                         0.989093
expl/Actions Min                        -0.995215
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                115000
eval/num paths total                   115
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.198946
eval/Actions Std                         0.34404
eval/Actions Max                         0.991364
eval/Actions Min                        -0.987379
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00490764
time/evaluation sampling (s)             0.936438
time/exploration sampling (s)            0.312741
time/logging (s)                         0.00890414
time/sac training (s)                   11.4701
time/saving (s)                          0.00368903
time/training (s)                        4.491e-05
time/epoch (s)                          12.7368
time/total (s)                         296.345
Epoch                                   22
----------------------------------  ---------------
2022-09-09 19:57:59.507406 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 23 finished
----------------------------------  ---------------
epoch                                   23
replay_buffer/size                   25000
trainer/num train calls              24000
trainer/QF1 Loss                         0.0123647
trainer/QF2 Loss                         0.0132562
trainer/Policy Loss                    -16.0601
trainer/Q1 Predictions Mean             15.9985
trainer/Q1 Predictions Std               0.685131
trainer/Q1 Predictions Max              16.8891
trainer/Q1 Predictions Min              12.0871
trainer/Q2 Predictions Mean             15.9846
trainer/Q2 Predictions Std               0.679548
trainer/Q2 Predictions Max              16.8699
trainer/Q2 Predictions Min              12.1733
trainer/Q Targets Mean                  16.0067
trainer/Q Targets Std                    0.65163
trainer/Q Targets Max                   16.8141
trainer/Q Targets Min                   12.1488
trainer/Log Pis Mean                     2.92344
trainer/Log Pis Std                      1.72517
trainer/Log Pis Max                      7.97102
trainer/Log Pis Min                     -2.73336
trainer/policy/mean Mean                -0.162406
trainer/policy/mean Std                  0.666716
trainer/policy/mean Max                  0.996891
trainer/policy/mean Min                 -0.987119
trainer/policy/normal/std Mean           0.466629
trainer/policy/normal/std Std            0.379623
trainer/policy/normal/std Max            1.70858
trainer/policy/normal/std Min            0.0311882
trainer/policy/normal/log_std Mean      -1.13833
trainer/policy/normal/log_std Std        0.94751
trainer/policy/normal/log_std Max        0.535661
trainer/policy/normal/log_std Min       -3.46772
trainer/Alpha                            0.00744469
trainer/Alpha Loss                      -0.375147
expl/num steps total                 25000
expl/num paths total                    44
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.109552
expl/Actions Std                         0.400828
expl/Actions Max                         0.99843
expl/Actions Min                        -0.99082
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                120000
eval/num paths total                   120
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0262283
eval/Actions Std                         0.51104
eval/Actions Max                         0.993531
eval/Actions Min                        -0.972794
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00438583
time/evaluation sampling (s)             0.928444
time/exploration sampling (s)            0.315317
time/logging (s)                         0.0114919
time/sac training (s)                   11.4557
time/saving (s)                          0.00544863
time/training (s)                        5.793e-05
time/epoch (s)                          12.7209
time/total (s)                         309.351
Epoch                                   23
----------------------------------  ---------------
2022-09-09 19:58:13.345108 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 24 finished
----------------------------------  ---------------
epoch                                   24
replay_buffer/size                   26000
trainer/num train calls              25000
trainer/QF1 Loss                         0.0111558
trainer/QF2 Loss                         0.00941079
trainer/Policy Loss                    -15.5762
trainer/Q1 Predictions Mean             15.4971
trainer/Q1 Predictions Std               0.680915
trainer/Q1 Predictions Max              16.469
trainer/Q1 Predictions Min              12.0199
trainer/Q2 Predictions Mean             15.5061
trainer/Q2 Predictions Std               0.679724
trainer/Q2 Predictions Max              16.5414
trainer/Q2 Predictions Min              12.275
trainer/Q Targets Mean                  15.5251
trainer/Q Targets Std                    0.638515
trainer/Q Targets Max                   16.4454
trainer/Q Targets Min                   12.638
trainer/Log Pis Mean                     2.9159
trainer/Log Pis Std                      1.89895
trainer/Log Pis Max                      7.49312
trainer/Log Pis Min                     -4.25379
trainer/policy/mean Mean                -0.281748
trainer/policy/mean Std                  0.6199
trainer/policy/mean Max                  0.995495
trainer/policy/mean Min                 -0.990047
trainer/policy/normal/std Mean           0.42214
trainer/policy/normal/std Std            0.282291
trainer/policy/normal/std Max            1.08844
trainer/policy/normal/std Min            0.0313078
trainer/policy/normal/log_std Mean      -1.19288
trainer/policy/normal/log_std Std        0.923435
trainer/policy/normal/log_std Max        0.0847497
trainer/policy/normal/log_std Min       -3.46389
trainer/Alpha                            0.0075024
trainer/Alpha Loss                      -0.411458
expl/num steps total                 26000
expl/num paths total                    45
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.127766
expl/Actions Std                         0.49938
expl/Actions Max                         0.989979
expl/Actions Min                        -0.994971
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                125000
eval/num paths total                   125
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.115174
eval/Actions Std                         0.516776
eval/Actions Max                         0.992988
eval/Actions Min                        -0.986064
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00488644
time/evaluation sampling (s)             0.99354
time/exploration sampling (s)            0.337563
time/logging (s)                         0.00902594
time/sac training (s)                   12.1519
time/saving (s)                          0.00362225
time/training (s)                        1.976e-05
time/epoch (s)                          13.5006
time/total (s)                         323.173
Epoch                                   24
----------------------------------  ---------------
2022-09-09 19:58:26.498688 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 25 finished
----------------------------------  ---------------
epoch                                   25
replay_buffer/size                   27000
trainer/num train calls              26000
trainer/QF1 Loss                         0.014971
trainer/QF2 Loss                         0.0147157
trainer/Policy Loss                    -14.9608
trainer/Q1 Predictions Mean             14.8988
trainer/Q1 Predictions Std               0.828487
trainer/Q1 Predictions Max              16.2653
trainer/Q1 Predictions Min              11.2031
trainer/Q2 Predictions Mean             14.9021
trainer/Q2 Predictions Std               0.839712
trainer/Q2 Predictions Max              16.315
trainer/Q2 Predictions Min              11.2075
trainer/Q Targets Mean                  14.9336
trainer/Q Targets Std                    0.78383
trainer/Q Targets Max                   16.158
trainer/Q Targets Min                   11.6127
trainer/Log Pis Mean                     2.49275
trainer/Log Pis Std                      2.53741
trainer/Log Pis Max                      8.67293
trainer/Log Pis Min                     -4.06463
trainer/policy/mean Mean                -0.282594
trainer/policy/mean Std                  0.547973
trainer/policy/mean Max                  0.996967
trainer/policy/mean Min                 -0.995525
trainer/policy/normal/std Mean           0.401667
trainer/policy/normal/std Std            0.284842
trainer/policy/normal/std Max            1.2595
trainer/policy/normal/std Min            0.0303943
trainer/policy/normal/log_std Mean      -1.2511
trainer/policy/normal/log_std Std        0.922177
trainer/policy/normal/log_std Max        0.230714
trainer/policy/normal/log_std Min       -3.4935
trainer/Alpha                            0.00683937
trainer/Alpha Loss                      -2.5287
expl/num steps total                 27000
expl/num paths total                    46
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.219413
expl/Actions Std                         0.593114
expl/Actions Max                         0.999972
expl/Actions Min                        -0.998714
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                130000
eval/num paths total                   130
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.289124
eval/Actions Std                         0.460206
eval/Actions Max                         0.987386
eval/Actions Min                        -0.983447
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00518985
time/evaluation sampling (s)             0.941681
time/exploration sampling (s)            0.300663
time/logging (s)                         0.00936667
time/sac training (s)                   11.5978
time/saving (s)                          0.00333456
time/training (s)                        1.967e-05
time/epoch (s)                          12.8581
time/total (s)                         336.315
Epoch                                   25
----------------------------------  ---------------
2022-09-09 19:58:39.224529 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 26 finished
----------------------------------  ---------------
epoch                                   26
replay_buffer/size                   28000
trainer/num train calls              27000
trainer/QF1 Loss                         0.0197579
trainer/QF2 Loss                         0.0187255
trainer/Policy Loss                    -14.6579
trainer/Q1 Predictions Mean             14.5847
trainer/Q1 Predictions Std               0.741839
trainer/Q1 Predictions Max              16.0251
trainer/Q1 Predictions Min              11.2983
trainer/Q2 Predictions Mean             14.5809
trainer/Q2 Predictions Std               0.740033
trainer/Q2 Predictions Max              16.0266
trainer/Q2 Predictions Min              11.1625
trainer/Q Targets Mean                  14.6126
trainer/Q Targets Std                    0.677369
trainer/Q Targets Max                   15.9175
trainer/Q Targets Min                   11.5193
trainer/Log Pis Mean                     3.15021
trainer/Log Pis Std                      2.3752
trainer/Log Pis Max                      9.4465
trainer/Log Pis Min                     -5.4095
trainer/policy/mean Mean                -0.34309
trainer/policy/mean Std                  0.614222
trainer/policy/mean Max                  0.999102
trainer/policy/mean Min                 -0.993572
trainer/policy/normal/std Mean           0.466959
trainer/policy/normal/std Std            0.293248
trainer/policy/normal/std Max            1.14427
trainer/policy/normal/std Min            0.0336984
trainer/policy/normal/log_std Mean      -1.09253
trainer/policy/normal/log_std Std        0.943424
trainer/policy/normal/log_std Max        0.134767
trainer/policy/normal/log_std Min       -3.39031
trainer/Alpha                            0.00705226
trainer/Alpha Loss                       0.744187
expl/num steps total                 28000
expl/num paths total                    47
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.211661
expl/Actions Std                         0.665034
expl/Actions Max                         0.999985
expl/Actions Min                        -0.999308
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                135000
eval/num paths total                   135
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.244205
eval/Actions Std                         0.587366
eval/Actions Max                         0.999504
eval/Actions Min                        -0.993555
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00333838
time/evaluation sampling (s)             0.934469
time/exploration sampling (s)            0.319651
time/logging (s)                         0.00989948
time/sac training (s)                   11.1835
time/saving (s)                          0.00340535
time/training (s)                        2.108e-05
time/epoch (s)                          12.4542
time/total (s)                         349.032
Epoch                                   26
----------------------------------  ---------------
2022-09-09 19:58:51.970909 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 27 finished
----------------------------------  ---------------
epoch                                   27
replay_buffer/size                   29000
trainer/num train calls              28000
trainer/QF1 Loss                         0.0116807
trainer/QF2 Loss                         0.0133805
trainer/Policy Loss                    -14.3102
trainer/Q1 Predictions Mean             14.228
trainer/Q1 Predictions Std               0.727626
trainer/Q1 Predictions Max              15.767
trainer/Q1 Predictions Min              11.382
trainer/Q2 Predictions Mean             14.217
trainer/Q2 Predictions Std               0.740974
trainer/Q2 Predictions Max              15.7991
trainer/Q2 Predictions Min              11.2206
trainer/Q Targets Mean                  14.2267
trainer/Q Targets Std                    0.714493
trainer/Q Targets Max                   15.7375
trainer/Q Targets Min                   11.4316
trainer/Log Pis Mean                     3.21034
trainer/Log Pis Std                      2.11671
trainer/Log Pis Max                      9.56035
trainer/Log Pis Min                     -4.20893
trainer/policy/mean Mean                -0.259564
trainer/policy/mean Std                  0.647836
trainer/policy/mean Max                  0.996824
trainer/policy/mean Min                 -0.995522
trainer/policy/normal/std Mean           0.437177
trainer/policy/normal/std Std            0.289992
trainer/policy/normal/std Max            1.81493
trainer/policy/normal/std Min            0.0250409
trainer/policy/normal/log_std Mean      -1.19116
trainer/policy/normal/log_std Std        0.996549
trainer/policy/normal/log_std Max        0.596047
trainer/policy/normal/log_std Min       -3.68724
trainer/Alpha                            0.00633478
trainer/Alpha Loss                       1.06467
expl/num steps total                 29000
expl/num paths total                    48
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.204844
expl/Actions Std                         0.602613
expl/Actions Max                         0.996726
expl/Actions Min                        -0.968897
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                140000
eval/num paths total                   140
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0343758
eval/Actions Std                         0.624947
eval/Actions Max                         0.993796
eval/Actions Min                        -0.990332
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00501512
time/evaluation sampling (s)             0.941423
time/exploration sampling (s)            0.310658
time/logging (s)                         0.00957311
time/sac training (s)                   11.2152
time/saving (s)                          0.00378703
time/training (s)                        2.623e-05
time/epoch (s)                          12.4856
time/total (s)                         361.768
Epoch                                   27
----------------------------------  ---------------
2022-09-09 19:59:04.721810 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 28 finished
----------------------------------  ---------------
epoch                                   28
replay_buffer/size                   30000
trainer/num train calls              29000
trainer/QF1 Loss                         0.0143304
trainer/QF2 Loss                         0.0115276
trainer/Policy Loss                    -13.8739
trainer/Q1 Predictions Mean             13.794
trainer/Q1 Predictions Std               0.826693
trainer/Q1 Predictions Max              15.6643
trainer/Q1 Predictions Min               9.72174
trainer/Q2 Predictions Mean             13.7963
trainer/Q2 Predictions Std               0.816175
trainer/Q2 Predictions Max              15.646
trainer/Q2 Predictions Min              10.1769
trainer/Q Targets Mean                  13.787
trainer/Q Targets Std                    0.810605
trainer/Q Targets Max                   15.4447
trainer/Q Targets Min                   10.3156
trainer/Log Pis Mean                     2.81286
trainer/Log Pis Std                      2.21032
trainer/Log Pis Max                     12.3736
trainer/Log Pis Min                     -4.94476
trainer/policy/mean Mean                -0.0499176
trainer/policy/mean Std                  0.720646
trainer/policy/mean Max                  0.999665
trainer/policy/mean Min                 -0.989916
trainer/policy/normal/std Mean           0.558474
trainer/policy/normal/std Std            0.313703
trainer/policy/normal/std Max            2.29989
trainer/policy/normal/std Min            0.0296362
trainer/policy/normal/log_std Mean      -0.85019
trainer/policy/normal/log_std Std        0.879119
trainer/policy/normal/log_std Max        0.832862
trainer/policy/normal/log_std Min       -3.51876
trainer/Alpha                            0.00673888
trainer/Alpha Loss                      -0.935683
expl/num steps total                 30000
expl/num paths total                    49
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.430414
expl/Actions Std                         0.471543
expl/Actions Max                         0.999995
expl/Actions Min                        -0.994323
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                145000
eval/num paths total                   145
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0498518
eval/Actions Std                         0.583041
eval/Actions Max                         0.990835
eval/Actions Min                        -0.946306
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00333092
time/evaluation sampling (s)             0.939016
time/exploration sampling (s)            0.304712
time/logging (s)                         0.0099566
time/sac training (s)                   11.2211
time/saving (s)                          0.00374799
time/training (s)                        2.008e-05
time/epoch (s)                          12.4818
time/total (s)                         374.51
Epoch                                   28
----------------------------------  ---------------
2022-09-09 19:59:17.341921 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 29 finished
----------------------------------  ---------------
epoch                                   29
replay_buffer/size                   31000
trainer/num train calls              30000
trainer/QF1 Loss                         0.354659
trainer/QF2 Loss                         0.371239
trainer/Policy Loss                    -13.5278
trainer/Q1 Predictions Mean             13.4388
trainer/Q1 Predictions Std               0.988992
trainer/Q1 Predictions Max              15.5751
trainer/Q1 Predictions Min               9.94743
trainer/Q2 Predictions Mean             13.4371
trainer/Q2 Predictions Std               0.985167
trainer/Q2 Predictions Max              15.5688
trainer/Q2 Predictions Min              10.2376
trainer/Q Targets Mean                  13.4301
trainer/Q Targets Std                    1.22005
trainer/Q Targets Max                   15.3588
trainer/Q Targets Min                    1
trainer/Log Pis Mean                     3.02624
trainer/Log Pis Std                      1.90336
trainer/Log Pis Max                      9.26089
trainer/Log Pis Min                     -3.62905
trainer/policy/mean Mean                -0.11505
trainer/policy/mean Std                  0.704512
trainer/policy/mean Max                  0.997766
trainer/policy/mean Min                 -0.997077
trainer/policy/normal/std Mean           0.454595
trainer/policy/normal/std Std            0.257346
trainer/policy/normal/std Max            1.13852
trainer/policy/normal/std Min            0.0357558
trainer/policy/normal/log_std Mean      -1.05344
trainer/policy/normal/log_std Std        0.852465
trainer/policy/normal/log_std Max        0.129726
trainer/policy/normal/log_std Min       -3.33104
trainer/Alpha                            0.00640476
trainer/Alpha Loss                       0.132517
expl/num steps total                 31000
expl/num paths total                    50
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.107749
expl/Actions Std                         0.531776
expl/Actions Max                         0.952323
expl/Actions Min                        -0.995672
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                150000
eval/num paths total                   150
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.118153
eval/Actions Std                         0.534308
eval/Actions Max                         0.969498
eval/Actions Min                        -0.985598
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00373349
time/evaluation sampling (s)             0.9478
time/exploration sampling (s)            0.324113
time/logging (s)                         0.00931343
time/sac training (s)                   11.0715
time/saving (s)                          0.00349735
time/training (s)                        1.954e-05
time/epoch (s)                          12.3599
time/total (s)                         387.12
Epoch                                   29
----------------------------------  ---------------
2022-09-09 19:59:30.518474 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 30 finished
----------------------------------  ---------------
epoch                                   30
replay_buffer/size                   32000
trainer/num train calls              31000
trainer/QF1 Loss                         0.0129232
trainer/QF2 Loss                         0.0111711
trainer/Policy Loss                    -13.4514
trainer/Q1 Predictions Mean             13.3595
trainer/Q1 Predictions Std               0.979228
trainer/Q1 Predictions Max              15.0446
trainer/Q1 Predictions Min               9.7791
trainer/Q2 Predictions Mean             13.3726
trainer/Q2 Predictions Std               0.976366
trainer/Q2 Predictions Max              15.0723
trainer/Q2 Predictions Min              10.2421
trainer/Q Targets Mean                  13.3868
trainer/Q Targets Std                    0.980467
trainer/Q Targets Max                   15.0111
trainer/Q Targets Min                    9.92177
trainer/Log Pis Mean                     2.95848
trainer/Log Pis Std                      2.13479
trainer/Log Pis Max                     10.0338
trainer/Log Pis Min                     -2.73238
trainer/policy/mean Mean                -0.186782
trainer/policy/mean Std                  0.676671
trainer/policy/mean Max                  0.99212
trainer/policy/mean Min                 -0.996792
trainer/policy/normal/std Mean           0.453296
trainer/policy/normal/std Std            0.271674
trainer/policy/normal/std Max            1.15422
trainer/policy/normal/std Min            0.0299571
trainer/policy/normal/log_std Mean      -1.07677
trainer/policy/normal/log_std Std        0.881001
trainer/policy/normal/log_std Max        0.143421
trainer/policy/normal/log_std Min       -3.50799
trainer/Alpha                            0.00683051
trainer/Alpha Loss                      -0.207036
expl/num steps total                 32000
expl/num paths total                    51
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0516348
expl/Actions Std                         0.431247
expl/Actions Max                         0.962716
expl/Actions Min                        -0.98415
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                155000
eval/num paths total                   155
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0545129
eval/Actions Std                         0.411259
eval/Actions Max                         0.990168
eval/Actions Min                        -0.994412
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00489086
time/evaluation sampling (s)             0.943749
time/exploration sampling (s)            0.311742
time/logging (s)                         0.0102469
time/sac training (s)                   11.5978
time/saving (s)                          0.00521441
time/training (s)                        7.811e-05
time/epoch (s)                          12.8737
time/total (s)                         400.286
Epoch                                   30
----------------------------------  ---------------
2022-09-09 19:59:43.328059 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 31 finished
----------------------------------  ---------------
epoch                                   31
replay_buffer/size                   33000
trainer/num train calls              32000
trainer/QF1 Loss                         0.00833016
trainer/QF2 Loss                         0.0105347
trainer/Policy Loss                    -13.2142
trainer/Q1 Predictions Mean             13.1493
trainer/Q1 Predictions Std               0.892213
trainer/Q1 Predictions Max              14.8129
trainer/Q1 Predictions Min              10.9687
trainer/Q2 Predictions Mean             13.1457
trainer/Q2 Predictions Std               0.897975
trainer/Q2 Predictions Max              14.9044
trainer/Q2 Predictions Min              10.9335
trainer/Q Targets Mean                  13.1321
trainer/Q Targets Std                    0.891847
trainer/Q Targets Max                   14.6513
trainer/Q Targets Min                   10.6903
trainer/Log Pis Mean                     3.02635
trainer/Log Pis Std                      2.43158
trainer/Log Pis Max                     11.3061
trainer/Log Pis Min                     -3.26577
trainer/policy/mean Mean                -0.183112
trainer/policy/mean Std                  0.634952
trainer/policy/mean Max                  0.996899
trainer/policy/mean Min                 -0.996945
trainer/policy/normal/std Mean           0.476106
trainer/policy/normal/std Std            0.37359
trainer/policy/normal/std Max            2.01241
trainer/policy/normal/std Min            0.0286068
trainer/policy/normal/log_std Mean      -1.13046
trainer/policy/normal/log_std Std        1.00029
trainer/policy/normal/log_std Max        0.699332
trainer/policy/normal/log_std Min       -3.55411
trainer/Alpha                            0.00660464
trainer/Alpha Loss                       0.132268
expl/num steps total                 33000
expl/num paths total                    52
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0719146
expl/Actions Std                         0.400913
expl/Actions Max                         0.971517
expl/Actions Min                        -0.972992
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                160000
eval/num paths total                   160
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.09469
eval/Actions Std                         0.314376
eval/Actions Max                         0.990273
eval/Actions Min                        -0.99555
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00509973
time/evaluation sampling (s)             0.955357
time/exploration sampling (s)            0.302955
time/logging (s)                         0.00971509
time/sac training (s)                   11.2683
time/saving (s)                          0.00350603
time/training (s)                        2.045e-05
time/epoch (s)                          12.545
time/total (s)                         413.085
Epoch                                   31
----------------------------------  ---------------
2022-09-09 19:59:56.024937 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 32 finished
----------------------------------  ---------------
epoch                                   32
replay_buffer/size                   34000
trainer/num train calls              33000
trainer/QF1 Loss                         0.00997512
trainer/QF2 Loss                         0.00836752
trainer/Policy Loss                    -13.0018
trainer/Q1 Predictions Mean             12.9277
trainer/Q1 Predictions Std               0.829294
trainer/Q1 Predictions Max              14.6253
trainer/Q1 Predictions Min              10.9384
trainer/Q2 Predictions Mean             12.903
trainer/Q2 Predictions Std               0.819481
trainer/Q2 Predictions Max              14.6257
trainer/Q2 Predictions Min              10.9104
trainer/Q Targets Mean                  12.926
trainer/Q Targets Std                    0.808078
trainer/Q Targets Max                   14.6014
trainer/Q Targets Min                   10.9715
trainer/Log Pis Mean                     3.40065
trainer/Log Pis Std                      2.19811
trainer/Log Pis Max                     10.5319
trainer/Log Pis Min                     -2.40572
trainer/policy/mean Mean                 0.0195391
trainer/policy/mean Std                  0.672144
trainer/policy/mean Max                  0.997867
trainer/policy/mean Min                 -0.995394
trainer/policy/normal/std Mean           0.375758
trainer/policy/normal/std Std            0.260367
trainer/policy/normal/std Max            1.6021
trainer/policy/normal/std Min            0.028057
trainer/policy/normal/log_std Mean      -1.28714
trainer/policy/normal/log_std Std        0.884462
trainer/policy/normal/log_std Max        0.471318
trainer/policy/normal/log_std Min       -3.57352
trainer/Alpha                            0.00685192
trainer/Alpha Loss                       1.99652
expl/num steps total                 34000
expl/num paths total                    53
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.139681
expl/Actions Std                         0.435089
expl/Actions Max                         0.977098
expl/Actions Min                        -0.988106
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                165000
eval/num paths total                   165
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.16625
eval/Actions Std                         0.398134
eval/Actions Max                         0.995888
eval/Actions Min                        -0.996239
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00328561
time/evaluation sampling (s)             0.925788
time/exploration sampling (s)            0.296893
time/logging (s)                         0.00947266
time/sac training (s)                   11.1894
time/saving (s)                          0.00459914
time/training (s)                        2.696e-05
time/epoch (s)                          12.4295
time/total (s)                         425.773
Epoch                                   32
----------------------------------  ---------------
2022-09-09 20:00:08.847140 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 33 finished
----------------------------------  ---------------
epoch                                   33
replay_buffer/size                   35000
trainer/num train calls              34000
trainer/QF1 Loss                         0.00661342
trainer/QF2 Loss                         0.00642133
trainer/Policy Loss                    -12.8467
trainer/Q1 Predictions Mean             12.7286
trainer/Q1 Predictions Std               0.694275
trainer/Q1 Predictions Max              14.3693
trainer/Q1 Predictions Min               9.63001
trainer/Q2 Predictions Mean             12.7344
trainer/Q2 Predictions Std               0.693846
trainer/Q2 Predictions Max              14.3466
trainer/Q2 Predictions Min               9.70287
trainer/Q Targets Mean                  12.7469
trainer/Q Targets Std                    0.677897
trainer/Q Targets Max                   14.3449
trainer/Q Targets Min                    9.95103
trainer/Log Pis Mean                     3.24589
trainer/Log Pis Std                      2.08612
trainer/Log Pis Max                     10.0118
trainer/Log Pis Min                     -4.07967
trainer/policy/mean Mean                -0.0879705
trainer/policy/mean Std                  0.684961
trainer/policy/mean Max                  0.994273
trainer/policy/mean Min                 -0.995493
trainer/policy/normal/std Mean           0.414335
trainer/policy/normal/std Std            0.273205
trainer/policy/normal/std Max            1.64965
trainer/policy/normal/std Min            0.0229265
trainer/policy/normal/log_std Mean      -1.16272
trainer/policy/normal/log_std Std        0.849481
trainer/policy/normal/log_std Max        0.500562
trainer/policy/normal/log_std Min       -3.77546
trainer/Alpha                            0.00719358
trainer/Alpha Loss                       1.21334
expl/num steps total                 35000
expl/num paths total                    54
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0865982
expl/Actions Std                         0.516563
expl/Actions Max                         0.993677
expl/Actions Min                        -0.997618
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                170000
eval/num paths total                   170
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0472851
eval/Actions Std                         0.433602
eval/Actions Max                         0.972111
eval/Actions Min                        -0.972978
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00325188
time/evaluation sampling (s)             0.916816
time/exploration sampling (s)            0.298326
time/logging (s)                         0.00912519
time/sac training (s)                   11.3019
time/saving (s)                          0.00327262
time/training (s)                        1.8981e-05
time/epoch (s)                          12.5327
time/total (s)                         438.584
Epoch                                   33
----------------------------------  ---------------
2022-09-09 20:00:21.462206 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 34 finished
----------------------------------  ---------------
epoch                                   34
replay_buffer/size                   36000
trainer/num train calls              35000
trainer/QF1 Loss                         0.00562607
trainer/QF2 Loss                         0.00483823
trainer/Policy Loss                    -12.7189
trainer/Q1 Predictions Mean             12.6424
trainer/Q1 Predictions Std               0.571436
trainer/Q1 Predictions Max              14.4324
trainer/Q1 Predictions Min              10.4235
trainer/Q2 Predictions Mean             12.6634
trainer/Q2 Predictions Std               0.571075
trainer/Q2 Predictions Max              14.3366
trainer/Q2 Predictions Min              10.3702
trainer/Q Targets Mean                  12.6647
trainer/Q Targets Std                    0.572484
trainer/Q Targets Max                   14.2881
trainer/Q Targets Min                   10.4956
trainer/Log Pis Mean                     3.07366
trainer/Log Pis Std                      2.18144
trainer/Log Pis Max                      9.72871
trainer/Log Pis Min                     -4.37925
trainer/policy/mean Mean                -0.0507178
trainer/policy/mean Std                  0.675885
trainer/policy/mean Max                  0.991111
trainer/policy/mean Min                 -0.996401
trainer/policy/normal/std Mean           0.384835
trainer/policy/normal/std Std            0.239686
trainer/policy/normal/std Max            1.66669
trainer/policy/normal/std Min            0.0233896
trainer/policy/normal/log_std Mean      -1.22719
trainer/policy/normal/log_std Std        0.847262
trainer/policy/normal/log_std Max        0.510842
trainer/policy/normal/log_std Min       -3.75546
trainer/Alpha                            0.00711264
trainer/Alpha Loss                       0.364291
expl/num steps total                 36000
expl/num paths total                    55
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.047408
expl/Actions Std                         0.404079
expl/Actions Max                         0.997635
expl/Actions Min                        -0.990703
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                175000
eval/num paths total                   175
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0591898
eval/Actions Std                         0.35967
eval/Actions Max                         0.991986
eval/Actions Min                        -0.995619
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0049698
time/evaluation sampling (s)             0.927396
time/exploration sampling (s)            0.308985
time/logging (s)                         0.00904252
time/sac training (s)                   11.0906
time/saving (s)                          0.00327905
time/training (s)                        1.93e-05
time/epoch (s)                          12.3443
time/total (s)                         451.19
Epoch                                   34
----------------------------------  ---------------
2022-09-09 20:00:34.217814 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 35 finished
----------------------------------  ---------------
epoch                                   35
replay_buffer/size                   37000
trainer/num train calls              36000
trainer/QF1 Loss                         0.00756169
trainer/QF2 Loss                         0.00914618
trainer/Policy Loss                    -12.5738
trainer/Q1 Predictions Mean             12.4533
trainer/Q1 Predictions Std               0.681994
trainer/Q1 Predictions Max              14.6895
trainer/Q1 Predictions Min              10.667
trainer/Q2 Predictions Mean             12.4504
trainer/Q2 Predictions Std               0.687153
trainer/Q2 Predictions Max              14.6346
trainer/Q2 Predictions Min              10.4067
trainer/Q Targets Mean                  12.4487
trainer/Q Targets Std                    0.657406
trainer/Q Targets Max                   14.5289
trainer/Q Targets Min                   10.8269
trainer/Log Pis Mean                     3.4008
trainer/Log Pis Std                      1.88489
trainer/Log Pis Max                      8.40456
trainer/Log Pis Min                     -2.80525
trainer/policy/mean Mean                 0.0735322
trainer/policy/mean Std                  0.736842
trainer/policy/mean Max                  0.994972
trainer/policy/mean Min                 -0.995471
trainer/policy/normal/std Mean           0.421085
trainer/policy/normal/std Std            0.217256
trainer/policy/normal/std Max            1.24569
trainer/policy/normal/std Min            0.0369291
trainer/policy/normal/log_std Mean      -1.08656
trainer/policy/normal/log_std Std        0.78467
trainer/policy/normal/log_std Max        0.219686
trainer/policy/normal/log_std Min       -3.29876
trainer/Alpha                            0.00854219
trainer/Alpha Loss                       1.90889
expl/num steps total                 37000
expl/num paths total                    56
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.00758538
expl/Actions Std                         0.432949
expl/Actions Max                         0.997286
expl/Actions Min                        -0.958627
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                180000
eval/num paths total                   180
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0041333
eval/Actions Std                         0.390196
eval/Actions Max                         0.98804
eval/Actions Min                        -0.995398
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00409177
time/evaluation sampling (s)             0.915803
time/exploration sampling (s)            0.318632
time/logging (s)                         0.00985593
time/sac training (s)                   11.2285
time/saving (s)                          0.00465576
time/training (s)                        2.936e-05
time/epoch (s)                          12.4815
time/total (s)                         463.936
Epoch                                   35
----------------------------------  ---------------
2022-09-09 20:00:46.923294 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 36 finished
----------------------------------  ---------------
epoch                                   36
replay_buffer/size                   38000
trainer/num train calls              37000
trainer/QF1 Loss                         0.00424598
trainer/QF2 Loss                         0.00542423
trainer/Policy Loss                    -12.5168
trainer/Q1 Predictions Mean             12.4005
trainer/Q1 Predictions Std               0.72219
trainer/Q1 Predictions Max              14.2012
trainer/Q1 Predictions Min              10.0857
trainer/Q2 Predictions Mean             12.4029
trainer/Q2 Predictions Std               0.722852
trainer/Q2 Predictions Max              14.2349
trainer/Q2 Predictions Min               9.96138
trainer/Q Targets Mean                  12.4084
trainer/Q Targets Std                    0.715713
trainer/Q Targets Max                   14.1107
trainer/Q Targets Min                   10.3366
trainer/Log Pis Mean                     3.01434
trainer/Log Pis Std                      2.11513
trainer/Log Pis Max                      8.70861
trainer/Log Pis Min                     -7.85212
trainer/policy/mean Mean                 0.0496836
trainer/policy/mean Std                  0.698311
trainer/policy/mean Max                  0.996645
trainer/policy/mean Min                 -0.993537
trainer/policy/normal/std Mean           0.417799
trainer/policy/normal/std Std            0.233145
trainer/policy/normal/std Max            1.33793
trainer/policy/normal/std Min            0.0405686
trainer/policy/normal/log_std Mean      -1.09965
trainer/policy/normal/log_std Std        0.767681
trainer/policy/normal/log_std Max        0.291123
trainer/policy/normal/log_std Min       -3.20476
trainer/Alpha                            0.00816888
trainer/Alpha Loss                       0.0689169
expl/num steps total                 38000
expl/num paths total                    57
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.174147
expl/Actions Std                         0.360855
expl/Actions Max                         0.899913
expl/Actions Min                        -0.994872
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                185000
eval/num paths total                   185
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.177939
eval/Actions Std                         0.430349
eval/Actions Max                         0.991247
eval/Actions Min                        -0.993873
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00325245
time/evaluation sampling (s)             0.923641
time/exploration sampling (s)            0.30814
time/logging (s)                         0.00886402
time/sac training (s)                   11.1834
time/saving (s)                          0.00370848
time/training (s)                        2.59e-05
time/epoch (s)                          12.431
time/total (s)                         476.631
Epoch                                   36
----------------------------------  ---------------
2022-09-09 20:00:59.430436 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 37 finished
----------------------------------  ---------------
epoch                                   37
replay_buffer/size                   39000
trainer/num train calls              38000
trainer/QF1 Loss                         0.00821277
trainer/QF2 Loss                         0.00643448
trainer/Policy Loss                    -12.4709
trainer/Q1 Predictions Mean             12.3676
trainer/Q1 Predictions Std               0.8468
trainer/Q1 Predictions Max              13.9363
trainer/Q1 Predictions Min               9.55662
trainer/Q2 Predictions Mean             12.3841
trainer/Q2 Predictions Std               0.834486
trainer/Q2 Predictions Max              13.9484
trainer/Q2 Predictions Min               9.91195
trainer/Q Targets Mean                  12.3842
trainer/Q Targets Std                    0.827051
trainer/Q Targets Max                   13.8729
trainer/Q Targets Min                    9.87396
trainer/Log Pis Mean                     2.96328
trainer/Log Pis Std                      2.17205
trainer/Log Pis Max                      9.17817
trainer/Log Pis Min                     -3.92505
trainer/policy/mean Mean                 0.06658
trainer/policy/mean Std                  0.699779
trainer/policy/mean Max                  0.995495
trainer/policy/mean Min                 -0.993427
trainer/policy/normal/std Mean           0.413038
trainer/policy/normal/std Std            0.229815
trainer/policy/normal/std Max            1.23802
trainer/policy/normal/std Min            0.0393699
trainer/policy/normal/log_std Mean      -1.1029
trainer/policy/normal/log_std Std        0.746042
trainer/policy/normal/log_std Max        0.21351
trainer/policy/normal/log_std Min       -3.23475
trainer/Alpha                            0.00837751
trainer/Alpha Loss                      -0.17559
expl/num steps total                 39000
expl/num paths total                    58
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0470529
expl/Actions Std                         0.613476
expl/Actions Max                         0.99672
expl/Actions Min                        -0.994408
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                190000
eval/num paths total                   190
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0360076
eval/Actions Std                         0.492622
eval/Actions Max                         0.992058
eval/Actions Min                        -0.993587
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00338467
time/evaluation sampling (s)             0.91613
time/exploration sampling (s)            0.308716
time/logging (s)                         0.00964731
time/sac training (s)                   10.9992
time/saving (s)                          0.00325324
time/training (s)                        1.914e-05
time/epoch (s)                          12.2404
time/total (s)                         489.129
Epoch                                   37
----------------------------------  ---------------
2022-09-09 20:01:12.054807 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 38 finished
----------------------------------  ---------------
epoch                                   38
replay_buffer/size                   40000
trainer/num train calls              39000
trainer/QF1 Loss                         0.00776493
trainer/QF2 Loss                         0.00725096
trainer/Policy Loss                    -12.3879
trainer/Q1 Predictions Mean             12.3098
trainer/Q1 Predictions Std               0.82876
trainer/Q1 Predictions Max              13.7356
trainer/Q1 Predictions Min               9.34014
trainer/Q2 Predictions Mean             12.3015
trainer/Q2 Predictions Std               0.823626
trainer/Q2 Predictions Max              13.7313
trainer/Q2 Predictions Min               9.35671
trainer/Q Targets Mean                  12.2789
trainer/Q Targets Std                    0.825098
trainer/Q Targets Max                   13.6205
trainer/Q Targets Min                    9.64839
trainer/Log Pis Mean                     2.92505
trainer/Log Pis Std                      1.80734
trainer/Log Pis Max                      7.15434
trainer/Log Pis Min                     -5.5969
trainer/policy/mean Mean                 0.0668818
trainer/policy/mean Std                  0.645077
trainer/policy/mean Max                  0.99265
trainer/policy/mean Min                 -0.995247
trainer/policy/normal/std Mean           0.37964
trainer/policy/normal/std Std            0.247633
trainer/policy/normal/std Max            1.20597
trainer/policy/normal/std Min            0.0368586
trainer/policy/normal/log_std Mean      -1.26976
trainer/policy/normal/log_std Std        0.86095
trainer/policy/normal/log_std Max        0.187283
trainer/policy/normal/log_std Min       -3.30066
trainer/Alpha                            0.00812463
trainer/Alpha Loss                      -0.360729
expl/num steps total                 40000
expl/num paths total                    59
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0874038
expl/Actions Std                         0.349962
expl/Actions Max                         0.985904
expl/Actions Min                        -0.997852
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                195000
eval/num paths total                   195
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0771837
eval/Actions Std                         0.187845
eval/Actions Max                         0.986951
eval/Actions Min                        -0.98884
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00501695
time/evaluation sampling (s)             0.905681
time/exploration sampling (s)            0.312485
time/logging (s)                         0.0095726
time/sac training (s)                   11.1234
time/saving (s)                          0.00465238
time/training (s)                        2.885e-05
time/epoch (s)                          12.3609
time/total (s)                         501.744
Epoch                                   38
----------------------------------  ---------------
2022-09-09 20:01:24.845225 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 39 finished
----------------------------------  ---------------
epoch                                   39
replay_buffer/size                   41000
trainer/num train calls              40000
trainer/QF1 Loss                         0.0138122
trainer/QF2 Loss                         0.0153356
trainer/Policy Loss                    -12.1419
trainer/Q1 Predictions Mean             12.0348
trainer/Q1 Predictions Std               0.880336
trainer/Q1 Predictions Max              13.6497
trainer/Q1 Predictions Min               9.55254
trainer/Q2 Predictions Mean             12.046
trainer/Q2 Predictions Std               0.863274
trainer/Q2 Predictions Max              13.5536
trainer/Q2 Predictions Min               9.50826
trainer/Q Targets Mean                  12.047
trainer/Q Targets Std                    0.838826
trainer/Q Targets Max                   13.5075
trainer/Q Targets Min                    9.46861
trainer/Log Pis Mean                     3.02205
trainer/Log Pis Std                      1.91555
trainer/Log Pis Max                      8.4563
trainer/Log Pis Min                     -3.56146
trainer/policy/mean Mean                 0.0324523
trainer/policy/mean Std                  0.651874
trainer/policy/mean Max                  0.995114
trainer/policy/mean Min                 -0.992968
trainer/policy/normal/std Mean           0.370366
trainer/policy/normal/std Std            0.244059
trainer/policy/normal/std Max            1.02725
trainer/policy/normal/std Min            0.0440725
trainer/policy/normal/log_std Mean      -1.30866
trainer/policy/normal/log_std Std        0.879499
trainer/policy/normal/log_std Max        0.0268875
trainer/policy/normal/log_std Min       -3.12192
trainer/Alpha                            0.00792326
trainer/Alpha Loss                       0.106691
expl/num steps total                 41000
expl/num paths total                    60
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.499838
expl/Actions Std                         0.273226
expl/Actions Max                         0.997737
expl/Actions Min                        -0.81174
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                200000
eval/num paths total                   200
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0822533
eval/Actions Std                         0.185579
eval/Actions Max                         0.987319
eval/Actions Min                        -0.979166
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00407728
time/evaluation sampling (s)             0.932442
time/exploration sampling (s)            0.303025
time/logging (s)                         0.0095248
time/sac training (s)                   11.254
time/saving (s)                          0.00430338
time/training (s)                        1.933e-05
time/epoch (s)                          12.5074
time/total (s)                         514.525
Epoch                                   39
----------------------------------  ---------------
2022-09-09 20:01:38.076516 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 40 finished
----------------------------------  ---------------
epoch                                   40
replay_buffer/size                   42000
trainer/num train calls              41000
trainer/QF1 Loss                         0.00515777
trainer/QF2 Loss                         0.00496335
trainer/Policy Loss                    -11.7891
trainer/Q1 Predictions Mean             11.7125
trainer/Q1 Predictions Std               0.850961
trainer/Q1 Predictions Max              13.2723
trainer/Q1 Predictions Min               9.37431
trainer/Q2 Predictions Mean             11.7175
trainer/Q2 Predictions Std               0.861607
trainer/Q2 Predictions Max              13.288
trainer/Q2 Predictions Min               9.47306
trainer/Q Targets Mean                  11.7203
trainer/Q Targets Std                    0.854827
trainer/Q Targets Max                   13.2782
trainer/Q Targets Min                    9.76796
trainer/Log Pis Mean                     3.03746
trainer/Log Pis Std                      1.9616
trainer/Log Pis Max                     10.6563
trainer/Log Pis Min                     -2.55915
trainer/policy/mean Mean                 0.0300103
trainer/policy/mean Std                  0.659152
trainer/policy/mean Max                  0.994425
trainer/policy/mean Min                 -0.999354
trainer/policy/normal/std Mean           0.380558
trainer/policy/normal/std Std            0.26857
trainer/policy/normal/std Max            1.18759
trainer/policy/normal/std Min            0.0371377
trainer/policy/normal/log_std Mean      -1.31077
trainer/policy/normal/log_std Std        0.92
trainer/policy/normal/log_std Max        0.171927
trainer/policy/normal/log_std Min       -3.29312
trainer/Alpha                            0.00807991
trainer/Alpha Loss                       0.180486
expl/num steps total                 42000
expl/num paths total                    61
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.376086
expl/Actions Std                         0.357639
expl/Actions Max                         0.997246
expl/Actions Min                        -0.727944
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                205000
eval/num paths total                   205
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.147613
eval/Actions Std                         0.368154
eval/Actions Max                         0.979154
eval/Actions Min                        -0.808904
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00414671
time/evaluation sampling (s)             0.907891
time/exploration sampling (s)            0.312218
time/logging (s)                         0.00944152
time/sac training (s)                   11.6883
time/saving (s)                          0.00441478
time/training (s)                        1.976e-05
time/epoch (s)                          12.9264
time/total (s)                         527.744
Epoch                                   40
----------------------------------  ---------------
2022-09-09 20:01:51.158213 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 41 finished
----------------------------------  ---------------
epoch                                   41
replay_buffer/size                   43000
trainer/num train calls              42000
trainer/QF1 Loss                         0.00533843
trainer/QF2 Loss                         0.00609222
trainer/Policy Loss                    -11.5408
trainer/Q1 Predictions Mean             11.462
trainer/Q1 Predictions Std               0.918381
trainer/Q1 Predictions Max              12.9769
trainer/Q1 Predictions Min               9.27249
trainer/Q2 Predictions Mean             11.4658
trainer/Q2 Predictions Std               0.925148
trainer/Q2 Predictions Max              13.0043
trainer/Q2 Predictions Min               9.1683
trainer/Q Targets Mean                  11.4702
trainer/Q Targets Std                    0.909831
trainer/Q Targets Max                   12.9637
trainer/Q Targets Min                    9.65664
trainer/Log Pis Mean                     2.6313
trainer/Log Pis Std                      1.8594
trainer/Log Pis Max                      7.30024
trainer/Log Pis Min                     -3.5832
trainer/policy/mean Mean                -0.0168513
trainer/policy/mean Std                  0.656998
trainer/policy/mean Max                  0.992977
trainer/policy/mean Min                 -0.995521
trainer/policy/normal/std Mean           0.404438
trainer/policy/normal/std Std            0.268846
trainer/policy/normal/std Max            1.26386
trainer/policy/normal/std Min            0.0370171
trainer/policy/normal/log_std Mean      -1.21235
trainer/policy/normal/log_std Std        0.870461
trainer/policy/normal/log_std Max        0.234174
trainer/policy/normal/log_std Min       -3.29638
trainer/Alpha                            0.0086837
trainer/Alpha Loss                      -1.74995
expl/num steps total                 43000
expl/num paths total                    62
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.194899
expl/Actions Std                         0.379868
expl/Actions Max                         0.9752
expl/Actions Min                        -0.972361
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                210000
eval/num paths total                   210
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.104356
eval/Actions Std                         0.186888
eval/Actions Max                         0.980644
eval/Actions Min                        -0.994103
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00492901
time/evaluation sampling (s)             0.941896
time/exploration sampling (s)            0.302845
time/logging (s)                         0.00938527
time/sac training (s)                   11.5185
time/saving (s)                          0.00465847
time/training (s)                        2.619e-05
time/epoch (s)                          12.7822
time/total (s)                         540.815
Epoch                                   41
----------------------------------  ---------------
2022-09-09 20:02:04.077787 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 42 finished
----------------------------------  ---------------
epoch                                   42
replay_buffer/size                   44000
trainer/num train calls              43000
trainer/QF1 Loss                         0.00613962
trainer/QF2 Loss                         0.00734369
trainer/Policy Loss                    -11.3943
trainer/Q1 Predictions Mean             11.3053
trainer/Q1 Predictions Std               0.908998
trainer/Q1 Predictions Max              12.7515
trainer/Q1 Predictions Min               9.48935
trainer/Q2 Predictions Mean             11.3062
trainer/Q2 Predictions Std               0.905482
trainer/Q2 Predictions Max              12.7382
trainer/Q2 Predictions Min               9.48622
trainer/Q Targets Mean                  11.2892
trainer/Q Targets Std                    0.913234
trainer/Q Targets Max                   12.6778
trainer/Q Targets Min                    9.46409
trainer/Log Pis Mean                     3.04522
trainer/Log Pis Std                      1.88155
trainer/Log Pis Max                      9.29452
trainer/Log Pis Min                     -3.52093
trainer/policy/mean Mean                 0.068046
trainer/policy/mean Std                  0.71118
trainer/policy/mean Max                  0.995048
trainer/policy/mean Min                 -0.998085
trainer/policy/normal/std Mean           0.453872
trainer/policy/normal/std Std            0.296952
trainer/policy/normal/std Max            2.03413
trainer/policy/normal/std Min            0.0442189
trainer/policy/normal/log_std Mean      -1.07135
trainer/policy/normal/log_std Std        0.846695
trainer/policy/normal/log_std Max        0.710067
trainer/policy/normal/log_std Min       -3.1186
trainer/Alpha                            0.0093903
trainer/Alpha Loss                       0.211113
expl/num steps total                 44000
expl/num paths total                    63
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.132333
expl/Actions Std                         0.321234
expl/Actions Max                         0.995132
expl/Actions Min                        -0.99762
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                215000
eval/num paths total                   215
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.151564
eval/Actions Std                         0.256194
eval/Actions Max                         0.989176
eval/Actions Min                        -0.997885
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00318489
time/evaluation sampling (s)             0.921471
time/exploration sampling (s)            0.289766
time/logging (s)                         0.00904642
time/sac training (s)                   11.406
time/saving (s)                          0.00338596
time/training (s)                        1.952e-05
time/epoch (s)                          12.6329
time/total (s)                         553.724
Epoch                                   42
----------------------------------  ---------------
2022-09-09 20:02:16.925808 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 43 finished
----------------------------------  ---------------
epoch                                   43
replay_buffer/size                   45000
trainer/num train calls              44000
trainer/QF1 Loss                         0.00865439
trainer/QF2 Loss                         0.00847278
trainer/Policy Loss                    -11.4027
trainer/Q1 Predictions Mean             11.3297
trainer/Q1 Predictions Std               0.879841
trainer/Q1 Predictions Max              12.5114
trainer/Q1 Predictions Min               9.69915
trainer/Q2 Predictions Mean             11.3223
trainer/Q2 Predictions Std               0.872453
trainer/Q2 Predictions Max              12.5293
trainer/Q2 Predictions Min               9.59907
trainer/Q Targets Mean                  11.3143
trainer/Q Targets Std                    0.857624
trainer/Q Targets Max                   12.429
trainer/Q Targets Min                    9.59197
trainer/Log Pis Mean                     2.953
trainer/Log Pis Std                      2.0522
trainer/Log Pis Max                      8.49936
trainer/Log Pis Min                     -5.02556
trainer/policy/mean Mean                 0.0526284
trainer/policy/mean Std                  0.712399
trainer/policy/mean Max                  0.989854
trainer/policy/mean Min                 -0.997037
trainer/policy/normal/std Mean           0.471709
trainer/policy/normal/std Std            0.293023
trainer/policy/normal/std Max            1.54672
trainer/policy/normal/std Min            0.0507998
trainer/policy/normal/log_std Mean      -1.02398
trainer/policy/normal/log_std Std        0.836121
trainer/policy/normal/log_std Max        0.436138
trainer/policy/normal/log_std Min       -2.97986
trainer/Alpha                            0.0093544
trainer/Alpha Loss                      -0.219591
expl/num steps total                 45000
expl/num paths total                    64
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.041211
expl/Actions Std                         0.354422
expl/Actions Max                         0.994315
expl/Actions Min                        -0.974911
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                220000
eval/num paths total                   220
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0345624
eval/Actions Std                         0.132556
eval/Actions Max                         0.988591
eval/Actions Min                        -0.993018
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.003254
time/evaluation sampling (s)             0.923359
time/exploration sampling (s)            0.301823
time/logging (s)                         0.0104246
time/sac training (s)                   11.3228
time/saving (s)                          0.00365147
time/training (s)                        1.94e-05
time/epoch (s)                          12.5653
time/total (s)                         566.563
Epoch                                   43
----------------------------------  ---------------
2022-09-09 20:02:29.859824 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 44 finished
----------------------------------  ---------------
epoch                                   44
replay_buffer/size                   46000
trainer/num train calls              45000
trainer/QF1 Loss                         0.004974
trainer/QF2 Loss                         0.00357898
trainer/Policy Loss                    -11.1849
trainer/Q1 Predictions Mean             11.1025
trainer/Q1 Predictions Std               0.867312
trainer/Q1 Predictions Max              12.2979
trainer/Q1 Predictions Min               9.4722
trainer/Q2 Predictions Mean             11.105
trainer/Q2 Predictions Std               0.857227
trainer/Q2 Predictions Max              12.2791
trainer/Q2 Predictions Min               9.5034
trainer/Q Targets Mean                  11.0969
trainer/Q Targets Std                    0.845091
trainer/Q Targets Max                   12.1897
trainer/Q Targets Min                    9.45565
trainer/Log Pis Mean                     3.21853
trainer/Log Pis Std                      2.02986
trainer/Log Pis Max                      9.28411
trainer/Log Pis Min                     -5.63235
trainer/policy/mean Mean                 0.0761542
trainer/policy/mean Std                  0.699707
trainer/policy/mean Max                  0.996378
trainer/policy/mean Min                 -0.99783
trainer/policy/normal/std Mean           0.398421
trainer/policy/normal/std Std            0.256206
trainer/policy/normal/std Max            1.25617
trainer/policy/normal/std Min            0.0382656
trainer/policy/normal/log_std Mean      -1.20817
trainer/policy/normal/log_std Std        0.843734
trainer/policy/normal/log_std Max        0.228071
trainer/policy/normal/log_std Min       -3.2632
trainer/Alpha                            0.0087062
trainer/Alpha Loss                       1.03666
expl/num steps total                 46000
expl/num paths total                    65
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.00596649
expl/Actions Std                         0.513384
expl/Actions Max                         0.998771
expl/Actions Min                        -0.961274
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                225000
eval/num paths total                   225
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0344921
eval/Actions Std                         0.486812
eval/Actions Max                         0.992588
eval/Actions Min                        -0.997868
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00337113
time/evaluation sampling (s)             0.927061
time/exploration sampling (s)            0.299783
time/logging (s)                         0.0122561
time/sac training (s)                   11.4018
time/saving (s)                          0.00551462
time/training (s)                        6.169e-05
time/epoch (s)                          12.6498
time/total (s)                         579.487
Epoch                                   44
----------------------------------  ---------------
2022-09-09 20:02:42.787809 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 45 finished
----------------------------------  ---------------
epoch                                   45
replay_buffer/size                   47000
trainer/num train calls              46000
trainer/QF1 Loss                         0.00369256
trainer/QF2 Loss                         0.00299166
trainer/Policy Loss                    -10.8176
trainer/Q1 Predictions Mean             10.7467
trainer/Q1 Predictions Std               0.824398
trainer/Q1 Predictions Max              11.7783
trainer/Q1 Predictions Min               8.82161
trainer/Q2 Predictions Mean             10.7419
trainer/Q2 Predictions Std               0.822405
trainer/Q2 Predictions Max              11.7904
trainer/Q2 Predictions Min               8.80461
trainer/Q Targets Mean                  10.7477
trainer/Q Targets Std                    0.81957
trainer/Q Targets Max                   11.7439
trainer/Q Targets Min                    9.20572
trainer/Log Pis Mean                     2.95306
trainer/Log Pis Std                      1.76841
trainer/Log Pis Max                      7.51354
trainer/Log Pis Min                     -4.66162
trainer/policy/mean Mean                 0.0890223
trainer/policy/mean Std                  0.679352
trainer/policy/mean Max                  0.992879
trainer/policy/mean Min                 -0.994944
trainer/policy/normal/std Mean           0.39832
trainer/policy/normal/std Std            0.265996
trainer/policy/normal/std Max            1.68261
trainer/policy/normal/std Min            0.0332931
trainer/policy/normal/log_std Mean      -1.21689
trainer/policy/normal/log_std Std        0.857162
trainer/policy/normal/log_std Max        0.520348
trainer/policy/normal/log_std Min       -3.4024
trainer/Alpha                            0.0081671
trainer/Alpha Loss                      -0.225666
expl/num steps total                 47000
expl/num paths total                    66
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0144537
expl/Actions Std                         0.470385
expl/Actions Max                         0.997742
expl/Actions Min                        -0.999419
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                230000
eval/num paths total                   230
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0217081
eval/Actions Std                         0.37056
eval/Actions Max                         0.9821
eval/Actions Min                        -0.987891
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00325229
time/evaluation sampling (s)             0.947625
time/exploration sampling (s)            0.305011
time/logging (s)                         0.00951711
time/sac training (s)                   11.3745
time/saving (s)                          0.00499542
time/training (s)                        3.525e-05
time/epoch (s)                          12.6449
time/total (s)                         592.402
Epoch                                   45
----------------------------------  ---------------
2022-09-09 20:02:55.752574 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 46 finished
----------------------------------  ---------------
epoch                                   46
replay_buffer/size                   48000
trainer/num train calls              47000
trainer/QF1 Loss                         0.213537
trainer/QF2 Loss                         0.238795
trainer/Policy Loss                    -10.7095
trainer/Q1 Predictions Mean             10.6532
trainer/Q1 Predictions Std               0.705814
trainer/Q1 Predictions Max              11.6823
trainer/Q1 Predictions Min               8.24998
trainer/Q2 Predictions Mean             10.6629
trainer/Q2 Predictions Std               0.711662
trainer/Q2 Predictions Max              11.8141
trainer/Q2 Predictions Min               8.66479
trainer/Q Targets Mean                  10.5701
trainer/Q Targets Std                    0.895448
trainer/Q Targets Max                   11.667
trainer/Q Targets Min                    1
trainer/Log Pis Mean                     2.78097
trainer/Log Pis Std                      2.00954
trainer/Log Pis Max                      7.68462
trainer/Log Pis Min                     -3.46316
trainer/policy/mean Mean                 0.00762496
trainer/policy/mean Std                  0.692235
trainer/policy/mean Max                  0.996364
trainer/policy/mean Min                 -0.99378
trainer/policy/normal/std Mean           0.42961
trainer/policy/normal/std Std            0.28141
trainer/policy/normal/std Max            1.54862
trainer/policy/normal/std Min            0.0403496
trainer/policy/normal/log_std Mean      -1.14335
trainer/policy/normal/log_std Std        0.866351
trainer/policy/normal/log_std Max        0.437365
trainer/policy/normal/log_std Min       -3.21017
trainer/Alpha                            0.00816142
trainer/Alpha Loss                      -1.05319
expl/num steps total                 48000
expl/num paths total                    67
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0206618
expl/Actions Std                         0.503042
expl/Actions Max                         0.998761
expl/Actions Min                        -0.99713
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                235000
eval/num paths total                   235
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0180204
eval/Actions Std                         0.387516
eval/Actions Max                         0.988845
eval/Actions Min                        -0.986242
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00329746
time/evaluation sampling (s)             0.940797
time/exploration sampling (s)            0.320974
time/logging (s)                         0.00933159
time/sac training (s)                   11.3891
time/saving (s)                          0.00473662
time/training (s)                        2.956e-05
time/epoch (s)                          12.6682
time/total (s)                         605.356
Epoch                                   46
----------------------------------  ---------------
2022-09-09 20:03:08.494100 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 47 finished
----------------------------------  ---------------
epoch                                   47
replay_buffer/size                   49000
trainer/num train calls              48000
trainer/QF1 Loss                         0.00484334
trainer/QF2 Loss                         0.00380316
trainer/Policy Loss                    -10.4055
trainer/Q1 Predictions Mean             10.3462
trainer/Q1 Predictions Std               0.588562
trainer/Q1 Predictions Max              11.3438
trainer/Q1 Predictions Min               8.88007
trainer/Q2 Predictions Mean             10.3152
trainer/Q2 Predictions Std               0.58604
trainer/Q2 Predictions Max              11.5507
trainer/Q2 Predictions Min               8.77206
trainer/Q Targets Mean                  10.3298
trainer/Q Targets Std                    0.578164
trainer/Q Targets Max                   11.3725
trainer/Q Targets Min                    8.8908
trainer/Log Pis Mean                     3.1185
trainer/Log Pis Std                      2.07608
trainer/Log Pis Max                     10.9147
trainer/Log Pis Min                     -4.45775
trainer/policy/mean Mean                 0.0523748
trainer/policy/mean Std                  0.741186
trainer/policy/mean Max                  0.996563
trainer/policy/mean Min                 -0.994936
trainer/policy/normal/std Mean           0.424849
trainer/policy/normal/std Std            0.247023
trainer/policy/normal/std Max            1.40456
trainer/policy/normal/std Min            0.0440831
trainer/policy/normal/log_std Mean      -1.10948
trainer/policy/normal/log_std Std        0.80891
trainer/policy/normal/log_std Max        0.339724
trainer/policy/normal/log_std Min       -3.12168
trainer/Alpha                            0.00772757
trainer/Alpha Loss                       0.576258
expl/num steps total                 49000
expl/num paths total                    68
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0756818
expl/Actions Std                         0.582529
expl/Actions Max                         0.998859
expl/Actions Min                        -0.996937
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                240000
eval/num paths total                   240
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.086342
eval/Actions Std                         0.440975
eval/Actions Max                         0.987595
eval/Actions Min                        -0.993336
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00332985
time/evaluation sampling (s)             0.928473
time/exploration sampling (s)            0.311272
time/logging (s)                         0.00950852
time/sac training (s)                   11.2124
time/saving (s)                          0.00466667
time/training (s)                        2.747e-05
time/epoch (s)                          12.4697
time/total (s)                         618.088
Epoch                                   47
----------------------------------  ---------------
2022-09-09 20:03:21.386329 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 48 finished
----------------------------------  ---------------
epoch                                   48
replay_buffer/size                   50000
trainer/num train calls              49000
trainer/QF1 Loss                         0.00325956
trainer/QF2 Loss                         0.00338369
trainer/Policy Loss                    -10.1389
trainer/Q1 Predictions Mean             10.0927
trainer/Q1 Predictions Std               0.477988
trainer/Q1 Predictions Max              11.0341
trainer/Q1 Predictions Min               8.81155
trainer/Q2 Predictions Mean             10.0833
trainer/Q2 Predictions Std               0.47834
trainer/Q2 Predictions Max              10.9665
trainer/Q2 Predictions Min               8.80925
trainer/Q Targets Mean                  10.0839
trainer/Q Targets Std                    0.475401
trainer/Q Targets Max                   11.0355
trainer/Q Targets Min                    8.72376
trainer/Log Pis Mean                     3.11128
trainer/Log Pis Std                      2.2617
trainer/Log Pis Max                      8.91721
trainer/Log Pis Min                     -3.87503
trainer/policy/mean Mean                 0.170173
trainer/policy/mean Std                  0.687438
trainer/policy/mean Max                  0.996995
trainer/policy/mean Min                 -0.988024
trainer/policy/normal/std Mean           0.392299
trainer/policy/normal/std Std            0.226771
trainer/policy/normal/std Max            1.15627
trainer/policy/normal/std Min            0.0397607
trainer/policy/normal/log_std Mean      -1.1988
trainer/policy/normal/log_std Std        0.827835
trainer/policy/normal/log_std Max        0.145199
trainer/policy/normal/log_std Min       -3.22488
trainer/Alpha                            0.00682757
trainer/Alpha Loss                       0.554928
expl/num steps total                 50000
expl/num paths total                    69
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.122668
expl/Actions Std                         0.685255
expl/Actions Max                         0.998358
expl/Actions Min                        -0.996468
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                245000
eval/num paths total                   245
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.378816
eval/Actions Std                         0.612263
eval/Actions Max                         0.990145
eval/Actions Min                        -0.982566
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00326639
time/evaluation sampling (s)             0.912502
time/exploration sampling (s)            0.311632
time/logging (s)                         0.00917876
time/sac training (s)                   11.3692
time/saving (s)                          0.00379275
time/training (s)                        2.713e-05
time/epoch (s)                          12.6096
time/total (s)                         630.97
Epoch                                   48
----------------------------------  ---------------
2022-09-09 20:03:34.546534 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 49 finished
----------------------------------  ---------------
epoch                                   49
replay_buffer/size                   51000
trainer/num train calls              50000
trainer/QF1 Loss                         0.00348888
trainer/QF2 Loss                         0.00309374
trainer/Policy Loss                     -9.79677
trainer/Q1 Predictions Mean              9.76676
trainer/Q1 Predictions Std               0.418658
trainer/Q1 Predictions Max              10.6414
trainer/Q1 Predictions Min               8.84878
trainer/Q2 Predictions Mean              9.76095
trainer/Q2 Predictions Std               0.40287
trainer/Q2 Predictions Max              10.6252
trainer/Q2 Predictions Min               8.8759
trainer/Q Targets Mean                   9.79613
trainer/Q Targets Std                    0.412922
trainer/Q Targets Max                   10.6904
trainer/Q Targets Min                    8.89788
trainer/Log Pis Mean                     3.34955
trainer/Log Pis Std                      2.40802
trainer/Log Pis Max                      9.71536
trainer/Log Pis Min                     -5.33297
trainer/policy/mean Mean                 0.13255
trainer/policy/mean Std                  0.682212
trainer/policy/mean Max                  0.994614
trainer/policy/mean Min                 -0.993495
trainer/policy/normal/std Mean           0.397163
trainer/policy/normal/std Std            0.23322
trainer/policy/normal/std Max            0.925024
trainer/policy/normal/std Min            0.0352845
trainer/policy/normal/log_std Mean      -1.2098
trainer/policy/normal/log_std Std        0.875481
trainer/policy/normal/log_std Max       -0.0779359
trainer/policy/normal/log_std Min       -3.34431
trainer/Alpha                            0.0066752
trainer/Alpha Loss                       1.75101
expl/num steps total                 51000
expl/num paths total                    70
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0264261
expl/Actions Std                         0.746175
expl/Actions Max                         0.99909
expl/Actions Min                        -0.998656
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                250000
eval/num paths total                   250
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0278687
eval/Actions Std                         0.67079
eval/Actions Max                         0.991351
eval/Actions Min                        -0.98216
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00367984
time/evaluation sampling (s)             0.937258
time/exploration sampling (s)            0.328635
time/logging (s)                         0.00975363
time/sac training (s)                   11.5541
time/saving (s)                          0.00465872
time/training (s)                        3.751e-05
time/epoch (s)                          12.8381
time/total (s)                         644.119
Epoch                                   49
----------------------------------  ---------------
2022-09-09 20:03:47.538793 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 50 finished
----------------------------------  ---------------
epoch                                   50
replay_buffer/size                   52000
trainer/num train calls              51000
trainer/QF1 Loss                         0.00498119
trainer/QF2 Loss                         0.00359019
trainer/Policy Loss                     -9.47802
trainer/Q1 Predictions Mean              9.4421
trainer/Q1 Predictions Std               0.434021
trainer/Q1 Predictions Max              10.3675
trainer/Q1 Predictions Min               8.64365
trainer/Q2 Predictions Mean              9.45718
trainer/Q2 Predictions Std               0.440437
trainer/Q2 Predictions Max              10.4409
trainer/Q2 Predictions Min               8.76417
trainer/Q Targets Mean                   9.46776
trainer/Q Targets Std                    0.441251
trainer/Q Targets Max                   10.3864
trainer/Q Targets Min                    8.68682
trainer/Log Pis Mean                     2.95213
trainer/Log Pis Std                      2.16459
trainer/Log Pis Max                      7.35648
trainer/Log Pis Min                     -2.48258
trainer/policy/mean Mean                 0.168677
trainer/policy/mean Std                  0.644005
trainer/policy/mean Max                  0.992709
trainer/policy/mean Min                 -0.995724
trainer/policy/normal/std Mean           0.357898
trainer/policy/normal/std Std            0.233271
trainer/policy/normal/std Max            1.1178
trainer/policy/normal/std Min            0.0339371
trainer/policy/normal/log_std Mean      -1.34149
trainer/policy/normal/log_std Std        0.893216
trainer/policy/normal/log_std Max        0.111361
trainer/policy/normal/log_std Min       -3.38325
trainer/Alpha                            0.00616814
trainer/Alpha Loss                      -0.243561
expl/num steps total                 52000
expl/num paths total                    71
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.129755
expl/Actions Std                         0.479146
expl/Actions Max                         0.981366
expl/Actions Min                        -0.993326
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                255000
eval/num paths total                   255
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.197209
eval/Actions Std                         0.490899
eval/Actions Max                         0.984919
eval/Actions Min                        -0.986105
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00333114
time/evaluation sampling (s)             0.945162
time/exploration sampling (s)            0.300923
time/logging (s)                         0.00917411
time/sac training (s)                   11.4432
time/saving (s)                          0.00326292
time/training (s)                        1.943e-05
time/epoch (s)                          12.7051
time/total (s)                         657.101
Epoch                                   50
----------------------------------  ---------------
2022-09-09 20:04:00.583583 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 51 finished
----------------------------------  ---------------
epoch                                   51
replay_buffer/size                   53000
trainer/num train calls              52000
trainer/QF1 Loss                         0.00236047
trainer/QF2 Loss                         0.00283909
trainer/Policy Loss                     -9.2081
trainer/Q1 Predictions Mean              9.16758
trainer/Q1 Predictions Std               0.439977
trainer/Q1 Predictions Max              10.0964
trainer/Q1 Predictions Min               8.35458
trainer/Q2 Predictions Mean              9.17906
trainer/Q2 Predictions Std               0.455349
trainer/Q2 Predictions Max              10.1858
trainer/Q2 Predictions Min               8.45673
trainer/Q Targets Mean                   9.16952
trainer/Q Targets Std                    0.438254
trainer/Q Targets Max                   10.0987
trainer/Q Targets Min                    8.49966
trainer/Log Pis Mean                     3.02398
trainer/Log Pis Std                      2.13065
trainer/Log Pis Max                      7.72959
trainer/Log Pis Min                     -4.37913
trainer/policy/mean Mean                 0.103991
trainer/policy/mean Std                  0.641111
trainer/policy/mean Max                  0.995367
trainer/policy/mean Min                 -0.994215
trainer/policy/normal/std Mean           0.359443
trainer/policy/normal/std Std            0.24779
trainer/policy/normal/std Max            1.23226
trainer/policy/normal/std Min            0.0386092
trainer/policy/normal/log_std Mean      -1.34952
trainer/policy/normal/log_std Std        0.903785
trainer/policy/normal/log_std Max        0.208851
trainer/policy/normal/log_std Min       -3.25426
trainer/Alpha                            0.0065381
trainer/Alpha Loss                       0.120631
expl/num steps total                 53000
expl/num paths total                    72
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0409726
expl/Actions Std                         0.507378
expl/Actions Max                         0.95519
expl/Actions Min                        -0.993296
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                260000
eval/num paths total                   260
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.117118
eval/Actions Std                         0.409267
eval/Actions Max                         0.974888
eval/Actions Min                        -0.970106
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00496457
time/evaluation sampling (s)             0.933891
time/exploration sampling (s)            0.306843
time/logging (s)                         0.00937938
time/sac training (s)                   11.4879
time/saving (s)                          0.00472567
time/training (s)                        2.784e-05
time/epoch (s)                          12.7477
time/total (s)                         670.135
Epoch                                   51
----------------------------------  ---------------
2022-09-09 20:04:12.947087 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 52 finished
----------------------------------  ---------------
epoch                                   52
replay_buffer/size                   54000
trainer/num train calls              53000
trainer/QF1 Loss                         0.00434179
trainer/QF2 Loss                         0.00338988
trainer/Policy Loss                     -8.90661
trainer/Q1 Predictions Mean              8.8739
trainer/Q1 Predictions Std               0.486169
trainer/Q1 Predictions Max               9.93054
trainer/Q1 Predictions Min               7.55382
trainer/Q2 Predictions Mean              8.86432
trainer/Q2 Predictions Std               0.48732
trainer/Q2 Predictions Max               9.90342
trainer/Q2 Predictions Min               7.75869
trainer/Q Targets Mean                   8.87561
trainer/Q Targets Std                    0.475278
trainer/Q Targets Max                    9.84793
trainer/Q Targets Min                    8.05222
trainer/Log Pis Mean                     3.00142
trainer/Log Pis Std                      2.03984
trainer/Log Pis Max                      7.42463
trainer/Log Pis Min                     -3.32526
trainer/policy/mean Mean                 0.0981087
trainer/policy/mean Std                  0.645625
trainer/policy/mean Max                  0.9899
trainer/policy/mean Min                 -0.99417
trainer/policy/normal/std Mean           0.351417
trainer/policy/normal/std Std            0.241911
trainer/policy/normal/std Max            1.22409
trainer/policy/normal/std Min            0.0373847
trainer/policy/normal/log_std Mean      -1.38717
trainer/policy/normal/log_std Std        0.928966
trainer/policy/normal/log_std Max        0.202195
trainer/policy/normal/log_std Min       -3.28649
trainer/Alpha                            0.00584242
trainer/Alpha Loss                       0.00728577
expl/num steps total                 54000
expl/num paths total                    73
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0527671
expl/Actions Std                         0.277238
expl/Actions Max                         0.984863
expl/Actions Min                        -0.919145
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                265000
eval/num paths total                   265
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.239042
eval/Actions Std                         0.527188
eval/Actions Max                         0.97975
eval/Actions Min                        -0.986355
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00499475
time/evaluation sampling (s)             0.915829
time/exploration sampling (s)            0.294238
time/logging (s)                         0.00900744
time/sac training (s)                   10.8791
time/saving (s)                          0.00346312
time/training (s)                        2.176e-05
time/epoch (s)                          12.1066
time/total (s)                         682.489
Epoch                                   52
----------------------------------  ---------------
2022-09-09 20:04:26.115870 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 53 finished
----------------------------------  ---------------
epoch                                   53
replay_buffer/size                   55000
trainer/num train calls              54000
trainer/QF1 Loss                         0.00505065
trainer/QF2 Loss                         0.006444
trainer/Policy Loss                     -8.66881
trainer/Q1 Predictions Mean              8.63014
trainer/Q1 Predictions Std               0.500276
trainer/Q1 Predictions Max               9.65536
trainer/Q1 Predictions Min               7.74109
trainer/Q2 Predictions Mean              8.6269
trainer/Q2 Predictions Std               0.500975
trainer/Q2 Predictions Max               9.57207
trainer/Q2 Predictions Min               7.74232
trainer/Q Targets Mean                   8.6081
trainer/Q Targets Std                    0.508808
trainer/Q Targets Max                    9.57751
trainer/Q Targets Min                    7.79316
trainer/Log Pis Mean                     2.66741
trainer/Log Pis Std                      2.13731
trainer/Log Pis Max                      7.85649
trainer/Log Pis Min                     -2.50311
trainer/policy/mean Mean                 0.0130157
trainer/policy/mean Std                  0.638427
trainer/policy/mean Max                  0.990958
trainer/policy/mean Min                 -0.998662
trainer/policy/normal/std Mean           0.361025
trainer/policy/normal/std Std            0.268887
trainer/policy/normal/std Max            1.3948
trainer/policy/normal/std Min            0.0343364
trainer/policy/normal/log_std Mean      -1.36758
trainer/policy/normal/log_std Std        0.907463
trainer/policy/normal/log_std Max        0.332751
trainer/policy/normal/log_std Min       -3.37155
trainer/Alpha                            0.00641754
trainer/Alpha Loss                      -1.67916
expl/num steps total                 55000
expl/num paths total                    74
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0536996
expl/Actions Std                         0.547717
expl/Actions Max                         0.986034
expl/Actions Min                        -1
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                270000
eval/num paths total                   270
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.13885
eval/Actions Std                         0.514342
eval/Actions Max                         0.971301
eval/Actions Min                        -0.996063
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00430529
time/evaluation sampling (s)             0.920772
time/exploration sampling (s)            0.280866
time/logging (s)                         0.00962234
time/sac training (s)                   11.6465
time/saving (s)                          0.0039627
time/training (s)                        3.14e-05
time/epoch (s)                          12.8661
time/total (s)                         695.647
Epoch                                   53
----------------------------------  ---------------
2022-09-09 20:04:39.250530 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 54 finished
----------------------------------  ---------------
epoch                                   54
replay_buffer/size                   56000
trainer/num train calls              55000
trainer/QF1 Loss                         0.00336732
trainer/QF2 Loss                         0.00409402
trainer/Policy Loss                     -8.48578
trainer/Q1 Predictions Mean              8.45
trainer/Q1 Predictions Std               0.511794
trainer/Q1 Predictions Max               9.37513
trainer/Q1 Predictions Min               7.15658
trainer/Q2 Predictions Mean              8.45519
trainer/Q2 Predictions Std               0.516179
trainer/Q2 Predictions Max               9.30797
trainer/Q2 Predictions Min               7.07498
trainer/Q Targets Mean                   8.47064
trainer/Q Targets Std                    0.512577
trainer/Q Targets Max                    9.31659
trainer/Q Targets Min                    7.29972
trainer/Log Pis Mean                     2.83525
trainer/Log Pis Std                      2.14913
trainer/Log Pis Max                      8.63784
trainer/Log Pis Min                     -3.78817
trainer/policy/mean Mean                -0.177546
trainer/policy/mean Std                  0.65497
trainer/policy/mean Max                  0.990211
trainer/policy/mean Min                 -0.998732
trainer/policy/normal/std Mean           0.428283
trainer/policy/normal/std Std            0.309924
trainer/policy/normal/std Max            1.37096
trainer/policy/normal/std Min            0.0339489
trainer/policy/normal/log_std Mean      -1.20529
trainer/policy/normal/log_std Std        0.955248
trainer/policy/normal/log_std Max        0.315511
trainer/policy/normal/log_std Min       -3.3829
trainer/Alpha                            0.00554939
trainer/Alpha Loss                      -0.855698
expl/num steps total                 56000
expl/num paths total                    75
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.478723
expl/Actions Std                         0.600759
expl/Actions Max                         0.993735
expl/Actions Min                        -0.99849
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                275000
eval/num paths total                   275
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0330462
eval/Actions Std                         0.646874
eval/Actions Max                         0.991402
eval/Actions Min                        -0.99072
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00337734
time/evaluation sampling (s)             0.968195
time/exploration sampling (s)            0.320126
time/logging (s)                         0.00994667
time/sac training (s)                   11.5135
time/saving (s)                          0.00405348
time/training (s)                        2.927e-05
time/epoch (s)                          12.8193
time/total (s)                         708.77
Epoch                                   54
----------------------------------  ---------------
2022-09-09 20:04:52.593832 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 55 finished
----------------------------------  ---------------
epoch                                   55
replay_buffer/size                   57000
trainer/num train calls              56000
trainer/QF1 Loss                         0.0021318
trainer/QF2 Loss                         0.00206971
trainer/Policy Loss                     -8.18389
trainer/Q1 Predictions Mean              8.15537
trainer/Q1 Predictions Std               0.511199
trainer/Q1 Predictions Max               9.04825
trainer/Q1 Predictions Min               7.36421
trainer/Q2 Predictions Mean              8.15217
trainer/Q2 Predictions Std               0.515973
trainer/Q2 Predictions Max               9.02291
trainer/Q2 Predictions Min               7.31907
trainer/Q Targets Mean                   8.1536
trainer/Q Targets Std                    0.515049
trainer/Q Targets Max                    9.00252
trainer/Q Targets Min                    7.27913
trainer/Log Pis Mean                     3.35151
trainer/Log Pis Std                      2.12025
trainer/Log Pis Max                     10.2511
trainer/Log Pis Min                     -3.70063
trainer/policy/mean Mean                -0.368991
trainer/policy/mean Std                  0.612607
trainer/policy/mean Max                  0.990004
trainer/policy/mean Min                 -0.998962
trainer/policy/normal/std Mean           0.397545
trainer/policy/normal/std Std            0.262121
trainer/policy/normal/std Max            1.16815
trainer/policy/normal/std Min            0.0319489
trainer/policy/normal/log_std Mean      -1.25482
trainer/policy/normal/log_std Std        0.938879
trainer/policy/normal/log_std Max        0.155422
trainer/policy/normal/log_std Min       -3.44362
trainer/Alpha                            0.00575919
trainer/Alpha Loss                       1.81274
expl/num steps total                 57000
expl/num paths total                    76
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.232512
expl/Actions Std                         0.720184
expl/Actions Max                         0.996744
expl/Actions Min                        -0.999999
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                280000
eval/num paths total                   280
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0706584
eval/Actions Std                         0.614297
eval/Actions Max                         0.979812
eval/Actions Min                        -0.995272
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0050461
time/evaluation sampling (s)             0.930495
time/exploration sampling (s)            0.320037
time/logging (s)                         0.00966781
time/sac training (s)                   11.7454
time/saving (s)                          0.00481196
time/training (s)                        3.814e-05
time/epoch (s)                          13.0155
time/total (s)                         722.101
Epoch                                   55
----------------------------------  ---------------
2022-09-09 20:05:07.130237 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 56 finished
----------------------------------  ---------------
epoch                                   56
replay_buffer/size                   58000
trainer/num train calls              57000
trainer/QF1 Loss                         0.00301722
trainer/QF2 Loss                         0.00402757
trainer/Policy Loss                     -7.88687
trainer/Q1 Predictions Mean              7.87969
trainer/Q1 Predictions Std               0.480931
trainer/Q1 Predictions Max               8.80664
trainer/Q1 Predictions Min               6.67464
trainer/Q2 Predictions Mean              7.86342
trainer/Q2 Predictions Std               0.491251
trainer/Q2 Predictions Max               8.76244
trainer/Q2 Predictions Min               6.41406
trainer/Q Targets Mean                   7.86583
trainer/Q Targets Std                    0.484665
trainer/Q Targets Max                    8.72069
trainer/Q Targets Min                    6.63823
trainer/Log Pis Mean                     3.33871
trainer/Log Pis Std                      2.18615
trainer/Log Pis Max                      7.91614
trainer/Log Pis Min                     -3.2695
trainer/policy/mean Mean                -0.377428
trainer/policy/mean Std                  0.600613
trainer/policy/mean Max                  0.986137
trainer/policy/mean Min                 -0.996717
trainer/policy/normal/std Mean           0.416644
trainer/policy/normal/std Std            0.286034
trainer/policy/normal/std Max            1.16238
trainer/policy/normal/std Min            0.028709
trainer/policy/normal/log_std Mean      -1.25736
trainer/policy/normal/log_std Std        1.01705
trainer/policy/normal/log_std Max        0.150471
trainer/policy/normal/log_std Min       -3.55055
trainer/Alpha                            0.00526832
trainer/Alpha Loss                       1.77687
expl/num steps total                 58000
expl/num paths total                    77
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.120832
expl/Actions Std                         0.330356
expl/Actions Max                         0.924952
expl/Actions Min                        -0.992502
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                285000
eval/num paths total                   285
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0473971
eval/Actions Std                         0.655082
eval/Actions Max                         0.979154
eval/Actions Min                        -0.977692
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00495376
time/evaluation sampling (s)             0.988833
time/exploration sampling (s)            0.319607
time/logging (s)                         0.00949436
time/sac training (s)                   12.8342
time/saving (s)                          0.00474459
time/training (s)                        2.763e-05
time/epoch (s)                          14.1619
time/total (s)                         736.623
Epoch                                   56
----------------------------------  ---------------
2022-09-09 20:05:20.764709 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 57 finished
----------------------------------  ---------------
epoch                                   57
replay_buffer/size                   59000
trainer/num train calls              58000
trainer/QF1 Loss                         0.00179568
trainer/QF2 Loss                         0.00240663
trainer/Policy Loss                     -7.56212
trainer/Q1 Predictions Mean              7.55309
trainer/Q1 Predictions Std               0.461018
trainer/Q1 Predictions Max               8.37268
trainer/Q1 Predictions Min               6.61446
trainer/Q2 Predictions Mean              7.54954
trainer/Q2 Predictions Std               0.460383
trainer/Q2 Predictions Max               8.37847
trainer/Q2 Predictions Min               6.62671
trainer/Q Targets Mean                   7.56474
trainer/Q Targets Std                    0.451051
trainer/Q Targets Max                    8.38516
trainer/Q Targets Min                    6.64155
trainer/Log Pis Mean                     2.88384
trainer/Log Pis Std                      2.09058
trainer/Log Pis Max                      7.79124
trainer/Log Pis Min                     -3.33754
trainer/policy/mean Mean                -0.166739
trainer/policy/mean Std                  0.630401
trainer/policy/mean Max                  0.987463
trainer/policy/mean Min                 -0.989285
trainer/policy/normal/std Mean           0.343231
trainer/policy/normal/std Std            0.277588
trainer/policy/normal/std Max            1.22221
trainer/policy/normal/std Min            0.029432
trainer/policy/normal/log_std Mean      -1.47852
trainer/policy/normal/log_std Std        0.986587
trainer/policy/normal/log_std Max        0.20066
trainer/policy/normal/log_std Min       -3.52567
trainer/Alpha                            0.00522129
trainer/Alpha Loss                      -0.610442
expl/num steps total                 59000
expl/num paths total                    78
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.12664
expl/Actions Std                         0.751745
expl/Actions Max                         0.999193
expl/Actions Min                        -0.998998
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                290000
eval/num paths total                   290
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0413869
eval/Actions Std                         0.495515
eval/Actions Max                         0.979958
eval/Actions Min                        -0.985432
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0037508
time/evaluation sampling (s)             0.971198
time/exploration sampling (s)            0.319581
time/logging (s)                         0.00970789
time/sac training (s)                   12.0012
time/saving (s)                          0.00474625
time/training (s)                        1.996e-05
time/epoch (s)                          13.3102
time/total (s)                         750.245
Epoch                                   57
----------------------------------  ---------------
2022-09-09 20:05:34.093260 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 58 finished
----------------------------------  ----------------
epoch                                   58
replay_buffer/size                   60000
trainer/num train calls              59000
trainer/QF1 Loss                         0.00225935
trainer/QF2 Loss                         0.00256242
trainer/Policy Loss                     -7.28412
trainer/Q1 Predictions Mean              7.27374
trainer/Q1 Predictions Std               0.445774
trainer/Q1 Predictions Max               8.15317
trainer/Q1 Predictions Min               5.8449
trainer/Q2 Predictions Mean              7.27521
trainer/Q2 Predictions Std               0.445241
trainer/Q2 Predictions Max               8.13584
trainer/Q2 Predictions Min               6.17992
trainer/Q Targets Mean                   7.29171
trainer/Q Targets Std                    0.452987
trainer/Q Targets Max                    8.15903
trainer/Q Targets Min                    6.00969
trainer/Log Pis Mean                     3.00826
trainer/Log Pis Std                      2.03965
trainer/Log Pis Max                      8.48622
trainer/Log Pis Min                     -4.38879
trainer/policy/mean Mean                -0.110398
trainer/policy/mean Std                  0.621747
trainer/policy/mean Max                  0.959307
trainer/policy/mean Min                 -0.98198
trainer/policy/normal/std Mean           0.29758
trainer/policy/normal/std Std            0.230236
trainer/policy/normal/std Max            1.0671
trainer/policy/normal/std Min            0.0265146
trainer/policy/normal/log_std Mean      -1.59966
trainer/policy/normal/log_std Std        0.953026
trainer/policy/normal/log_std Max        0.0649444
trainer/policy/normal/log_std Min       -3.63006
trainer/Alpha                            0.00583912
trainer/Alpha Loss                       0.0425066
expl/num steps total                 60000
expl/num paths total                    79
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.257315
expl/Actions Std                         0.381325
expl/Actions Max                         0.983477
expl/Actions Min                        -0.471892
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                294002
eval/num paths total                   295
eval/path length Mean                  800.4
eval/path length Std                   399.2
eval/path length Max                  1000
eval/path length Min                     2
eval/Rewards Mean                        0.000249875
eval/Rewards Std                         0.0158055
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        0.2
eval/Returns Std                         0.4
eval/Returns Max                         1
eval/Returns Min                         0
eval/Actions Mean                        0.0929525
eval/Actions Std                         0.437088
eval/Actions Max                         0.904761
eval/Actions Min                        -0.967973
eval/Num Paths                           5
eval/Average Returns                     0.2
time/data storing (s)                    0.0032838
time/evaluation sampling (s)             0.964341
time/exploration sampling (s)            0.317255
time/logging (s)                         0.00810741
time/sac training (s)                   11.7279
time/saving (s)                          0.00470062
time/training (s)                        2.569e-05
time/epoch (s)                          13.0256
time/total (s)                         763.561
Epoch                                   58
----------------------------------  ----------------
2022-09-09 20:05:47.230399 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 59 finished
----------------------------------  ---------------
epoch                                   59
replay_buffer/size                   61000
trainer/num train calls              60000
trainer/QF1 Loss                         0.00400292
trainer/QF2 Loss                         0.00439937
trainer/Policy Loss                     -7.11363
trainer/Q1 Predictions Mean              7.09739
trainer/Q1 Predictions Std               0.411948
trainer/Q1 Predictions Max               7.94487
trainer/Q1 Predictions Min               6.21883
trainer/Q2 Predictions Mean              7.09261
trainer/Q2 Predictions Std               0.4089
trainer/Q2 Predictions Max               7.94535
trainer/Q2 Predictions Min               6.24848
trainer/Q Targets Mean                   7.06063
trainer/Q Targets Std                    0.407383
trainer/Q Targets Max                    7.90304
trainer/Q Targets Min                    6.17417
trainer/Log Pis Mean                     3.17684
trainer/Log Pis Std                      2.12955
trainer/Log Pis Max                     10.0782
trainer/Log Pis Min                     -4.03705
trainer/policy/mean Mean                -0.169283
trainer/policy/mean Std                  0.562416
trainer/policy/mean Max                  0.967734
trainer/policy/mean Min                 -0.994183
trainer/policy/normal/std Mean           0.317827
trainer/policy/normal/std Std            0.274525
trainer/policy/normal/std Max            1.26783
trainer/policy/normal/std Min            0.0218531
trainer/policy/normal/log_std Mean      -1.60519
trainer/policy/normal/log_std Std        1.02654
trainer/policy/normal/log_std Max        0.237309
trainer/policy/normal/log_std Min       -3.82341
trainer/Alpha                            0.00557223
trainer/Alpha Loss                       0.917768
expl/num steps total                 61000
expl/num paths total                    80
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.183667
expl/Actions Std                         0.316877
expl/Actions Max                         0.990046
expl/Actions Min                        -0.975742
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                299002
eval/num paths total                   300
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.152092
eval/Actions Std                         0.336507
eval/Actions Max                         0.940616
eval/Actions Min                        -0.985152
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00329265
time/evaluation sampling (s)             0.95507
time/exploration sampling (s)            0.304821
time/logging (s)                         0.00920415
time/sac training (s)                   11.5607
time/saving (s)                          0.0034294
time/training (s)                        2.228e-05
time/epoch (s)                          12.8365
time/total (s)                         776.688
Epoch                                   59
----------------------------------  ---------------
2022-09-09 20:06:00.020248 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 60 finished
----------------------------------  ---------------
epoch                                   60
replay_buffer/size                   62000
trainer/num train calls              61000
trainer/QF1 Loss                         0.00278657
trainer/QF2 Loss                         0.00279828
trainer/Policy Loss                     -6.92168
trainer/Q1 Predictions Mean              6.9052
trainer/Q1 Predictions Std               0.312836
trainer/Q1 Predictions Max               7.69442
trainer/Q1 Predictions Min               5.61966
trainer/Q2 Predictions Mean              6.88852
trainer/Q2 Predictions Std               0.307314
trainer/Q2 Predictions Max               7.705
trainer/Q2 Predictions Min               5.75174
trainer/Q Targets Mean                   6.89543
trainer/Q Targets Std                    0.302706
trainer/Q Targets Max                    7.60582
trainer/Q Targets Min                    5.89821
trainer/Log Pis Mean                     3.17929
trainer/Log Pis Std                      2.12882
trainer/Log Pis Max                      8.76975
trainer/Log Pis Min                     -2.83203
trainer/policy/mean Mean                -0.213962
trainer/policy/mean Std                  0.591073
trainer/policy/mean Max                  0.951201
trainer/policy/mean Min                 -0.99343
trainer/policy/normal/std Mean           0.351567
trainer/policy/normal/std Std            0.279505
trainer/policy/normal/std Max            1.08898
trainer/policy/normal/std Min            0.0296652
trainer/policy/normal/log_std Mean      -1.48107
trainer/policy/normal/log_std Std        1.02486
trainer/policy/normal/log_std Max        0.085244
trainer/policy/normal/log_std Min       -3.51778
trainer/Alpha                            0.0059375
trainer/Alpha Loss                       0.919132
expl/num steps total                 62000
expl/num paths total                    81
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.144679
expl/Actions Std                         0.311016
expl/Actions Max                         0.984612
expl/Actions Min                        -0.992602
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                304002
eval/num paths total                   305
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.194779
eval/Actions Std                         0.366434
eval/Actions Max                         0.841583
eval/Actions Min                        -0.502502
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00323308
time/evaluation sampling (s)             0.950579
time/exploration sampling (s)            0.292894
time/logging (s)                         0.0093417
time/sac training (s)                   11.2483
time/saving (s)                          0.00388837
time/training (s)                        2.854e-05
time/epoch (s)                          12.5083
time/total (s)                         789.468
Epoch                                   60
----------------------------------  ---------------
2022-09-09 20:06:12.922246 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 61 finished
----------------------------------  ---------------
epoch                                   61
replay_buffer/size                   63000
trainer/num train calls              62000
trainer/QF1 Loss                         0.0511199
trainer/QF2 Loss                         0.0653393
trainer/Policy Loss                     -6.68089
trainer/Q1 Predictions Mean              6.65963
trainer/Q1 Predictions Std               0.333849
trainer/Q1 Predictions Max               7.27888
trainer/Q1 Predictions Min               4.55751
trainer/Q2 Predictions Mean              6.65504
trainer/Q2 Predictions Std               0.323844
trainer/Q2 Predictions Max               7.28104
trainer/Q2 Predictions Min               5.04072
trainer/Q Targets Mean                   6.6379
trainer/Q Targets Std                    0.466857
trainer/Q Targets Max                    7.28046
trainer/Q Targets Min                    1
trainer/Log Pis Mean                     3.25326
trainer/Log Pis Std                      2.10434
trainer/Log Pis Max                      8.97809
trainer/Log Pis Min                     -2.32608
trainer/policy/mean Mean                -0.146346
trainer/policy/mean Std                  0.622759
trainer/policy/mean Max                  0.995134
trainer/policy/mean Min                 -0.989646
trainer/policy/normal/std Mean           0.342771
trainer/policy/normal/std Std            0.283114
trainer/policy/normal/std Max            1.31514
trainer/policy/normal/std Min            0.0283313
trainer/policy/normal/log_std Mean      -1.51
trainer/policy/normal/log_std Std        1.01787
trainer/policy/normal/log_std Max        0.273943
trainer/policy/normal/log_std Min       -3.56379
trainer/Alpha                            0.00509402
trainer/Alpha Loss                       1.33712
expl/num steps total                 63000
expl/num paths total                    82
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.198388
expl/Actions Std                         0.493267
expl/Actions Max                         0.992122
expl/Actions Min                        -0.999761
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                309002
eval/num paths total                   310
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.173068
eval/Actions Std                         0.513613
eval/Actions Max                         0.900924
eval/Actions Min                        -0.979191
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00328502
time/evaluation sampling (s)             0.971408
time/exploration sampling (s)            0.295038
time/logging (s)                         0.00916665
time/sac training (s)                   11.345
time/saving (s)                          0.00340173
time/training (s)                        2.025e-05
time/epoch (s)                          12.6273
time/total (s)                         802.359
Epoch                                   61
----------------------------------  ---------------
2022-09-09 20:06:26.020888 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 62 finished
----------------------------------  ----------------
epoch                                   62
replay_buffer/size                   64000
trainer/num train calls              63000
trainer/QF1 Loss                         0.000952168
trainer/QF2 Loss                         0.00137318
trainer/Policy Loss                     -6.39035
trainer/Q1 Predictions Mean              6.37843
trainer/Q1 Predictions Std               0.28673
trainer/Q1 Predictions Max               7.00392
trainer/Q1 Predictions Min               5.85397
trainer/Q2 Predictions Mean              6.37174
trainer/Q2 Predictions Std               0.287746
trainer/Q2 Predictions Max               6.97197
trainer/Q2 Predictions Min               5.83776
trainer/Q Targets Mean                   6.37499
trainer/Q Targets Std                    0.289828
trainer/Q Targets Max                    6.99497
trainer/Q Targets Min                    5.81758
trainer/Log Pis Mean                     3.05859
trainer/Log Pis Std                      2.25147
trainer/Log Pis Max                      8.66817
trainer/Log Pis Min                     -2.89292
trainer/policy/mean Mean                -0.25567
trainer/policy/mean Std                  0.587295
trainer/policy/mean Max                  0.989797
trainer/policy/mean Min                 -0.992053
trainer/policy/normal/std Mean           0.367369
trainer/policy/normal/std Std            0.294828
trainer/policy/normal/std Max            1.30147
trainer/policy/normal/std Min            0.0274002
trainer/policy/normal/log_std Mean      -1.46517
trainer/policy/normal/log_std Std        1.07069
trainer/policy/normal/log_std Max        0.263496
trainer/policy/normal/log_std Min       -3.5972
trainer/Alpha                            0.00508708
trainer/Alpha Loss                       0.309439
expl/num steps total                 64000
expl/num paths total                    83
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.111129
expl/Actions Std                         0.589616
expl/Actions Max                         0.994741
expl/Actions Min                        -0.998688
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                314002
eval/num paths total                   315
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0494039
eval/Actions Std                         0.437369
eval/Actions Max                         0.858078
eval/Actions Min                        -0.986462
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0049076
time/evaluation sampling (s)             0.934629
time/exploration sampling (s)            0.310868
time/logging (s)                         0.00922856
time/sac training (s)                   11.5538
time/saving (s)                          0.00379057
time/training (s)                        3.222e-05
time/epoch (s)                          12.8173
time/total (s)                         815.448
Epoch                                   62
----------------------------------  ----------------
2022-09-09 20:06:39.000814 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 63 finished
----------------------------------  ----------------
epoch                                   63
replay_buffer/size                   65000
trainer/num train calls              64000
trainer/QF1 Loss                         0.000931004
trainer/QF2 Loss                         0.00110822
trainer/Policy Loss                     -6.14016
trainer/Q1 Predictions Mean              6.12885
trainer/Q1 Predictions Std               0.321418
trainer/Q1 Predictions Max               6.7743
trainer/Q1 Predictions Min               5.4434
trainer/Q2 Predictions Mean              6.12418
trainer/Q2 Predictions Std               0.32565
trainer/Q2 Predictions Max               6.73928
trainer/Q2 Predictions Min               5.39215
trainer/Q Targets Mean                   6.12806
trainer/Q Targets Std                    0.320157
trainer/Q Targets Max                    6.72844
trainer/Q Targets Min                    5.48273
trainer/Log Pis Mean                     3.01815
trainer/Log Pis Std                      2.19574
trainer/Log Pis Max                      7.88238
trainer/Log Pis Min                     -5.67265
trainer/policy/mean Mean                -0.160829
trainer/policy/mean Std                  0.618094
trainer/policy/mean Max                  0.994004
trainer/policy/mean Min                 -0.991062
trainer/policy/normal/std Mean           0.387861
trainer/policy/normal/std Std            0.329216
trainer/policy/normal/std Max            1.80484
trainer/policy/normal/std Min            0.0206009
trainer/policy/normal/log_std Mean      -1.44631
trainer/policy/normal/log_std Std        1.11724
trainer/policy/normal/log_std Max        0.590475
trainer/policy/normal/log_std Min       -3.88242
trainer/Alpha                            0.00470304
trainer/Alpha Loss                       0.0972519
expl/num steps total                 65000
expl/num paths total                    84
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0183392
expl/Actions Std                         0.650061
expl/Actions Max                         0.998199
expl/Actions Min                        -0.999853
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                319002
eval/num paths total                   320
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.058616
eval/Actions Std                         0.498146
eval/Actions Max                         0.821295
eval/Actions Min                        -0.959387
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00328928
time/evaluation sampling (s)             0.939519
time/exploration sampling (s)            0.308158
time/logging (s)                         0.00927543
time/sac training (s)                   11.4343
time/saving (s)                          0.00342944
time/training (s)                        2.23e-05
time/epoch (s)                          12.698
time/total (s)                         828.418
Epoch                                   63
----------------------------------  ----------------
2022-09-09 20:06:52.076399 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 64 finished
----------------------------------  ---------------
epoch                                   64
replay_buffer/size                   66000
trainer/num train calls              65000
trainer/QF1 Loss                         0.00140216
trainer/QF2 Loss                         0.00113561
trainer/Policy Loss                     -5.90876
trainer/Q1 Predictions Mean              5.90285
trainer/Q1 Predictions Std               0.361944
trainer/Q1 Predictions Max               6.51414
trainer/Q1 Predictions Min               4.92691
trainer/Q2 Predictions Mean              5.9008
trainer/Q2 Predictions Std               0.36107
trainer/Q2 Predictions Max               6.53375
trainer/Q2 Predictions Min               5.16764
trainer/Q Targets Mean                   5.89031
trainer/Q Targets Std                    0.358633
trainer/Q Targets Max                    6.48053
trainer/Q Targets Min                    5.25119
trainer/Log Pis Mean                     3.28881
trainer/Log Pis Std                      2.11312
trainer/Log Pis Max                      7.7843
trainer/Log Pis Min                     -4.48687
trainer/policy/mean Mean                -0.10933
trainer/policy/mean Std                  0.633587
trainer/policy/mean Max                  0.989255
trainer/policy/mean Min                 -0.98727
trainer/policy/normal/std Mean           0.321004
trainer/policy/normal/std Std            0.259795
trainer/policy/normal/std Max            1.18795
trainer/policy/normal/std Min            0.023721
trainer/policy/normal/log_std Mean      -1.59077
trainer/policy/normal/log_std Std        1.05345
trainer/policy/normal/log_std Max        0.172228
trainer/policy/normal/log_std Min       -3.74139
trainer/Alpha                            0.00430642
trainer/Alpha Loss                       1.57334
expl/num steps total                 66000
expl/num paths total                    85
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.23599
expl/Actions Std                         0.599284
expl/Actions Max                         0.993917
expl/Actions Min                        -0.992743
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                324002
eval/num paths total                   325
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0289915
eval/Actions Std                         0.519565
eval/Actions Max                         0.970515
eval/Actions Min                        -0.991524
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00498006
time/evaluation sampling (s)             0.936826
time/exploration sampling (s)            0.309347
time/logging (s)                         0.00956081
time/sac training (s)                   11.5251
time/saving (s)                          0.00371787
time/training (s)                        1.938e-05
time/epoch (s)                          12.7896
time/total (s)                         841.484
Epoch                                   64
----------------------------------  ---------------
2022-09-09 20:07:05.240000 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 65 finished
----------------------------------  ----------------
epoch                                   65
replay_buffer/size                   67000
trainer/num train calls              66000
trainer/QF1 Loss                         0.000726453
trainer/QF2 Loss                         0.000898859
trainer/Policy Loss                     -5.69044
trainer/Q1 Predictions Mean              5.67614
trainer/Q1 Predictions Std               0.339573
trainer/Q1 Predictions Max               6.22229
trainer/Q1 Predictions Min               5.04855
trainer/Q2 Predictions Mean              5.67886
trainer/Q2 Predictions Std               0.340331
trainer/Q2 Predictions Max               6.23712
trainer/Q2 Predictions Min               5.03903
trainer/Q Targets Mean                   5.67582
trainer/Q Targets Std                    0.343989
trainer/Q Targets Max                    6.21535
trainer/Q Targets Min                    5.04519
trainer/Log Pis Mean                     2.82718
trainer/Log Pis Std                      2.22134
trainer/Log Pis Max                      7.24966
trainer/Log Pis Min                     -7.47221
trainer/policy/mean Mean                -0.207595
trainer/policy/mean Std                  0.649973
trainer/policy/mean Max                  0.994743
trainer/policy/mean Min                 -0.98725
trainer/policy/normal/std Mean           0.421358
trainer/policy/normal/std Std            0.357116
trainer/policy/normal/std Max            1.99809
trainer/policy/normal/std Min            0.0284377
trainer/policy/normal/log_std Mean      -1.33028
trainer/policy/normal/log_std Std        1.06525
trainer/policy/normal/log_std Max        0.692189
trainer/policy/normal/log_std Min       -3.56004
trainer/Alpha                            0.00491342
trainer/Alpha Loss                      -0.918695
expl/num steps total                 67000
expl/num paths total                    86
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0387787
expl/Actions Std                         0.631928
expl/Actions Max                         0.993228
expl/Actions Min                        -0.998438
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                329002
eval/num paths total                   330
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.187912
eval/Actions Std                         0.463828
eval/Actions Max                         0.919104
eval/Actions Min                        -0.956377
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00454256
time/evaluation sampling (s)             0.942671
time/exploration sampling (s)            0.326
time/logging (s)                         0.00949306
time/sac training (s)                   11.6035
time/saving (s)                          0.00462067
time/training (s)                        2.951e-05
time/epoch (s)                          12.8909
time/total (s)                         854.637
Epoch                                   65
----------------------------------  ----------------
2022-09-09 20:07:18.556725 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 66 finished
----------------------------------  ---------------
epoch                                   66
replay_buffer/size                   68000
trainer/num train calls              67000
trainer/QF1 Loss                         0.00124599
trainer/QF2 Loss                         0.00121675
trainer/Policy Loss                     -5.44679
trainer/Q1 Predictions Mean              5.42942
trainer/Q1 Predictions Std               0.28572
trainer/Q1 Predictions Max               5.9468
trainer/Q1 Predictions Min               4.82762
trainer/Q2 Predictions Mean              5.44216
trainer/Q2 Predictions Std               0.288232
trainer/Q2 Predictions Max               5.96916
trainer/Q2 Predictions Min               4.83621
trainer/Q Targets Mean                   5.44579
trainer/Q Targets Std                    0.287469
trainer/Q Targets Max                    5.96314
trainer/Q Targets Min                    4.83034
trainer/Log Pis Mean                     3.0852
trainer/Log Pis Std                      2.27934
trainer/Log Pis Max                      8.09016
trainer/Log Pis Min                     -2.74026
trainer/policy/mean Mean                -0.161893
trainer/policy/mean Std                  0.63284
trainer/policy/mean Max                  0.990119
trainer/policy/mean Min                 -0.990222
trainer/policy/normal/std Mean           0.395448
trainer/policy/normal/std Std            0.33644
trainer/policy/normal/std Max            2.62994
trainer/policy/normal/std Min            0.0282988
trainer/policy/normal/log_std Mean      -1.39319
trainer/policy/normal/log_std Std        1.09247
trainer/policy/normal/log_std Max        0.966961
trainer/policy/normal/log_std Min       -3.56494
trainer/Alpha                            0.00413723
trainer/Alpha Loss                       0.467564
expl/num steps total                 68000
expl/num paths total                    87
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.238238
expl/Actions Std                         0.358189
expl/Actions Max                         0.805388
expl/Actions Min                        -0.97127
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                334002
eval/num paths total                   335
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0130985
eval/Actions Std                         0.53634
eval/Actions Max                         0.941186
eval/Actions Min                        -0.982889
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00323117
time/evaluation sampling (s)             0.928592
time/exploration sampling (s)            0.316485
time/logging (s)                         0.00965399
time/sac training (s)                   11.7446
time/saving (s)                          0.00363273
time/training (s)                        2.026e-05
time/epoch (s)                          13.0062
time/total (s)                         867.943
Epoch                                   66
----------------------------------  ---------------
2022-09-09 20:07:32.087882 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 67 finished
----------------------------------  ---------------
epoch                                   67
replay_buffer/size                   69000
trainer/num train calls              68000
trainer/QF1 Loss                         0.00217168
trainer/QF2 Loss                         0.00132803
trainer/Policy Loss                     -5.33597
trainer/Q1 Predictions Mean              5.31264
trainer/Q1 Predictions Std               0.286851
trainer/Q1 Predictions Max               5.71379
trainer/Q1 Predictions Min               4.1709
trainer/Q2 Predictions Mean              5.30731
trainer/Q2 Predictions Std               0.282316
trainer/Q2 Predictions Max               5.72791
trainer/Q2 Predictions Min               4.5481
trainer/Q Targets Mean                   5.31878
trainer/Q Targets Std                    0.281583
trainer/Q Targets Max                    5.73626
trainer/Q Targets Min                    4.63203
trainer/Log Pis Mean                     2.99288
trainer/Log Pis Std                      1.99986
trainer/Log Pis Max                      7.48685
trainer/Log Pis Min                     -3.31696
trainer/policy/mean Mean                -0.0110241
trainer/policy/mean Std                  0.663182
trainer/policy/mean Max                  0.996776
trainer/policy/mean Min                 -0.987195
trainer/policy/normal/std Mean           0.37248
trainer/policy/normal/std Std            0.269295
trainer/policy/normal/std Max            1.19512
trainer/policy/normal/std Min            0.0303516
trainer/policy/normal/log_std Mean      -1.38902
trainer/policy/normal/log_std Std        1.01421
trainer/policy/normal/log_std Max        0.178246
trainer/policy/normal/log_std Min       -3.49491
trainer/Alpha                            0.00445324
trainer/Alpha Loss                      -0.0385661
expl/num steps total                 69000
expl/num paths total                    88
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0649133
expl/Actions Std                         0.24733
expl/Actions Max                         0.897465
expl/Actions Min                        -0.916527
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                339002
eval/num paths total                   340
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0842688
eval/Actions Std                         0.429441
eval/Actions Max                         0.996628
eval/Actions Min                        -0.978902
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00328788
time/evaluation sampling (s)             0.935739
time/exploration sampling (s)            0.31949
time/logging (s)                         0.00949799
time/sac training (s)                   11.9174
time/saving (s)                          0.00495434
time/training (s)                        2.945e-05
time/epoch (s)                          13.1904
time/total (s)                         881.461
Epoch                                   67
----------------------------------  ---------------
2022-09-09 20:07:45.412760 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 68 finished
----------------------------------  ---------------
epoch                                   68
replay_buffer/size                   70000
trainer/num train calls              69000
trainer/QF1 Loss                         0.002102
trainer/QF2 Loss                         0.00184566
trainer/Policy Loss                     -5.20448
trainer/Q1 Predictions Mean              5.16716
trainer/Q1 Predictions Std               0.244284
trainer/Q1 Predictions Max               5.5935
trainer/Q1 Predictions Min               4.09814
trainer/Q2 Predictions Mean              5.16571
trainer/Q2 Predictions Std               0.241177
trainer/Q2 Predictions Max               5.58729
trainer/Q2 Predictions Min               4.1992
trainer/Q Targets Mean                   5.17531
trainer/Q Targets Std                    0.236119
trainer/Q Targets Max                    5.56575
trainer/Q Targets Min                    4.54602
trainer/Log Pis Mean                     3.36456
trainer/Log Pis Std                      1.75367
trainer/Log Pis Max                     10.5531
trainer/Log Pis Min                     -1.79232
trainer/policy/mean Mean                -0.0651867
trainer/policy/mean Std                  0.648234
trainer/policy/mean Max                  0.995348
trainer/policy/mean Min                 -0.991219
trainer/policy/normal/std Mean           0.308148
trainer/policy/normal/std Std            0.220749
trainer/policy/normal/std Max            0.83083
trainer/policy/normal/std Min            0.0346435
trainer/policy/normal/log_std Mean      -1.54615
trainer/policy/normal/log_std Std        0.950909
trainer/policy/normal/log_std Max       -0.185331
trainer/policy/normal/log_std Min       -3.36265
trainer/Alpha                            0.00447243
trainer/Alpha Loss                       1.97222
expl/num steps total                 70000
expl/num paths total                    89
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.00427894
expl/Actions Std                         0.324653
expl/Actions Max                         0.968388
expl/Actions Min                        -0.9908
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                344002
eval/num paths total                   345
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.101528
eval/Actions Std                         0.310842
eval/Actions Max                         0.993306
eval/Actions Min                        -0.986794
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00510703
time/evaluation sampling (s)             0.943434
time/exploration sampling (s)            0.332066
time/logging (s)                         0.0096123
time/sac training (s)                   11.7229
time/saving (s)                          0.00331101
time/training (s)                        2.036e-05
time/epoch (s)                          13.0164
time/total (s)                         894.775
Epoch                                   68
----------------------------------  ---------------
2022-09-09 20:07:58.637647 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 69 finished
----------------------------------  ---------------
epoch                                   69
replay_buffer/size                   71000
trainer/num train calls              70000
trainer/QF1 Loss                         0.0106747
trainer/QF2 Loss                         0.00786536
trainer/Policy Loss                     -5.12993
trainer/Q1 Predictions Mean              5.10167
trainer/Q1 Predictions Std               0.246217
trainer/Q1 Predictions Max               5.52961
trainer/Q1 Predictions Min               3.28238
trainer/Q2 Predictions Mean              5.08943
trainer/Q2 Predictions Std               0.239799
trainer/Q2 Predictions Max               5.57311
trainer/Q2 Predictions Min               3.54799
trainer/Q Targets Mean                   5.09327
trainer/Q Targets Std                    0.212041
trainer/Q Targets Max                    5.47584
trainer/Q Targets Min                    4.63575
trainer/Log Pis Mean                     3.14266
trainer/Log Pis Std                      2.00385
trainer/Log Pis Max                      7.88927
trainer/Log Pis Min                     -3.33966
trainer/policy/mean Mean                -0.0557073
trainer/policy/mean Std                  0.651454
trainer/policy/mean Max                  0.984208
trainer/policy/mean Min                 -0.993897
trainer/policy/normal/std Mean           0.335256
trainer/policy/normal/std Std            0.238538
trainer/policy/normal/std Max            0.985696
trainer/policy/normal/std Min            0.035366
trainer/policy/normal/log_std Mean      -1.45101
trainer/policy/normal/log_std Std        0.93748
trainer/policy/normal/log_std Max       -0.014407
trainer/policy/normal/log_std Min       -3.342
trainer/Alpha                            0.004243
trainer/Alpha Loss                       0.779295
expl/num steps total                 71000
expl/num paths total                    90
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.038678
expl/Actions Std                         0.328853
expl/Actions Max                         0.987573
expl/Actions Min                        -0.99941
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                349002
eval/num paths total                   350
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.161918
eval/Actions Std                         0.33193
eval/Actions Max                         0.992337
eval/Actions Min                        -0.992743
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00516599
time/evaluation sampling (s)             0.93821
time/exploration sampling (s)            0.30406
time/logging (s)                         0.0130833
time/sac training (s)                   11.6534
time/saving (s)                          0.00468209
time/training (s)                        2.576e-05
time/epoch (s)                          12.9186
time/total (s)                         907.992
Epoch                                   69
----------------------------------  ---------------
2022-09-09 20:08:11.952300 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 70 finished
----------------------------------  ----------------
epoch                                   70
replay_buffer/size                   72000
trainer/num train calls              71000
trainer/QF1 Loss                         0.000684683
trainer/QF2 Loss                         0.000518056
trainer/Policy Loss                     -4.98169
trainer/Q1 Predictions Mean              4.95834
trainer/Q1 Predictions Std               0.211404
trainer/Q1 Predictions Max               5.33339
trainer/Q1 Predictions Min               4.32159
trainer/Q2 Predictions Mean              4.96038
trainer/Q2 Predictions Std               0.211065
trainer/Q2 Predictions Max               5.31802
trainer/Q2 Predictions Min               4.34452
trainer/Q Targets Mean                   4.95382
trainer/Q Targets Std                    0.212819
trainer/Q Targets Max                    5.31325
trainer/Q Targets Min                    4.42315
trainer/Log Pis Mean                     3.10011
trainer/Log Pis Std                      1.81235
trainer/Log Pis Max                      7.09828
trainer/Log Pis Min                     -3.30212
trainer/policy/mean Mean                -0.0986463
trainer/policy/mean Std                  0.629194
trainer/policy/mean Max                  0.987675
trainer/policy/mean Min                 -0.993583
trainer/policy/normal/std Mean           0.321945
trainer/policy/normal/std Std            0.240086
trainer/policy/normal/std Max            1.0136
trainer/policy/normal/std Min            0.0363411
trainer/policy/normal/log_std Mean      -1.52445
trainer/policy/normal/log_std Std        0.980145
trainer/policy/normal/log_std Max        0.0135081
trainer/policy/normal/log_std Min       -3.31481
trainer/Alpha                            0.00415223
trainer/Alpha Loss                       0.549001
expl/num steps total                 72000
expl/num paths total                    91
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.157581
expl/Actions Std                         0.244871
expl/Actions Max                         0.938525
expl/Actions Min                        -0.924097
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                354002
eval/num paths total                   355
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0960668
eval/Actions Std                         0.413003
eval/Actions Max                         0.838288
eval/Actions Min                        -0.993092
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00333254
time/evaluation sampling (s)             0.936131
time/exploration sampling (s)            0.329064
time/logging (s)                         0.00912354
time/sac training (s)                   11.7208
time/saving (s)                          0.00338637
time/training (s)                        2.232e-05
time/epoch (s)                          13.0018
time/total (s)                         921.29
Epoch                                   70
----------------------------------  ----------------
2022-09-09 20:08:24.900261 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 71 finished
----------------------------------  ----------------
epoch                                   71
replay_buffer/size                   73000
trainer/num train calls              72000
trainer/QF1 Loss                         0.000970172
trainer/QF2 Loss                         0.000702388
trainer/Policy Loss                     -4.84968
trainer/Q1 Predictions Mean              4.84497
trainer/Q1 Predictions Std               0.222162
trainer/Q1 Predictions Max               5.23557
trainer/Q1 Predictions Min               4.43766
trainer/Q2 Predictions Mean              4.82838
trainer/Q2 Predictions Std               0.231182
trainer/Q2 Predictions Max               5.21555
trainer/Q2 Predictions Min               4.40729
trainer/Q Targets Mean                   4.82379
trainer/Q Targets Std                    0.226727
trainer/Q Targets Max                    5.19741
trainer/Q Targets Min                    4.4357
trainer/Log Pis Mean                     2.97199
trainer/Log Pis Std                      1.81876
trainer/Log Pis Max                      7.64636
trainer/Log Pis Min                     -3.50274
trainer/policy/mean Mean                -0.00757784
trainer/policy/mean Std                  0.625289
trainer/policy/mean Max                  0.977481
trainer/policy/mean Min                 -0.994146
trainer/policy/normal/std Mean           0.314864
trainer/policy/normal/std Std            0.243224
trainer/policy/normal/std Max            1.04452
trainer/policy/normal/std Min            0.0324147
trainer/policy/normal/log_std Mean      -1.55444
trainer/policy/normal/log_std Std        0.980407
trainer/policy/normal/log_std Max        0.0435595
trainer/policy/normal/log_std Min       -3.42914
trainer/Alpha                            0.00413224
trainer/Alpha Loss                      -0.153754
expl/num steps total                 73000
expl/num paths total                    92
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.21201
expl/Actions Std                         0.289362
expl/Actions Max                         0.95471
expl/Actions Min                        -0.75028
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                359002
eval/num paths total                   360
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0792605
eval/Actions Std                         0.458949
eval/Actions Max                         0.853747
eval/Actions Min                        -0.993076
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00326377
time/evaluation sampling (s)             0.930788
time/exploration sampling (s)            0.318107
time/logging (s)                         0.00912234
time/sac training (s)                   11.4074
time/saving (s)                          0.00345916
time/training (s)                        2.018e-05
time/epoch (s)                          12.6722
time/total (s)                         934.229
Epoch                                   71
----------------------------------  ----------------
2022-09-09 20:08:37.658060 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 72 finished
----------------------------------  ----------------
epoch                                   72
replay_buffer/size                   74000
trainer/num train calls              73000
trainer/QF1 Loss                         0.000783953
trainer/QF2 Loss                         0.00104852
trainer/Policy Loss                     -4.61968
trainer/Q1 Predictions Mean              4.61555
trainer/Q1 Predictions Std               0.251401
trainer/Q1 Predictions Max               5.11187
trainer/Q1 Predictions Min               4.23207
trainer/Q2 Predictions Mean              4.60419
trainer/Q2 Predictions Std               0.252193
trainer/Q2 Predictions Max               5.06972
trainer/Q2 Predictions Min               4.13592
trainer/Q Targets Mean                   4.62017
trainer/Q Targets Std                    0.257517
trainer/Q Targets Max                    5.087
trainer/Q Targets Min                    4.14473
trainer/Log Pis Mean                     2.84745
trainer/Log Pis Std                      1.94108
trainer/Log Pis Max                      7.32323
trainer/Log Pis Min                     -4.27566
trainer/policy/mean Mean                -0.0175134
trainer/policy/mean Std                  0.614149
trainer/policy/mean Max                  0.966965
trainer/policy/mean Min                 -0.992114
trainer/policy/normal/std Mean           0.306748
trainer/policy/normal/std Std            0.232609
trainer/policy/normal/std Max            0.987515
trainer/policy/normal/std Min            0.0347606
trainer/policy/normal/log_std Mean      -1.57198
trainer/policy/normal/log_std Std        0.971323
trainer/policy/normal/log_std Max       -0.0125636
trainer/policy/normal/log_std Min       -3.35927
trainer/Alpha                            0.003816
trainer/Alpha Loss                      -0.849482
expl/num steps total                 74000
expl/num paths total                    93
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.101728
expl/Actions Std                         0.342715
expl/Actions Max                         0.977208
expl/Actions Min                        -0.969181
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                364002
eval/num paths total                   365
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.113052
eval/Actions Std                         0.196179
eval/Actions Max                         0.974298
eval/Actions Min                        -0.770991
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00504931
time/evaluation sampling (s)             0.934694
time/exploration sampling (s)            0.305266
time/logging (s)                         0.00970427
time/sac training (s)                   11.2255
time/saving (s)                          0.00463113
time/training (s)                        2.741e-05
time/epoch (s)                          12.4849
time/total (s)                         946.977
Epoch                                   72
----------------------------------  ----------------
2022-09-09 20:08:50.420645 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 73 finished
----------------------------------  ----------------
epoch                                   73
replay_buffer/size                   75000
trainer/num train calls              74000
trainer/QF1 Loss                         0.00101134
trainer/QF2 Loss                         0.000515011
trainer/Policy Loss                     -4.4701
trainer/Q1 Predictions Mean              4.45698
trainer/Q1 Predictions Std               0.293126
trainer/Q1 Predictions Max               4.94075
trainer/Q1 Predictions Min               3.68594
trainer/Q2 Predictions Mean              4.45518
trainer/Q2 Predictions Std               0.29202
trainer/Q2 Predictions Max               4.9322
trainer/Q2 Predictions Min               3.93501
trainer/Q Targets Mean                   4.45297
trainer/Q Targets Std                    0.28934
trainer/Q Targets Max                    4.92731
trainer/Q Targets Min                    4.01193
trainer/Log Pis Mean                     2.84824
trainer/Log Pis Std                      2.29671
trainer/Log Pis Max                      7.8167
trainer/Log Pis Min                     -5.42015
trainer/policy/mean Mean                 0.0520753
trainer/policy/mean Std                  0.617048
trainer/policy/mean Max                  0.987443
trainer/policy/mean Min                 -0.990115
trainer/policy/normal/std Mean           0.317144
trainer/policy/normal/std Std            0.22731
trainer/policy/normal/std Max            1.06684
trainer/policy/normal/std Min            0.0264966
trainer/policy/normal/log_std Mean      -1.53793
trainer/policy/normal/log_std Std        1.00223
trainer/policy/normal/log_std Max        0.0647041
trainer/policy/normal/log_std Min       -3.63074
trainer/Alpha                            0.00331188
trainer/Alpha Loss                      -0.866602
expl/num steps total                 75000
expl/num paths total                    94
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.339985
expl/Actions Std                         0.386661
expl/Actions Max                         0.950917
expl/Actions Min                        -0.862607
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                369002
eval/num paths total                   370
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.164199
eval/Actions Std                         0.267337
eval/Actions Max                         0.955817
eval/Actions Min                        -0.983416
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00480594
time/evaluation sampling (s)             0.940931
time/exploration sampling (s)            0.316739
time/logging (s)                         0.00963204
time/sac training (s)                   11.208
time/saving (s)                          0.00464598
time/training (s)                        2.68e-05
time/epoch (s)                          12.4848
time/total (s)                         959.73
Epoch                                   73
----------------------------------  ----------------
2022-09-09 20:09:03.728022 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 74 finished
----------------------------------  ----------------
epoch                                   74
replay_buffer/size                   76000
trainer/num train calls              75000
trainer/QF1 Loss                         0.000340059
trainer/QF2 Loss                         0.000451468
trainer/Policy Loss                     -4.31465
trainer/Q1 Predictions Mean              4.30577
trainer/Q1 Predictions Std               0.314017
trainer/Q1 Predictions Max               4.83066
trainer/Q1 Predictions Min               3.79758
trainer/Q2 Predictions Mean              4.30218
trainer/Q2 Predictions Std               0.309665
trainer/Q2 Predictions Max               4.84602
trainer/Q2 Predictions Min               3.81224
trainer/Q Targets Mean                   4.30254
trainer/Q Targets Std                    0.316006
trainer/Q Targets Max                    4.8396
trainer/Q Targets Min                    3.80409
trainer/Log Pis Mean                     2.57965
trainer/Log Pis Std                      2.22434
trainer/Log Pis Max                      7.09961
trainer/Log Pis Min                     -5.12426
trainer/policy/mean Mean                 0.0116035
trainer/policy/mean Std                  0.638608
trainer/policy/mean Max                  0.990891
trainer/policy/mean Min                 -0.987219
trainer/policy/normal/std Mean           0.385979
trainer/policy/normal/std Std            0.312299
trainer/policy/normal/std Max            1.20627
trainer/policy/normal/std Min            0.0242367
trainer/policy/normal/log_std Mean      -1.40776
trainer/policy/normal/log_std Std        1.07564
trainer/policy/normal/log_std Max        0.187532
trainer/policy/normal/log_std Min       -3.71989
trainer/Alpha                            0.00332513
trainer/Alpha Loss                      -2.39863
expl/num steps total                 76000
expl/num paths total                    95
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.219905
expl/Actions Std                         0.459489
expl/Actions Max                         0.999422
expl/Actions Min                        -0.998021
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                374002
eval/num paths total                   375
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0977292
eval/Actions Std                         0.472244
eval/Actions Max                         0.975854
eval/Actions Min                        -0.987597
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00495075
time/evaluation sampling (s)             0.931795
time/exploration sampling (s)            0.338405
time/logging (s)                         0.00957887
time/sac training (s)                   11.7023
time/saving (s)                          0.00490222
time/training (s)                        2.967e-05
time/epoch (s)                          12.992
time/total (s)                         973.025
Epoch                                   74
----------------------------------  ----------------
2022-09-09 20:09:16.648312 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 75 finished
----------------------------------  ----------------
epoch                                   75
replay_buffer/size                   77000
trainer/num train calls              76000
trainer/QF1 Loss                         0.000495632
trainer/QF2 Loss                         0.000492129
trainer/Policy Loss                     -4.1633
trainer/Q1 Predictions Mean              4.15729
trainer/Q1 Predictions Std               0.334991
trainer/Q1 Predictions Max               4.6963
trainer/Q1 Predictions Min               3.61195
trainer/Q2 Predictions Mean              4.15671
trainer/Q2 Predictions Std               0.34347
trainer/Q2 Predictions Max               4.71018
trainer/Q2 Predictions Min               3.60182
trainer/Q Targets Mean                   4.15317
trainer/Q Targets Std                    0.337912
trainer/Q Targets Max                    4.68935
trainer/Q Targets Min                    3.62442
trainer/Log Pis Mean                     2.96138
trainer/Log Pis Std                      2.2734
trainer/Log Pis Max                      7.5331
trainer/Log Pis Min                     -4.77907
trainer/policy/mean Mean                -0.101412
trainer/policy/mean Std                  0.671444
trainer/policy/mean Max                  0.985205
trainer/policy/mean Min                 -0.992815
trainer/policy/normal/std Mean           0.416875
trainer/policy/normal/std Std            0.297515
trainer/policy/normal/std Max            1.28786
trainer/policy/normal/std Min            0.0200305
trainer/policy/normal/log_std Mean      -1.28352
trainer/policy/normal/log_std Std        1.05859
trainer/policy/normal/log_std Max        0.252984
trainer/policy/normal/log_std Min       -3.9105
trainer/Alpha                            0.00279121
trainer/Alpha Loss                      -0.227136
expl/num steps total                 77000
expl/num paths total                    96
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0993289
expl/Actions Std                         0.37217
expl/Actions Max                         0.857281
expl/Actions Min                        -0.97888
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                379002
eval/num paths total                   380
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0402669
eval/Actions Std                         0.357367
eval/Actions Max                         0.89463
eval/Actions Min                        -0.99056
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00501442
time/evaluation sampling (s)             0.936064
time/exploration sampling (s)            0.297989
time/logging (s)                         0.00967733
time/sac training (s)                   11.3883
time/saving (s)                          0.00481092
time/training (s)                        3.968e-05
time/epoch (s)                          12.6419
time/total (s)                         985.936
Epoch                                   75
----------------------------------  ----------------
2022-09-09 20:09:29.254621 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 76 finished
----------------------------------  ----------------
epoch                                   76
replay_buffer/size                   78000
trainer/num train calls              77000
trainer/QF1 Loss                         0.000759762
trainer/QF2 Loss                         0.00127058
trainer/Policy Loss                     -4.04995
trainer/Q1 Predictions Mean              4.04423
trainer/Q1 Predictions Std               0.365864
trainer/Q1 Predictions Max               4.58423
trainer/Q1 Predictions Min               3.43731
trainer/Q2 Predictions Mean              4.04954
trainer/Q2 Predictions Std               0.366579
trainer/Q2 Predictions Max               4.60089
trainer/Q2 Predictions Min               3.4419
trainer/Q Targets Mean                   4.03296
trainer/Q Targets Std                    0.365408
trainer/Q Targets Max                    4.55441
trainer/Q Targets Min                    3.42541
trainer/Log Pis Mean                     2.5076
trainer/Log Pis Std                      2.4689
trainer/Log Pis Max                      9.12537
trainer/Log Pis Min                     -5.14188
trainer/policy/mean Mean                -0.174748
trainer/policy/mean Std                  0.639638
trainer/policy/mean Max                  0.977222
trainer/policy/mean Min                 -0.99418
trainer/policy/normal/std Mean           0.434924
trainer/policy/normal/std Std            0.279909
trainer/policy/normal/std Max            1.21773
trainer/policy/normal/std Min            0.0248964
trainer/policy/normal/log_std Mean      -1.15488
trainer/policy/normal/log_std Std        0.932347
trainer/policy/normal/log_std Max        0.196991
trainer/policy/normal/log_std Min       -3.69303
trainer/Alpha                            0.00286187
trainer/Alpha Loss                      -2.88365
expl/num steps total                 78000
expl/num paths total                    97
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0478375
expl/Actions Std                         0.500696
expl/Actions Max                         0.99442
expl/Actions Min                        -0.986245
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                384002
eval/num paths total                   385
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0962017
eval/Actions Std                         0.193947
eval/Actions Max                         0.953761
eval/Actions Min                        -0.992835
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00330073
time/evaluation sampling (s)             0.939752
time/exploration sampling (s)            0.308414
time/logging (s)                         0.00928795
time/sac training (s)                   11.0795
time/saving (s)                          0.00331509
time/training (s)                        2.015e-05
time/epoch (s)                          12.3436
time/total (s)                         998.532
Epoch                                   76
----------------------------------  ----------------
2022-09-09 20:09:42.454451 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 77 finished
----------------------------------  ----------------
epoch                                   77
replay_buffer/size                   79000
trainer/num train calls              78000
trainer/QF1 Loss                         0.000373503
trainer/QF2 Loss                         0.000762666
trainer/Policy Loss                     -3.86986
trainer/Q1 Predictions Mean              3.87048
trainer/Q1 Predictions Std               0.351049
trainer/Q1 Predictions Max               4.44901
trainer/Q1 Predictions Min               3.24421
trainer/Q2 Predictions Mean              3.88056
trainer/Q2 Predictions Std               0.357787
trainer/Q2 Predictions Max               4.45289
trainer/Q2 Predictions Min               3.23544
trainer/Q Targets Mean                   3.87344
trainer/Q Targets Std                    0.353632
trainer/Q Targets Max                    4.42487
trainer/Q Targets Min                    3.24249
trainer/Log Pis Mean                     3.23232
trainer/Log Pis Std                      2.29147
trainer/Log Pis Max                      8.48639
trainer/Log Pis Min                     -4.03221
trainer/policy/mean Mean                -0.171506
trainer/policy/mean Std                  0.677337
trainer/policy/mean Max                  0.993894
trainer/policy/mean Min                 -0.992653
trainer/policy/normal/std Mean           0.422184
trainer/policy/normal/std Std            0.291742
trainer/policy/normal/std Max            1.61276
trainer/policy/normal/std Min            0.0271345
trainer/policy/normal/log_std Mean      -1.23222
trainer/policy/normal/log_std Std        0.985197
trainer/policy/normal/log_std Max        0.477945
trainer/policy/normal/log_std Min       -3.60695
trainer/Alpha                            0.00283002
trainer/Alpha Loss                       1.36312
expl/num steps total                 79000
expl/num paths total                    98
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.217366
expl/Actions Std                         0.506923
expl/Actions Max                         0.998549
expl/Actions Min                        -0.99515
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                389002
eval/num paths total                   390
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.233347
eval/Actions Std                         0.225672
eval/Actions Max                         0.978746
eval/Actions Min                        -0.993364
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00327834
time/evaluation sampling (s)             0.950471
time/exploration sampling (s)            0.309536
time/logging (s)                         0.00914594
time/sac training (s)                   11.6234
time/saving (s)                          0.00347667
time/training (s)                        4.172e-05
time/epoch (s)                          12.8993
time/total (s)                        1011.72
Epoch                                   77
----------------------------------  ----------------
2022-09-09 20:09:55.852269 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 78 finished
----------------------------------  ----------------
epoch                                   78
replay_buffer/size                   80000
trainer/num train calls              79000
trainer/QF1 Loss                         0.000261551
trainer/QF2 Loss                         0.000767905
trainer/Policy Loss                     -3.80659
trainer/Q1 Predictions Mean              3.78204
trainer/Q1 Predictions Std               0.300704
trainer/Q1 Predictions Max               4.26476
trainer/Q1 Predictions Min               3.32328
trainer/Q2 Predictions Mean              3.78752
trainer/Q2 Predictions Std               0.30262
trainer/Q2 Predictions Max               4.28404
trainer/Q2 Predictions Min               3.31133
trainer/Q Targets Mean                   3.78228
trainer/Q Targets Std                    0.300462
trainer/Q Targets Max                    4.2725
trainer/Q Targets Min                    3.28224
trainer/Log Pis Mean                     3.04384
trainer/Log Pis Std                      1.84811
trainer/Log Pis Max                      7.50398
trainer/Log Pis Min                     -3.75459
trainer/policy/mean Mean                -0.161491
trainer/policy/mean Std                  0.628062
trainer/policy/mean Max                  0.985844
trainer/policy/mean Min                 -0.986015
trainer/policy/normal/std Mean           0.397231
trainer/policy/normal/std Std            0.291081
trainer/policy/normal/std Max            1.117
trainer/policy/normal/std Min            0.0215092
trainer/policy/normal/log_std Mean      -1.32092
trainer/policy/normal/log_std Std        1.01186
trainer/policy/normal/log_std Max        0.110644
trainer/policy/normal/log_std Min       -3.83927
trainer/Alpha                            0.00277736
trainer/Alpha Loss                       0.258061
expl/num steps total                 80000
expl/num paths total                    99
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.00633075
expl/Actions Std                         0.532561
expl/Actions Max                         0.999193
expl/Actions Min                        -0.997093
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                394002
eval/num paths total                   395
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0644943
eval/Actions Std                         0.170702
eval/Actions Max                         0.985589
eval/Actions Min                        -0.982505
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00499667
time/evaluation sampling (s)             0.959876
time/exploration sampling (s)            0.364954
time/logging (s)                         0.0122034
time/sac training (s)                   11.7518
time/saving (s)                          0.00552046
time/training (s)                        8.242e-05
time/epoch (s)                          13.0994
time/total (s)                        1025.11
Epoch                                   78
----------------------------------  ----------------
2022-09-09 20:10:09.254556 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 79 finished
----------------------------------  ---------------
epoch                                   79
replay_buffer/size                   81000
trainer/num train calls              80000
trainer/QF1 Loss                         0.00158188
trainer/QF2 Loss                         0.00107545
trainer/Policy Loss                     -3.70841
trainer/Q1 Predictions Mean              3.69494
trainer/Q1 Predictions Std               0.254932
trainer/Q1 Predictions Max               4.04357
trainer/Q1 Predictions Min               2.75821
trainer/Q2 Predictions Mean              3.69683
trainer/Q2 Predictions Std               0.24977
trainer/Q2 Predictions Max               4.04076
trainer/Q2 Predictions Min               2.89445
trainer/Q Targets Mean                   3.69902
trainer/Q Targets Std                    0.249985
trainer/Q Targets Max                    4.05552
trainer/Q Targets Min                    3.31004
trainer/Log Pis Mean                     3.18823
trainer/Log Pis Std                      2.19299
trainer/Log Pis Max                      7.91095
trainer/Log Pis Min                     -5.1203
trainer/policy/mean Mean                -0.206065
trainer/policy/mean Std                  0.633084
trainer/policy/mean Max                  0.993459
trainer/policy/mean Min                 -0.985829
trainer/policy/normal/std Mean           0.365946
trainer/policy/normal/std Std            0.282065
trainer/policy/normal/std Max            1.56162
trainer/policy/normal/std Min            0.0203602
trainer/policy/normal/log_std Mean      -1.41745
trainer/policy/normal/log_std Std        1.03103
trainer/policy/normal/log_std Max        0.445725
trainer/policy/normal/log_std Min       -3.89417
trainer/Alpha                            0.00241409
trainer/Alpha Loss                       1.13436
expl/num steps total                 81000
expl/num paths total                   100
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.320053
expl/Actions Std                         0.497497
expl/Actions Max                         0.99049
expl/Actions Min                        -0.990034
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                399002
eval/num paths total                   400
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.386668
eval/Actions Std                         0.336751
eval/Actions Max                         0.915892
eval/Actions Min                        -0.981987
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00499861
time/evaluation sampling (s)             0.965399
time/exploration sampling (s)            0.339869
time/logging (s)                         0.00944112
time/sac training (s)                   11.7515
time/saving (s)                          0.00345608
time/training (s)                        2.003e-05
time/epoch (s)                          13.0747
time/total (s)                        1038.5
Epoch                                   79
----------------------------------  ---------------
2022-09-09 20:10:22.258081 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 80 finished
----------------------------------  ----------------
epoch                                   80
replay_buffer/size                   82000
trainer/num train calls              81000
trainer/QF1 Loss                         0.000258811
trainer/QF2 Loss                         0.000496981
trainer/Policy Loss                     -3.59291
trainer/Q1 Predictions Mean              3.58351
trainer/Q1 Predictions Std               0.207805
trainer/Q1 Predictions Max               3.88266
trainer/Q1 Predictions Min               3.14835
trainer/Q2 Predictions Mean              3.58844
trainer/Q2 Predictions Std               0.20722
trainer/Q2 Predictions Max               3.88762
trainer/Q2 Predictions Min               3.16775
trainer/Q Targets Mean                   3.58495
trainer/Q Targets Std                    0.210728
trainer/Q Targets Max                    3.87914
trainer/Q Targets Min                    3.12048
trainer/Log Pis Mean                     2.97923
trainer/Log Pis Std                      2.02411
trainer/Log Pis Max                      7.34021
trainer/Log Pis Min                     -3.19263
trainer/policy/mean Mean                -0.152657
trainer/policy/mean Std                  0.614042
trainer/policy/mean Max                  0.990051
trainer/policy/mean Min                 -0.991233
trainer/policy/normal/std Mean           0.373373
trainer/policy/normal/std Std            0.291017
trainer/policy/normal/std Max            1.41393
trainer/policy/normal/std Min            0.0233739
trainer/policy/normal/log_std Mean      -1.405
trainer/policy/normal/log_std Std        1.02917
trainer/policy/normal/log_std Max        0.346374
trainer/policy/normal/log_std Min       -3.75614
trainer/Alpha                            0.00259281
trainer/Alpha Loss                      -0.123717
expl/num steps total                 82000
expl/num paths total                   101
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.261103
expl/Actions Std                         0.473527
expl/Actions Max                         0.973159
expl/Actions Min                        -0.992994
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                404002
eval/num paths total                   405
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.247069
eval/Actions Std                         0.360972
eval/Actions Max                         0.975153
eval/Actions Min                        -0.992384
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00519861
time/evaluation sampling (s)             0.955105
time/exploration sampling (s)            0.345037
time/logging (s)                         0.00944104
time/sac training (s)                   11.3976
time/saving (s)                          0.00466433
time/training (s)                        2.711e-05
time/epoch (s)                          12.7171
time/total (s)                        1051.49
Epoch                                   80
----------------------------------  ----------------
2022-09-09 20:10:35.762887 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 81 finished
----------------------------------  ----------------
epoch                                   81
replay_buffer/size                   83000
trainer/num train calls              82000
trainer/QF1 Loss                         0.000261097
trainer/QF2 Loss                         0.000441493
trainer/Policy Loss                     -3.45771
trainer/Q1 Predictions Mean              3.44915
trainer/Q1 Predictions Std               0.188831
trainer/Q1 Predictions Max               3.76735
trainer/Q1 Predictions Min               2.77933
trainer/Q2 Predictions Mean              3.45227
trainer/Q2 Predictions Std               0.188175
trainer/Q2 Predictions Max               3.75747
trainer/Q2 Predictions Min               2.67116
trainer/Q Targets Mean                   3.45379
trainer/Q Targets Std                    0.18849
trainer/Q Targets Max                    3.74724
trainer/Q Targets Min                    2.87869
trainer/Log Pis Mean                     2.89823
trainer/Log Pis Std                      2.45289
trainer/Log Pis Max                      8.69229
trainer/Log Pis Min                     -3.4791
trainer/policy/mean Mean                -0.140046
trainer/policy/mean Std                  0.641438
trainer/policy/mean Max                  0.99508
trainer/policy/mean Min                 -0.991082
trainer/policy/normal/std Mean           0.393065
trainer/policy/normal/std Std            0.298244
trainer/policy/normal/std Max            1.73442
trainer/policy/normal/std Min            0.022896
trainer/policy/normal/log_std Mean      -1.30929
trainer/policy/normal/log_std Std        0.972829
trainer/policy/normal/log_std Max        0.55067
trainer/policy/normal/log_std Min       -3.77679
trainer/Alpha                            0.00248057
trainer/Alpha Loss                      -0.610571
expl/num steps total                 83000
expl/num paths total                   102
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.138413
expl/Actions Std                         0.384562
expl/Actions Max                         0.983882
expl/Actions Min                        -0.964325
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                409002
eval/num paths total                   410
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.100698
eval/Actions Std                         0.277592
eval/Actions Max                         0.986172
eval/Actions Min                        -0.966795
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00464472
time/evaluation sampling (s)             0.967501
time/exploration sampling (s)            0.350435
time/logging (s)                         0.0097318
time/sac training (s)                   11.8368
time/saving (s)                          0.00464774
time/training (s)                        0.000217701
time/epoch (s)                          13.174
time/total (s)                        1064.98
Epoch                                   81
----------------------------------  ----------------
2022-09-09 20:10:48.941983 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 82 finished
----------------------------------  ----------------
epoch                                   82
replay_buffer/size                   84000
trainer/num train calls              83000
trainer/QF1 Loss                         0.00183202
trainer/QF2 Loss                         0.000667939
trainer/Policy Loss                     -3.33675
trainer/Q1 Predictions Mean              3.32922
trainer/Q1 Predictions Std               0.174865
trainer/Q1 Predictions Max               3.60885
trainer/Q1 Predictions Min               2.41606
trainer/Q2 Predictions Mean              3.32178
trainer/Q2 Predictions Std               0.164848
trainer/Q2 Predictions Max               3.58382
trainer/Q2 Predictions Min               2.75666
trainer/Q Targets Mean                   3.33258
trainer/Q Targets Std                    0.162087
trainer/Q Targets Max                    3.59874
trainer/Q Targets Min                    2.92554
trainer/Log Pis Mean                     2.84029
trainer/Log Pis Std                      2.36059
trainer/Log Pis Max                      9.472
trainer/Log Pis Min                     -4.6537
trainer/policy/mean Mean                -0.133857
trainer/policy/mean Std                  0.641426
trainer/policy/mean Max                  0.985644
trainer/policy/mean Min                 -0.995858
trainer/policy/normal/std Mean           0.405692
trainer/policy/normal/std Std            0.294909
trainer/policy/normal/std Max            1.63045
trainer/policy/normal/std Min            0.0225026
trainer/policy/normal/log_std Mean      -1.28048
trainer/policy/normal/log_std Std        0.996859
trainer/policy/normal/log_std Max        0.488854
trainer/policy/normal/log_std Min       -3.79412
trainer/Alpha                            0.00225017
trainer/Alpha Loss                      -0.973721
expl/num steps total                 84000
expl/num paths total                   103
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.130951
expl/Actions Std                         0.512889
expl/Actions Max                         0.992283
expl/Actions Min                        -0.993376
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                414002
eval/num paths total                   415
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.18183
eval/Actions Std                         0.294863
eval/Actions Max                         0.906848
eval/Actions Min                        -0.870037
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00519949
time/evaluation sampling (s)             0.924992
time/exploration sampling (s)            0.302654
time/logging (s)                         0.00950975
time/sac training (s)                   11.6323
time/saving (s)                          0.00465849
time/training (s)                        3.08e-05
time/epoch (s)                          12.8793
time/total (s)                        1078.15
Epoch                                   82
----------------------------------  ----------------
2022-09-09 20:11:02.028198 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 83 finished
----------------------------------  ----------------
epoch                                   83
replay_buffer/size                   85000
trainer/num train calls              84000
trainer/QF1 Loss                         0.000926712
trainer/QF2 Loss                         0.000730346
trainer/Policy Loss                     -3.2131
trainer/Q1 Predictions Mean              3.2007
trainer/Q1 Predictions Std               0.155804
trainer/Q1 Predictions Max               3.45401
trainer/Q1 Predictions Min               2.4427
trainer/Q2 Predictions Mean              3.2082
trainer/Q2 Predictions Std               0.15643
trainer/Q2 Predictions Max               3.45986
trainer/Q2 Predictions Min               2.56395
trainer/Q Targets Mean                   3.20197
trainer/Q Targets Std                    0.148267
trainer/Q Targets Max                    3.45587
trainer/Q Targets Min                    2.88689
trainer/Log Pis Mean                     2.91542
trainer/Log Pis Std                      2.67886
trainer/Log Pis Max                      8.84588
trainer/Log Pis Min                     -4.00766
trainer/policy/mean Mean                -0.0783092
trainer/policy/mean Std                  0.679851
trainer/policy/mean Max                  0.991302
trainer/policy/mean Min                 -0.993005
trainer/policy/normal/std Mean           0.45265
trainer/policy/normal/std Std            0.32984
trainer/policy/normal/std Max            2.48243
trainer/policy/normal/std Min            0.0183626
trainer/policy/normal/log_std Mean      -1.15369
trainer/policy/normal/log_std Std        0.999416
trainer/policy/normal/log_std Max        0.909238
trainer/policy/normal/log_std Min       -3.99744
trainer/Alpha                            0.00199429
trainer/Alpha Loss                      -0.525897
expl/num steps total                 85000
expl/num paths total                   104
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.204136
expl/Actions Std                         0.624334
expl/Actions Max                         0.999525
expl/Actions Min                        -0.988504
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                419002
eval/num paths total                   420
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.220399
eval/Actions Std                         0.428796
eval/Actions Max                         0.997432
eval/Actions Min                        -0.948661
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00356269
time/evaluation sampling (s)             0.968988
time/exploration sampling (s)            0.304751
time/logging (s)                         0.0089689
time/sac training (s)                   11.4953
time/saving (s)                          0.00340405
time/training (s)                        2.858e-05
time/epoch (s)                          12.785
time/total (s)                        1091.23
Epoch                                   83
----------------------------------  ----------------
2022-09-09 20:11:15.340802 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 84 finished
----------------------------------  ---------------
epoch                                   84
replay_buffer/size                   86000
trainer/num train calls              85000
trainer/QF1 Loss                         0.00020503
trainer/QF2 Loss                         0.00029558
trainer/Policy Loss                     -3.07204
trainer/Q1 Predictions Mean              3.06432
trainer/Q1 Predictions Std               0.131722
trainer/Q1 Predictions Max               3.3015
trainer/Q1 Predictions Min               2.78953
trainer/Q2 Predictions Mean              3.06576
trainer/Q2 Predictions Std               0.134696
trainer/Q2 Predictions Max               3.30366
trainer/Q2 Predictions Min               2.77901
trainer/Q Targets Mean                   3.06245
trainer/Q Targets Std                    0.13487
trainer/Q Targets Max                    3.31221
trainer/Q Targets Min                    2.76696
trainer/Log Pis Mean                     2.90201
trainer/Log Pis Std                      2.49155
trainer/Log Pis Max                      8.98712
trainer/Log Pis Min                     -4.58536
trainer/policy/mean Mean                -0.0817458
trainer/policy/mean Std                  0.697926
trainer/policy/mean Max                  0.983728
trainer/policy/mean Min                 -0.996147
trainer/policy/normal/std Mean           0.435453
trainer/policy/normal/std Std            0.278286
trainer/policy/normal/std Max            1.30863
trainer/policy/normal/std Min            0.0221496
trainer/policy/normal/log_std Mean      -1.17544
trainer/policy/normal/log_std Std        0.975748
trainer/policy/normal/log_std Max        0.26898
trainer/policy/normal/log_std Min       -3.80994
trainer/Alpha                            0.00207463
trainer/Alpha Loss                      -0.605397
expl/num steps total                 86000
expl/num paths total                   105
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0550367
expl/Actions Std                         0.408037
expl/Actions Max                         0.997839
expl/Actions Min                        -0.844086
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                424002
eval/num paths total                   425
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.167478
eval/Actions Std                         0.405067
eval/Actions Max                         0.990346
eval/Actions Min                        -0.963589
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0035561
time/evaluation sampling (s)             0.935538
time/exploration sampling (s)            0.311502
time/logging (s)                         0.00935036
time/sac training (s)                   11.7421
time/saving (s)                          0.00472798
time/training (s)                        2.809e-05
time/epoch (s)                          13.0068
time/total (s)                        1104.53
Epoch                                   84
----------------------------------  ---------------
2022-09-09 20:11:28.103791 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 85 finished
----------------------------------  ----------------
epoch                                   85
replay_buffer/size                   87000
trainer/num train calls              86000
trainer/QF1 Loss                         0.000214682
trainer/QF2 Loss                         0.000789097
trainer/Policy Loss                     -2.9378
trainer/Q1 Predictions Mean              2.93655
trainer/Q1 Predictions Std               0.134271
trainer/Q1 Predictions Max               3.18292
trainer/Q1 Predictions Min               2.63529
trainer/Q2 Predictions Mean              2.93149
trainer/Q2 Predictions Std               0.135673
trainer/Q2 Predictions Max               3.18449
trainer/Q2 Predictions Min               2.38896
trainer/Q Targets Mean                   2.9321
trainer/Q Targets Std                    0.135396
trainer/Q Targets Max                    3.19646
trainer/Q Targets Min                    2.62783
trainer/Log Pis Mean                     2.85479
trainer/Log Pis Std                      2.56172
trainer/Log Pis Max                     10.6228
trainer/Log Pis Min                     -5.49147
trainer/policy/mean Mean                -0.126046
trainer/policy/mean Std                  0.709162
trainer/policy/mean Max                  0.986548
trainer/policy/mean Min                 -0.993113
trainer/policy/normal/std Mean           0.470231
trainer/policy/normal/std Std            0.297429
trainer/policy/normal/std Max            1.47479
trainer/policy/normal/std Min            0.0214289
trainer/policy/normal/log_std Mean      -1.07903
trainer/policy/normal/log_std Std        0.94272
trainer/policy/normal/log_std Max        0.388518
trainer/policy/normal/log_std Min       -3.84301
trainer/Alpha                            0.00202246
trainer/Alpha Loss                      -0.900811
expl/num steps total                 87000
expl/num paths total                   106
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.268051
expl/Actions Std                         0.478527
expl/Actions Max                         0.995693
expl/Actions Min                        -0.985438
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                429002
eval/num paths total                   430
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.168065
eval/Actions Std                         0.416549
eval/Actions Max                         0.966665
eval/Actions Min                        -0.988127
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0035461
time/evaluation sampling (s)             0.923062
time/exploration sampling (s)            0.310043
time/logging (s)                         0.00920926
time/sac training (s)                   11.2367
time/saving (s)                          0.0046214
time/training (s)                        2.559e-05
time/epoch (s)                          12.4873
time/total (s)                        1117.28
Epoch                                   85
----------------------------------  ----------------
2022-09-09 20:11:40.897750 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 86 finished
----------------------------------  ----------------
epoch                                   86
replay_buffer/size                   88000
trainer/num train calls              87000
trainer/QF1 Loss                         0.000158917
trainer/QF2 Loss                         0.000180344
trainer/Policy Loss                     -2.85267
trainer/Q1 Predictions Mean              2.84593
trainer/Q1 Predictions Std               0.135009
trainer/Q1 Predictions Max               3.06772
trainer/Q1 Predictions Min               2.46143
trainer/Q2 Predictions Mean              2.84459
trainer/Q2 Predictions Std               0.136132
trainer/Q2 Predictions Max               3.07405
trainer/Q2 Predictions Min               2.41994
trainer/Q Targets Mean                   2.84146
trainer/Q Targets Std                    0.135135
trainer/Q Targets Max                    3.07359
trainer/Q Targets Min                    2.47713
trainer/Log Pis Mean                     2.85429
trainer/Log Pis Std                      2.46611
trainer/Log Pis Max                      9.13426
trainer/Log Pis Min                     -3.3834
trainer/policy/mean Mean                -0.0980732
trainer/policy/mean Std                  0.693448
trainer/policy/mean Max                  0.992418
trainer/policy/mean Min                 -0.995978
trainer/policy/normal/std Mean           0.467003
trainer/policy/normal/std Std            0.314138
trainer/policy/normal/std Max            1.42901
trainer/policy/normal/std Min            0.0189865
trainer/policy/normal/log_std Mean      -1.12648
trainer/policy/normal/log_std Std        1.0106
trainer/policy/normal/log_std Max        0.356985
trainer/policy/normal/log_std Min       -3.96403
trainer/Alpha                            0.00187333
trainer/Alpha Loss                      -0.915041
expl/num steps total                 88000
expl/num paths total                   107
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.221678
expl/Actions Std                         0.456207
expl/Actions Max                         0.989433
expl/Actions Min                        -0.999586
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                434002
eval/num paths total                   435
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.137482
eval/Actions Std                         0.290928
eval/Actions Max                         0.80957
eval/Actions Min                        -0.985713
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00361703
time/evaluation sampling (s)             0.922071
time/exploration sampling (s)            0.320173
time/logging (s)                         0.0098238
time/sac training (s)                   11.259
time/saving (s)                          0.00470008
time/training (s)                        2.509e-05
time/epoch (s)                          12.5194
time/total (s)                        1130.07
Epoch                                   86
----------------------------------  ----------------
2022-09-09 20:11:53.999611 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 87 finished
----------------------------------  ----------------
epoch                                   87
replay_buffer/size                   89000
trainer/num train calls              88000
trainer/QF1 Loss                         8.81189e-05
trainer/QF2 Loss                         0.000178141
trainer/Policy Loss                     -2.74746
trainer/Q1 Predictions Mean              2.73805
trainer/Q1 Predictions Std               0.136273
trainer/Q1 Predictions Max               2.94716
trainer/Q1 Predictions Min               2.451
trainer/Q2 Predictions Mean              2.74212
trainer/Q2 Predictions Std               0.136301
trainer/Q2 Predictions Max               2.9421
trainer/Q2 Predictions Min               2.44557
trainer/Q Targets Mean                   2.74008
trainer/Q Targets Std                    0.136799
trainer/Q Targets Max                    2.95095
trainer/Q Targets Min                    2.42471
trainer/Log Pis Mean                     2.69023
trainer/Log Pis Std                      2.24338
trainer/Log Pis Max                      7.95858
trainer/Log Pis Min                     -2.75922
trainer/policy/mean Mean                -0.0861391
trainer/policy/mean Std                  0.689936
trainer/policy/mean Max                  0.979577
trainer/policy/mean Min                 -0.995077
trainer/policy/normal/std Mean           0.475764
trainer/policy/normal/std Std            0.312198
trainer/policy/normal/std Max            1.31898
trainer/policy/normal/std Min            0.0181083
trainer/policy/normal/log_std Mean      -1.08877
trainer/policy/normal/log_std Std        0.987307
trainer/policy/normal/log_std Max        0.276859
trainer/policy/normal/log_std Min       -4.01138
trainer/Alpha                            0.00163001
trainer/Alpha Loss                      -1.98849
expl/num steps total                 89000
expl/num paths total                   108
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0676198
expl/Actions Std                         0.489869
expl/Actions Max                         0.990309
expl/Actions Min                        -0.99449
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                439002
eval/num paths total                   440
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.238977
eval/Actions Std                         0.35297
eval/Actions Max                         0.970667
eval/Actions Min                        -0.984129
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00518557
time/evaluation sampling (s)             0.953666
time/exploration sampling (s)            0.308824
time/logging (s)                         0.00935999
time/sac training (s)                   11.5199
time/saving (s)                          0.00456131
time/training (s)                        2.142e-05
time/epoch (s)                          12.8015
time/total (s)                        1143.16
Epoch                                   87
----------------------------------  ----------------
2022-09-09 20:12:07.222482 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 88 finished
----------------------------------  ----------------
epoch                                   88
replay_buffer/size                   90000
trainer/num train calls              89000
trainer/QF1 Loss                         8.29108e-05
trainer/QF2 Loss                         0.000168791
trainer/Policy Loss                     -2.64698
trainer/Q1 Predictions Mean              2.6415
trainer/Q1 Predictions Std               0.137022
trainer/Q1 Predictions Max               2.83449
trainer/Q1 Predictions Min               2.38026
trainer/Q2 Predictions Mean              2.64203
trainer/Q2 Predictions Std               0.138274
trainer/Q2 Predictions Max               2.85371
trainer/Q2 Predictions Min               2.37574
trainer/Q Targets Mean                   2.64507
trainer/Q Targets Std                    0.137582
trainer/Q Targets Max                    2.85964
trainer/Q Targets Min                    2.37446
trainer/Log Pis Mean                     2.89289
trainer/Log Pis Std                      2.57121
trainer/Log Pis Max                      8.6611
trainer/Log Pis Min                     -3.63884
trainer/policy/mean Mean                -0.0351298
trainer/policy/mean Std                  0.725758
trainer/policy/mean Max                  0.99497
trainer/policy/mean Min                 -0.997287
trainer/policy/normal/std Mean           0.492894
trainer/policy/normal/std Std            0.317406
trainer/policy/normal/std Max            1.69453
trainer/policy/normal/std Min            0.0211919
trainer/policy/normal/log_std Mean      -1.04426
trainer/policy/normal/log_std Std        0.994455
trainer/policy/normal/log_std Max        0.527407
trainer/policy/normal/log_std Min       -3.85413
trainer/Alpha                            0.00144926
trainer/Alpha Loss                      -0.700139
expl/num steps total                 90000
expl/num paths total                   109
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.132983
expl/Actions Std                         0.450958
expl/Actions Max                         0.992489
expl/Actions Min                        -0.99315
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                444002
eval/num paths total                   445
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.105745
eval/Actions Std                         0.32195
eval/Actions Max                         0.967687
eval/Actions Min                        -0.960203
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00358349
time/evaluation sampling (s)             0.951629
time/exploration sampling (s)            0.348055
time/logging (s)                         0.0092467
time/sac training (s)                   11.6017
time/saving (s)                          0.00336035
time/training (s)                        1.958e-05
time/epoch (s)                          12.9176
time/total (s)                        1156.37
Epoch                                   88
----------------------------------  ----------------
2022-09-09 20:12:19.945875 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 89 finished
----------------------------------  ----------------
epoch                                   89
replay_buffer/size                   91000
trainer/num train calls              90000
trainer/QF1 Loss                         8.4032e-05
trainer/QF2 Loss                         0.000160606
trainer/Policy Loss                     -2.54226
trainer/Q1 Predictions Mean              2.54113
trainer/Q1 Predictions Std               0.123835
trainer/Q1 Predictions Max               2.71978
trainer/Q1 Predictions Min               2.28121
trainer/Q2 Predictions Mean              2.53602
trainer/Q2 Predictions Std               0.124549
trainer/Q2 Predictions Max               2.71671
trainer/Q2 Predictions Min               2.28775
trainer/Q Targets Mean                   2.53834
trainer/Q Targets Std                    0.125019
trainer/Q Targets Max                    2.7143
trainer/Q Targets Min                    2.26024
trainer/Log Pis Mean                     3.30989
trainer/Log Pis Std                      2.38995
trainer/Log Pis Max                      8.53203
trainer/Log Pis Min                     -3.96345
trainer/policy/mean Mean                -0.0826865
trainer/policy/mean Std                  0.731439
trainer/policy/mean Max                  0.997317
trainer/policy/mean Min                 -0.994182
trainer/policy/normal/std Mean           0.494161
trainer/policy/normal/std Std            0.307492
trainer/policy/normal/std Max            1.51313
trainer/policy/normal/std Min            0.0198196
trainer/policy/normal/log_std Mean      -1.03779
trainer/policy/normal/log_std Std        0.9916
trainer/policy/normal/log_std Max        0.414179
trainer/policy/normal/log_std Min       -3.92109
trainer/Alpha                            0.00134568
trainer/Alpha Loss                       2.04867
expl/num steps total                 91000
expl/num paths total                   110
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.10837
expl/Actions Std                         0.433665
expl/Actions Max                         0.995647
expl/Actions Min                        -0.977031
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                449002
eval/num paths total                   450
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.14172
eval/Actions Std                         0.21497
eval/Actions Max                         0.982464
eval/Actions Min                        -0.998908
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00518807
time/evaluation sampling (s)             0.931571
time/exploration sampling (s)            0.295323
time/logging (s)                         0.00928401
time/sac training (s)                   11.21
time/saving (s)                          0.00479035
time/training (s)                        2.621e-05
time/epoch (s)                          12.4562
time/total (s)                        1169.08
Epoch                                   89
----------------------------------  ----------------
2022-09-09 20:12:33.105806 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 90 finished
----------------------------------  ----------------
epoch                                   90
replay_buffer/size                   92000
trainer/num train calls              91000
trainer/QF1 Loss                         8.37957e-05
trainer/QF2 Loss                         0.000172867
trainer/Policy Loss                     -2.45392
trainer/Q1 Predictions Mean              2.44898
trainer/Q1 Predictions Std               0.114039
trainer/Q1 Predictions Max               2.59789
trainer/Q1 Predictions Min               2.17513
trainer/Q2 Predictions Mean              2.44993
trainer/Q2 Predictions Std               0.114941
trainer/Q2 Predictions Max               2.59833
trainer/Q2 Predictions Min               2.16198
trainer/Q Targets Mean                   2.446
trainer/Q Targets Std                    0.114496
trainer/Q Targets Max                    2.59331
trainer/Q Targets Min                    2.14836
trainer/Log Pis Mean                     2.95806
trainer/Log Pis Std                      2.18936
trainer/Log Pis Max                      8.92074
trainer/Log Pis Min                     -4.04693
trainer/policy/mean Mean                -0.087419
trainer/policy/mean Std                  0.687643
trainer/policy/mean Max                  0.997134
trainer/policy/mean Min                 -0.996057
trainer/policy/normal/std Mean           0.450656
trainer/policy/normal/std Std            0.319495
trainer/policy/normal/std Max            2.26317
trainer/policy/normal/std Min            0.0250509
trainer/policy/normal/log_std Mean      -1.14218
trainer/policy/normal/log_std Std        0.956867
trainer/policy/normal/log_std Max        0.816766
trainer/policy/normal/log_std Min       -3.68685
trainer/Alpha                            0.00146224
trainer/Alpha Loss                      -0.27379
expl/num steps total                 92000
expl/num paths total                   111
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.106129
expl/Actions Std                         0.456351
expl/Actions Max                         0.990603
expl/Actions Min                        -0.989329
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                454002
eval/num paths total                   455
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.133064
eval/Actions Std                         0.230903
eval/Actions Max                         0.996598
eval/Actions Min                        -0.989488
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00355525
time/evaluation sampling (s)             0.934977
time/exploration sampling (s)            0.329769
time/logging (s)                         0.0093546
time/sac training (s)                   11.5982
time/saving (s)                          0.00357447
time/training (s)                        1.91e-05
time/epoch (s)                          12.8794
time/total (s)                        1182.23
Epoch                                   90
----------------------------------  ----------------
2022-09-09 20:12:46.283635 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 91 finished
----------------------------------  ----------------
epoch                                   91
replay_buffer/size                   93000
trainer/num train calls              92000
trainer/QF1 Loss                         8.69695e-05
trainer/QF2 Loss                         0.000196554
trainer/Policy Loss                     -2.34089
trainer/Q1 Predictions Mean              2.34388
trainer/Q1 Predictions Std               0.114685
trainer/Q1 Predictions Max               2.48718
trainer/Q1 Predictions Min               2.08643
trainer/Q2 Predictions Mean              2.33387
trainer/Q2 Predictions Std               0.11088
trainer/Q2 Predictions Max               2.49779
trainer/Q2 Predictions Min               2.06183
trainer/Q Targets Mean                   2.34313
trainer/Q Targets Std                    0.113674
trainer/Q Targets Max                    2.49075
trainer/Q Targets Min                    2.06858
trainer/Log Pis Mean                     2.79197
trainer/Log Pis Std                      2.25939
trainer/Log Pis Max                      9.23316
trainer/Log Pis Min                     -5.32618
trainer/policy/mean Mean                -0.160555
trainer/policy/mean Std                  0.676608
trainer/policy/mean Max                  0.996441
trainer/policy/mean Min                 -0.997992
trainer/policy/normal/std Mean           0.479379
trainer/policy/normal/std Std            0.328825
trainer/policy/normal/std Max            2.14524
trainer/policy/normal/std Min            0.02552
trainer/policy/normal/log_std Mean      -1.05814
trainer/policy/normal/log_std Std        0.921524
trainer/policy/normal/log_std Max        0.763252
trainer/policy/normal/log_std Min       -3.66829
trainer/Alpha                            0.0012242
trainer/Alpha Loss                      -1.39492
expl/num steps total                 93000
expl/num paths total                   112
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.340852
expl/Actions Std                         0.496241
expl/Actions Max                         0.99895
expl/Actions Min                        -0.998494
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                459002
eval/num paths total                   460
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.412903
eval/Actions Std                         0.374969
eval/Actions Max                         0.998729
eval/Actions Min                        -0.987752
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00351081
time/evaluation sampling (s)             0.926625
time/exploration sampling (s)            0.305727
time/logging (s)                         0.00926678
time/sac training (s)                   11.6445
time/saving (s)                          0.00461195
time/training (s)                        2.557e-05
time/epoch (s)                          12.8942
time/total (s)                        1195.4
Epoch                                   91
----------------------------------  ----------------
2022-09-09 20:12:59.548788 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 92 finished
----------------------------------  ----------------
epoch                                   92
replay_buffer/size                   94000
trainer/num train calls              93000
trainer/QF1 Loss                         4.60517e-05
trainer/QF2 Loss                         0.000127452
trainer/Policy Loss                     -2.22924
trainer/Q1 Predictions Mean              2.2261
trainer/Q1 Predictions Std               0.10913
trainer/Q1 Predictions Max               2.38407
trainer/Q1 Predictions Min               2.00342
trainer/Q2 Predictions Mean              2.22769
trainer/Q2 Predictions Std               0.108091
trainer/Q2 Predictions Max               2.3949
trainer/Q2 Predictions Min               2.00964
trainer/Q Targets Mean                   2.22538
trainer/Q Targets Std                    0.109798
trainer/Q Targets Max                    2.37778
trainer/Q Targets Min                    2.00986
trainer/Log Pis Mean                     3.06854
trainer/Log Pis Std                      2.17716
trainer/Log Pis Max                      9.65118
trainer/Log Pis Min                     -4.07005
trainer/policy/mean Mean                -0.121005
trainer/policy/mean Std                  0.705471
trainer/policy/mean Max                  0.995827
trainer/policy/mean Min                 -0.997582
trainer/policy/normal/std Mean           0.459949
trainer/policy/normal/std Std            0.297468
trainer/policy/normal/std Max            1.77043
trainer/policy/normal/std Min            0.0197733
trainer/policy/normal/log_std Mean      -1.09246
trainer/policy/normal/log_std Std        0.917166
trainer/policy/normal/log_std Max        0.571222
trainer/policy/normal/log_std Min       -3.92342
trainer/Alpha                            0.00105959
trainer/Alpha Loss                       0.469517
expl/num steps total                 94000
expl/num paths total                   113
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0130151
expl/Actions Std                         0.47366
expl/Actions Max                         0.999348
expl/Actions Min                        -0.988133
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                464002
eval/num paths total                   465
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0331002
eval/Actions Std                         0.145118
eval/Actions Max                         0.995728
eval/Actions Min                        -0.994303
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0063956
time/evaluation sampling (s)             0.930224
time/exploration sampling (s)            0.327477
time/logging (s)                         0.00956358
time/sac training (s)                   11.6892
time/saving (s)                          0.00511711
time/training (s)                        7.688e-05
time/epoch (s)                          12.9681
time/total (s)                        1208.65
Epoch                                   92
----------------------------------  ----------------
2022-09-09 20:13:14.153460 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 93 finished
----------------------------------  ----------------
epoch                                   93
replay_buffer/size                   95000
trainer/num train calls              94000
trainer/QF1 Loss                         9.80807e-05
trainer/QF2 Loss                         9.10019e-05
trainer/Policy Loss                     -2.1592
trainer/Q1 Predictions Mean              2.15924
trainer/Q1 Predictions Std               0.101038
trainer/Q1 Predictions Max               2.29334
trainer/Q1 Predictions Min               1.95918
trainer/Q2 Predictions Mean              2.15561
trainer/Q2 Predictions Std               0.103071
trainer/Q2 Predictions Max               2.29528
trainer/Q2 Predictions Min               1.95059
trainer/Q Targets Mean                   2.15172
trainer/Q Targets Std                    0.102087
trainer/Q Targets Max                    2.29492
trainer/Q Targets Min                    1.95823
trainer/Log Pis Mean                     3.09678
trainer/Log Pis Std                      2.25084
trainer/Log Pis Max                      8.41956
trainer/Log Pis Min                     -3.80993
trainer/policy/mean Mean                -0.122202
trainer/policy/mean Std                  0.685458
trainer/policy/mean Max                  0.99665
trainer/policy/mean Min                 -0.997313
trainer/policy/normal/std Mean           0.45496
trainer/policy/normal/std Std            0.280632
trainer/policy/normal/std Max            1.40234
trainer/policy/normal/std Min            0.015621
trainer/policy/normal/log_std Mean      -1.12779
trainer/policy/normal/log_std Std        1.00249
trainer/policy/normal/log_std Max        0.338144
trainer/policy/normal/log_std Min       -4.15914
trainer/Alpha                            0.000969064
trainer/Alpha Loss                       0.671546
expl/num steps total                 95000
expl/num paths total                   114
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.290413
expl/Actions Std                         0.485077
expl/Actions Max                         0.970368
expl/Actions Min                        -0.986462
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                469002
eval/num paths total                   470
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.361588
eval/Actions Std                         0.332758
eval/Actions Max                         0.976491
eval/Actions Min                        -0.979458
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00356765
time/evaluation sampling (s)             0.952493
time/exploration sampling (s)            0.357754
time/logging (s)                         0.00953122
time/sac training (s)                   12.8984
time/saving (s)                          0.00467295
time/training (s)                        2.826e-05
time/epoch (s)                          14.2265
time/total (s)                        1223.24
Epoch                                   93
----------------------------------  ----------------
2022-09-09 20:13:27.267269 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 94 finished
----------------------------------  ----------------
epoch                                   94
replay_buffer/size                   96000
trainer/num train calls              95000
trainer/QF1 Loss                         6.48142e-05
trainer/QF2 Loss                         9.53667e-05
trainer/Policy Loss                     -2.06602
trainer/Q1 Predictions Mean              2.06436
trainer/Q1 Predictions Std               0.0926097
trainer/Q1 Predictions Max               2.20924
trainer/Q1 Predictions Min               1.87987
trainer/Q2 Predictions Mean              2.06735
trainer/Q2 Predictions Std               0.0954819
trainer/Q2 Predictions Max               2.2203
trainer/Q2 Predictions Min               1.87567
trainer/Q Targets Mean                   2.06787
trainer/Q Targets Std                    0.0928938
trainer/Q Targets Max                    2.21893
trainer/Q Targets Min                    1.88473
trainer/Log Pis Mean                     2.57739
trainer/Log Pis Std                      2.19309
trainer/Log Pis Max                      8.97969
trainer/Log Pis Min                     -2.70591
trainer/policy/mean Mean                -0.0635841
trainer/policy/mean Std                  0.660738
trainer/policy/mean Max                  0.994454
trainer/policy/mean Min                 -0.995608
trainer/policy/normal/std Mean           0.481619
trainer/policy/normal/std Std            0.298418
trainer/policy/normal/std Max            1.66876
trainer/policy/normal/std Min            0.0167857
trainer/policy/normal/log_std Mean      -1.04045
trainer/policy/normal/log_std Std        0.933079
trainer/policy/normal/log_std Max        0.512079
trainer/policy/normal/log_std Min       -4.08723
trainer/Alpha                            0.000951554
trainer/Alpha Loss                      -2.94027
expl/num steps total                 96000
expl/num paths total                   115
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0863356
expl/Actions Std                         0.519828
expl/Actions Max                         0.997688
expl/Actions Min                        -0.998058
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                474002
eval/num paths total                   475
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.119546
eval/Actions Std                         0.514871
eval/Actions Max                         0.998321
eval/Actions Min                        -0.960172
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00355967
time/evaluation sampling (s)             0.948585
time/exploration sampling (s)            0.314021
time/logging (s)                         0.0101133
time/sac training (s)                   11.5325
time/saving (s)                          0.00449034
time/training (s)                        3.554e-05
time/epoch (s)                          12.8133
time/total (s)                        1236.35
Epoch                                   94
----------------------------------  ----------------
2022-09-09 20:13:41.391280 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 95 finished
----------------------------------  ----------------
epoch                                   95
replay_buffer/size                   97000
trainer/num train calls              96000
trainer/QF1 Loss                         5.50179e-05
trainer/QF2 Loss                         6.20466e-05
trainer/Policy Loss                     -1.98278
trainer/Q1 Predictions Mean              1.98154
trainer/Q1 Predictions Std               0.0896346
trainer/Q1 Predictions Max               2.13958
trainer/Q1 Predictions Min               1.80388
trainer/Q2 Predictions Mean              1.97761
trainer/Q2 Predictions Std               0.0898109
trainer/Q2 Predictions Max               2.1658
trainer/Q2 Predictions Min               1.80235
trainer/Q Targets Mean                   1.9771
trainer/Q Targets Std                    0.0888851
trainer/Q Targets Max                    2.1429
trainer/Q Targets Min                    1.80907
trainer/Log Pis Mean                     3.30098
trainer/Log Pis Std                      2.29998
trainer/Log Pis Max                     10.3539
trainer/Log Pis Min                     -2.66087
trainer/policy/mean Mean                -0.056404
trainer/policy/mean Std                  0.674929
trainer/policy/mean Max                  0.99641
trainer/policy/mean Min                 -0.995146
trainer/policy/normal/std Mean           0.416929
trainer/policy/normal/std Std            0.286309
trainer/policy/normal/std Max            1.52223
trainer/policy/normal/std Min            0.0146874
trainer/policy/normal/log_std Mean      -1.24314
trainer/policy/normal/log_std Std        1.01536
trainer/policy/normal/log_std Max        0.420176
trainer/policy/normal/log_std Min       -4.22077
trainer/Alpha                            0.000758604
trainer/Alpha Loss                       2.16226
expl/num steps total                 97000
expl/num paths total                   116
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0501397
expl/Actions Std                         0.663814
expl/Actions Max                         0.997509
expl/Actions Min                        -0.998692
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                479002
eval/num paths total                   480
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0567119
eval/Actions Std                         0.667581
eval/Actions Max                         0.989283
eval/Actions Min                        -0.984591
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00399507
time/evaluation sampling (s)             0.963765
time/exploration sampling (s)            0.338447
time/logging (s)                         0.00977192
time/sac training (s)                   12.4475
time/saving (s)                          0.0047407
time/training (s)                        3.201e-05
time/epoch (s)                          13.7683
time/total (s)                        1250.45
Epoch                                   95
----------------------------------  ----------------
2022-09-09 20:13:55.579379 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 96 finished
----------------------------------  ----------------
epoch                                   96
replay_buffer/size                   98000
trainer/num train calls              97000
trainer/QF1 Loss                         2.85571e-05
trainer/QF2 Loss                         0.000102637
trainer/Policy Loss                     -1.90702
trainer/Q1 Predictions Mean              1.90953
trainer/Q1 Predictions Std               0.0895341
trainer/Q1 Predictions Max               2.07573
trainer/Q1 Predictions Min               1.73651
trainer/Q2 Predictions Mean              1.90638
trainer/Q2 Predictions Std               0.0877727
trainer/Q2 Predictions Max               2.08122
trainer/Q2 Predictions Min               1.7365
trainer/Q Targets Mean                   1.90707
trainer/Q Targets Std                    0.0894836
trainer/Q Targets Max                    2.07362
trainer/Q Targets Min                    1.74521
trainer/Log Pis Mean                     3.1058
trainer/Log Pis Std                      2.65442
trainer/Log Pis Max                      9.34667
trainer/Log Pis Min                     -6.35543
trainer/policy/mean Mean                -0.116876
trainer/policy/mean Std                  0.694283
trainer/policy/mean Max                  0.997068
trainer/policy/mean Min                 -0.995759
trainer/policy/normal/std Mean           0.423647
trainer/policy/normal/std Std            0.269229
trainer/policy/normal/std Max            2.05898
trainer/policy/normal/std Min            0.0158089
trainer/policy/normal/log_std Mean      -1.17486
trainer/policy/normal/log_std Std        0.94903
trainer/policy/normal/log_std Max        0.722212
trainer/policy/normal/log_std Min       -4.14718
trainer/Alpha                            0.000747916
trainer/Alpha Loss                       0.761576
expl/num steps total                 98000
expl/num paths total                   117
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.13483
expl/Actions Std                         0.567002
expl/Actions Max                         0.995999
expl/Actions Min                        -0.997425
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                484002
eval/num paths total                   485
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.129356
eval/Actions Std                         0.57659
eval/Actions Max                         0.998272
eval/Actions Min                        -0.988677
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00372173
time/evaluation sampling (s)             0.969974
time/exploration sampling (s)            0.304452
time/logging (s)                         0.00895053
time/sac training (s)                   12.5421
time/saving (s)                          0.00463242
time/training (s)                        3.486e-05
time/epoch (s)                          13.8338
time/total (s)                        1264.63
Epoch                                   96
----------------------------------  ----------------
2022-09-09 20:14:08.860564 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 97 finished
----------------------------------  ----------------
epoch                                   97
replay_buffer/size                   99000
trainer/num train calls              98000
trainer/QF1 Loss                         2.58391e-05
trainer/QF2 Loss                         8.04896e-05
trainer/Policy Loss                     -1.81506
trainer/Q1 Predictions Mean              1.81712
trainer/Q1 Predictions Std               0.0897798
trainer/Q1 Predictions Max               2.01952
trainer/Q1 Predictions Min               1.66955
trainer/Q2 Predictions Mean              1.81085
trainer/Q2 Predictions Std               0.0894075
trainer/Q2 Predictions Max               2.01282
trainer/Q2 Predictions Min               1.64044
trainer/Q Targets Mean                   1.81713
trainer/Q Targets Std                    0.0892533
trainer/Q Targets Max                    2.00558
trainer/Q Targets Min                    1.67037
trainer/Log Pis Mean                     2.79536
trainer/Log Pis Std                      2.44001
trainer/Log Pis Max                     10.2987
trainer/Log Pis Min                     -5.4289
trainer/policy/mean Mean                -0.105974
trainer/policy/mean Std                  0.653044
trainer/policy/mean Max                  0.99669
trainer/policy/mean Min                 -0.996892
trainer/policy/normal/std Mean           0.379369
trainer/policy/normal/std Std            0.264325
trainer/policy/normal/std Max            1.66014
trainer/policy/normal/std Min            0.015744
trainer/policy/normal/log_std Mean      -1.30772
trainer/policy/normal/log_std Std        0.933003
trainer/policy/normal/log_std Max        0.506901
trainer/policy/normal/log_std Min       -4.1513
trainer/Alpha                            0.000620423
trainer/Alpha Loss                      -1.51129
expl/num steps total                 99000
expl/num paths total                   118
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.155721
expl/Actions Std                         0.458213
expl/Actions Max                         0.932554
expl/Actions Min                        -0.998503
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                489002
eval/num paths total                   490
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.163014
eval/Actions Std                         0.314929
eval/Actions Max                         0.996397
eval/Actions Min                        -0.974346
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00528017
time/evaluation sampling (s)             0.954627
time/exploration sampling (s)            0.287018
time/logging (s)                         0.0106649
time/sac training (s)                   11.7259
time/saving (s)                          0.0049496
time/training (s)                        3.44e-05
time/epoch (s)                          12.9884
time/total (s)                        1277.9
Epoch                                   97
----------------------------------  ----------------
2022-09-09 20:14:22.327706 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 98 finished
----------------------------------  ----------------
epoch                                   98
replay_buffer/size                  100000
trainer/num train calls              99000
trainer/QF1 Loss                         2.7667e-05
trainer/QF2 Loss                         7.17206e-05
trainer/Policy Loss                     -1.73629
trainer/Q1 Predictions Mean              1.73942
trainer/Q1 Predictions Std               0.0897148
trainer/Q1 Predictions Max               1.92505
trainer/Q1 Predictions Min               1.58962
trainer/Q2 Predictions Mean              1.73591
trainer/Q2 Predictions Std               0.0905492
trainer/Q2 Predictions Max               1.92627
trainer/Q2 Predictions Min               1.57846
trainer/Q Targets Mean                   1.74052
trainer/Q Targets Std                    0.0907852
trainer/Q Targets Max                    1.92383
trainer/Q Targets Min                    1.57712
trainer/Log Pis Mean                     3.06213
trainer/Log Pis Std                      2.67653
trainer/Log Pis Max                     10.2094
trainer/Log Pis Min                     -4.51889
trainer/policy/mean Mean                 0.0168354
trainer/policy/mean Std                  0.687186
trainer/policy/mean Max                  0.995856
trainer/policy/mean Min                 -0.995747
trainer/policy/normal/std Mean           0.393391
trainer/policy/normal/std Std            0.322262
trainer/policy/normal/std Max            3.17403
trainer/policy/normal/std Min            0.0145478
trainer/policy/normal/log_std Mean      -1.29469
trainer/policy/normal/log_std Std        0.961438
trainer/policy/normal/log_std Max        1.155
trainer/policy/normal/log_std Min       -4.23032
trainer/Alpha                            0.000525989
trainer/Alpha Loss                       0.469102
expl/num steps total                100000
expl/num paths total                   119
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.272731
expl/Actions Std                         0.428246
expl/Actions Max                         0.996619
expl/Actions Min                        -0.985173
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                494002
eval/num paths total                   495
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.358917
eval/Actions Std                         0.308717
eval/Actions Max                         0.994976
eval/Actions Min                        -0.978894
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00354512
time/evaluation sampling (s)             0.955387
time/exploration sampling (s)            0.33134
time/logging (s)                         0.00934742
time/sac training (s)                   11.8567
time/saving (s)                          0.00354453
time/training (s)                        2.219e-05
time/epoch (s)                          13.1599
time/total (s)                        1291.35
Epoch                                   98
----------------------------------  ----------------
2022-09-09 20:14:35.765486 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 99 finished
----------------------------------  ----------------
epoch                                   99
replay_buffer/size                  101000
trainer/num train calls             100000
trainer/QF1 Loss                         1.4009e-05
trainer/QF2 Loss                         5.48385e-05
trainer/Policy Loss                     -1.65726
trainer/Q1 Predictions Mean              1.65766
trainer/Q1 Predictions Std               0.0817477
trainer/Q1 Predictions Max               1.88356
trainer/Q1 Predictions Min               1.52719
trainer/Q2 Predictions Mean              1.65315
trainer/Q2 Predictions Std               0.0806518
trainer/Q2 Predictions Max               1.88181
trainer/Q2 Predictions Min               1.50215
trainer/Q Targets Mean                   1.65771
trainer/Q Targets Std                    0.0816271
trainer/Q Targets Max                    1.88316
trainer/Q Targets Min                    1.5275
trainer/Log Pis Mean                     2.68109
trainer/Log Pis Std                      2.7671
trainer/Log Pis Max                     10.1405
trainer/Log Pis Min                     -4.36587
trainer/policy/mean Mean                -0.0502806
trainer/policy/mean Std                  0.670898
trainer/policy/mean Max                  0.995133
trainer/policy/mean Min                 -0.998938
trainer/policy/normal/std Mean           0.409082
trainer/policy/normal/std Std            0.267464
trainer/policy/normal/std Max            1.66875
trainer/policy/normal/std Min            0.0128231
trainer/policy/normal/log_std Mean      -1.18889
trainer/policy/normal/log_std Std        0.890676
trainer/policy/normal/log_std Max        0.512077
trainer/policy/normal/log_std Min       -4.35651
trainer/Alpha                            0.000481605
trainer/Alpha Loss                      -2.43594
expl/num steps total                101000
expl/num paths total                   120
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.214893
expl/Actions Std                         0.465023
expl/Actions Max                         0.998526
expl/Actions Min                        -0.993581
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                499002
eval/num paths total                   500
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.313256
eval/Actions Std                         0.322056
eval/Actions Max                         0.998228
eval/Actions Min                        -0.998229
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0053727
time/evaluation sampling (s)             0.954133
time/exploration sampling (s)            0.320644
time/logging (s)                         0.00897845
time/sac training (s)                   11.8519
time/saving (s)                          0.00576042
time/training (s)                        3.253e-05
time/epoch (s)                          13.1469
time/total (s)                        1304.78
Epoch                                   99
----------------------------------  ----------------
2022-09-09 20:14:49.485222 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 100 finished
----------------------------------  ----------------
epoch                                  100
replay_buffer/size                  102000
trainer/num train calls             101000
trainer/QF1 Loss                         2.03755e-05
trainer/QF2 Loss                         4.56016e-05
trainer/Policy Loss                     -1.59067
trainer/Q1 Predictions Mean              1.58837
trainer/Q1 Predictions Std               0.0935809
trainer/Q1 Predictions Max               1.81021
trainer/Q1 Predictions Min               1.43272
trainer/Q2 Predictions Mean              1.59095
trainer/Q2 Predictions Std               0.0941939
trainer/Q2 Predictions Max               1.81715
trainer/Q2 Predictions Min               1.4344
trainer/Q Targets Mean                   1.58798
trainer/Q Targets Std                    0.093862
trainer/Q Targets Max                    1.81422
trainer/Q Targets Min                    1.44149
trainer/Log Pis Mean                     3.00472
trainer/Log Pis Std                      2.50177
trainer/Log Pis Max                     10.623
trainer/Log Pis Min                     -3.66775
trainer/policy/mean Mean                -0.0361693
trainer/policy/mean Std                  0.684026
trainer/policy/mean Max                  0.997082
trainer/policy/mean Min                 -0.994562
trainer/policy/normal/std Mean           0.400552
trainer/policy/normal/std Std            0.277245
trainer/policy/normal/std Max            2.01626
trainer/policy/normal/std Min            0.0126731
trainer/policy/normal/log_std Mean      -1.20703
trainer/policy/normal/log_std Std        0.855235
trainer/policy/normal/log_std Max        0.701246
trainer/policy/normal/log_std Min       -4.36828
trainer/Alpha                            0.000497663
trainer/Alpha Loss                       0.0359319
expl/num steps total                102000
expl/num paths total                   121
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.187035
expl/Actions Std                         0.451583
expl/Actions Max                         0.952343
expl/Actions Min                        -0.996198
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                504002
eval/num paths total                   505
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.202677
eval/Actions Std                         0.375865
eval/Actions Max                         0.996904
eval/Actions Min                        -0.990827
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0035286
time/evaluation sampling (s)             0.976692
time/exploration sampling (s)            0.334024
time/logging (s)                         0.0102742
time/sac training (s)                   12.0773
time/saving (s)                          0.00448118
time/training (s)                        2.919e-05
time/epoch (s)                          13.4063
time/total (s)                        1318.49
Epoch                                  100
----------------------------------  ----------------
2022-09-09 20:15:03.147579 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 101 finished
----------------------------------  ----------------
epoch                                  101
replay_buffer/size                  103000
trainer/num train calls             102000
trainer/QF1 Loss                         2.46455e-05
trainer/QF2 Loss                         3.97092e-05
trainer/Policy Loss                     -1.52603
trainer/Q1 Predictions Mean              1.52499
trainer/Q1 Predictions Std               0.0911624
trainer/Q1 Predictions Max               1.75385
trainer/Q1 Predictions Min               1.40072
trainer/Q2 Predictions Mean              1.52187
trainer/Q2 Predictions Std               0.0923852
trainer/Q2 Predictions Max               1.75704
trainer/Q2 Predictions Min               1.38983
trainer/Q Targets Mean                   1.52395
trainer/Q Targets Std                    0.0927594
trainer/Q Targets Max                    1.75826
trainer/Q Targets Min                    1.39084
trainer/Log Pis Mean                     3.39321
trainer/Log Pis Std                      2.60459
trainer/Log Pis Max                      9.62213
trainer/Log Pis Min                     -5.63595
trainer/policy/mean Mean                -0.0108564
trainer/policy/mean Std                  0.731871
trainer/policy/mean Max                  0.994694
trainer/policy/mean Min                 -0.99914
trainer/policy/normal/std Mean           0.42941
trainer/policy/normal/std Std            0.257122
trainer/policy/normal/std Max            1.97943
trainer/policy/normal/std Min            0.0148233
trainer/policy/normal/log_std Mean      -1.11859
trainer/policy/normal/log_std Std        0.882128
trainer/policy/normal/log_std Max        0.68281
trainer/policy/normal/log_std Min       -4.21156
trainer/Alpha                            0.000485229
trainer/Alpha Loss                       3.00053
expl/num steps total                103000
expl/num paths total                   122
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.185312
expl/Actions Std                         0.449117
expl/Actions Max                         0.942886
expl/Actions Min                        -0.999126
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                509002
eval/num paths total                   510
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.249783
eval/Actions Std                         0.322924
eval/Actions Max                         0.939231
eval/Actions Min                        -0.997455
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0052469
time/evaluation sampling (s)             0.958179
time/exploration sampling (s)            0.319907
time/logging (s)                         0.00918432
time/sac training (s)                   12.0481
time/saving (s)                          0.00367633
time/training (s)                        1.948e-05
time/epoch (s)                          13.3443
time/total (s)                        1332.14
Epoch                                  101
----------------------------------  ----------------
2022-09-09 20:15:17.233030 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 102 finished
----------------------------------  ----------------
epoch                                  102
replay_buffer/size                  104000
trainer/num train calls             103000
trainer/QF1 Loss                         2.40393e-05
trainer/QF2 Loss                         6.2656e-05
trainer/Policy Loss                     -1.476
trainer/Q1 Predictions Mean              1.47342
trainer/Q1 Predictions Std               0.0907518
trainer/Q1 Predictions Max               1.70562
trainer/Q1 Predictions Min               1.37847
trainer/Q2 Predictions Mean              1.47037
trainer/Q2 Predictions Std               0.0926804
trainer/Q2 Predictions Max               1.70734
trainer/Q2 Predictions Min               1.37243
trainer/Q Targets Mean                   1.47119
trainer/Q Targets Std                    0.0905348
trainer/Q Targets Max                    1.69926
trainer/Q Targets Min                    1.37675
trainer/Log Pis Mean                     3.15636
trainer/Log Pis Std                      2.60471
trainer/Log Pis Max                      9.2048
trainer/Log Pis Min                     -6.76732
trainer/policy/mean Mean                -0.0253369
trainer/policy/mean Std                  0.697773
trainer/policy/mean Max                  0.99179
trainer/policy/mean Min                 -0.991993
trainer/policy/normal/std Mean           0.401177
trainer/policy/normal/std Std            0.248959
trainer/policy/normal/std Max            1.40948
trainer/policy/normal/std Min            0.0131287
trainer/policy/normal/log_std Mean      -1.18685
trainer/policy/normal/log_std Std        0.870307
trainer/policy/normal/log_std Max        0.343223
trainer/policy/normal/log_std Min       -4.33296
trainer/Alpha                            0.000501749
trainer/Alpha Loss                       1.18794
expl/num steps total                104000
expl/num paths total                   123
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.152013
expl/Actions Std                         0.248571
expl/Actions Max                         0.462066
expl/Actions Min                        -0.864286
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                514002
eval/num paths total                   515
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.185963
eval/Actions Std                         0.241166
eval/Actions Max                         0.720314
eval/Actions Min                        -0.982993
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0035535
time/evaluation sampling (s)             0.968813
time/exploration sampling (s)            0.319333
time/logging (s)                         0.00953507
time/sac training (s)                   12.4297
time/saving (s)                          0.0036518
time/training (s)                        0.00023473
time/epoch (s)                          13.7348
time/total (s)                        1346.21
Epoch                                  102
----------------------------------  ----------------
2022-09-09 20:15:31.004275 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 103 finished
----------------------------------  ----------------
epoch                                  103
replay_buffer/size                  105000
trainer/num train calls             104000
trainer/QF1 Loss                         1.95452e-05
trainer/QF2 Loss                         4.33794e-05
trainer/Policy Loss                     -1.43197
trainer/Q1 Predictions Mean              1.4282
trainer/Q1 Predictions Std               0.0922539
trainer/Q1 Predictions Max               1.62521
trainer/Q1 Predictions Min               1.30987
trainer/Q2 Predictions Mean              1.42811
trainer/Q2 Predictions Std               0.0931536
trainer/Q2 Predictions Max               1.63932
trainer/Q2 Predictions Min               1.3038
trainer/Q Targets Mean                   1.42701
trainer/Q Targets Std                    0.0923651
trainer/Q Targets Max                    1.62381
trainer/Q Targets Min                    1.31876
trainer/Log Pis Mean                     2.88812
trainer/Log Pis Std                      2.6316
trainer/Log Pis Max                      8.74819
trainer/Log Pis Min                     -5.60548
trainer/policy/mean Mean                 0.0547577
trainer/policy/mean Std                  0.655824
trainer/policy/mean Max                  0.997572
trainer/policy/mean Min                 -0.995808
trainer/policy/normal/std Mean           0.38785
trainer/policy/normal/std Std            0.228048
trainer/policy/normal/std Max            1.15022
trainer/policy/normal/std Min            0.0105611
trainer/policy/normal/log_std Mean      -1.24467
trainer/policy/normal/log_std Std        0.956842
trainer/policy/normal/log_std Max        0.139956
trainer/policy/normal/log_std Min       -4.55058
trainer/Alpha                            0.00047964
trainer/Alpha Loss                      -0.855053
expl/num steps total                105000
expl/num paths total                   124
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.103012
expl/Actions Std                         0.433827
expl/Actions Max                         0.98277
expl/Actions Min                        -0.946048
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                519002
eval/num paths total                   520
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.116146
eval/Actions Std                         0.529011
eval/Actions Max                         0.994441
eval/Actions Min                        -0.97951
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00550709
time/evaluation sampling (s)             0.976909
time/exploration sampling (s)            0.314656
time/logging (s)                         0.00953295
time/sac training (s)                   12.1364
time/saving (s)                          0.00464928
time/training (s)                        3.33e-05
time/epoch (s)                          13.4476
time/total (s)                        1359.97
Epoch                                  103
----------------------------------  ----------------
2022-09-09 20:15:44.634732 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 104 finished
----------------------------------  ----------------
epoch                                  104
replay_buffer/size                  106000
trainer/num train calls             105000
trainer/QF1 Loss                         1.81638e-05
trainer/QF2 Loss                         3.38616e-05
trainer/Policy Loss                     -1.38131
trainer/Q1 Predictions Mean              1.37755
trainer/Q1 Predictions Std               0.0966162
trainer/Q1 Predictions Max               1.54887
trainer/Q1 Predictions Min               1.27411
trainer/Q2 Predictions Mean              1.37579
trainer/Q2 Predictions Std               0.0965287
trainer/Q2 Predictions Max               1.54519
trainer/Q2 Predictions Min               1.25901
trainer/Q Targets Mean                   1.37932
trainer/Q Targets Std                    0.0967
trainer/Q Targets Max                    1.55322
trainer/Q Targets Min                    1.27221
trainer/Log Pis Mean                     2.80212
trainer/Log Pis Std                      2.33954
trainer/Log Pis Max                      8.6662
trainer/Log Pis Min                     -2.95871
trainer/policy/mean Mean                -0.0964832
trainer/policy/mean Std                  0.668773
trainer/policy/mean Max                  0.994723
trainer/policy/mean Min                 -0.994908
trainer/policy/normal/std Mean           0.454249
trainer/policy/normal/std Std            0.282891
trainer/policy/normal/std Max            1.65952
trainer/policy/normal/std Min            0.0211453
trainer/policy/normal/log_std Mean      -1.04922
trainer/policy/normal/log_std Std        0.835356
trainer/policy/normal/log_std Max        0.506529
trainer/policy/normal/log_std Min       -3.85634
trainer/Alpha                            0.000370469
trainer/Alpha Loss                      -1.56338
expl/num steps total                106000
expl/num paths total                   125
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0698146
expl/Actions Std                         0.480886
expl/Actions Max                         0.970624
expl/Actions Min                        -0.962757
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                524002
eval/num paths total                   525
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0589029
eval/Actions Std                         0.562888
eval/Actions Max                         0.973577
eval/Actions Min                        -0.988977
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00517129
time/evaluation sampling (s)             0.94412
time/exploration sampling (s)            0.334406
time/logging (s)                         0.00977268
time/sac training (s)                   12.0193
time/saving (s)                          0.00347722
time/training (s)                        3.997e-05
time/epoch (s)                          13.3162
time/total (s)                        1373.59
Epoch                                  104
----------------------------------  ----------------
2022-09-09 20:15:58.268821 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 105 finished
----------------------------------  ----------------
epoch                                  105
replay_buffer/size                  107000
trainer/num train calls             106000
trainer/QF1 Loss                         1.71511e-05
trainer/QF2 Loss                         2.73346e-05
trainer/Policy Loss                     -1.3423
trainer/Q1 Predictions Mean              1.33525
trainer/Q1 Predictions Std               0.0970208
trainer/Q1 Predictions Max               1.51784
trainer/Q1 Predictions Min               1.20792
trainer/Q2 Predictions Mean              1.33687
trainer/Q2 Predictions Std               0.0968862
trainer/Q2 Predictions Max               1.51956
trainer/Q2 Predictions Min               1.21003
trainer/Q Targets Mean                   1.33614
trainer/Q Targets Std                    0.0960263
trainer/Q Targets Max                    1.51796
trainer/Q Targets Min                    1.2068
trainer/Log Pis Mean                     3.24706
trainer/Log Pis Std                      2.506
trainer/Log Pis Max                      9.30735
trainer/Log Pis Min                     -5.26006
trainer/policy/mean Mean                -0.132828
trainer/policy/mean Std                  0.756132
trainer/policy/mean Max                  0.992787
trainer/policy/mean Min                 -0.997117
trainer/policy/normal/std Mean           0.450988
trainer/policy/normal/std Std            0.224567
trainer/policy/normal/std Max            1.06865
trainer/policy/normal/std Min            0.0244299
trainer/policy/normal/log_std Mean      -0.984946
trainer/policy/normal/log_std Std        0.716872
trainer/policy/normal/log_std Max        0.0663991
trainer/policy/normal/log_std Min       -3.71195
trainer/Alpha                            0.000459517
trainer/Alpha Loss                       1.89875
expl/num steps total                107000
expl/num paths total                   126
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0629048
expl/Actions Std                         0.197296
expl/Actions Max                         0.657126
expl/Actions Min                        -0.847253
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                529002
eval/num paths total                   530
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0299572
eval/Actions Std                         0.327307
eval/Actions Max                         0.984307
eval/Actions Min                        -0.998082
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0051941
time/evaluation sampling (s)             0.967031
time/exploration sampling (s)            0.328196
time/logging (s)                         0.00938841
time/sac training (s)                   12.0149
time/saving (s)                          0.00337635
time/training (s)                        1.854e-05
time/epoch (s)                          13.3281
time/total (s)                        1387.21
Epoch                                  105
----------------------------------  ----------------
2022-09-09 20:16:11.944653 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 106 finished
----------------------------------  ----------------
epoch                                  106
replay_buffer/size                  108000
trainer/num train calls             107000
trainer/QF1 Loss                         1.92427e-05
trainer/QF2 Loss                         2.68102e-05
trainer/Policy Loss                     -1.30359
trainer/Q1 Predictions Mean              1.29772
trainer/Q1 Predictions Std               0.0925859
trainer/Q1 Predictions Max               1.47182
trainer/Q1 Predictions Min               1.15623
trainer/Q2 Predictions Mean              1.29719
trainer/Q2 Predictions Std               0.0920287
trainer/Q2 Predictions Max               1.46998
trainer/Q2 Predictions Min               1.15613
trainer/Q Targets Mean                   1.29848
trainer/Q Targets Std                    0.0924391
trainer/Q Targets Max                    1.47328
trainer/Q Targets Min                    1.15845
trainer/Log Pis Mean                     2.83982
trainer/Log Pis Std                      2.43358
trainer/Log Pis Max                      9.30283
trainer/Log Pis Min                     -5.95674
trainer/policy/mean Mean                 0.0186442
trainer/policy/mean Std                  0.719729
trainer/policy/mean Max                  0.999897
trainer/policy/mean Min                 -0.997684
trainer/policy/normal/std Mean           0.469152
trainer/policy/normal/std Std            0.216912
trainer/policy/normal/std Max            1.51747
trainer/policy/normal/std Min            0.0192958
trainer/policy/normal/log_std Mean      -0.928827
trainer/policy/normal/log_std Std        0.709795
trainer/policy/normal/log_std Max        0.417045
trainer/policy/normal/log_std Min       -3.94787
trainer/Alpha                            0.000471327
trainer/Alpha Loss                      -1.22697
expl/num steps total                108000
expl/num paths total                   127
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0548001
expl/Actions Std                         0.232795
expl/Actions Max                         0.820183
expl/Actions Min                        -0.99787
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                534002
eval/num paths total                   535
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0754657
eval/Actions Std                         0.444445
eval/Actions Max                         0.975226
eval/Actions Min                        -0.995855
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00560033
time/evaluation sampling (s)             0.945617
time/exploration sampling (s)            0.325797
time/logging (s)                         0.00894242
time/sac training (s)                   12.0777
time/saving (s)                          0.00436661
time/training (s)                        2.456e-05
time/epoch (s)                          13.3681
time/total (s)                        1400.87
Epoch                                  106
----------------------------------  ----------------
2022-09-09 20:16:25.471771 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 107 finished
----------------------------------  ----------------
epoch                                  107
replay_buffer/size                  109000
trainer/num train calls             108000
trainer/QF1 Loss                         1.4485e-05
trainer/QF2 Loss                         3.34131e-05
trainer/Policy Loss                     -1.28735
trainer/Q1 Predictions Mean              1.28614
trainer/Q1 Predictions Std               0.0820736
trainer/Q1 Predictions Max               1.45216
trainer/Q1 Predictions Min               1.12134
trainer/Q2 Predictions Mean              1.27884
trainer/Q2 Predictions Std               0.0828625
trainer/Q2 Predictions Max               1.44666
trainer/Q2 Predictions Min               1.11652
trainer/Q Targets Mean                   1.28337
trainer/Q Targets Std                    0.0821688
trainer/Q Targets Max                    1.452
trainer/Q Targets Min                    1.11535
trainer/Log Pis Mean                     2.81766
trainer/Log Pis Std                      2.40058
trainer/Log Pis Max                      9.66646
trainer/Log Pis Min                     -5.79426
trainer/policy/mean Mean                -0.0541435
trainer/policy/mean Std                  0.691367
trainer/policy/mean Max                  0.998608
trainer/policy/mean Min                 -0.996335
trainer/policy/normal/std Mean           0.430315
trainer/policy/normal/std Std            0.232075
trainer/policy/normal/std Max            0.976011
trainer/policy/normal/std Min            0.0176186
trainer/policy/normal/log_std Mean      -1.05809
trainer/policy/normal/log_std Std        0.756227
trainer/policy/normal/log_std Max       -0.0242816
trainer/policy/normal/log_std Min       -4.0388
trainer/Alpha                            0.000428539
trainer/Alpha Loss                      -1.41408
expl/num steps total                109000
expl/num paths total                   128
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.237279
expl/Actions Std                         0.42881
expl/Actions Max                         0.994006
expl/Actions Min                        -0.986852
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                539002
eval/num paths total                   540
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.0357561
eval/Actions Std                         0.704206
eval/Actions Max                         0.990853
eval/Actions Min                        -0.992048
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00353039
time/evaluation sampling (s)             0.932159
time/exploration sampling (s)            0.300803
time/logging (s)                         0.00928711
time/sac training (s)                   11.9679
time/saving (s)                          0.00467928
time/training (s)                        2.605e-05
time/epoch (s)                          13.2184
time/total (s)                        1414.39
Epoch                                  107
----------------------------------  ----------------
2022-09-09 20:16:38.581446 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 108 finished
----------------------------------  ----------------
epoch                                  108
replay_buffer/size                  110000
trainer/num train calls             109000
trainer/QF1 Loss                         1.11951e-05
trainer/QF2 Loss                         2.63211e-05
trainer/Policy Loss                     -1.249
trainer/Q1 Predictions Mean              1.24379
trainer/Q1 Predictions Std               0.0890445
trainer/Q1 Predictions Max               1.46641
trainer/Q1 Predictions Min               1.09302
trainer/Q2 Predictions Mean              1.24336
trainer/Q2 Predictions Std               0.0898048
trainer/Q2 Predictions Max               1.48147
trainer/Q2 Predictions Min               1.09551
trainer/Q Targets Mean                   1.24327
trainer/Q Targets Std                    0.0883117
trainer/Q Targets Max                    1.45387
trainer/Q Targets Min                    1.09346
trainer/Log Pis Mean                     2.90871
trainer/Log Pis Std                      2.43691
trainer/Log Pis Max                      9.12567
trainer/Log Pis Min                     -4.05857
trainer/policy/mean Mean                -0.0436266
trainer/policy/mean Std                  0.682788
trainer/policy/mean Max                  0.995823
trainer/policy/mean Min                 -0.998128
trainer/policy/normal/std Mean           0.400363
trainer/policy/normal/std Std            0.222911
trainer/policy/normal/std Max            0.922736
trainer/policy/normal/std Min            0.0167995
trainer/policy/normal/log_std Mean      -1.16078
trainer/policy/normal/log_std Std        0.820242
trainer/policy/normal/log_std Max       -0.0804117
trainer/policy/normal/log_std Min       -4.08641
trainer/Alpha                            0.000379139
trainer/Alpha Loss                      -0.719127
expl/num steps total                110000
expl/num paths total                   129
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.00798251
expl/Actions Std                         0.754294
expl/Actions Max                         0.991859
expl/Actions Min                        -0.99773
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                544002
eval/num paths total                   545
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.105195
eval/Actions Std                         0.614989
eval/Actions Max                         0.996063
eval/Actions Min                        -0.990881
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.0035481
time/evaluation sampling (s)             0.938663
time/exploration sampling (s)            0.309246
time/logging (s)                         0.0091873
time/sac training (s)                   11.5762
time/saving (s)                          0.00326179
time/training (s)                        1.861e-05
time/epoch (s)                          12.8402
time/total (s)                        1427.49
Epoch                                  108
----------------------------------  ----------------
2022-09-09 20:16:52.147643 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 109 finished
----------------------------------  ----------------
epoch                                  109
replay_buffer/size                  111000
trainer/num train calls             110000
trainer/QF1 Loss                         1.31661e-05
trainer/QF2 Loss                         1.42355e-05
trainer/Policy Loss                     -1.21432
trainer/Q1 Predictions Mean              1.21052
trainer/Q1 Predictions Std               0.0903553
trainer/Q1 Predictions Max               1.42429
trainer/Q1 Predictions Min               1.10033
trainer/Q2 Predictions Mean              1.20991
trainer/Q2 Predictions Std               0.0898281
trainer/Q2 Predictions Max               1.43422
trainer/Q2 Predictions Min               1.09652
trainer/Q Targets Mean                   1.20824
trainer/Q Targets Std                    0.0896116
trainer/Q Targets Max                    1.41092
trainer/Q Targets Min                    1.09751
trainer/Log Pis Mean                     2.46771
trainer/Log Pis Std                      2.22801
trainer/Log Pis Max                      7.72422
trainer/Log Pis Min                     -3.28182
trainer/policy/mean Mean                -0.0245513
trainer/policy/mean Std                  0.643126
trainer/policy/mean Max                  0.995974
trainer/policy/mean Min                 -0.997556
trainer/policy/normal/std Mean           0.37473
trainer/policy/normal/std Std            0.224189
trainer/policy/normal/std Max            0.909847
trainer/policy/normal/std Min            0.0182727
trainer/policy/normal/log_std Mean      -1.23056
trainer/policy/normal/log_std Std        0.803393
trainer/policy/normal/log_std Max       -0.0944791
trainer/policy/normal/log_std Min       -4.00235
trainer/Alpha                            0.000270241
trainer/Alpha Loss                      -4.37344
expl/num steps total                111000
expl/num paths total                   130
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.562214
expl/Actions Std                         0.437279
expl/Actions Max                         0.997626
expl/Actions Min                        -0.98859
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                549002
eval/num paths total                   550
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.448932
eval/Actions Std                         0.465407
eval/Actions Max                         0.988936
eval/Actions Min                        -0.985337
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00348661
time/evaluation sampling (s)             0.936961
time/exploration sampling (s)            0.329108
time/logging (s)                         0.00959938
time/sac training (s)                   11.9846
time/saving (s)                          0.00492176
time/training (s)                        2.877e-05
time/epoch (s)                          13.2687
time/total (s)                        1441.04
Epoch                                  109
----------------------------------  ----------------
2022-09-09 20:17:06.115834 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 110 finished
----------------------------------  ----------------
epoch                                  110
replay_buffer/size                  112000
trainer/num train calls             111000
trainer/QF1 Loss                         6.72482e-06
trainer/QF2 Loss                         2.96345e-05
trainer/Policy Loss                     -1.1631
trainer/Q1 Predictions Mean              1.16172
trainer/Q1 Predictions Std               0.088565
trainer/Q1 Predictions Max               1.35625
trainer/Q1 Predictions Min               1.06365
trainer/Q2 Predictions Mean              1.15879
trainer/Q2 Predictions Std               0.0880353
trainer/Q2 Predictions Max               1.35233
trainer/Q2 Predictions Min               1.06507
trainer/Q Targets Mean                   1.1621
trainer/Q Targets Std                    0.0875367
trainer/Q Targets Max                    1.34826
trainer/Q Targets Min                    1.06203
trainer/Log Pis Mean                     2.62009
trainer/Log Pis Std                      2.1436
trainer/Log Pis Max                      9.84606
trainer/Log Pis Min                     -4.2614
trainer/policy/mean Mean                -0.00594008
trainer/policy/mean Std                  0.659887
trainer/policy/mean Max                  0.999
trainer/policy/mean Min                 -0.997154
trainer/policy/normal/std Mean           0.369604
trainer/policy/normal/std Std            0.255696
trainer/policy/normal/std Max            2.04994
trainer/policy/normal/std Min            0.0156045
trainer/policy/normal/log_std Mean      -1.28694
trainer/policy/normal/log_std Std        0.843084
trainer/policy/normal/log_std Max        0.71781
trainer/policy/normal/log_std Min       -4.16019
trainer/Alpha                            0.00021856
trainer/Alpha Loss                      -3.20207
expl/num steps total                112000
expl/num paths total                   131
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0746927
expl/Actions Std                         0.342319
expl/Actions Max                         0.953071
expl/Actions Min                        -0.979724
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                554002
eval/num paths total                   555
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.286483
eval/Actions Std                         0.427728
eval/Actions Max                         0.990844
eval/Actions Min                        -0.997756
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00358148
time/evaluation sampling (s)             0.974452
time/exploration sampling (s)            0.321996
time/logging (s)                         0.00907072
time/sac training (s)                   12.3326
time/saving (s)                          0.00335996
time/training (s)                        1.94e-05
time/epoch (s)                          13.6451
time/total (s)                        1455
Epoch                                  110
----------------------------------  ----------------
2022-09-09 20:17:19.169895 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 111 finished
----------------------------------  ----------------
epoch                                  111
replay_buffer/size                  113000
trainer/num train calls             112000
trainer/QF1 Loss                         6.20839e-06
trainer/QF2 Loss                         7.00967e-06
trainer/Policy Loss                     -1.12444
trainer/Q1 Predictions Mean              1.12205
trainer/Q1 Predictions Std               0.0894813
trainer/Q1 Predictions Max               1.29347
trainer/Q1 Predictions Min               1.03356
trainer/Q2 Predictions Mean              1.12148
trainer/Q2 Predictions Std               0.0898328
trainer/Q2 Predictions Max               1.29568
trainer/Q2 Predictions Min               1.02778
trainer/Q Targets Mean                   1.12168
trainer/Q Targets Std                    0.0897915
trainer/Q Targets Max                    1.29311
trainer/Q Targets Min                    1.01909
trainer/Log Pis Mean                     3.12628
trainer/Log Pis Std                      2.58119
trainer/Log Pis Max                     11.6927
trainer/Log Pis Min                     -4.34904
trainer/policy/mean Mean                 0.0637952
trainer/policy/mean Std                  0.650864
trainer/policy/mean Max                  0.999797
trainer/policy/mean Min                 -0.996794
trainer/policy/normal/std Mean           0.356318
trainer/policy/normal/std Std            0.276071
trainer/policy/normal/std Max            1.89949
trainer/policy/normal/std Min            0.0176065
trainer/policy/normal/log_std Mean      -1.39061
trainer/policy/normal/log_std Std        0.930727
trainer/policy/normal/log_std Max        0.641587
trainer/policy/normal/log_std Min       -4.03949
trainer/Alpha                            0.0001992
trainer/Alpha Loss                       1.07608
expl/num steps total                113000
expl/num paths total                   132
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.219503
expl/Actions Std                         0.380828
expl/Actions Max                         0.996737
expl/Actions Min                        -0.729576
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                559002
eval/num paths total                   560
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0830865
eval/Actions Std                         0.251433
eval/Actions Max                         0.972807
eval/Actions Min                        -0.971537
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00348617
time/evaluation sampling (s)             0.934953
time/exploration sampling (s)            0.286363
time/logging (s)                         0.00903305
time/sac training (s)                   11.5549
time/saving (s)                          0.00340997
time/training (s)                        1.814e-05
time/epoch (s)                          12.7922
time/total (s)                        1468.04
Epoch                                  111
----------------------------------  ----------------
2022-09-09 20:17:32.419285 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 112 finished
----------------------------------  ----------------
epoch                                  112
replay_buffer/size                  114000
trainer/num train calls             113000
trainer/QF1 Loss                         7.60802e-06
trainer/QF2 Loss                         1.5608e-05
trainer/Policy Loss                     -1.08181
trainer/Q1 Predictions Mean              1.08003
trainer/Q1 Predictions Std               0.0938796
trainer/Q1 Predictions Max               1.24497
trainer/Q1 Predictions Min               0.986223
trainer/Q2 Predictions Mean              1.07922
trainer/Q2 Predictions Std               0.0944845
trainer/Q2 Predictions Max               1.24775
trainer/Q2 Predictions Min               0.974555
trainer/Q Targets Mean                   1.08193
trainer/Q Targets Std                    0.0942322
trainer/Q Targets Max                    1.24654
trainer/Q Targets Min                    0.982934
trainer/Log Pis Mean                     2.56379
trainer/Log Pis Std                      2.936
trainer/Log Pis Max                     12.3282
trainer/Log Pis Min                     -3.29238
trainer/policy/mean Mean                 0.111136
trainer/policy/mean Std                  0.614126
trainer/policy/mean Max                  0.99996
trainer/policy/mean Min                 -0.984377
trainer/policy/normal/std Mean           0.41319
trainer/policy/normal/std Std            0.281601
trainer/policy/normal/std Max            1.54697
trainer/policy/normal/std Min            0.0201201
trainer/policy/normal/log_std Mean      -1.21545
trainer/policy/normal/log_std Std        0.924994
trainer/policy/normal/log_std Max        0.4363
trainer/policy/normal/log_std Min       -3.90603
trainer/Alpha                            0.000174295
trainer/Alpha Loss                      -3.77525
expl/num steps total                114000
expl/num paths total                   133
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0701423
expl/Actions Std                         0.370517
expl/Actions Max                         0.993466
expl/Actions Min                        -0.952523
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                564002
eval/num paths total                   565
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0117327
eval/Actions Std                         0.166008
eval/Actions Max                         0.999494
eval/Actions Min                        -0.986387
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00347467
time/evaluation sampling (s)             0.941825
time/exploration sampling (s)            0.301802
time/logging (s)                         0.00937436
time/sac training (s)                   11.7069
time/saving (s)                          0.0044487
time/training (s)                        2.583e-05
time/epoch (s)                          12.9679
time/total (s)                        1481.28
Epoch                                  112
----------------------------------  ----------------
2022-09-09 20:17:45.945965 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 113 finished
----------------------------------  ----------------
epoch                                  113
replay_buffer/size                  115000
trainer/num train calls             114000
trainer/QF1 Loss                         1.36863e-05
trainer/QF2 Loss                         9.30528e-06
trainer/Policy Loss                     -1.03876
trainer/Q1 Predictions Mean              1.03469
trainer/Q1 Predictions Std               0.0901692
trainer/Q1 Predictions Max               1.19272
trainer/Q1 Predictions Min               0.946169
trainer/Q2 Predictions Mean              1.0387
trainer/Q2 Predictions Std               0.0910782
trainer/Q2 Predictions Max               1.19926
trainer/Q2 Predictions Min               0.949481
trainer/Q Targets Mean                   1.03719
trainer/Q Targets Std                    0.0911739
trainer/Q Targets Max                    1.19787
trainer/Q Targets Min                    0.945204
trainer/Log Pis Mean                     3.34448
trainer/Log Pis Std                      2.78484
trainer/Log Pis Max                     12.7278
trainer/Log Pis Min                     -4.04627
trainer/policy/mean Mean                 0.243637
trainer/policy/mean Std                  0.654069
trainer/policy/mean Max                  0.999448
trainer/policy/mean Min                 -0.995923
trainer/policy/normal/std Mean           0.447419
trainer/policy/normal/std Std            0.324189
trainer/policy/normal/std Max            3.2255
trainer/policy/normal/std Min            0.0311253
trainer/policy/normal/log_std Mean      -1.13592
trainer/policy/normal/log_std Std        0.927865
trainer/policy/normal/log_std Max        1.17109
trainer/policy/normal/log_std Min       -3.46973
trainer/Alpha                            0.000162377
trainer/Alpha Loss                       3.00583
expl/num steps total                115000
expl/num paths total                   134
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.246283
expl/Actions Std                         0.364129
expl/Actions Max                         0.959216
expl/Actions Min                        -0.33247
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                569002
eval/num paths total                   570
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.254613
eval/Actions Std                         0.383038
eval/Actions Max                         0.999735
eval/Actions Min                        -0.994718
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00401869
time/evaluation sampling (s)             0.974866
time/exploration sampling (s)            0.332028
time/logging (s)                         0.00915202
time/sac training (s)                   11.9051
time/saving (s)                          0.00341631
time/training (s)                        1.825e-05
time/epoch (s)                          13.2286
time/total (s)                        1494.79
Epoch                                  113
----------------------------------  ----------------
2022-09-09 20:17:59.023471 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 114 finished
----------------------------------  ----------------
epoch                                  114
replay_buffer/size                  116000
trainer/num train calls             115000
trainer/QF1 Loss                         3.21899e-06
trainer/QF2 Loss                         8.81642e-06
trainer/Policy Loss                     -1.00981
trainer/Q1 Predictions Mean              1.00506
trainer/Q1 Predictions Std               0.0875177
trainer/Q1 Predictions Max               1.14648
trainer/Q1 Predictions Min               0.909965
trainer/Q2 Predictions Mean              1.00604
trainer/Q2 Predictions Std               0.0868061
trainer/Q2 Predictions Max               1.14795
trainer/Q2 Predictions Min               0.911933
trainer/Q Targets Mean                   1.0049
trainer/Q Targets Std                    0.0876226
trainer/Q Targets Max                    1.14759
trainer/Q Targets Min                    0.909502
trainer/Log Pis Mean                     4.375
trainer/Log Pis Std                      2.64147
trainer/Log Pis Max                     12.9567
trainer/Log Pis Min                     -3.97912
trainer/policy/mean Mean                 0.31717
trainer/policy/mean Std                  0.701548
trainer/policy/mean Max                  0.997049
trainer/policy/mean Min                 -0.988332
trainer/policy/normal/std Mean           0.471512
trainer/policy/normal/std Std            0.270644
trainer/policy/normal/std Max            1.69314
trainer/policy/normal/std Min            0.019582
trainer/policy/normal/log_std Mean      -1.00286
trainer/policy/normal/log_std Std        0.838399
trainer/policy/normal/log_std Max        0.526582
trainer/policy/normal/log_std Min       -3.93314
trainer/Alpha                            0.000212307
trainer/Alpha Loss                      11.629
expl/num steps total                116000
expl/num paths total                   135
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0582617
expl/Actions Std                         0.240639
expl/Actions Max                         0.99927
expl/Actions Min                        -0.769597
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                574002
eval/num paths total                   575
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0626734
eval/Actions Std                         0.101163
eval/Actions Max                         0.997628
eval/Actions Min                        -0.592331
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00422202
time/evaluation sampling (s)             0.93548
time/exploration sampling (s)            0.307073
time/logging (s)                         0.00934179
time/sac training (s)                   11.5521
time/saving (s)                          0.00484728
time/training (s)                        1.933e-05
time/epoch (s)                          12.8131
time/total (s)                        1507.86
Epoch                                  114
----------------------------------  ----------------
2022-09-09 20:18:11.960768 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 115 finished
----------------------------------  ----------------
epoch                                  115
replay_buffer/size                  117000
trainer/num train calls             116000
trainer/QF1 Loss                         4.69167e-06
trainer/QF2 Loss                         1.02671e-05
trainer/Policy Loss                     -0.982476
trainer/Q1 Predictions Mean              0.977952
trainer/Q1 Predictions Std               0.0732043
trainer/Q1 Predictions Max               1.09205
trainer/Q1 Predictions Min               0.882388
trainer/Q2 Predictions Mean              0.978526
trainer/Q2 Predictions Std               0.0724203
trainer/Q2 Predictions Max               1.09343
trainer/Q2 Predictions Min               0.885606
trainer/Q Targets Mean                   0.976924
trainer/Q Targets Std                    0.0724961
trainer/Q Targets Max                    1.0913
trainer/Q Targets Min                    0.882504
trainer/Log Pis Mean                     2.93351
trainer/Log Pis Std                      2.63481
trainer/Log Pis Max                     10.1227
trainer/Log Pis Min                     -4.53271
trainer/policy/mean Mean                 0.250394
trainer/policy/mean Std                  0.700535
trainer/policy/mean Max                  0.996399
trainer/policy/mean Min                 -0.981019
trainer/policy/normal/std Mean           0.533271
trainer/policy/normal/std Std            0.250148
trainer/policy/normal/std Max            1.32915
trainer/policy/normal/std Min            0.0297613
trainer/policy/normal/log_std Mean      -0.802973
trainer/policy/normal/log_std Std        0.70189
trainer/policy/normal/log_std Max        0.284543
trainer/policy/normal/log_std Min       -3.51455
trainer/Alpha                            0.000284366
trainer/Alpha Loss                      -0.542909
expl/num steps total                117000
expl/num paths total                   136
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.0458364
expl/Actions Std                         0.31508
expl/Actions Max                         0.982319
expl/Actions Min                        -0.974847
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                579002
eval/num paths total                   580
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                        0.0582653
eval/Actions Std                         0.103787
eval/Actions Max                         0.993705
eval/Actions Min                        -0.914955
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00508426
time/evaluation sampling (s)             0.954064
time/exploration sampling (s)            0.315344
time/logging (s)                         0.00943713
time/sac training (s)                   11.3843
time/saving (s)                          0.00464329
time/training (s)                        2.585e-05
time/epoch (s)                          12.6729
time/total (s)                        1520.79
Epoch                                  115
----------------------------------  ----------------
2022-09-09 20:18:25.035020 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 116 finished
----------------------------------  ----------------
epoch                                  116
replay_buffer/size                  118000
trainer/num train calls             117000
trainer/QF1 Loss                         4.02577e-06
trainer/QF2 Loss                         5.50373e-06
trainer/Policy Loss                     -0.963213
trainer/Q1 Predictions Mean              0.958437
trainer/Q1 Predictions Std               0.0581318
trainer/Q1 Predictions Max               1.04228
trainer/Q1 Predictions Min               0.876533
trainer/Q2 Predictions Mean              0.957724
trainer/Q2 Predictions Std               0.0584346
trainer/Q2 Predictions Max               1.0427
trainer/Q2 Predictions Min               0.878213
trainer/Q Targets Mean                   0.957439
trainer/Q Targets Std                    0.0585101
trainer/Q Targets Max                    1.03934
trainer/Q Targets Min                    0.874294
trainer/Log Pis Mean                     2.94143
trainer/Log Pis Std                      2.9001
trainer/Log Pis Max                     12.6813
trainer/Log Pis Min                     -4.20513
trainer/policy/mean Mean                 0.127995
trainer/policy/mean Std                  0.752955
trainer/policy/mean Max                  0.999731
trainer/policy/mean Min                 -0.986662
trainer/policy/normal/std Mean           0.632237
trainer/policy/normal/std Std            0.316471
trainer/policy/normal/std Max            1.84668
trainer/policy/normal/std Min            0.0705439
trainer/policy/normal/log_std Mean      -0.595468
trainer/policy/normal/log_std Std        0.554319
trainer/policy/normal/log_std Max        0.61339
trainer/policy/normal/log_std Min       -2.65152
trainer/Alpha                            0.000251174
trainer/Alpha Loss                      -0.485471
expl/num steps total                118000
expl/num paths total                   137
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                        0.204119
expl/Actions Std                         0.403191
expl/Actions Max                         0.999426
expl/Actions Min                        -0.992438
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                583004
eval/num paths total                   585
eval/path length Mean                  800.4
eval/path length Std                   399.2
eval/path length Max                  1000
eval/path length Min                     2
eval/Rewards Mean                        0.000249875
eval/Rewards Std                         0.0158055
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        0.2
eval/Returns Std                         0.4
eval/Returns Max                         1
eval/Returns Min                         0
eval/Actions Mean                        0.132558
eval/Actions Std                         0.395968
eval/Actions Max                         0.997949
eval/Actions Min                        -0.987368
eval/Num Paths                           5
eval/Average Returns                     0.2
time/data storing (s)                    0.00560393
time/evaluation sampling (s)             0.933666
time/exploration sampling (s)            0.307335
time/logging (s)                         0.00780464
time/sac training (s)                   11.547
time/saving (s)                          0.00346677
time/training (s)                        1.796e-05
time/epoch (s)                          12.8049
time/total (s)                        1533.85
Epoch                                  116
----------------------------------  ----------------
2022-09-09 20:18:38.382643 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 117 finished
----------------------------------  ----------------
epoch                                  117
replay_buffer/size                  119000
trainer/num train calls             118000
trainer/QF1 Loss                         3.95679e-06
trainer/QF2 Loss                         1.36487e-05
trainer/Policy Loss                     -0.935907
trainer/Q1 Predictions Mean              0.93215
trainer/Q1 Predictions Std               0.0409211
trainer/Q1 Predictions Max               0.994257
trainer/Q1 Predictions Min               0.864782
trainer/Q2 Predictions Mean              0.930519
trainer/Q2 Predictions Std               0.0408188
trainer/Q2 Predictions Max               0.995287
trainer/Q2 Predictions Min               0.864734
trainer/Q Targets Mean                   0.932341
trainer/Q Targets Std                    0.0412762
trainer/Q Targets Max                    0.997432
trainer/Q Targets Min                    0.862471
trainer/Log Pis Mean                     3.22091
trainer/Log Pis Std                      2.47835
trainer/Log Pis Max                     10.4387
trainer/Log Pis Min                     -3.62923
trainer/policy/mean Mean                 0.0576294
trainer/policy/mean Std                  0.794873
trainer/policy/mean Max                  0.999265
trainer/policy/mean Min                 -0.99107
trainer/policy/normal/std Mean           0.584252
trainer/policy/normal/std Std            0.268816
trainer/policy/normal/std Max            1.78176
trainer/policy/normal/std Min            0.0823422
trainer/policy/normal/log_std Mean      -0.648684
trainer/policy/normal/log_std Std        0.492744
trainer/policy/normal/log_std Max        0.577602
trainer/policy/normal/log_std Min       -2.49687
trainer/Alpha                            0.000279104
trainer/Alpha Loss                       1.80793
expl/num steps total                119000
expl/num paths total                   138
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.129155
expl/Actions Std                         0.464204
expl/Actions Max                         0.926772
expl/Actions Min                        -0.995128
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                587010
eval/num paths total                   590
eval/path length Mean                  801.2
eval/path length Std                   397.6
eval/path length Max                  1000
eval/path length Min                     6
eval/Rewards Mean                        0.000249626
eval/Rewards Std                         0.0157976
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        0.2
eval/Returns Std                         0.4
eval/Returns Max                         1
eval/Returns Min                         0
eval/Actions Mean                       -0.171382
eval/Actions Std                         0.403569
eval/Actions Max                         0.996351
eval/Actions Min                        -0.989697
eval/Num Paths                           5
eval/Average Returns                     0.2
time/data storing (s)                    0.00346879
time/evaluation sampling (s)             0.946066
time/exploration sampling (s)            0.298958
time/logging (s)                         0.00842065
time/sac training (s)                   11.8065
time/saving (s)                          0.00366023
time/training (s)                        2.041e-05
time/epoch (s)                          13.0671
time/total (s)                        1547.19
Epoch                                  117
----------------------------------  ----------------
2022-09-09 20:18:51.604461 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 118 finished
----------------------------------  ----------------
epoch                                  118
replay_buffer/size                  120000
trainer/num train calls             119000
trainer/QF1 Loss                         4.60087e-06
trainer/QF2 Loss                         1.94276e-05
trainer/Policy Loss                     -0.915177
trainer/Q1 Predictions Mean              0.911197
trainer/Q1 Predictions Std               0.0286718
trainer/Q1 Predictions Max               0.95558
trainer/Q1 Predictions Min               0.854761
trainer/Q2 Predictions Mean              0.914004
trainer/Q2 Predictions Std               0.0276067
trainer/Q2 Predictions Max               0.957944
trainer/Q2 Predictions Min               0.858913
trainer/Q Targets Mean                   0.910876
trainer/Q Targets Std                    0.0287963
trainer/Q Targets Max                    0.953966
trainer/Q Targets Min                    0.850165
trainer/Log Pis Mean                     3.66457
trainer/Log Pis Std                      2.64009
trainer/Log Pis Max                     14.7857
trainer/Log Pis Min                     -2.08981
trainer/policy/mean Mean                 0.0644591
trainer/policy/mean Std                  0.815523
trainer/policy/mean Max                  0.995446
trainer/policy/mean Min                 -0.995509
trainer/policy/normal/std Mean           0.667518
trainer/policy/normal/std Std            0.469119
trainer/policy/normal/std Max            4.06755
trainer/policy/normal/std Min            0.103649
trainer/policy/normal/log_std Mean      -0.553489
trainer/policy/normal/log_std Std        0.518638
trainer/policy/normal/log_std Max        1.40304
trainer/policy/normal/log_std Min       -2.26675
trainer/Alpha                            0.000302827
trainer/Alpha Loss                       5.38455
expl/num steps total                120000
expl/num paths total                   139
expl/path length Mean                 1000
expl/path length Std                     0
expl/path length Max                  1000
expl/path length Min                  1000
expl/Rewards Mean                        0
expl/Rewards Std                         0
expl/Rewards Max                         0
expl/Rewards Min                         0
expl/Returns Mean                        0
expl/Returns Std                         0
expl/Returns Max                         0
expl/Returns Min                         0
expl/Actions Mean                       -0.0961756
expl/Actions Std                         0.527797
expl/Actions Max                         0.99855
expl/Actions Min                        -0.994582
expl/Num Paths                           1
expl/Average Returns                     0
eval/num steps total                592010
eval/num paths total                   595
eval/path length Mean                 1000
eval/path length Std                     0
eval/path length Max                  1000
eval/path length Min                  1000
eval/Rewards Mean                        0
eval/Rewards Std                         0
eval/Rewards Max                         0
eval/Rewards Min                         0
eval/Returns Mean                        0
eval/Returns Std                         0
eval/Returns Max                         0
eval/Returns Min                         0
eval/Actions Mean                       -0.129571
eval/Actions Std                         0.352344
eval/Actions Max                         0.996278
eval/Actions Min                        -0.978225
eval/Num Paths                           5
eval/Average Returns                     0
time/data storing (s)                    0.00341084
time/evaluation sampling (s)             0.952067
time/exploration sampling (s)            0.31448
time/logging (s)                         0.00970217
time/sac training (s)                   11.6666
time/saving (s)                          0.00474317
time/training (s)                        2.74e-05
time/epoch (s)                          12.951
time/total (s)                        1560.4
Epoch                                  118
----------------------------------  ----------------
2022-09-09 20:19:04.923839 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 119 finished
----------------------------------  ----------------
epoch                                  119
replay_buffer/size                  121000
trainer/num train calls             120000
trainer/QF1 Loss                         3.72687e-06
trainer/QF2 Loss                         9.05568e-06
trainer/Policy Loss                     -0.893175
trainer/Q1 Predictions Mean              0.88947
trainer/Q1 Predictions Std               0.0197511
trainer/Q1 Predictions Max               0.924288
trainer/Q1 Predictions Min               0.848205
trainer/Q2 Predictions Mean              0.888366
trainer/Q2 Predictions Std               0.0202847
trainer/Q2 Predictions Max               0.922817
trainer/Q2 Predictions Min               0.846537
trainer/Q Targets Mean                   0.88995
trainer/Q Targets Std                    0.0198846
trainer/Q Targets Max                    0.928462
trainer/Q Targets Min                    0.848595
trainer/Log Pis Mean                     2.86491
trainer/Log Pis Std                      2.5515
trainer/Log Pis Max                     10.555
trainer/Log Pis Min                     -5.44716
trainer/policy/mean Mean                 0.00725833
trainer/policy/mean Std                  0.773386
trainer/policy/mean Max                  0.997378
trainer/policy/mean Min                 -0.995592
trainer/policy/normal/std Mean           0.61882
trainer/policy/normal/std Std            0.368624
trainer/policy/normal/std Max            3.87648
trainer/policy/normal/std Min            0.0587677
trainer/policy/normal/log_std Mean      -0.61499
trainer/policy/normal/log_std Std        0.529876
trainer/policy/normal/log_std Max        1.35493
trainer/policy/normal/log_std Min       -2.83416
trainer/Alpha                            0.000370928
trainer/Alpha Loss                      -1.06711
expl/num steps total                121000
expl/num paths total                   144
expl/path length Mean                  200
expl/path length Std                   392.007
expl/path length Max                   984
expl/path length Min                     1
expl/Rewards Mean                        0.004
expl/Rewards Std                         0.0631189
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.8
expl/Returns Std                         0.4
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.172848
expl/Actions Std                         0.472182
expl/Actions Max                         0.994758
expl/Actions Min                        -0.998197
expl/Num Paths                           5
expl/Average Returns                     0.8
eval/num steps total                596053
eval/num paths total                   605
eval/path length Mean                  404.3
eval/path length Std                   486.407
eval/path length Max                  1000
eval/path length Min                     1
eval/Rewards Mean                        0.00148405
eval/Rewards Std                         0.0384947
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        0.6
eval/Returns Std                         0.489898
eval/Returns Max                         1
eval/Returns Min                         0
eval/Actions Mean                        0.212648
eval/Actions Std                         0.326896
eval/Actions Max                         0.99068
eval/Actions Min                        -0.990195
eval/Num Paths                          10
eval/Average Returns                     0.6
time/data storing (s)                    0.00550808
time/evaluation sampling (s)             0.945585
time/exploration sampling (s)            0.318413
time/logging (s)                         0.00827155
time/sac training (s)                   11.7661
time/saving (s)                          0.00359124
time/training (s)                        2.466e-05
time/epoch (s)                          13.0475
time/total (s)                        1573.71
Epoch                                  119
----------------------------------  ----------------
2022-09-09 20:19:18.318617 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 120 finished
----------------------------------  ----------------
epoch                                  120
replay_buffer/size                  122000
trainer/num train calls             121000
trainer/QF1 Loss                         4.33464e-06
trainer/QF2 Loss                         8.23267e-06
trainer/Policy Loss                     -0.870475
trainer/Q1 Predictions Mean              0.86465
trainer/Q1 Predictions Std               0.018942
trainer/Q1 Predictions Max               0.916125
trainer/Q1 Predictions Min               0.822951
trainer/Q2 Predictions Mean              0.864842
trainer/Q2 Predictions Std               0.0191604
trainer/Q2 Predictions Max               0.913355
trainer/Q2 Predictions Min               0.820908
trainer/Q Targets Mean                   0.865888
trainer/Q Targets Std                    0.0187625
trainer/Q Targets Max                    0.919616
trainer/Q Targets Min                    0.820577
trainer/Log Pis Mean                     3.56225
trainer/Log Pis Std                      2.26166
trainer/Log Pis Max                      9.94777
trainer/Log Pis Min                     -7.16617
trainer/policy/mean Mean                 0.0993905
trainer/policy/mean Std                  0.795921
trainer/policy/mean Max                  0.996307
trainer/policy/mean Min                 -0.993668
trainer/policy/normal/std Mean           0.542102
trainer/policy/normal/std Std            0.250579
trainer/policy/normal/std Max            2.79924
trainer/policy/normal/std Min            0.0987706
trainer/policy/normal/log_std Mean      -0.719631
trainer/policy/normal/log_std Std        0.493997
trainer/policy/normal/log_std Max        1.02935
trainer/policy/normal/log_std Min       -2.31496
trainer/Alpha                            0.000377674
trainer/Alpha Loss                       4.43139
expl/num steps total                122000
expl/num paths total                   148
expl/path length Mean                  250
expl/path length Std                   423.776
expl/path length Max                   984
expl/path length Min                     4
expl/Rewards Mean                        0.003
expl/Rewards Std                         0.05469
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.75
expl/Returns Std                         0.433013
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.223287
expl/Actions Std                         0.646219
expl/Actions Max                         0.999826
expl/Actions Min                        -0.98198
expl/Num Paths                           4
expl/Average Returns                     0.75
eval/num steps total                600085
eval/num paths total                   617
eval/path length Mean                  336
eval/path length Std                   469.522
eval/path length Max                  1000
eval/path length Min                     1
eval/Rewards Mean                        0.00198413
eval/Rewards Std                         0.0444993
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        0.666667
eval/Returns Std                         0.471405
eval/Returns Max                         1
eval/Returns Min                         0
eval/Actions Mean                        0.25098
eval/Actions Std                         0.664657
eval/Actions Max                         0.99142
eval/Actions Min                        -0.993785
eval/Num Paths                          12
eval/Average Returns                     0.666667
time/data storing (s)                    0.00347068
time/evaluation sampling (s)             0.939241
time/exploration sampling (s)            0.297304
time/logging (s)                         0.00836791
time/sac training (s)                   11.8703
time/saving (s)                          0.00567339
time/training (s)                        3.547e-05
time/epoch (s)                          13.1244
time/total (s)                        1587.09
Epoch                                  120
----------------------------------  ----------------
2022-09-09 20:19:32.878368 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 121 finished
----------------------------------  ----------------
epoch                                  121
replay_buffer/size                  123000
trainer/num train calls             122000
trainer/QF1 Loss                         2.545e-06
trainer/QF2 Loss                         5.35946e-06
trainer/Policy Loss                     -0.845488
trainer/Q1 Predictions Mean              0.841191
trainer/Q1 Predictions Std               0.0207373
trainer/Q1 Predictions Max               0.904033
trainer/Q1 Predictions Min               0.808861
trainer/Q2 Predictions Mean              0.841245
trainer/Q2 Predictions Std               0.021377
trainer/Q2 Predictions Max               0.903827
trainer/Q2 Predictions Min               0.805373
trainer/Q Targets Mean                   0.841949
trainer/Q Targets Std                    0.0206045
trainer/Q Targets Max                    0.902498
trainer/Q Targets Min                    0.808872
trainer/Log Pis Mean                     2.6282
trainer/Log Pis Std                      2.24766
trainer/Log Pis Max                      8.38203
trainer/Log Pis Min                     -4.83525
trainer/policy/mean Mean                 0.0982354
trainer/policy/mean Std                  0.78691
trainer/policy/mean Max                  0.994406
trainer/policy/mean Min                 -0.993122
trainer/policy/normal/std Mean           0.641676
trainer/policy/normal/std Std            0.286655
trainer/policy/normal/std Max            1.91154
trainer/policy/normal/std Min            0.124479
trainer/policy/normal/log_std Mean      -0.546414
trainer/policy/normal/log_std Std        0.472389
trainer/policy/normal/log_std Max        0.647907
trainer/policy/normal/log_std Min       -2.08362
trainer/Alpha                            0.000419241
trainer/Alpha Loss                      -2.89149
expl/num steps total                123000
expl/num paths total                   151
expl/path length Mean                  333.333
expl/path length Std                   462.92
expl/path length Max                   988
expl/path length Min                     5
expl/Rewards Mean                        0.002
expl/Rewards Std                         0.0446766
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.666667
expl/Returns Std                         0.471405
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0305986
expl/Actions Std                         0.658286
expl/Actions Max                         0.996314
expl/Actions Min                        -0.999355
expl/Num Paths                           3
expl/Average Returns                     0.666667
eval/num steps total                604087
eval/num paths total                   622
eval/path length Mean                  800.4
eval/path length Std                   399.2
eval/path length Max                  1000
eval/path length Min                     2
eval/Rewards Mean                        0.000249875
eval/Rewards Std                         0.0158055
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        0.2
eval/Returns Std                         0.4
eval/Returns Max                         1
eval/Returns Min                         0
eval/Actions Mean                       -0.0530755
eval/Actions Std                         0.470277
eval/Actions Max                         0.964332
eval/Actions Min                        -0.993759
eval/Num Paths                           5
eval/Average Returns                     0.2
time/data storing (s)                    0.00360672
time/evaluation sampling (s)             0.955511
time/exploration sampling (s)            0.332181
time/logging (s)                         0.00819859
time/sac training (s)                   12.8711
time/saving (s)                          0.00513388
time/training (s)                        4.104e-05
time/epoch (s)                          14.1758
time/total (s)                        1601.63
Epoch                                  121
----------------------------------  ----------------
2022-09-09 20:19:46.965065 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 122 finished
----------------------------------  ----------------
epoch                                  122
replay_buffer/size                  124000
trainer/num train calls             123000
trainer/QF1 Loss                         4.5167e-06
trainer/QF2 Loss                         2.75926e-05
trainer/Policy Loss                     -0.83394
trainer/Q1 Predictions Mean              0.829623
trainer/Q1 Predictions Std               0.0307358
trainer/Q1 Predictions Max               0.90721
trainer/Q1 Predictions Min               0.781902
trainer/Q2 Predictions Mean              0.826567
trainer/Q2 Predictions Std               0.0330671
trainer/Q2 Predictions Max               0.907801
trainer/Q2 Predictions Min               0.77646
trainer/Q Targets Mean                   0.830391
trainer/Q Targets Std                    0.0310296
trainer/Q Targets Max                    0.909997
trainer/Q Targets Min                    0.779763
trainer/Log Pis Mean                     2.99494
trainer/Log Pis Std                      2.55309
trainer/Log Pis Max                      8.41808
trainer/Log Pis Min                     -4.65111
trainer/policy/mean Mean                 0.0176269
trainer/policy/mean Std                  0.795735
trainer/policy/mean Max                  0.996802
trainer/policy/mean Min                 -0.991926
trainer/policy/normal/std Mean           0.710059
trainer/policy/normal/std Std            0.371049
trainer/policy/normal/std Max            2.9479
trainer/policy/normal/std Min            0.171772
trainer/policy/normal/log_std Mean      -0.449705
trainer/policy/normal/log_std Std        0.451176
trainer/policy/normal/log_std Max        1.08109
trainer/policy/normal/log_std Min       -1.76159
trainer/Alpha                            0.000387975
trainer/Alpha Loss                      -0.0397086
expl/num steps total                124000
expl/num paths total                   168
expl/path length Mean                   58.8235
expl/path length Std                   109.41
expl/path length Max                   431
expl/path length Min                     1
expl/Rewards Mean                        0.016
expl/Rewards Std                         0.125475
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.941176
expl/Returns Std                         0.235294
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.120654
expl/Actions Std                         0.614936
expl/Actions Max                         0.999956
expl/Actions Min                        -0.99988
expl/Num Paths                          17
expl/Average Returns                     0.941176
eval/num steps total                608136
eval/num paths total                   636
eval/path length Mean                  289.214
eval/path length Std                   449.542
eval/path length Max                  1000
eval/path length Min                     2
eval/Rewards Mean                        0.00246975
eval/Rewards Std                         0.0496351
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        0.714286
eval/Returns Std                         0.451754
eval/Returns Max                         1
eval/Returns Min                         0
eval/Actions Mean                        0.199698
eval/Actions Std                         0.306826
eval/Actions Max                         0.989784
eval/Actions Min                        -0.992379
eval/Num Paths                          14
eval/Average Returns                     0.714286
time/data storing (s)                    0.00568131
time/evaluation sampling (s)             0.9539
time/exploration sampling (s)            0.327801
time/logging (s)                         0.00783935
time/sac training (s)                   12.4822
time/saving (s)                          0.00422666
time/training (s)                        5.2311e-05
time/epoch (s)                          13.7817
time/total (s)                        1615.71
Epoch                                  122
----------------------------------  ----------------
2022-09-09 20:20:02.718289 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 123 finished
----------------------------------  ----------------
epoch                                  123
replay_buffer/size                  125000
trainer/num train calls             124000
trainer/QF1 Loss                         9.14622e-06
trainer/QF2 Loss                         3.47896e-05
trainer/Policy Loss                     -0.858326
trainer/Q1 Predictions Mean              0.844627
trainer/Q1 Predictions Std               0.0399974
trainer/Q1 Predictions Max               0.97259
trainer/Q1 Predictions Min               0.760981
trainer/Q2 Predictions Mean              0.843679
trainer/Q2 Predictions Std               0.0396794
trainer/Q2 Predictions Max               0.926537
trainer/Q2 Predictions Min               0.761258
trainer/Q Targets Mean                   0.845429
trainer/Q Targets Std                    0.0411548
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.756959
trainer/Log Pis Mean                     3.65329
trainer/Log Pis Std                      2.246
trainer/Log Pis Max                     10.1638
trainer/Log Pis Min                     -4.66343
trainer/policy/mean Mean                 0.120579
trainer/policy/mean Std                  0.789197
trainer/policy/mean Max                  0.996975
trainer/policy/mean Min                 -0.995997
trainer/policy/normal/std Mean           0.61117
trainer/policy/normal/std Std            0.276115
trainer/policy/normal/std Max            1.46647
trainer/policy/normal/std Min            0.0554672
trainer/policy/normal/log_std Mean      -0.616161
trainer/policy/normal/log_std Std        0.547062
trainer/policy/normal/log_std Max        0.382859
trainer/policy/normal/log_std Min       -2.89196
trainer/Alpha                            0.000547801
trainer/Alpha Loss                       4.90594
expl/num steps total                125000
expl/num paths total                   394
expl/path length Mean                    4.42478
expl/path length Std                     2.04076
expl/path length Max                    10
expl/path length Min                     1
expl/Rewards Mean                        0.226
expl/Rewards Std                         0.418239
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.134923
expl/Actions Std                         0.79187
expl/Actions Max                         0.999923
expl/Actions Min                        -0.999754
expl/Num Paths                         226
expl/Average Returns                     1
eval/num steps total                613135
eval/num paths total                  1805
eval/path length Mean                    4.2763
eval/path length Std                     1.93472
eval/path length Max                    10
eval/path length Min                     1
eval/Rewards Mean                        0.233847
eval/Rewards Std                         0.423276
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0878791
eval/Actions Std                         0.790319
eval/Actions Max                         0.998989
eval/Actions Min                        -0.997841
eval/Num Paths                        1169
eval/Average Returns                     1
time/data storing (s)                    0.00659735
time/evaluation sampling (s)             1.07491
time/exploration sampling (s)            0.389407
time/logging (s)                         0.0182594
time/sac training (s)                   13.8658
time/saving (s)                          0.00561065
time/training (s)                        5.05e-05
time/epoch (s)                          15.3606
time/total (s)                        1631.45
Epoch                                  123
----------------------------------  ----------------
2022-09-09 20:20:16.457403 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 124 finished
----------------------------------  ----------------
epoch                                  124
replay_buffer/size                  126000
trainer/num train calls             125000
trainer/QF1 Loss                         7.25837e-06
trainer/QF2 Loss                         1.08146e-05
trainer/Policy Loss                     -0.894308
trainer/Q1 Predictions Mean              0.87566
trainer/Q1 Predictions Std               0.0380812
trainer/Q1 Predictions Max               0.967285
trainer/Q1 Predictions Min               0.780652
trainer/Q2 Predictions Mean              0.87496
trainer/Q2 Predictions Std               0.0383344
trainer/Q2 Predictions Max               0.971157
trainer/Q2 Predictions Min               0.77794
trainer/Q Targets Mean                   0.87443
trainer/Q Targets Std                    0.0382626
trainer/Q Targets Max                    0.972819
trainer/Q Targets Min                    0.777313
trainer/Log Pis Mean                     3.27953
trainer/Log Pis Std                      2.13619
trainer/Log Pis Max                      7.83486
trainer/Log Pis Min                     -7.39425
trainer/policy/mean Mean                 0.145415
trainer/policy/mean Std                  0.789827
trainer/policy/mean Max                  0.991083
trainer/policy/mean Min                 -0.987987
trainer/policy/normal/std Mean           0.628814
trainer/policy/normal/std Std            0.204045
trainer/policy/normal/std Max            1.43197
trainer/policy/normal/std Min            0.0705199
trainer/policy/normal/log_std Mean      -0.526383
trainer/policy/normal/log_std Std        0.382894
trainer/policy/normal/log_std Max        0.359054
trainer/policy/normal/log_std Min       -2.65186
trainer/Alpha                            0.000664497
trainer/Alpha Loss                       2.04515
expl/num steps total                126000
expl/num paths total                   627
expl/path length Mean                    4.29185
expl/path length Std                     1.90792
expl/path length Max                     8
expl/path length Min                     1
expl/Rewards Mean                        0.232
expl/Rewards Std                         0.422109
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995708
expl/Returns Std                         0.0653714
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0614922
expl/Actions Std                         0.780563
expl/Actions Max                         0.999538
expl/Actions Min                        -0.998048
expl/Num Paths                         233
expl/Average Returns                     0.995708
eval/num steps total                618131
eval/num paths total                  3016
eval/path length Mean                    4.12552
eval/path length Std                     1.75524
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.242394
eval/Rewards Std                         0.428531
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0565303
eval/Actions Std                         0.740417
eval/Actions Max                         0.994764
eval/Actions Min                        -0.989314
eval/Num Paths                        1211
eval/Average Returns                     1
time/data storing (s)                    0.0061864
time/evaluation sampling (s)             1.02648
time/exploration sampling (s)            0.331859
time/logging (s)                         0.0182483
time/sac training (s)                   12.0382
time/saving (s)                          0.00423211
time/training (s)                        4.204e-05
time/epoch (s)                          13.4253
time/total (s)                        1645.18
Epoch                                  124
----------------------------------  ----------------
2022-09-09 20:20:30.197701 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 125 finished
----------------------------------  ----------------
epoch                                  125
replay_buffer/size                  127000
trainer/num train calls             126000
trainer/QF1 Loss                         9.27324e-06
trainer/QF2 Loss                         1.6548e-05
trainer/Policy Loss                     -0.926574
trainer/Q1 Predictions Mean              0.914057
trainer/Q1 Predictions Std               0.0249705
trainer/Q1 Predictions Max               0.998479
trainer/Q1 Predictions Min               0.839972
trainer/Q2 Predictions Mean              0.912578
trainer/Q2 Predictions Std               0.0254418
trainer/Q2 Predictions Max               1.00191
trainer/Q2 Predictions Min               0.83609
trainer/Q Targets Mean                   0.91565
trainer/Q Targets Std                    0.025549
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.840439
trainer/Log Pis Mean                     2.78603
trainer/Log Pis Std                      1.90594
trainer/Log Pis Max                      7.80763
trainer/Log Pis Min                     -5.47714
trainer/policy/mean Mean                 0.095895
trainer/policy/mean Std                  0.74409
trainer/policy/mean Max                  0.994302
trainer/policy/mean Min                 -0.990149
trainer/policy/normal/std Mean           0.586168
trainer/policy/normal/std Std            0.24364
trainer/policy/normal/std Max            1.25423
trainer/policy/normal/std Min            0.056718
trainer/policy/normal/log_std Mean      -0.652971
trainer/policy/normal/log_std Std        0.550723
trainer/policy/normal/log_std Max        0.226523
trainer/policy/normal/log_std Min       -2.86966
trainer/Alpha                            0.000572638
trainer/Alpha Loss                      -1.59737
expl/num steps total                127000
expl/num paths total                   857
expl/path length Mean                    4.34783
expl/path length Std                     1.91126
expl/path length Max                     9
expl/path length Min                     1
expl/Rewards Mean                        0.229
expl/Rewards Std                         0.420189
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995652
expl/Returns Std                         0.0657945
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.013027
expl/Actions Std                         0.749976
expl/Actions Max                         0.998488
expl/Actions Min                        -0.999513
expl/Num Paths                         230
expl/Average Returns                     0.995652
eval/num steps total                623129
eval/num paths total                  4209
eval/path length Mean                    4.18944
eval/path length Std                     1.8088
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.238695
eval/Rewards Std                         0.426286
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0357237
eval/Actions Std                         0.692469
eval/Actions Max                         0.992656
eval/Actions Min                        -0.993388
eval/Num Paths                        1193
eval/Average Returns                     1
time/data storing (s)                    0.00553005
time/evaluation sampling (s)             0.996498
time/exploration sampling (s)            0.325537
time/logging (s)                         0.0199914
time/sac training (s)                   12.0772
time/saving (s)                          0.00503437
time/training (s)                        3.108e-05
time/epoch (s)                          13.4298
time/total (s)                        1658.91
Epoch                                  125
----------------------------------  ----------------
2022-09-09 20:20:43.724319 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 126 finished
----------------------------------  ----------------
epoch                                  126
replay_buffer/size                  128000
trainer/num train calls             127000
trainer/QF1 Loss                         4.86616e-06
trainer/QF2 Loss                         6.5183e-06
trainer/Policy Loss                     -0.93562
trainer/Q1 Predictions Mean              0.925478
trainer/Q1 Predictions Std               0.01618
trainer/Q1 Predictions Max               0.994595
trainer/Q1 Predictions Min               0.889471
trainer/Q2 Predictions Mean              0.927675
trainer/Q2 Predictions Std               0.0160304
trainer/Q2 Predictions Max               0.997813
trainer/Q2 Predictions Min               0.891971
trainer/Q Targets Mean                   0.926831
trainer/Q Targets Std                    0.0162841
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.891318
trainer/Log Pis Mean                     2.71219
trainer/Log Pis Std                      1.96664
trainer/Log Pis Max                      7.39466
trainer/Log Pis Min                     -3.16373
trainer/policy/mean Mean                 0.036479
trainer/policy/mean Std                  0.735694
trainer/policy/mean Max                  0.993325
trainer/policy/mean Min                 -0.990112
trainer/policy/normal/std Mean           0.595543
trainer/policy/normal/std Std            0.238888
trainer/policy/normal/std Max            1.48851
trainer/policy/normal/std Min            0.0570686
trainer/policy/normal/log_std Mean      -0.621619
trainer/policy/normal/log_std Std        0.505821
trainer/policy/normal/log_std Max        0.397773
trainer/policy/normal/log_std Min       -2.8635
trainer/Alpha                            0.000436692
trainer/Alpha Loss                      -2.2266
expl/num steps total                128000
expl/num paths total                  1096
expl/path length Mean                    4.1841
expl/path length Std                     1.80411
expl/path length Max                     8
expl/path length Min                     1
expl/Rewards Mean                        0.238
expl/Rewards Std                         0.425859
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995816
expl/Returns Std                         0.0645492
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0487578
expl/Actions Std                         0.728609
expl/Actions Max                         0.999439
expl/Actions Min                        -0.999803
expl/Num Paths                         239
expl/Average Returns                     0.995816
eval/num steps total                628129
eval/num paths total                  5386
eval/path length Mean                    4.24809
eval/path length Std                     1.75557
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2354
eval/Rewards Std                         0.424249
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0247493
eval/Actions Std                         0.685102
eval/Actions Max                         0.993693
eval/Actions Min                        -0.99541
eval/Num Paths                        1177
eval/Average Returns                     1
time/data storing (s)                    0.00500129
time/evaluation sampling (s)             1.00556
time/exploration sampling (s)            0.306227
time/logging (s)                         0.0220926
time/sac training (s)                   11.8905
time/saving (s)                          0.00420701
time/training (s)                        0.00010213
time/epoch (s)                          13.2336
time/total (s)                        1672.43
Epoch                                  126
----------------------------------  ----------------
2022-09-09 20:20:57.154459 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 127 finished
----------------------------------  ----------------
epoch                                  127
replay_buffer/size                  129000
trainer/num train calls             128000
trainer/QF1 Loss                         3.73128e-06
trainer/QF2 Loss                         5.10882e-06
trainer/Policy Loss                     -0.938015
trainer/Q1 Predictions Mean              0.929135
trainer/Q1 Predictions Std               0.0170959
trainer/Q1 Predictions Max               1.00095
trainer/Q1 Predictions Min               0.907149
trainer/Q2 Predictions Mean              0.930759
trainer/Q2 Predictions Std               0.0169218
trainer/Q2 Predictions Max               1.00669
trainer/Q2 Predictions Min               0.908605
trainer/Q Targets Mean                   0.930141
trainer/Q Targets Std                    0.0167346
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.907948
trainer/Log Pis Mean                     3.03308
trainer/Log Pis Std                      2.09303
trainer/Log Pis Max                      9.77211
trainer/Log Pis Min                     -5.06442
trainer/policy/mean Mean                -0.0214354
trainer/policy/mean Std                  0.743122
trainer/policy/mean Max                  0.992865
trainer/policy/mean Min                 -0.993132
trainer/policy/normal/std Mean           0.582411
trainer/policy/normal/std Std            0.234815
trainer/policy/normal/std Max            1.37214
trainer/policy/normal/std Min            0.0407241
trainer/policy/normal/log_std Mean      -0.651109
trainer/policy/normal/log_std Std        0.536254
trainer/policy/normal/log_std Max        0.31637
trainer/policy/normal/log_std Min       -3.20093
trainer/Alpha                            0.000372254
trainer/Alpha Loss                       0.261197
expl/num steps total                129000
expl/num paths total                  1322
expl/path length Mean                    4.42478
expl/path length Std                     1.78393
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.225
expl/Rewards Std                         0.417582
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995575
expl/Returns Std                         0.0663717
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00913324
expl/Actions Std                         0.737137
expl/Actions Max                         0.999179
expl/Actions Min                        -0.999788
expl/Num Paths                         226
expl/Average Returns                     0.995575
eval/num steps total                633129
eval/num paths total                  6626
eval/path length Mean                    4.03226
eval/path length Std                     1.77862
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.248
eval/Rewards Std                         0.431852
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0440487
eval/Actions Std                         0.699779
eval/Actions Max                         0.995255
eval/Actions Min                        -0.996278
eval/Num Paths                        1240
eval/Average Returns                     1
time/data storing (s)                    0.0061046
time/evaluation sampling (s)             0.998949
time/exploration sampling (s)            0.311063
time/logging (s)                         0.018042
time/sac training (s)                   11.8012
time/saving (s)                          0.00476821
time/training (s)                        2.63e-05
time/epoch (s)                          13.1401
time/total (s)                        1685.84
Epoch                                  127
----------------------------------  ----------------
2022-09-09 20:21:10.422877 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 128 finished
----------------------------------  ----------------
epoch                                  128
replay_buffer/size                  130000
trainer/num train calls             129000
trainer/QF1 Loss                         3.17351e-06
trainer/QF2 Loss                         4.85722e-06
trainer/Policy Loss                     -0.938117
trainer/Q1 Predictions Mean              0.929484
trainer/Q1 Predictions Std               0.0153979
trainer/Q1 Predictions Max               1.00101
trainer/Q1 Predictions Min               0.9104
trainer/Q2 Predictions Mean              0.929243
trainer/Q2 Predictions Std               0.0156683
trainer/Q2 Predictions Max               1.00099
trainer/Q2 Predictions Min               0.910129
trainer/Q Targets Mean                   0.929916
trainer/Q Targets Std                    0.015434
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.91037
trainer/Log Pis Mean                     2.90711
trainer/Log Pis Std                      1.91721
trainer/Log Pis Max                      8.58193
trainer/Log Pis Min                     -4.479
trainer/policy/mean Mean                 0.0904787
trainer/policy/mean Std                  0.726792
trainer/policy/mean Max                  0.992061
trainer/policy/mean Min                 -0.991806
trainer/policy/normal/std Mean           0.610043
trainer/policy/normal/std Std            0.255217
trainer/policy/normal/std Max            1.48845
trainer/policy/normal/std Min            0.0568722
trainer/policy/normal/log_std Mean      -0.605323
trainer/policy/normal/log_std Std        0.529295
trainer/policy/normal/log_std Max        0.397733
trainer/policy/normal/log_std Min       -2.86695
trainer/Alpha                            0.000363404
trainer/Alpha Loss                      -0.735682
expl/num steps total                130000
expl/num paths total                  1569
expl/path length Mean                    4.04858
expl/path length Std                     1.88045
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.246
expl/Rewards Std                         0.430679
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995951
expl/Returns Std                         0.0634995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0112541
expl/Actions Std                         0.754946
expl/Actions Max                         0.998575
expl/Actions Min                        -0.999646
expl/Num Paths                         247
expl/Average Returns                     0.995951
eval/num steps total                638125
eval/num paths total                  7853
eval/path length Mean                    4.07172
eval/path length Std                     1.74207
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.245596
eval/Rewards Std                         0.43044
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0225212
eval/Actions Std                         0.698504
eval/Actions Max                         0.99372
eval/Actions Min                        -0.995624
eval/Num Paths                        1227
eval/Average Returns                     1
time/data storing (s)                    0.00621226
time/evaluation sampling (s)             0.986212
time/exploration sampling (s)            0.333785
time/logging (s)                         0.0177511
time/sac training (s)                   11.6466
time/saving (s)                          0.00470258
time/training (s)                        2.789e-05
time/epoch (s)                          12.9953
time/total (s)                        1699.1
Epoch                                  128
----------------------------------  ----------------
2022-09-09 20:21:23.892834 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 129 finished
----------------------------------  ----------------
epoch                                  129
replay_buffer/size                  131000
trainer/num train calls             130000
trainer/QF1 Loss                         1.77014e-06
trainer/QF2 Loss                         3.81242e-06
trainer/Policy Loss                     -0.940272
trainer/Q1 Predictions Mean              0.930877
trainer/Q1 Predictions Std               0.0158656
trainer/Q1 Predictions Max               0.999472
trainer/Q1 Predictions Min               0.911257
trainer/Q2 Predictions Mean              0.931358
trainer/Q2 Predictions Std               0.0161411
trainer/Q2 Predictions Max               1.00753
trainer/Q2 Predictions Min               0.910724
trainer/Q Targets Mean                   0.931453
trainer/Q Targets Std                    0.0160047
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.911838
trainer/Log Pis Mean                     2.79082
trainer/Log Pis Std                      2.20804
trainer/Log Pis Max                      7.78732
trainer/Log Pis Min                     -4.90983
trainer/policy/mean Mean                 0.112911
trainer/policy/mean Std                  0.73615
trainer/policy/mean Max                  0.99254
trainer/policy/mean Min                 -0.9915
trainer/policy/normal/std Mean           0.597748
trainer/policy/normal/std Std            0.233297
trainer/policy/normal/std Max            1.32544
trainer/policy/normal/std Min            0.0607943
trainer/policy/normal/log_std Mean      -0.61255
trainer/policy/normal/log_std Std        0.489903
trainer/policy/normal/log_std Max        0.281742
trainer/policy/normal/log_std Min       -2.80026
trainer/Alpha                            0.000354777
trainer/Alpha Loss                      -1.66171
expl/num steps total                131000
expl/num paths total                  1806
expl/path length Mean                    4.21941
expl/path length Std                     1.75094
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.236
expl/Rewards Std                         0.424622
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995781
expl/Returns Std                         0.0648198
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00859471
expl/Actions Std                         0.754474
expl/Actions Max                         0.99911
expl/Actions Min                        -0.99934
expl/Num Paths                         237
expl/Average Returns                     0.995781
eval/num steps total                643122
eval/num paths total                  9085
eval/path length Mean                    4.05601
eval/path length Std                     1.72669
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.246548
eval/Rewards Std                         0.431001
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0301074
eval/Actions Std                         0.696651
eval/Actions Max                         0.993965
eval/Actions Min                        -0.995861
eval/Num Paths                        1232
eval/Average Returns                     1
time/data storing (s)                    0.00599091
time/evaluation sampling (s)             0.967678
time/exploration sampling (s)            0.319161
time/logging (s)                         0.0191064
time/sac training (s)                   11.8657
time/saving (s)                          0.00335065
time/training (s)                        1.95e-05
time/epoch (s)                          13.181
time/total (s)                        1712.56
Epoch                                  129
----------------------------------  ----------------
2022-09-09 20:21:37.053844 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 130 finished
----------------------------------  ----------------
epoch                                  130
replay_buffer/size                  132000
trainer/num train calls             131000
trainer/QF1 Loss                         1.85998e-06
trainer/QF2 Loss                         3.06634e-06
trainer/Policy Loss                     -0.940149
trainer/Q1 Predictions Mean              0.931554
trainer/Q1 Predictions Std               0.0152068
trainer/Q1 Predictions Max               1.00403
trainer/Q1 Predictions Min               0.911535
trainer/Q2 Predictions Mean              0.931948
trainer/Q2 Predictions Std               0.0152672
trainer/Q2 Predictions Max               1.00626
trainer/Q2 Predictions Min               0.912191
trainer/Q Targets Mean                   0.931845
trainer/Q Targets Std                    0.0149995
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.913794
trainer/Log Pis Mean                     2.88656
trainer/Log Pis Std                      2.09883
trainer/Log Pis Max                      9.17191
trainer/Log Pis Min                     -5.7486
trainer/policy/mean Mean                 0.0654064
trainer/policy/mean Std                  0.735955
trainer/policy/mean Max                  0.990157
trainer/policy/mean Min                 -0.992434
trainer/policy/normal/std Mean           0.595827
trainer/policy/normal/std Std            0.22353
trainer/policy/normal/std Max            1.38489
trainer/policy/normal/std Min            0.0621128
trainer/policy/normal/log_std Mean      -0.609206
trainer/policy/normal/log_std Std        0.474134
trainer/policy/normal/log_std Max        0.325622
trainer/policy/normal/log_std Min       -2.7788
trainer/Alpha                            0.000346371
trainer/Alpha Loss                      -0.903885
expl/num steps total                132000
expl/num paths total                  2047
expl/path length Mean                    4.14938
expl/path length Std                     1.85202
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.24
expl/Rewards Std                         0.427083
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995851
expl/Returns Std                         0.0642819
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0329572
expl/Actions Std                         0.752487
expl/Actions Max                         0.999245
expl/Actions Min                        -0.999278
expl/Num Paths                         241
expl/Average Returns                     0.995851
eval/num steps total                648121
eval/num paths total                 10303
eval/path length Mean                    4.10427
eval/path length Std                     1.72677
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.243649
eval/Rewards Std                         0.429283
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00534308
eval/Actions Std                         0.694805
eval/Actions Max                         0.994043
eval/Actions Min                        -0.995556
eval/Num Paths                        1218
eval/Average Returns                     1
time/data storing (s)                    0.00636599
time/evaluation sampling (s)             1.01778
time/exploration sampling (s)            0.293858
time/logging (s)                         0.0176922
time/sac training (s)                   11.5515
time/saving (s)                          0.00335581
time/training (s)                        1.942e-05
time/epoch (s)                          12.8906
time/total (s)                        1725.71
Epoch                                  130
----------------------------------  ----------------
2022-09-09 20:21:50.201959 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 131 finished
----------------------------------  ----------------
epoch                                  131
replay_buffer/size                  133000
trainer/num train calls             132000
trainer/QF1 Loss                         5.22171e-06
trainer/QF2 Loss                         3.0517e-06
trainer/Policy Loss                     -0.939284
trainer/Q1 Predictions Mean              0.930288
trainer/Q1 Predictions Std               0.0156817
trainer/Q1 Predictions Max               0.995953
trainer/Q1 Predictions Min               0.91263
trainer/Q2 Predictions Mean              0.932907
trainer/Q2 Predictions Std               0.0157158
trainer/Q2 Predictions Max               1.00406
trainer/Q2 Predictions Min               0.915133
trainer/Q Targets Mean                   0.932084
trainer/Q Targets Std                    0.0159707
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.914141
trainer/Log Pis Mean                     3.02817
trainer/Log Pis Std                      1.99645
trainer/Log Pis Max                      8.22974
trainer/Log Pis Min                     -3.1282
trainer/policy/mean Mean                 0.0130278
trainer/policy/mean Std                  0.740125
trainer/policy/mean Max                  0.993195
trainer/policy/mean Min                 -0.991198
trainer/policy/normal/std Mean           0.61206
trainer/policy/normal/std Std            0.234683
trainer/policy/normal/std Max            1.26203
trainer/policy/normal/std Min            0.0641802
trainer/policy/normal/log_std Mean      -0.585783
trainer/policy/normal/log_std Std        0.482271
trainer/policy/normal/log_std Max        0.232718
trainer/policy/normal/log_std Min       -2.74606
trainer/Alpha                            0.000338961
trainer/Alpha Loss                       0.225099
expl/num steps total                133000
expl/num paths total                  2300
expl/path length Mean                    3.95257
expl/path length Std                     1.73937
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.252
expl/Rewards Std                         0.434161
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996047
expl/Returns Std                         0.0627451
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0424212
expl/Actions Std                         0.754537
expl/Actions Max                         0.999244
expl/Actions Min                        -0.999434
expl/Num Paths                         253
expl/Average Returns                     0.996047
eval/num steps total                653120
eval/num paths total                 11536
eval/path length Mean                    4.05434
eval/path length Std                     1.71567
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.246649
eval/Rewards Std                         0.431061
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0463078
eval/Actions Std                         0.70352
eval/Actions Max                         0.993928
eval/Actions Min                        -0.995001
eval/Num Paths                        1233
eval/Average Returns                     1
time/data storing (s)                    0.0039529
time/evaluation sampling (s)             0.95869
time/exploration sampling (s)            0.31431
time/logging (s)                         0.0182911
time/sac training (s)                   11.5723
time/saving (s)                          0.0046199
time/training (s)                        3.08e-05
time/epoch (s)                          12.8722
time/total (s)                        1738.85
Epoch                                  131
----------------------------------  ----------------
2022-09-09 20:22:03.470972 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 132 finished
----------------------------------  ----------------
epoch                                  132
replay_buffer/size                  134000
trainer/num train calls             133000
trainer/QF1 Loss                         1.55766e-06
trainer/QF2 Loss                         2.03995e-06
trainer/Policy Loss                     -0.942633
trainer/Q1 Predictions Mean              0.933698
trainer/Q1 Predictions Std               0.0158107
trainer/Q1 Predictions Max               1.0002
trainer/Q1 Predictions Min               0.915996
trainer/Q2 Predictions Mean              0.933882
trainer/Q2 Predictions Std               0.0159406
trainer/Q2 Predictions Max               1.00233
trainer/Q2 Predictions Min               0.915196
trainer/Q Targets Mean                   0.933519
trainer/Q Targets Std                    0.0160321
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.914009
trainer/Log Pis Mean                     2.79951
trainer/Log Pis Std                      1.99985
trainer/Log Pis Max                      8.74085
trainer/Log Pis Min                     -2.9192
trainer/policy/mean Mean                 0.00721313
trainer/policy/mean Std                  0.740344
trainer/policy/mean Max                  0.994809
trainer/policy/mean Min                 -0.995838
trainer/policy/normal/std Mean           0.604383
trainer/policy/normal/std Std            0.23244
trainer/policy/normal/std Max            1.47222
trainer/policy/normal/std Min            0.0605102
trainer/policy/normal/log_std Mean      -0.603824
trainer/policy/normal/log_std Std        0.502206
trainer/policy/normal/log_std Max        0.386775
trainer/policy/normal/log_std Min       -2.80494
trainer/Alpha                            0.000337728
trainer/Alpha Loss                      -1.60254
expl/num steps total                134000
expl/num paths total                  2543
expl/path length Mean                    4.11523
expl/path length Std                     1.71267
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.242
expl/Rewards Std                         0.428294
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995885
expl/Returns Std                         0.0640179
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0333958
expl/Actions Std                         0.753578
expl/Actions Max                         0.99986
expl/Actions Min                        -0.998989
expl/Num Paths                         243
expl/Average Returns                     0.995885
eval/num steps total                658118
eval/num paths total                 12789
eval/path length Mean                    3.98883
eval/path length Std                     1.74327
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2507
eval/Rewards Std                         0.433416
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.054946
eval/Actions Std                         0.701935
eval/Actions Max                         0.995062
eval/Actions Min                        -0.996649
eval/Num Paths                        1253
eval/Average Returns                     1
time/data storing (s)                    0.0061004
time/evaluation sampling (s)             0.957193
time/exploration sampling (s)            0.377577
time/logging (s)                         0.018291
time/sac training (s)                   11.6167
time/saving (s)                          0.00325394
time/training (s)                        2.081e-05
time/epoch (s)                          12.9791
time/total (s)                        1752.11
Epoch                                  132
----------------------------------  ----------------
2022-09-09 20:22:16.617810 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 133 finished
----------------------------------  ----------------
epoch                                  133
replay_buffer/size                  135000
trainer/num train calls             134000
trainer/QF1 Loss                         1.74047e-06
trainer/QF2 Loss                         2.83379e-06
trainer/Policy Loss                     -0.941366
trainer/Q1 Predictions Mean              0.932919
trainer/Q1 Predictions Std               0.0191028
trainer/Q1 Predictions Max               1.00101
trainer/Q1 Predictions Min               0.913532
trainer/Q2 Predictions Mean              0.933898
trainer/Q2 Predictions Std               0.0191098
trainer/Q2 Predictions Max               1.00232
trainer/Q2 Predictions Min               0.91438
trainer/Q Targets Mean                   0.933618
trainer/Q Targets Std                    0.0190159
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.914416
trainer/Log Pis Mean                     3.08166
trainer/Log Pis Std                      1.98836
trainer/Log Pis Max                      8.186
trainer/Log Pis Min                     -3.73386
trainer/policy/mean Mean                 0.0559693
trainer/policy/mean Std                  0.748657
trainer/policy/mean Max                  0.992661
trainer/policy/mean Min                 -0.995903
trainer/policy/normal/std Mean           0.62172
trainer/policy/normal/std Std            0.270005
trainer/policy/normal/std Max            1.8724
trainer/policy/normal/std Min            0.0768393
trainer/policy/normal/log_std Mean      -0.588063
trainer/policy/normal/log_std Std        0.517242
trainer/policy/normal/log_std Max        0.627221
trainer/policy/normal/log_std Min       -2.56604
trainer/Alpha                            0.000348967
trainer/Alpha Loss                       0.650035
expl/num steps total                135000
expl/num paths total                  2793
expl/path length Mean                    4
expl/path length Std                     1.74585
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.25
expl/Rewards Std                         0.433013
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0465421
expl/Actions Std                         0.76307
expl/Actions Max                         0.999371
expl/Actions Min                        -0.999206
expl/Num Paths                         250
expl/Average Returns                     1
eval/num steps total                663115
eval/num paths total                 14007
eval/path length Mean                    4.10263
eval/path length Std                     1.7589
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.243746
eval/Rewards Std                         0.429341
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00364976
eval/Actions Std                         0.702182
eval/Actions Max                         0.993509
eval/Actions Min                        -0.996564
eval/Num Paths                        1218
eval/Average Returns                     1
time/data storing (s)                    0.00609985
time/evaluation sampling (s)             0.974939
time/exploration sampling (s)            0.352106
time/logging (s)                         0.0171686
time/sac training (s)                   11.5165
time/saving (s)                          0.00333368
time/training (s)                        1.896e-05
time/epoch (s)                          12.8702
time/total (s)                        1765.24
Epoch                                  133
----------------------------------  ----------------
2022-09-09 20:22:29.670289 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 134 finished
----------------------------------  ----------------
epoch                                  134
replay_buffer/size                  136000
trainer/num train calls             135000
trainer/QF1 Loss                         2.62348e-05
trainer/QF2 Loss                         3.65072e-06
trainer/Policy Loss                     -0.938559
trainer/Q1 Predictions Mean              0.929126
trainer/Q1 Predictions Std               0.0170988
trainer/Q1 Predictions Max               0.999158
trainer/Q1 Predictions Min               0.91039
trainer/Q2 Predictions Mean              0.933079
trainer/Q2 Predictions Std               0.0169236
trainer/Q2 Predictions Max               1.00038
trainer/Q2 Predictions Min               0.916102
trainer/Q Targets Mean                   0.933853
trainer/Q Targets Std                    0.0170616
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.915631
trainer/Log Pis Mean                     3.16655
trainer/Log Pis Std                      2.05255
trainer/Log Pis Max                      8.33457
trainer/Log Pis Min                     -2.90522
trainer/policy/mean Mean                 0.0212187
trainer/policy/mean Std                  0.754404
trainer/policy/mean Max                  0.994381
trainer/policy/mean Min                 -0.995148
trainer/policy/normal/std Mean           0.624399
trainer/policy/normal/std Std            0.247932
trainer/policy/normal/std Max            2.39138
trainer/policy/normal/std Min            0.0472991
trainer/policy/normal/log_std Mean      -0.559478
trainer/policy/normal/log_std Std        0.453808
trainer/policy/normal/log_std Max        0.871872
trainer/policy/normal/log_std Min       -3.05126
trainer/Alpha                            0.000333063
trainer/Alpha Loss                       1.33362
expl/num steps total                136000
expl/num paths total                  3049
expl/path length Mean                    3.90625
expl/path length Std                     1.71591
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.255
expl/Rewards Std                         0.435861
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996094
expl/Returns Std                         0.0623778
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0309235
expl/Actions Std                         0.759484
expl/Actions Max                         0.999435
expl/Actions Min                        -0.999717
expl/Num Paths                         256
expl/Average Returns                     0.996094
eval/num steps total                668114
eval/num paths total                 15238
eval/path length Mean                    4.06093
eval/path length Std                     1.70068
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.246249
eval/Rewards Std                         0.430825
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0426055
eval/Actions Std                         0.704815
eval/Actions Max                         0.994399
eval/Actions Min                        -0.997673
eval/Num Paths                        1231
eval/Average Returns                     1
time/data storing (s)                    0.00391547
time/evaluation sampling (s)             0.954554
time/exploration sampling (s)            0.308172
time/logging (s)                         0.0193664
time/sac training (s)                   11.4932
time/saving (s)                          0.00472709
time/training (s)                        2.779e-05
time/epoch (s)                          12.784
time/total (s)                        1778.29
Epoch                                  134
----------------------------------  ----------------
2022-09-09 20:22:42.997540 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 135 finished
----------------------------------  ----------------
epoch                                  135
replay_buffer/size                  137000
trainer/num train calls             136000
trainer/QF1 Loss                         2.12545e-06
trainer/QF2 Loss                         2.48663e-06
trainer/Policy Loss                     -0.943817
trainer/Q1 Predictions Mean              0.935723
trainer/Q1 Predictions Std               0.0168875
trainer/Q1 Predictions Max               1.00086
trainer/Q1 Predictions Min               0.917928
trainer/Q2 Predictions Mean              0.93487
trainer/Q2 Predictions Std               0.0169398
trainer/Q2 Predictions Max               0.999102
trainer/Q2 Predictions Min               0.916775
trainer/Q Targets Mean                   0.935014
trainer/Q Targets Std                    0.017049
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.917774
trainer/Log Pis Mean                     2.99361
trainer/Log Pis Std                      1.81323
trainer/Log Pis Max                      9.49629
trainer/Log Pis Min                     -3.03096
trainer/policy/mean Mean                 0.022289
trainer/policy/mean Std                  0.737825
trainer/policy/mean Max                  0.993673
trainer/policy/mean Min                 -0.995416
trainer/policy/normal/std Mean           0.604216
trainer/policy/normal/std Std            0.269823
trainer/policy/normal/std Max            2.02139
trainer/policy/normal/std Min            0.0861999
trainer/policy/normal/log_std Mean      -0.613385
trainer/policy/normal/log_std Std        0.496992
trainer/policy/normal/log_std Max        0.703785
trainer/policy/normal/log_std Min       -2.45109
trainer/Alpha                            0.000322922
trainer/Alpha Loss                      -0.0513408
expl/num steps total                137000
expl/num paths total                  3302
expl/path length Mean                    3.95257
expl/path length Std                     1.76195
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.253
expl/Rewards Std                         0.434731
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0285428
expl/Actions Std                         0.756068
expl/Actions Max                         0.999817
expl/Actions Min                        -0.9996
expl/Num Paths                         253
expl/Average Returns                     1
eval/num steps total                673114
eval/num paths total                 16478
eval/path length Mean                    4.03226
eval/path length Std                     1.75304
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.248
eval/Rewards Std                         0.431852
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0718595
eval/Actions Std                         0.7023
eval/Actions Max                         0.99422
eval/Actions Min                        -0.996605
eval/Num Paths                        1240
eval/Average Returns                     1
time/data storing (s)                    0.00413938
time/evaluation sampling (s)             0.973124
time/exploration sampling (s)            0.353903
time/logging (s)                         0.0195405
time/sac training (s)                   11.6848
time/saving (s)                          0.00467333
time/training (s)                        2.486e-05
time/epoch (s)                          13.0402
time/total (s)                        1791.6
Epoch                                  135
----------------------------------  ----------------
2022-09-09 20:22:56.283491 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 136 finished
----------------------------------  ----------------
epoch                                  136
replay_buffer/size                  138000
trainer/num train calls             137000
trainer/QF1 Loss                         4.90769e-06
trainer/QF2 Loss                         7.39937e-06
trainer/Policy Loss                     -0.942623
trainer/Q1 Predictions Mean              0.933179
trainer/Q1 Predictions Std               0.0168282
trainer/Q1 Predictions Max               0.998087
trainer/Q1 Predictions Min               0.916247
trainer/Q2 Predictions Mean              0.937175
trainer/Q2 Predictions Std               0.0168039
trainer/Q2 Predictions Max               1.00339
trainer/Q2 Predictions Min               0.920299
trainer/Q Targets Mean                   0.934972
trainer/Q Targets Std                    0.0170386
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.919147
trainer/Log Pis Mean                     2.95624
trainer/Log Pis Std                      1.94854
trainer/Log Pis Max                      8.29468
trainer/Log Pis Min                     -2.40106
trainer/policy/mean Mean                -0.000983647
trainer/policy/mean Std                  0.715651
trainer/policy/mean Max                  0.994596
trainer/policy/mean Min                 -0.995017
trainer/policy/normal/std Mean           0.59909
trainer/policy/normal/std Std            0.251269
trainer/policy/normal/std Max            1.79932
trainer/policy/normal/std Min            0.0929795
trainer/policy/normal/log_std Mean      -0.613657
trainer/policy/normal/log_std Std        0.479587
trainer/policy/normal/log_std Max        0.587411
trainer/policy/normal/log_std Min       -2.37538
trainer/Alpha                            0.000317335
trainer/Alpha Loss                      -0.352481
expl/num steps total                138000
expl/num paths total                  3550
expl/path length Mean                    4.03226
expl/path length Std                     1.79352
expl/path length Max                     8
expl/path length Min                     1
expl/Rewards Mean                        0.247
expl/Rewards Std                         0.431267
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995968
expl/Returns Std                         0.0633719
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0130892
expl/Actions Std                         0.74372
expl/Actions Max                         0.99985
expl/Actions Min                        -0.99935
expl/Num Paths                         248
expl/Average Returns                     0.995968
eval/num steps total                678114
eval/num paths total                 17697
eval/path length Mean                    4.10172
eval/path length Std                     1.69625
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2438
eval/Rewards Std                         0.429373
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0248017
eval/Actions Std                         0.703963
eval/Actions Max                         0.993516
eval/Actions Min                        -0.996594
eval/Num Paths                        1219
eval/Average Returns                     1
time/data storing (s)                    0.0040832
time/evaluation sampling (s)             0.969378
time/exploration sampling (s)            0.318269
time/logging (s)                         0.0185453
time/sac training (s)                   11.6761
time/saving (s)                          0.00484058
time/training (s)                        4.256e-05
time/epoch (s)                          12.9912
time/total (s)                        1804.88
Epoch                                  136
----------------------------------  ----------------
2022-09-09 20:23:09.747528 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 137 finished
----------------------------------  ----------------
epoch                                  137
replay_buffer/size                  139000
trainer/num train calls             138000
trainer/QF1 Loss                         2.16261e-06
trainer/QF2 Loss                         3.31206e-06
trainer/Policy Loss                     -0.944066
trainer/Q1 Predictions Mean              0.935666
trainer/Q1 Predictions Std               0.018439
trainer/Q1 Predictions Max               0.999817
trainer/Q1 Predictions Min               0.916243
trainer/Q2 Predictions Mean              0.935386
trainer/Q2 Predictions Std               0.0185948
trainer/Q2 Predictions Max               1.0032
trainer/Q2 Predictions Min               0.914775
trainer/Q Targets Mean                   0.936433
trainer/Q Targets Std                    0.0186657
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.917388
trainer/Log Pis Mean                     3.06736
trainer/Log Pis Std                      1.97676
trainer/Log Pis Max                      8.0066
trainer/Log Pis Min                     -3.94949
trainer/policy/mean Mean                -0.0206957
trainer/policy/mean Std                  0.74101
trainer/policy/mean Max                  0.995897
trainer/policy/mean Min                 -0.995539
trainer/policy/normal/std Mean           0.612533
trainer/policy/normal/std Std            0.258767
trainer/policy/normal/std Max            1.87903
trainer/policy/normal/std Min            0.0688719
trainer/policy/normal/log_std Mean      -0.603002
trainer/policy/normal/log_std Std        0.52395
trainer/policy/normal/log_std Max        0.630756
trainer/policy/normal/log_std Min       -2.67551
trainer/Alpha                            0.000301725
trainer/Alpha Loss                       0.546045
expl/num steps total                139000
expl/num paths total                  3799
expl/path length Mean                    4.01606
expl/path length Std                     1.79013
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0745634
expl/Actions Std                         0.759138
expl/Actions Max                         0.999608
expl/Actions Min                        -0.999495
expl/Num Paths                         249
expl/Average Returns                     1
eval/num steps total                683111
eval/num paths total                 18945
eval/path length Mean                    4.00401
eval/path length Std                     1.72672
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.24975
eval/Rewards Std                         0.432868
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0635333
eval/Actions Std                         0.695951
eval/Actions Max                         0.99528
eval/Actions Min                        -0.995213
eval/Num Paths                        1248
eval/Average Returns                     1
time/data storing (s)                    0.00622479
time/evaluation sampling (s)             1.00567
time/exploration sampling (s)            0.343393
time/logging (s)                         0.0210468
time/sac training (s)                   11.7957
time/saving (s)                          0.00464849
time/training (s)                        2.723e-05
time/epoch (s)                          13.1767
time/total (s)                        1818.33
Epoch                                  137
----------------------------------  ----------------
2022-09-09 20:23:23.426287 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 138 finished
----------------------------------  ----------------
epoch                                  138
replay_buffer/size                  140000
trainer/num train calls             139000
trainer/QF1 Loss                         2.87482e-06
trainer/QF2 Loss                         4.81678e-06
trainer/Policy Loss                     -0.9463
trainer/Q1 Predictions Mean              0.937785
trainer/Q1 Predictions Std               0.0173317
trainer/Q1 Predictions Max               1.0042
trainer/Q1 Predictions Min               0.919481
trainer/Q2 Predictions Mean              0.937967
trainer/Q2 Predictions Std               0.0168004
trainer/Q2 Predictions Max               1.00698
trainer/Q2 Predictions Min               0.91953
trainer/Q Targets Mean                   0.9365
trainer/Q Targets Std                    0.0172961
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.919138
trainer/Log Pis Mean                     3.02355
trainer/Log Pis Std                      1.89667
trainer/Log Pis Max                      9.0301
trainer/Log Pis Min                     -2.51664
trainer/policy/mean Mean                 0.0314223
trainer/policy/mean Std                  0.72579
trainer/policy/mean Max                  0.995193
trainer/policy/mean Min                 -0.990506
trainer/policy/normal/std Mean           0.612147
trainer/policy/normal/std Std            0.255325
trainer/policy/normal/std Max            1.54363
trainer/policy/normal/std Min            0.0885651
trainer/policy/normal/log_std Mean      -0.59807
trainer/policy/normal/log_std Std        0.502761
trainer/policy/normal/log_std Max        0.434135
trainer/policy/normal/log_std Min       -2.42402
trainer/Alpha                            0.000293207
trainer/Alpha Loss                       0.191545
expl/num steps total                140000
expl/num paths total                  4037
expl/path length Mean                    4.20168
expl/path length Std                     1.71538
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.237
expl/Rewards Std                         0.425242
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995798
expl/Returns Std                         0.0646841
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0292868
expl/Actions Std                         0.764162
expl/Actions Max                         0.999591
expl/Actions Min                        -0.999646
expl/Num Paths                         238
expl/Average Returns                     0.995798
eval/num steps total                688110
eval/num paths total                 20198
eval/path length Mean                    3.98962
eval/path length Std                     1.78064
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25065
eval/Rewards Std                         0.433387
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0120685
eval/Actions Std                         0.697336
eval/Actions Max                         0.995343
eval/Actions Min                        -0.99525
eval/Num Paths                        1253
eval/Average Returns                     1
time/data storing (s)                    0.00602299
time/evaluation sampling (s)             0.975799
time/exploration sampling (s)            0.337767
time/logging (s)                         0.0205154
time/sac training (s)                   12.0274
time/saving (s)                          0.00367644
time/training (s)                        3.192e-05
time/epoch (s)                          13.3712
time/total (s)                        1832
Epoch                                  138
----------------------------------  ----------------
2022-09-09 20:23:36.950127 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 139 finished
----------------------------------  ----------------
epoch                                  139
replay_buffer/size                  141000
trainer/num train calls             140000
trainer/QF1 Loss                         1.46134e-06
trainer/QF2 Loss                         7.35005e-06
trainer/Policy Loss                     -0.945399
trainer/Q1 Predictions Mean              0.937481
trainer/Q1 Predictions Std               0.0189425
trainer/Q1 Predictions Max               1.00026
trainer/Q1 Predictions Min               0.91675
trainer/Q2 Predictions Mean              0.936353
trainer/Q2 Predictions Std               0.0189639
trainer/Q2 Predictions Max               1.00051
trainer/Q2 Predictions Min               0.915031
trainer/Q Targets Mean                   0.938202
trainer/Q Targets Std                    0.0189122
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.916804
trainer/Log Pis Mean                     2.98538
trainer/Log Pis Std                      1.91845
trainer/Log Pis Max                      7.9484
trainer/Log Pis Min                     -2.06153
trainer/policy/mean Mean                -0.00902479
trainer/policy/mean Std                  0.722516
trainer/policy/mean Max                  0.994564
trainer/policy/mean Min                 -0.992564
trainer/policy/normal/std Mean           0.62268
trainer/policy/normal/std Std            0.254729
trainer/policy/normal/std Max            2.04285
trainer/policy/normal/std Min            0.0859637
trainer/policy/normal/log_std Mean      -0.570027
trainer/policy/normal/log_std Std        0.470149
trainer/policy/normal/log_std Max        0.714345
trainer/policy/normal/log_std Min       -2.45383
trainer/Alpha                            0.000288561
trainer/Alpha Loss                      -0.119189
expl/num steps total                141000
expl/num paths total                  4292
expl/path length Mean                    3.92157
expl/path length Std                     1.74494
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.255
expl/Rewards Std                         0.435861
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.00854415
expl/Actions Std                         0.761638
expl/Actions Max                         0.999952
expl/Actions Min                        -0.998696
expl/Num Paths                         255
expl/Average Returns                     1
eval/num steps total                693108
eval/num paths total                 21448
eval/path length Mean                    3.9984
eval/path length Std                     1.72186
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2501
eval/Rewards Std                         0.43307
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.028076
eval/Actions Std                         0.691874
eval/Actions Max                         0.995172
eval/Actions Min                        -0.995096
eval/Num Paths                        1250
eval/Average Returns                     1
time/data storing (s)                    0.00400263
time/evaluation sampling (s)             1.01016
time/exploration sampling (s)            0.35075
time/logging (s)                         0.0201298
time/sac training (s)                   11.8348
time/saving (s)                          0.00466624
time/training (s)                        2.582e-05
time/epoch (s)                          13.2245
time/total (s)                        1845.51
Epoch                                  139
----------------------------------  ----------------
2022-09-09 20:23:50.098131 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 140 finished
----------------------------------  ----------------
epoch                                  140
replay_buffer/size                  142000
trainer/num train calls             141000
trainer/QF1 Loss                         9.0227e-07
trainer/QF2 Loss                         2.91569e-06
trainer/Policy Loss                     -0.944112
trainer/Q1 Predictions Mean              0.936551
trainer/Q1 Predictions Std               0.0169542
trainer/Q1 Predictions Max               1.00341
trainer/Q1 Predictions Min               0.917301
trainer/Q2 Predictions Mean              0.935378
trainer/Q2 Predictions Std               0.0170227
trainer/Q2 Predictions Max               1.00576
trainer/Q2 Predictions Min               0.917087
trainer/Q Targets Mean                   0.936351
trainer/Q Targets Std                    0.0166108
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.917922
trainer/Log Pis Mean                     2.77682
trainer/Log Pis Std                      2.05682
trainer/Log Pis Max                      8.22771
trainer/Log Pis Min                     -3.89893
trainer/policy/mean Mean                 0.0365189
trainer/policy/mean Std                  0.719225
trainer/policy/mean Max                  0.993035
trainer/policy/mean Min                 -0.993793
trainer/policy/normal/std Mean           0.61059
trainer/policy/normal/std Std            0.247041
trainer/policy/normal/std Max            1.57581
trainer/policy/normal/std Min            0.097392
trainer/policy/normal/log_std Mean      -0.591772
trainer/policy/normal/log_std Std        0.477835
trainer/policy/normal/log_std Max        0.454768
trainer/policy/normal/log_std Min       -2.32901
trainer/Alpha                            0.00027619
trainer/Alpha Loss                      -1.82881
expl/num steps total                142000
expl/num paths total                  4533
expl/path length Mean                    4.14938
expl/path length Std                     1.66065
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.24
expl/Rewards Std                         0.427083
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995851
expl/Returns Std                         0.0642819
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0366877
expl/Actions Std                         0.760922
expl/Actions Max                         0.999984
expl/Actions Min                        -0.998993
expl/Num Paths                         241
expl/Average Returns                     0.995851
eval/num steps total                698108
eval/num paths total                 22694
eval/path length Mean                    4.01284
eval/path length Std                     1.69358
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2492
eval/Rewards Std                         0.43255
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0249252
eval/Actions Std                         0.690498
eval/Actions Max                         0.994578
eval/Actions Min                        -0.994291
eval/Num Paths                        1246
eval/Average Returns                     1
time/data storing (s)                    0.00388168
time/evaluation sampling (s)             0.963058
time/exploration sampling (s)            0.322468
time/logging (s)                         0.0174838
time/sac training (s)                   11.5643
time/saving (s)                          0.00466924
time/training (s)                        2.513e-05
time/epoch (s)                          12.8759
time/total (s)                        1858.65
Epoch                                  140
----------------------------------  ----------------
2022-09-09 20:24:03.354945 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 141 finished
----------------------------------  ----------------
epoch                                  141
replay_buffer/size                  143000
trainer/num train calls             142000
trainer/QF1 Loss                         9.72146e-07
trainer/QF2 Loss                         2.82576e-06
trainer/Policy Loss                     -0.946001
trainer/Q1 Predictions Mean              0.93866
trainer/Q1 Predictions Std               0.0196206
trainer/Q1 Predictions Max               1.0031
trainer/Q1 Predictions Min               0.917788
trainer/Q2 Predictions Mean              0.93798
trainer/Q2 Predictions Std               0.0196898
trainer/Q2 Predictions Max               1.00519
trainer/Q2 Predictions Min               0.916119
trainer/Q Targets Mean                   0.93893
trainer/Q Targets Std                    0.0196654
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.9179
trainer/Log Pis Mean                     2.96857
trainer/Log Pis Std                      1.96038
trainer/Log Pis Max                      7.69448
trainer/Log Pis Min                     -5.16002
trainer/policy/mean Mean                 0.0400367
trainer/policy/mean Std                  0.732206
trainer/policy/mean Max                  0.994707
trainer/policy/mean Min                 -0.995031
trainer/policy/normal/std Mean           0.603137
trainer/policy/normal/std Std            0.254813
trainer/policy/normal/std Max            1.61973
trainer/policy/normal/std Min            0.0728567
trainer/policy/normal/log_std Mean      -0.615077
trainer/policy/normal/log_std Std        0.508455
trainer/policy/normal/log_std Max        0.48226
trainer/policy/normal/log_std Min       -2.61926
trainer/Alpha                            0.000270753
trainer/Alpha Loss                      -0.25815
expl/num steps total                143000
expl/num paths total                  4773
expl/path length Mean                    4.16667
expl/path length Std                     1.67
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.24
expl/Rewards Std                         0.427083
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.00552127
expl/Actions Std                         0.759717
expl/Actions Max                         0.999186
expl/Actions Min                        -0.999474
expl/Num Paths                         240
expl/Average Returns                     1
eval/num steps total                703108
eval/num paths total                 23933
eval/path length Mean                    4.03551
eval/path length Std                     1.68228
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2478
eval/Rewards Std                         0.431735
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00417091
eval/Actions Std                         0.69483
eval/Actions Max                         0.994647
eval/Actions Min                        -0.995349
eval/Num Paths                        1239
eval/Average Returns                     1
time/data storing (s)                    0.00613565
time/evaluation sampling (s)             0.957249
time/exploration sampling (s)            0.318912
time/logging (s)                         0.0180494
time/sac training (s)                   11.6611
time/saving (s)                          0.00349293
time/training (s)                        1.881e-05
time/epoch (s)                          12.9649
time/total (s)                        1871.89
Epoch                                  141
----------------------------------  ----------------
2022-09-09 20:24:17.803178 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 142 finished
----------------------------------  ----------------
epoch                                  142
replay_buffer/size                  144000
trainer/num train calls             143000
trainer/QF1 Loss                         7.67717e-07
trainer/QF2 Loss                         2.01185e-06
trainer/Policy Loss                     -0.946568
trainer/Q1 Predictions Mean              0.939335
trainer/Q1 Predictions Std               0.0189852
trainer/Q1 Predictions Max               1.00097
trainer/Q1 Predictions Min               0.918357
trainer/Q2 Predictions Mean              0.939078
trainer/Q2 Predictions Std               0.0190761
trainer/Q2 Predictions Max               1.00024
trainer/Q2 Predictions Min               0.918202
trainer/Q Targets Mean                   0.939353
trainer/Q Targets Std                    0.0192195
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.918784
trainer/Log Pis Mean                     2.83024
trainer/Log Pis Std                      1.96006
trainer/Log Pis Max                      7.43812
trainer/Log Pis Min                     -5.31653
trainer/policy/mean Mean                 0.0362584
trainer/policy/mean Std                  0.720704
trainer/policy/mean Max                  0.995138
trainer/policy/mean Min                 -0.99406
trainer/policy/normal/std Mean           0.609976
trainer/policy/normal/std Std            0.242403
trainer/policy/normal/std Max            1.30655
trainer/policy/normal/std Min            0.0859011
trainer/policy/normal/log_std Mean      -0.593581
trainer/policy/normal/log_std Std        0.486388
trainer/policy/normal/log_std Max        0.267393
trainer/policy/normal/log_std Min       -2.45456
trainer/Alpha                            0.000266743
trainer/Alpha Loss                      -1.39702
expl/num steps total                144000
expl/num paths total                  5039
expl/path length Mean                    3.7594
expl/path length Std                     1.73053
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.266
expl/Rewards Std                         0.441864
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.00357387
expl/Actions Std                         0.758896
expl/Actions Max                         0.99925
expl/Actions Min                        -0.999333
expl/Num Paths                         266
expl/Average Returns                     1
eval/num steps total                708102
eval/num paths total                 25176
eval/path length Mean                    4.0177
eval/path length Std                     1.70032
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.248899
eval/Rewards Std                         0.432375
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0362013
eval/Actions Std                         0.689874
eval/Actions Max                         0.995333
eval/Actions Min                        -0.995314
eval/Num Paths                        1243
eval/Average Returns                     1
time/data storing (s)                    0.00617225
time/evaluation sampling (s)             0.989312
time/exploration sampling (s)            0.338979
time/logging (s)                         0.0205634
time/sac training (s)                   12.7436
time/saving (s)                          0.00558064
time/training (s)                        4.297e-05
time/epoch (s)                          14.1043
time/total (s)                        1886.33
Epoch                                  142
----------------------------------  ----------------
2022-09-09 20:24:32.375024 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 143 finished
----------------------------------  ----------------
epoch                                  143
replay_buffer/size                  145000
trainer/num train calls             144000
trainer/QF1 Loss                         2.19365e-06
trainer/QF2 Loss                         5.75122e-06
trainer/Policy Loss                     -0.94544
trainer/Q1 Predictions Mean              0.937923
trainer/Q1 Predictions Std               0.0197552
trainer/Q1 Predictions Max               0.999166
trainer/Q1 Predictions Min               0.916809
trainer/Q2 Predictions Mean              0.937064
trainer/Q2 Predictions Std               0.0197401
trainer/Q2 Predictions Max               0.999958
trainer/Q2 Predictions Min               0.914767
trainer/Q Targets Mean                   0.938747
trainer/Q Targets Std                    0.019892
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.917917
trainer/Log Pis Mean                     3.13207
trainer/Log Pis Std                      2.30819
trainer/Log Pis Max                      8.58888
trainer/Log Pis Min                     -6.35324
trainer/policy/mean Mean                 0.0479564
trainer/policy/mean Std                  0.740468
trainer/policy/mean Max                  0.995658
trainer/policy/mean Min                 -0.99642
trainer/policy/normal/std Mean           0.634065
trainer/policy/normal/std Std            0.22925
trainer/policy/normal/std Max            2.02819
trainer/policy/normal/std Min            0.102354
trainer/policy/normal/log_std Mean      -0.527859
trainer/policy/normal/log_std Std        0.398656
trainer/policy/normal/log_std Max        0.707144
trainer/policy/normal/log_std Min       -2.27932
trainer/Alpha                            0.000260043
trainer/Alpha Loss                       1.09021
expl/num steps total                145000
expl/num paths total                  5300
expl/path length Mean                    3.83142
expl/path length Std                     1.75794
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.26
expl/Rewards Std                         0.438634
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996169
expl/Returns Std                         0.0617798
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0113725
expl/Actions Std                         0.761459
expl/Actions Max                         0.99957
expl/Actions Min                        -0.998992
expl/Num Paths                         261
expl/Average Returns                     0.996169
eval/num steps total                713097
eval/num paths total                 26428
eval/path length Mean                    3.98962
eval/path length Std                     1.70997
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.250651
eval/Rewards Std                         0.433388
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00768445
eval/Actions Std                         0.687307
eval/Actions Max                         0.994673
eval/Actions Min                        -0.995762
eval/Num Paths                        1252
eval/Average Returns                     1
time/data storing (s)                    0.00623298
time/evaluation sampling (s)             1.05014
time/exploration sampling (s)            0.329292
time/logging (s)                         0.0661077
time/sac training (s)                   12.7855
time/saving (s)                          0.00357426
time/training (s)                        2.86e-05
time/epoch (s)                          14.2409
time/total (s)                        1900.93
Epoch                                  143
----------------------------------  ----------------
2022-09-09 20:24:45.755979 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 144 finished
----------------------------------  ----------------
epoch                                  144
replay_buffer/size                  146000
trainer/num train calls             145000
trainer/QF1 Loss                         1.55139e-06
trainer/QF2 Loss                         5.11847e-06
trainer/Policy Loss                     -0.945879
trainer/Q1 Predictions Mean              0.937484
trainer/Q1 Predictions Std               0.0188575
trainer/Q1 Predictions Max               1.0003
trainer/Q1 Predictions Min               0.917533
trainer/Q2 Predictions Mean              0.939731
trainer/Q2 Predictions Std               0.0188019
trainer/Q2 Predictions Max               1.00411
trainer/Q2 Predictions Min               0.921297
trainer/Q Targets Mean                   0.938205
trainer/Q Targets Std                    0.0190811
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.91801
trainer/Log Pis Mean                     2.94364
trainer/Log Pis Std                      1.84382
trainer/Log Pis Max                      8.30038
trainer/Log Pis Min                     -3.8514
trainer/policy/mean Mean                 0.024918
trainer/policy/mean Std                  0.720005
trainer/policy/mean Max                  0.992605
trainer/policy/mean Min                 -0.993028
trainer/policy/normal/std Mean           0.618694
trainer/policy/normal/std Std            0.242253
trainer/policy/normal/std Max            1.38615
trainer/policy/normal/std Min            0.118431
trainer/policy/normal/log_std Mean      -0.570949
trainer/policy/normal/log_std Std        0.453565
trainer/policy/normal/log_std Max        0.326532
trainer/policy/normal/log_std Min       -2.13343
trainer/Alpha                            0.000260293
trainer/Alpha Loss                      -0.465152
expl/num steps total                146000
expl/num paths total                  5545
expl/path length Mean                    4.08163
expl/path length Std                     1.71472
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.244
expl/Rewards Std                         0.429493
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995918
expl/Returns Std                         0.0637571
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0357932
expl/Actions Std                         0.757388
expl/Actions Max                         0.9995
expl/Actions Min                        -0.999711
expl/Num Paths                         245
expl/Average Returns                     0.995918
eval/num steps total                718094
eval/num paths total                 27701
eval/path length Mean                    3.92537
eval/path length Std                     1.73271
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254753
eval/Rewards Std                         0.435722
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0114389
eval/Actions Std                         0.685426
eval/Actions Max                         0.995115
eval/Actions Min                        -0.99441
eval/Num Paths                        1273
eval/Average Returns                     1
time/data storing (s)                    0.00405368
time/evaluation sampling (s)             0.974567
time/exploration sampling (s)            0.339992
time/logging (s)                         0.0205097
time/sac training (s)                   11.6912
time/saving (s)                          0.00491163
time/training (s)                        4.562e-05
time/epoch (s)                          13.0353
time/total (s)                        1914.26
Epoch                                  144
----------------------------------  ----------------
2022-09-09 20:24:58.918908 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 145 finished
----------------------------------  ----------------
epoch                                  145
replay_buffer/size                  147000
trainer/num train calls             146000
trainer/QF1 Loss                         1.19744e-06
trainer/QF2 Loss                         2.3263e-06
trainer/Policy Loss                     -0.949258
trainer/Q1 Predictions Mean              0.941696
trainer/Q1 Predictions Std               0.0213406
trainer/Q1 Predictions Max               1.00239
trainer/Q1 Predictions Min               0.919014
trainer/Q2 Predictions Mean              0.941995
trainer/Q2 Predictions Std               0.0216676
trainer/Q2 Predictions Max               1.00484
trainer/Q2 Predictions Min               0.91905
trainer/Q Targets Mean                   0.941733
trainer/Q Targets Std                    0.0213208
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.919641
trainer/Log Pis Mean                     2.9825
trainer/Log Pis Std                      2.25781
trainer/Log Pis Max                      9.22921
trainer/Log Pis Min                     -5.17096
trainer/policy/mean Mean                 0.0738579
trainer/policy/mean Std                  0.726814
trainer/policy/mean Max                  0.995315
trainer/policy/mean Min                 -0.991032
trainer/policy/normal/std Mean           0.599582
trainer/policy/normal/std Std            0.222431
trainer/policy/normal/std Max            1.23342
trainer/policy/normal/std Min            0.104371
trainer/policy/normal/log_std Mean      -0.597269
trainer/policy/normal/log_std Std        0.448039
trainer/policy/normal/log_std Max        0.20979
trainer/policy/normal/log_std Min       -2.25981
trainer/Alpha                            0.000243605
trainer/Alpha Loss                      -0.145588
expl/num steps total                147000
expl/num paths total                  5800
expl/path length Mean                    3.92157
expl/path length Std                     1.79152
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.254
expl/Rewards Std                         0.435298
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996078
expl/Returns Std                         0.0624995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.073626
expl/Actions Std                         0.759301
expl/Actions Max                         0.999672
expl/Actions Min                        -0.999508
expl/Num Paths                         255
expl/Average Returns                     0.996078
eval/num steps total                723091
eval/num paths total                 28915
eval/path length Mean                    4.11614
eval/path length Std                     1.61251
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.242946
eval/Rewards Std                         0.428863
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00664632
eval/Actions Std                         0.695243
eval/Actions Max                         0.995592
eval/Actions Min                        -0.993348
eval/Num Paths                        1214
eval/Average Returns                     1
time/data storing (s)                    0.00620802
time/evaluation sampling (s)             0.962687
time/exploration sampling (s)            0.338952
time/logging (s)                         0.0190512
time/sac training (s)                   11.5409
time/saving (s)                          0.00465659
time/training (s)                        2.891e-05
time/epoch (s)                          12.8724
time/total (s)                        1927.41
Epoch                                  145
----------------------------------  ----------------
2022-09-09 20:25:12.009649 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 146 finished
----------------------------------  ----------------
epoch                                  146
replay_buffer/size                  148000
trainer/num train calls             147000
trainer/QF1 Loss                         1.51587e-06
trainer/QF2 Loss                         2.02113e-06
trainer/Policy Loss                     -0.945926
trainer/Q1 Predictions Mean              0.939156
trainer/Q1 Predictions Std               0.0178059
trainer/Q1 Predictions Max               1.00095
trainer/Q1 Predictions Min               0.919324
trainer/Q2 Predictions Mean              0.93752
trainer/Q2 Predictions Std               0.017873
trainer/Q2 Predictions Max               1.00059
trainer/Q2 Predictions Min               0.91854
trainer/Q Targets Mean                   0.938306
trainer/Q Targets Std                    0.0181076
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.919306
trainer/Log Pis Mean                     2.87718
trainer/Log Pis Std                      1.90376
trainer/Log Pis Max                      7.86851
trainer/Log Pis Min                     -3.77198
trainer/policy/mean Mean                 0.0946072
trainer/policy/mean Std                  0.710923
trainer/policy/mean Max                  0.994515
trainer/policy/mean Min                 -0.994823
trainer/policy/normal/std Mean           0.634455
trainer/policy/normal/std Std            0.248335
trainer/policy/normal/std Max            1.82706
trainer/policy/normal/std Min            0.103928
trainer/policy/normal/log_std Mean      -0.548263
trainer/policy/normal/log_std Std        0.469863
trainer/policy/normal/log_std Max        0.602709
trainer/policy/normal/log_std Min       -2.26405
trainer/Alpha                            0.000244394
trainer/Alpha Loss                      -1.02147
expl/num steps total                148000
expl/num paths total                  6047
expl/path length Mean                    4.04858
expl/path length Std                     1.79227
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.246
expl/Rewards Std                         0.430679
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995951
expl/Returns Std                         0.0634995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0250776
expl/Actions Std                         0.754093
expl/Actions Max                         0.999803
expl/Actions Min                        -0.99886
expl/Num Paths                         247
expl/Average Returns                     0.995951
eval/num steps total                728091
eval/num paths total                 30177
eval/path length Mean                    3.96197
eval/path length Std                     1.72797
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2524
eval/Rewards Std                         0.43439
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0193998
eval/Actions Std                         0.68674
eval/Actions Max                         0.996162
eval/Actions Min                        -0.995906
eval/Num Paths                        1262
eval/Average Returns                     1
time/data storing (s)                    0.00381605
time/evaluation sampling (s)             0.959634
time/exploration sampling (s)            0.322586
time/logging (s)                         0.0184115
time/sac training (s)                   11.5005
time/saving (s)                          0.00348019
time/training (s)                        2.255e-05
time/epoch (s)                          12.8085
time/total (s)                        1940.49
Epoch                                  146
----------------------------------  ----------------
2022-09-09 20:25:25.212224 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 147 finished
----------------------------------  ----------------
epoch                                  147
replay_buffer/size                  149000
trainer/num train calls             148000
trainer/QF1 Loss                         1.3399e-06
trainer/QF2 Loss                         5.19039e-06
trainer/Policy Loss                     -0.948651
trainer/Q1 Predictions Mean              0.942188
trainer/Q1 Predictions Std               0.0221195
trainer/Q1 Predictions Max               1.00228
trainer/Q1 Predictions Min               0.919212
trainer/Q2 Predictions Mean              0.940154
trainer/Q2 Predictions Std               0.0223446
trainer/Q2 Predictions Max               1.00103
trainer/Q2 Predictions Min               0.916033
trainer/Q Targets Mean                   0.941572
trainer/Q Targets Std                    0.0217967
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.919176
trainer/Log Pis Mean                     2.69773
trainer/Log Pis Std                      1.9257
trainer/Log Pis Max                      8.97657
trainer/Log Pis Min                     -3.58425
trainer/policy/mean Mean                 0.123538
trainer/policy/mean Std                  0.714162
trainer/policy/mean Max                  0.994055
trainer/policy/mean Min                 -0.994655
trainer/policy/normal/std Mean           0.646543
trainer/policy/normal/std Std            0.235945
trainer/policy/normal/std Max            1.78864
trainer/policy/normal/std Min            0.114524
trainer/policy/normal/log_std Mean      -0.515284
trainer/policy/normal/log_std Std        0.427419
trainer/policy/normal/log_std Max        0.581455
trainer/policy/normal/log_std Min       -2.16698
trainer/Alpha                            0.000239848
trainer/Alpha Loss                      -2.51957
expl/num steps total                149000
expl/num paths total                  6298
expl/path length Mean                    3.98406
expl/path length Std                     1.7423
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0510369
expl/Actions Std                         0.748207
expl/Actions Max                         0.999561
expl/Actions Min                        -0.999598
expl/Num Paths                         251
expl/Average Returns                     1
eval/num steps total                733087
eval/num paths total                 31421
eval/path length Mean                    4.01608
eval/path length Std                     1.68254
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.248999
eval/Rewards Std                         0.432433
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0419828
eval/Actions Std                         0.68575
eval/Actions Max                         0.994789
eval/Actions Min                        -0.996475
eval/Num Paths                        1244
eval/Average Returns                     1
time/data storing (s)                    0.00606475
time/evaluation sampling (s)             0.967255
time/exploration sampling (s)            0.336986
time/logging (s)                         0.0181614
time/sac training (s)                   11.5822
time/saving (s)                          0.00418291
time/training (s)                        3.036e-05
time/epoch (s)                          12.9149
time/total (s)                        1953.68
Epoch                                  147
----------------------------------  ----------------
2022-09-09 20:25:38.788756 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 148 finished
----------------------------------  ----------------
epoch                                  148
replay_buffer/size                  150000
trainer/num train calls             149000
trainer/QF1 Loss                         8.45834e-07
trainer/QF2 Loss                         2.39916e-06
trainer/Policy Loss                     -0.949033
trainer/Q1 Predictions Mean              0.941469
trainer/Q1 Predictions Std               0.021084
trainer/Q1 Predictions Max               1.00105
trainer/Q1 Predictions Min               0.920741
trainer/Q2 Predictions Mean              0.941085
trainer/Q2 Predictions Std               0.0209588
trainer/Q2 Predictions Max               1.00269
trainer/Q2 Predictions Min               0.920422
trainer/Q Targets Mean                   0.941233
trainer/Q Targets Std                    0.0211096
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.919783
trainer/Log Pis Mean                     2.9305
trainer/Log Pis Std                      2.02538
trainer/Log Pis Max                      8.30471
trainer/Log Pis Min                     -5.42766
trainer/policy/mean Mean                 0.0687458
trainer/policy/mean Std                  0.720524
trainer/policy/mean Max                  0.9936
trainer/policy/mean Min                 -0.993285
trainer/policy/normal/std Mean           0.632445
trainer/policy/normal/std Std            0.229952
trainer/policy/normal/std Max            1.23212
trainer/policy/normal/std Min            0.109611
trainer/policy/normal/log_std Mean      -0.539072
trainer/policy/normal/log_std Std        0.433653
trainer/policy/normal/log_std Max        0.208737
trainer/policy/normal/log_std Min       -2.21082
trainer/Alpha                            0.000234229
trainer/Alpha Loss                      -0.580946
expl/num steps total                150000
expl/num paths total                  6543
expl/path length Mean                    4.08163
expl/path length Std                     1.6762
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.245
expl/Rewards Std                         0.430087
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0537526
expl/Actions Std                         0.750903
expl/Actions Max                         0.999417
expl/Actions Min                        -0.999536
expl/Num Paths                         245
expl/Average Returns                     1
eval/num steps total                738085
eval/num paths total                 32666
eval/path length Mean                    4.01446
eval/path length Std                     1.70182
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2491
eval/Rewards Std                         0.432492
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0083966
eval/Actions Std                         0.683917
eval/Actions Max                         0.995469
eval/Actions Min                        -0.996424
eval/Num Paths                        1245
eval/Average Returns                     1
time/data storing (s)                    0.00385121
time/evaluation sampling (s)             0.955578
time/exploration sampling (s)            0.316371
time/logging (s)                         0.0196507
time/sac training (s)                   11.965
time/saving (s)                          0.00502951
time/training (s)                        1.919e-05
time/epoch (s)                          13.2655
time/total (s)                        1967.25
Epoch                                  148
----------------------------------  ----------------
2022-09-09 20:25:51.640857 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 149 finished
----------------------------------  ----------------
epoch                                  149
replay_buffer/size                  151000
trainer/num train calls             150000
trainer/QF1 Loss                         1.47395e-06
trainer/QF2 Loss                         2.28629e-06
trainer/Policy Loss                     -0.950756
trainer/Q1 Predictions Mean              0.943076
trainer/Q1 Predictions Std               0.0211003
trainer/Q1 Predictions Max               1.00444
trainer/Q1 Predictions Min               0.920227
trainer/Q2 Predictions Mean              0.943099
trainer/Q2 Predictions Std               0.0208876
trainer/Q2 Predictions Max               1.00462
trainer/Q2 Predictions Min               0.919912
trainer/Q Targets Mean                   0.942533
trainer/Q Targets Std                    0.0205656
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.919399
trainer/Log Pis Mean                     3.00163
trainer/Log Pis Std                      1.93956
trainer/Log Pis Max                      8.59818
trainer/Log Pis Min                     -5.01968
trainer/policy/mean Mean                 0.0919178
trainer/policy/mean Std                  0.713055
trainer/policy/mean Max                  0.995438
trainer/policy/mean Min                 -0.993561
trainer/policy/normal/std Mean           0.628939
trainer/policy/normal/std Std            0.244083
trainer/policy/normal/std Max            1.448
trainer/policy/normal/std Min            0.104014
trainer/policy/normal/log_std Mean      -0.557431
trainer/policy/normal/log_std Std        0.468837
trainer/policy/normal/log_std Max        0.370186
trainer/policy/normal/log_std Min       -2.26323
trainer/Alpha                            0.000234826
trainer/Alpha Loss                       0.0136208
expl/num steps total                151000
expl/num paths total                  6786
expl/path length Mean                    4.11523
expl/path length Std                     1.75069
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.243
expl/Rewards Std                         0.428895
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.00160219
expl/Actions Std                         0.765797
expl/Actions Max                         0.999603
expl/Actions Min                        -0.999614
expl/Num Paths                         243
expl/Average Returns                     1
eval/num steps total                743082
eval/num paths total                 33919
eval/path length Mean                    3.98803
eval/path length Std                     1.69097
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25075
eval/Rewards Std                         0.433445
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00653893
eval/Actions Std                         0.687262
eval/Actions Max                         0.995316
eval/Actions Min                        -0.994506
eval/Num Paths                        1253
eval/Average Returns                     1
time/data storing (s)                    0.00614121
time/evaluation sampling (s)             0.962473
time/exploration sampling (s)            0.305994
time/logging (s)                         0.0178114
time/sac training (s)                   11.2891
time/saving (s)                          0.00336636
time/training (s)                        1.863e-05
time/epoch (s)                          12.5849
time/total (s)                        1980.09
Epoch                                  149
----------------------------------  ----------------
2022-09-09 20:26:04.454550 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 150 finished
----------------------------------  ----------------
epoch                                  150
replay_buffer/size                  152000
trainer/num train calls             151000
trainer/QF1 Loss                         9.30766e-07
trainer/QF2 Loss                         2.33223e-06
trainer/Policy Loss                     -0.948952
trainer/Q1 Predictions Mean              0.94126
trainer/Q1 Predictions Std               0.0199711
trainer/Q1 Predictions Max               1.00045
trainer/Q1 Predictions Min               0.92054
trainer/Q2 Predictions Mean              0.941544
trainer/Q2 Predictions Std               0.0197413
trainer/Q2 Predictions Max               1.00234
trainer/Q2 Predictions Min               0.921211
trainer/Q Targets Mean                   0.940881
trainer/Q Targets Std                    0.0201838
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.919522
trainer/Log Pis Mean                     3.05793
trainer/Log Pis Std                      1.92542
trainer/Log Pis Max                      8.80841
trainer/Log Pis Min                     -2.76197
trainer/policy/mean Mean                 0.0991753
trainer/policy/mean Std                  0.713743
trainer/policy/mean Max                  0.995853
trainer/policy/mean Min                 -0.994056
trainer/policy/normal/std Mean           0.637465
trainer/policy/normal/std Std            0.238416
trainer/policy/normal/std Max            1.63925
trainer/policy/normal/std Min            0.100361
trainer/policy/normal/log_std Mean      -0.533849
trainer/policy/normal/log_std Std        0.439926
trainer/policy/normal/log_std Max        0.494241
trainer/policy/normal/log_std Min       -2.29898
trainer/Alpha                            0.000223221
trainer/Alpha Loss                       0.487033
expl/num steps total                152000
expl/num paths total                  7037
expl/path length Mean                    3.98406
expl/path length Std                     1.72622
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -9.99858e-05
expl/Actions Std                         0.754779
expl/Actions Max                         0.999533
expl/Actions Min                        -0.998916
expl/Num Paths                         251
expl/Average Returns                     1
eval/num steps total                748080
eval/num paths total                 35178
eval/path length Mean                    3.96982
eval/path length Std                     1.72743
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251901
eval/Rewards Std                         0.434105
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00210464
eval/Actions Std                         0.678235
eval/Actions Max                         0.995548
eval/Actions Min                        -0.995307
eval/Num Paths                        1259
eval/Average Returns                     1
time/data storing (s)                    0.0038733
time/evaluation sampling (s)             0.989012
time/exploration sampling (s)            0.320062
time/logging (s)                         0.0190031
time/sac training (s)                   11.2199
time/saving (s)                          0.00470745
time/training (s)                        2.648e-05
time/epoch (s)                          12.5566
time/total (s)                        1992.89
Epoch                                  150
----------------------------------  ----------------
2022-09-09 20:26:17.833427 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 151 finished
----------------------------------  ----------------
epoch                                  151
replay_buffer/size                  153000
trainer/num train calls             152000
trainer/QF1 Loss                         5.01951e-06
trainer/QF2 Loss                         2.76284e-06
trainer/Policy Loss                     -0.947484
trainer/Q1 Predictions Mean              0.939777
trainer/Q1 Predictions Std               0.0211833
trainer/Q1 Predictions Max               0.998988
trainer/Q1 Predictions Min               0.917426
trainer/Q2 Predictions Mean              0.941175
trainer/Q2 Predictions Std               0.0212976
trainer/Q2 Predictions Max               1.00267
trainer/Q2 Predictions Min               0.918417
trainer/Q Targets Mean                   0.941668
trainer/Q Targets Std                    0.0213409
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.920001
trainer/Log Pis Mean                     3.046
trainer/Log Pis Std                      1.90423
trainer/Log Pis Max                      8.46543
trainer/Log Pis Min                     -2.24109
trainer/policy/mean Mean                 0.0919655
trainer/policy/mean Std                  0.711037
trainer/policy/mean Max                  0.994109
trainer/policy/mean Min                 -0.993703
trainer/policy/normal/std Mean           0.610645
trainer/policy/normal/std Std            0.2319
trainer/policy/normal/std Max            1.19812
trainer/policy/normal/std Min            0.114863
trainer/policy/normal/log_std Mean      -0.580971
trainer/policy/normal/log_std Std        0.449926
trainer/policy/normal/log_std Max        0.18075
trainer/policy/normal/log_std Min       -2.16402
trainer/Alpha                            0.000227101
trainer/Alpha Loss                       0.385907
expl/num steps total                153000
expl/num paths total                  7273
expl/path length Mean                    4.23729
expl/path length Std                     1.70084
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.235
expl/Rewards Std                         0.423999
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995763
expl/Returns Std                         0.0649564
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0264207
expl/Actions Std                         0.749896
expl/Actions Max                         0.999445
expl/Actions Min                        -0.999349
expl/Num Paths                         236
expl/Average Returns                     0.995763
eval/num steps total                753078
eval/num paths total                 36424
eval/path length Mean                    4.01124
eval/path length Std                     1.76142
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2493
eval/Rewards Std                         0.432608
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00732577
eval/Actions Std                         0.679347
eval/Actions Max                         0.995287
eval/Actions Min                        -0.996589
eval/Num Paths                        1246
eval/Average Returns                     1
time/data storing (s)                    0.00374879
time/evaluation sampling (s)             0.95574
time/exploration sampling (s)            0.310223
time/logging (s)                         0.0187182
time/sac training (s)                   11.7772
time/saving (s)                          0.00481601
time/training (s)                        0.0002013
time/epoch (s)                          13.0707
time/total (s)                        2006.26
Epoch                                  151
----------------------------------  ----------------
2022-09-09 20:26:31.090670 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 152 finished
----------------------------------  ----------------
epoch                                  152
replay_buffer/size                  154000
trainer/num train calls             153000
trainer/QF1 Loss                         1.15719e-06
trainer/QF2 Loss                         1.79472e-06
trainer/Policy Loss                     -0.949045
trainer/Q1 Predictions Mean              0.942175
trainer/Q1 Predictions Std               0.0206172
trainer/Q1 Predictions Max               0.999448
trainer/Q1 Predictions Min               0.920881
trainer/Q2 Predictions Mean              0.942006
trainer/Q2 Predictions Std               0.0204854
trainer/Q2 Predictions Max               1.00216
trainer/Q2 Predictions Min               0.920088
trainer/Q Targets Mean                   0.942047
trainer/Q Targets Std                    0.0205519
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.9203
trainer/Log Pis Mean                     3.09524
trainer/Log Pis Std                      1.85805
trainer/Log Pis Max                      7.917
trainer/Log Pis Min                     -3.03968
trainer/policy/mean Mean                 0.0929461
trainer/policy/mean Std                  0.713745
trainer/policy/mean Max                  0.994164
trainer/policy/mean Min                 -0.992333
trainer/policy/normal/std Mean           0.621869
trainer/policy/normal/std Std            0.224298
trainer/policy/normal/std Max            1.15066
trainer/policy/normal/std Min            0.117168
trainer/policy/normal/log_std Mean      -0.553974
trainer/policy/normal/log_std Std        0.424727
trainer/policy/normal/log_std Max        0.140337
trainer/policy/normal/log_std Min       -2.14415
trainer/Alpha                            0.0002305
trainer/Alpha Loss                       0.797629
expl/num steps total                154000
expl/num paths total                  7534
expl/path length Mean                    3.83142
expl/path length Std                     1.74481
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.261
expl/Rewards Std                         0.43918
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.00882819
expl/Actions Std                         0.758976
expl/Actions Max                         0.999382
expl/Actions Min                        -0.999188
expl/Num Paths                         261
expl/Average Returns                     1
eval/num steps total                758072
eval/num paths total                 37669
eval/path length Mean                    4.01124
eval/path length Std                     1.71125
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.249299
eval/Rewards Std                         0.432607
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0127838
eval/Actions Std                         0.684972
eval/Actions Max                         0.995464
eval/Actions Min                        -0.993801
eval/Num Paths                        1245
eval/Average Returns                     1
time/data storing (s)                    0.00389313
time/evaluation sampling (s)             0.969588
time/exploration sampling (s)            0.310989
time/logging (s)                         0.0196757
time/sac training (s)                   11.6497
time/saving (s)                          0.00332567
time/training (s)                        1.919e-05
time/epoch (s)                          12.9572
time/total (s)                        2019.51
Epoch                                  152
----------------------------------  ----------------
2022-09-09 20:26:44.316230 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 153 finished
----------------------------------  ----------------
epoch                                  153
replay_buffer/size                  155000
trainer/num train calls             154000
trainer/QF1 Loss                         3.23467e-06
trainer/QF2 Loss                         3.82712e-06
trainer/Policy Loss                     -0.947631
trainer/Q1 Predictions Mean              0.940085
trainer/Q1 Predictions Std               0.0209885
trainer/Q1 Predictions Max               1.00062
trainer/Q1 Predictions Min               0.918566
trainer/Q2 Predictions Mean              0.940251
trainer/Q2 Predictions Std               0.0211328
trainer/Q2 Predictions Max               1.00198
trainer/Q2 Predictions Min               0.918536
trainer/Q Targets Mean                   0.941645
trainer/Q Targets Std                    0.0209012
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.920708
trainer/Log Pis Mean                     2.89949
trainer/Log Pis Std                      2.00781
trainer/Log Pis Max                      8.06344
trainer/Log Pis Min                     -5.10271
trainer/policy/mean Mean                 0.11828
trainer/policy/mean Std                  0.71848
trainer/policy/mean Max                  0.994563
trainer/policy/mean Min                 -0.993215
trainer/policy/normal/std Mean           0.622303
trainer/policy/normal/std Std            0.216099
trainer/policy/normal/std Max            1.12862
trainer/policy/normal/std Min            0.105123
trainer/policy/normal/log_std Mean      -0.549105
trainer/policy/normal/log_std Std        0.419172
trainer/policy/normal/log_std Max        0.120996
trainer/policy/normal/log_std Min       -2.25262
trainer/Alpha                            0.000228548
trainer/Alpha Loss                      -0.842655
expl/num steps total                155000
expl/num paths total                  7784
expl/path length Mean                    4
expl/path length Std                     1.75955
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996
expl/Returns Std                         0.0631189
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0273443
expl/Actions Std                         0.759103
expl/Actions Max                         0.999548
expl/Actions Min                        -0.999411
expl/Num Paths                         250
expl/Average Returns                     0.996
eval/num steps total                763071
eval/num paths total                 38926
eval/path length Mean                    3.97693
eval/path length Std                     1.69757
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25145
eval/Rewards Std                         0.433847
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0140874
eval/Actions Std                         0.677927
eval/Actions Max                         0.994725
eval/Actions Min                        -0.995451
eval/Num Paths                        1257
eval/Average Returns                     1
time/data storing (s)                    0.0038103
time/evaluation sampling (s)             0.957347
time/exploration sampling (s)            0.330291
time/logging (s)                         0.0182097
time/sac training (s)                   11.6162
time/saving (s)                          0.00469726
time/training (s)                        2.647e-05
time/epoch (s)                          12.9305
time/total (s)                        2032.72
Epoch                                  153
----------------------------------  ----------------
2022-09-09 20:26:57.240400 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 154 finished
----------------------------------  ----------------
epoch                                  154
replay_buffer/size                  156000
trainer/num train calls             155000
trainer/QF1 Loss                         3.18172e-06
trainer/QF2 Loss                         1.55511e-06
trainer/Policy Loss                     -0.949194
trainer/Q1 Predictions Mean              0.941537
trainer/Q1 Predictions Std               0.0221701
trainer/Q1 Predictions Max               1.00048
trainer/Q1 Predictions Min               0.918468
trainer/Q2 Predictions Mean              0.942391
trainer/Q2 Predictions Std               0.0221949
trainer/Q2 Predictions Max               1.00246
trainer/Q2 Predictions Min               0.919986
trainer/Q Targets Mean                   0.942957
trainer/Q Targets Std                    0.0220028
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.920769
trainer/Log Pis Mean                     2.78365
trainer/Log Pis Std                      1.83536
trainer/Log Pis Max                      7.87368
trainer/Log Pis Min                     -4.83742
trainer/policy/mean Mean                 0.136431
trainer/policy/mean Std                  0.702752
trainer/policy/mean Max                  0.993897
trainer/policy/mean Min                 -0.994597
trainer/policy/normal/std Mean           0.625222
trainer/policy/normal/std Std            0.23357
trainer/policy/normal/std Max            1.2088
trainer/policy/normal/std Min            0.122334
trainer/policy/normal/log_std Mean      -0.555205
trainer/policy/normal/log_std Std        0.444905
trainer/policy/normal/log_std Max        0.18963
trainer/policy/normal/log_std Min       -2.101
trainer/Alpha                            0.000226545
trainer/Alpha Loss                      -1.81569
expl/num steps total                156000
expl/num paths total                  8031
expl/path length Mean                    4.04858
expl/path length Std                     1.73721
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.246
expl/Rewards Std                         0.430679
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995951
expl/Returns Std                         0.0634995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0260797
expl/Actions Std                         0.762128
expl/Actions Max                         0.999499
expl/Actions Min                        -0.999713
expl/Num Paths                         247
expl/Average Returns                     0.995951
eval/num steps total                768067
eval/num paths total                 40192
eval/path length Mean                    3.94629
eval/path length Std                     1.71656
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253403
eval/Rewards Std                         0.43496
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0167608
eval/Actions Std                         0.679388
eval/Actions Max                         0.994952
eval/Actions Min                        -0.996154
eval/Num Paths                        1266
eval/Average Returns                     1
time/data storing (s)                    0.00392859
time/evaluation sampling (s)             0.956238
time/exploration sampling (s)            0.329243
time/logging (s)                         0.0188008
time/sac training (s)                   11.3549
time/saving (s)                          0.00350554
time/training (s)                        1.904e-05
time/epoch (s)                          12.6666
time/total (s)                        2045.64
Epoch                                  154
----------------------------------  ----------------
2022-09-09 20:27:10.181202 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 155 finished
----------------------------------  ----------------
epoch                                  155
replay_buffer/size                  157000
trainer/num train calls             156000
trainer/QF1 Loss                         5.12375e-06
trainer/QF2 Loss                         2.58366e-06
trainer/Policy Loss                     -0.949869
trainer/Q1 Predictions Mean              0.94224
trainer/Q1 Predictions Std               0.0223946
trainer/Q1 Predictions Max               0.999861
trainer/Q1 Predictions Min               0.919498
trainer/Q2 Predictions Mean              0.945253
trainer/Q2 Predictions Std               0.0223827
trainer/Q2 Predictions Max               1.00332
trainer/Q2 Predictions Min               0.922726
trainer/Q Targets Mean                   0.944255
trainer/Q Targets Std                    0.0222584
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.920901
trainer/Log Pis Mean                     2.8418
trainer/Log Pis Std                      1.93939
trainer/Log Pis Max                      8.28754
trainer/Log Pis Min                     -7.30627
trainer/policy/mean Mean                 0.0517774
trainer/policy/mean Std                  0.705996
trainer/policy/mean Max                  0.994598
trainer/policy/mean Min                 -0.995662
trainer/policy/normal/std Mean           0.610542
trainer/policy/normal/std Std            0.246888
trainer/policy/normal/std Max            1.46303
trainer/policy/normal/std Min            0.0859494
trainer/policy/normal/log_std Mean      -0.592809
trainer/policy/normal/log_std Std        0.482102
trainer/policy/normal/log_std Max        0.380507
trainer/policy/normal/log_std Min       -2.454
trainer/Alpha                            0.000216783
trainer/Alpha Loss                      -1.33468
expl/num steps total                157000
expl/num paths total                  8276
expl/path length Mean                    4.08163
expl/path length Std                     1.67133
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.244
expl/Rewards Std                         0.429493
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995918
expl/Returns Std                         0.0637571
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0123116
expl/Actions Std                         0.76515
expl/Actions Max                         0.999542
expl/Actions Min                        -0.999281
expl/Num Paths                         245
expl/Average Returns                     0.995918
eval/num steps total                773064
eval/num paths total                 41426
eval/path length Mean                    4.04943
eval/path length Std                     1.70232
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.246948
eval/Rewards Std                         0.431236
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00709406
eval/Actions Std                         0.685355
eval/Actions Max                         0.994831
eval/Actions Min                        -0.99517
eval/Num Paths                        1234
eval/Average Returns                     1
time/data storing (s)                    0.00619706
time/evaluation sampling (s)             0.95779
time/exploration sampling (s)            0.308816
time/logging (s)                         0.0190282
time/sac training (s)                   11.3797
time/saving (s)                          0.00332605
time/training (s)                        1.905e-05
time/epoch (s)                          12.6748
time/total (s)                        2058.57
Epoch                                  155
----------------------------------  ----------------
2022-09-09 20:27:23.120014 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 156 finished
----------------------------------  ----------------
epoch                                  156
replay_buffer/size                  158000
trainer/num train calls             157000
trainer/QF1 Loss                         1.89821e-06
trainer/QF2 Loss                         2.1728e-06
trainer/Policy Loss                     -0.951583
trainer/Q1 Predictions Mean              0.944304
trainer/Q1 Predictions Std               0.023752
trainer/Q1 Predictions Max               1.00115
trainer/Q1 Predictions Min               0.919288
trainer/Q2 Predictions Mean              0.944676
trainer/Q2 Predictions Std               0.0240064
trainer/Q2 Predictions Max               1.00292
trainer/Q2 Predictions Min               0.919008
trainer/Q Targets Mean                   0.945028
trainer/Q Targets Std                    0.0238107
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.921037
trainer/Log Pis Mean                     3.00453
trainer/Log Pis Std                      1.73934
trainer/Log Pis Max                      8.70746
trainer/Log Pis Min                     -3.70056
trainer/policy/mean Mean                 0.0816868
trainer/policy/mean Std                  0.717747
trainer/policy/mean Max                  0.993153
trainer/policy/mean Min                 -0.992459
trainer/policy/normal/std Mean           0.617085
trainer/policy/normal/std Std            0.239308
trainer/policy/normal/std Max            1.50193
trainer/policy/normal/std Min            0.0940912
trainer/policy/normal/log_std Mean      -0.576068
trainer/policy/normal/log_std Std        0.467206
trainer/policy/normal/log_std Max        0.406752
trainer/policy/normal/log_std Min       -2.36349
trainer/Alpha                            0.00022383
trainer/Alpha Loss                       0.0380951
expl/num steps total                158000
expl/num paths total                  8518
expl/path length Mean                    4.13223
expl/path length Std                     1.78581
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.241
expl/Rewards Std                         0.42769
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995868
expl/Returns Std                         0.0641495
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0262242
expl/Actions Std                         0.750932
expl/Actions Max                         0.999297
expl/Actions Min                        -0.999291
expl/Num Paths                         242
expl/Average Returns                     0.995868
eval/num steps total                778060
eval/num paths total                 42677
eval/path length Mean                    3.99361
eval/path length Std                     1.72904
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2504
eval/Rewards Std                         0.433244
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00609977
eval/Actions Std                         0.683547
eval/Actions Max                         0.996129
eval/Actions Min                        -0.993901
eval/Num Paths                        1251
eval/Average Returns                     1
time/data storing (s)                    0.00614787
time/evaluation sampling (s)             0.954222
time/exploration sampling (s)            0.361377
time/logging (s)                         0.0192991
time/sac training (s)                   11.3303
time/saving (s)                          0.00461361
time/training (s)                        2.871e-05
time/epoch (s)                          12.676
time/total (s)                        2071.5
Epoch                                  156
----------------------------------  ----------------
2022-09-09 20:27:36.067410 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 157 finished
----------------------------------  ----------------
epoch                                  157
replay_buffer/size                  159000
trainer/num train calls             158000
trainer/QF1 Loss                         1.13716e-06
trainer/QF2 Loss                         8.27532e-06
trainer/Policy Loss                     -0.947721
trainer/Q1 Predictions Mean              0.942397
trainer/Q1 Predictions Std               0.0208993
trainer/Q1 Predictions Max               1.00255
trainer/Q1 Predictions Min               0.921591
trainer/Q2 Predictions Mean              0.940133
trainer/Q2 Predictions Std               0.0204662
trainer/Q2 Predictions Max               0.999265
trainer/Q2 Predictions Min               0.920162
trainer/Q Targets Mean                   0.942414
trainer/Q Targets Std                    0.0207715
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.921209
trainer/Log Pis Mean                     2.9768
trainer/Log Pis Std                      1.96343
trainer/Log Pis Max                      7.97086
trainer/Log Pis Min                     -4.24467
trainer/policy/mean Mean                 0.0286749
trainer/policy/mean Std                  0.735049
trainer/policy/mean Max                  0.992514
trainer/policy/mean Min                 -0.994181
trainer/policy/normal/std Mean           0.634951
trainer/policy/normal/std Std            0.224951
trainer/policy/normal/std Max            1.35126
trainer/policy/normal/std Min            0.128355
trainer/policy/normal/log_std Mean      -0.523745
trainer/policy/normal/log_std Std        0.389643
trainer/policy/normal/log_std Max        0.301036
trainer/policy/normal/log_std Min       -2.05295
trainer/Alpha                            0.00022286
trainer/Alpha Loss                      -0.195061
expl/num steps total                159000
expl/num paths total                  8774
expl/path length Mean                    3.90625
expl/path length Std                     1.67209
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.256
expl/Rewards Std                         0.436422
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0101919
expl/Actions Std                         0.748981
expl/Actions Max                         0.999513
expl/Actions Min                        -0.999404
expl/Num Paths                         256
expl/Average Returns                     1
eval/num steps total                783060
eval/num paths total                 43954
eval/path length Mean                    3.91543
eval/path length Std                     1.71293
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2554
eval/Rewards Std                         0.436086
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00277985
eval/Actions Std                         0.678654
eval/Actions Max                         0.994158
eval/Actions Min                        -0.993876
eval/Num Paths                        1277
eval/Average Returns                     1
time/data storing (s)                    0.0038075
time/evaluation sampling (s)             0.957992
time/exploration sampling (s)            0.314035
time/logging (s)                         0.0192491
time/sac training (s)                   11.3834
time/saving (s)                          0.00466838
time/training (s)                        2.555e-05
time/epoch (s)                          12.6832
time/total (s)                        2084.44
Epoch                                  157
----------------------------------  ----------------
2022-09-09 20:27:48.972348 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 158 finished
----------------------------------  ----------------
epoch                                  158
replay_buffer/size                  160000
trainer/num train calls             159000
trainer/QF1 Loss                         1.06577e-06
trainer/QF2 Loss                         5.67963e-06
trainer/Policy Loss                     -0.950427
trainer/Q1 Predictions Mean              0.944314
trainer/Q1 Predictions Std               0.0233948
trainer/Q1 Predictions Max               1.00149
trainer/Q1 Predictions Min               0.921183
trainer/Q2 Predictions Mean              0.943167
trainer/Q2 Predictions Std               0.0235359
trainer/Q2 Predictions Max               1.00146
trainer/Q2 Predictions Min               0.920501
trainer/Q Targets Mean                   0.944792
trainer/Q Targets Std                    0.0232776
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.921112
trainer/Log Pis Mean                     2.99351
trainer/Log Pis Std                      1.80071
trainer/Log Pis Max                      8.93409
trainer/Log Pis Min                     -3.47387
trainer/policy/mean Mean                 0.0654892
trainer/policy/mean Std                  0.722645
trainer/policy/mean Max                  0.994265
trainer/policy/mean Min                 -0.993201
trainer/policy/normal/std Mean           0.6133
trainer/policy/normal/std Std            0.223931
trainer/policy/normal/std Max            1.32118
trainer/policy/normal/std Min            0.142127
trainer/policy/normal/log_std Mean      -0.564478
trainer/policy/normal/log_std Std        0.407945
trainer/policy/normal/log_std Max        0.278529
trainer/policy/normal/log_std Min       -1.95103
trainer/Alpha                            0.000220596
trainer/Alpha Loss                      -0.0546446
expl/num steps total                160000
expl/num paths total                  9023
expl/path length Mean                    4.01606
expl/path length Std                     1.80354
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.248
expl/Rewards Std                         0.431852
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995984
expl/Returns Std                         0.063245
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00358285
expl/Actions Std                         0.757425
expl/Actions Max                         0.999577
expl/Actions Min                        -0.999166
expl/Num Paths                         249
expl/Average Returns                     0.995984
eval/num steps total                788060
eval/num paths total                 45206
eval/path length Mean                    3.99361
eval/path length Std                     1.69003
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2504
eval/Rewards Std                         0.433243
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0120082
eval/Actions Std                         0.683194
eval/Actions Max                         0.995002
eval/Actions Min                        -0.994276
eval/Num Paths                        1252
eval/Average Returns                     1
time/data storing (s)                    0.00388888
time/evaluation sampling (s)             0.955397
time/exploration sampling (s)            0.312379
time/logging (s)                         0.0175551
time/sac training (s)                   11.3418
time/saving (s)                          0.00468801
time/training (s)                        3.041e-05
time/epoch (s)                          12.6357
time/total (s)                        2097.33
Epoch                                  158
----------------------------------  ----------------
2022-09-09 20:28:02.099457 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 159 finished
----------------------------------  ----------------
epoch                                  159
replay_buffer/size                  161000
trainer/num train calls             160000
trainer/QF1 Loss                         7.03868e-07
trainer/QF2 Loss                         3.10934e-06
trainer/Policy Loss                     -0.950843
trainer/Q1 Predictions Mean              0.944482
trainer/Q1 Predictions Std               0.0208256
trainer/Q1 Predictions Max               1.00112
trainer/Q1 Predictions Min               0.922042
trainer/Q2 Predictions Mean              0.943303
trainer/Q2 Predictions Std               0.0210771
trainer/Q2 Predictions Max               1.00198
trainer/Q2 Predictions Min               0.917484
trainer/Q Targets Mean                   0.944129
trainer/Q Targets Std                    0.0207352
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.921977
trainer/Log Pis Mean                     2.82139
trainer/Log Pis Std                      1.97465
trainer/Log Pis Max                      9.0574
trainer/Log Pis Min                     -4.72588
trainer/policy/mean Mean                 0.0428411
trainer/policy/mean Std                  0.715387
trainer/policy/mean Max                  0.994734
trainer/policy/mean Min                 -0.992916
trainer/policy/normal/std Mean           0.635097
trainer/policy/normal/std Std            0.221109
trainer/policy/normal/std Max            1.35834
trainer/policy/normal/std Min            0.132834
trainer/policy/normal/log_std Mean      -0.524724
trainer/policy/normal/log_std Std        0.398091
trainer/policy/normal/log_std Max        0.306267
trainer/policy/normal/log_std Min       -2.01866
trainer/Alpha                            0.000214947
trainer/Alpha Loss                      -1.5084
expl/num steps total                161000
expl/num paths total                  9283
expl/path length Mean                    3.84615
expl/path length Std                     1.69371
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.259
expl/Rewards Std                         0.438086
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996154
expl/Returns Std                         0.061898
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0142176
expl/Actions Std                         0.763536
expl/Actions Max                         0.999276
expl/Actions Min                        -0.999857
expl/Num Paths                         260
expl/Average Returns                     0.996154
eval/num steps total                793058
eval/num paths total                 46463
eval/path length Mean                    3.97613
eval/path length Std                     1.66419
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251501
eval/Rewards Std                         0.433876
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0290641
eval/Actions Std                         0.684665
eval/Actions Max                         0.994928
eval/Actions Min                        -0.994878
eval/Num Paths                        1257
eval/Average Returns                     1
time/data storing (s)                    0.00395363
time/evaluation sampling (s)             0.966141
time/exploration sampling (s)            0.307624
time/logging (s)                         0.0181785
time/sac training (s)                   11.5518
time/saving (s)                          0.00357169
time/training (s)                        1.881e-05
time/epoch (s)                          12.8513
time/total (s)                        2110.45
Epoch                                  159
----------------------------------  ----------------
2022-09-09 20:28:15.104471 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 160 finished
----------------------------------  ----------------
epoch                                  160
replay_buffer/size                  162000
trainer/num train calls             161000
trainer/QF1 Loss                         1.24274e-06
trainer/QF2 Loss                         4.12685e-06
trainer/Policy Loss                     -0.951969
trainer/Q1 Predictions Mean              0.944563
trainer/Q1 Predictions Std               0.0206047
trainer/Q1 Predictions Max               1.00064
trainer/Q1 Predictions Min               0.921169
trainer/Q2 Predictions Mean              0.945229
trainer/Q2 Predictions Std               0.0205697
trainer/Q2 Predictions Max               1.00189
trainer/Q2 Predictions Min               0.923188
trainer/Q Targets Mean                   0.943843
trainer/Q Targets Std                    0.0209451
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.920738
trainer/Log Pis Mean                     3.07557
trainer/Log Pis Std                      2.08673
trainer/Log Pis Max                      9.25451
trainer/Log Pis Min                     -5.01216
trainer/policy/mean Mean                 0.0787924
trainer/policy/mean Std                  0.715805
trainer/policy/mean Max                  0.996174
trainer/policy/mean Min                 -0.995481
trainer/policy/normal/std Mean           0.615592
trainer/policy/normal/std Std            0.225768
trainer/policy/normal/std Max            1.13378
trainer/policy/normal/std Min            0.131473
trainer/policy/normal/log_std Mean      -0.563331
trainer/policy/normal/log_std Std        0.416935
trainer/policy/normal/log_std Max        0.125559
trainer/policy/normal/log_std Min       -2.02895
trainer/Alpha                            0.000212069
trainer/Alpha Loss                       0.639203
expl/num steps total                162000
expl/num paths total                  9534
expl/path length Mean                    3.98406
expl/path length Std                     1.76727
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.25
expl/Rewards Std                         0.433013
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996016
expl/Returns Std                         0.0629936
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0132989
expl/Actions Std                         0.759249
expl/Actions Max                         0.999559
expl/Actions Min                        -0.999687
expl/Num Paths                         251
expl/Average Returns                     0.996016
eval/num steps total                798053
eval/num paths total                 47735
eval/path length Mean                    3.92689
eval/path length Std                     1.71017
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254655
eval/Rewards Std                         0.435667
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00304794
eval/Actions Std                         0.678304
eval/Actions Max                         0.995588
eval/Actions Min                        -0.995678
eval/Num Paths                        1272
eval/Average Returns                     1
time/data storing (s)                    0.00620639
time/evaluation sampling (s)             0.997709
time/exploration sampling (s)            0.336807
time/logging (s)                         0.0178227
time/sac training (s)                   11.3767
time/saving (s)                          0.00340986
time/training (s)                        2.249e-05
time/epoch (s)                          12.7386
time/total (s)                        2123.44
Epoch                                  160
----------------------------------  ----------------
2022-09-09 20:28:28.149375 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 161 finished
----------------------------------  ----------------
epoch                                  161
replay_buffer/size                  163000
trainer/num train calls             162000
trainer/QF1 Loss                         6.00864e-07
trainer/QF2 Loss                         2.27477e-06
trainer/Policy Loss                     -0.951358
trainer/Q1 Predictions Mean              0.944412
trainer/Q1 Predictions Std               0.0220595
trainer/Q1 Predictions Max               1.00131
trainer/Q1 Predictions Min               0.922222
trainer/Q2 Predictions Mean              0.94518
trainer/Q2 Predictions Std               0.0219098
trainer/Q2 Predictions Max               1.00534
trainer/Q2 Predictions Min               0.92408
trainer/Q Targets Mean                   0.944157
trainer/Q Targets Std                    0.0221189
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.921625
trainer/Log Pis Mean                     3.16082
trainer/Log Pis Std                      1.73178
trainer/Log Pis Max                      8.0405
trainer/Log Pis Min                     -1.46236
trainer/policy/mean Mean                 0.0709674
trainer/policy/mean Std                  0.723354
trainer/policy/mean Max                  0.992907
trainer/policy/mean Min                 -0.993766
trainer/policy/normal/std Mean           0.619817
trainer/policy/normal/std Std            0.214037
trainer/policy/normal/std Max            1.28504
trainer/policy/normal/std Min            0.110598
trainer/policy/normal/log_std Mean      -0.551895
trainer/policy/normal/log_std Std        0.413193
trainer/policy/normal/log_std Max        0.250793
trainer/policy/normal/log_std Min       -2.20186
trainer/Alpha                            0.000209148
trainer/Alpha Loss                       1.36252
expl/num steps total                163000
expl/num paths total                  9791
expl/path length Mean                    3.89105
expl/path length Std                     1.68646
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.256
expl/Rewards Std                         0.436422
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996109
expl/Returns Std                         0.0622568
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0744783
expl/Actions Std                         0.74955
expl/Actions Max                         0.999562
expl/Actions Min                        -0.999479
expl/Num Paths                         257
expl/Average Returns                     0.996109
eval/num steps total                803050
eval/num paths total                 48990
eval/path length Mean                    3.98167
eval/path length Std                     1.71206
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251151
eval/Rewards Std                         0.433675
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0204916
eval/Actions Std                         0.673895
eval/Actions Max                         0.995069
eval/Actions Min                        -0.994686
eval/Num Paths                        1255
eval/Average Returns                     1
time/data storing (s)                    0.00393481
time/evaluation sampling (s)             0.956993
time/exploration sampling (s)            0.337104
time/logging (s)                         0.0201173
time/sac training (s)                   11.4523
time/saving (s)                          0.0046507
time/training (s)                        2.454e-05
time/epoch (s)                          12.7751
time/total (s)                        2136.48
Epoch                                  161
----------------------------------  ----------------
2022-09-09 20:28:41.106060 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 162 finished
----------------------------------  ----------------
epoch                                  162
replay_buffer/size                  164000
trainer/num train calls             163000
trainer/QF1 Loss                         9.33277e-07
trainer/QF2 Loss                         7.25981e-06
trainer/Policy Loss                     -0.950085
trainer/Q1 Predictions Mean              0.944458
trainer/Q1 Predictions Std               0.0220363
trainer/Q1 Predictions Max               1.0017
trainer/Q1 Predictions Min               0.921018
trainer/Q2 Predictions Mean              0.942472
trainer/Q2 Predictions Std               0.0223962
trainer/Q2 Predictions Max               0.998697
trainer/Q2 Predictions Min               0.917172
trainer/Q Targets Mean                   0.944793
trainer/Q Targets Std                    0.0221551
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.921567
trainer/Log Pis Mean                     2.88668
trainer/Log Pis Std                      1.87874
trainer/Log Pis Max                      8.20466
trainer/Log Pis Min                     -3.50177
trainer/policy/mean Mean                 0.0445325
trainer/policy/mean Std                  0.715192
trainer/policy/mean Max                  0.994062
trainer/policy/mean Min                 -0.991613
trainer/policy/normal/std Mean           0.609631
trainer/policy/normal/std Std            0.227403
trainer/policy/normal/std Max            1.15364
trainer/policy/normal/std Min            0.122374
trainer/policy/normal/log_std Mean      -0.578072
trainer/policy/normal/log_std Std        0.433757
trainer/policy/normal/log_std Max        0.142923
trainer/policy/normal/log_std Min       -2.10067
trainer/Alpha                            0.000207864
trainer/Alpha Loss                      -0.960821
expl/num steps total                164000
expl/num paths total                 10037
expl/path length Mean                    4.06504
expl/path length Std                     1.66865
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.245
expl/Rewards Std                         0.430087
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995935
expl/Returns Std                         0.063628
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00563552
expl/Actions Std                         0.747164
expl/Actions Max                         0.999805
expl/Actions Min                        -0.999258
expl/Num Paths                         246
expl/Average Returns                     0.995935
eval/num steps total                808047
eval/num paths total                 50236
eval/path length Mean                    4.01043
eval/path length Std                     1.68814
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.24935
eval/Rewards Std                         0.432637
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00129121
eval/Actions Std                         0.677027
eval/Actions Max                         0.993857
eval/Actions Min                        -0.994734
eval/Num Paths                        1246
eval/Average Returns                     1
time/data storing (s)                    0.00390176
time/evaluation sampling (s)             0.956337
time/exploration sampling (s)            0.296499
time/logging (s)                         0.0175979
time/sac training (s)                   11.4109
time/saving (s)                          0.00377141
time/training (s)                        1.913e-05
time/epoch (s)                          12.689
time/total (s)                        2149.43
Epoch                                  162
----------------------------------  ----------------
2022-09-09 20:28:54.078453 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 163 finished
----------------------------------  ----------------
epoch                                  163
replay_buffer/size                  165000
trainer/num train calls             164000
trainer/QF1 Loss                         7.36667e-07
trainer/QF2 Loss                         3.96665e-06
trainer/Policy Loss                     -0.952239
trainer/Q1 Predictions Mean              0.945109
trainer/Q1 Predictions Std               0.0219454
trainer/Q1 Predictions Max               1.00027
trainer/Q1 Predictions Min               0.923325
trainer/Q2 Predictions Mean              0.946204
trainer/Q2 Predictions Std               0.0216513
trainer/Q2 Predictions Max               1.00363
trainer/Q2 Predictions Min               0.923752
trainer/Q Targets Mean                   0.944958
trainer/Q Targets Std                    0.0222656
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.922531
trainer/Log Pis Mean                     2.82292
trainer/Log Pis Std                      1.9829
trainer/Log Pis Max                      8.41134
trainer/Log Pis Min                     -4.33216
trainer/policy/mean Mean                 0.0465658
trainer/policy/mean Std                  0.713264
trainer/policy/mean Max                  0.993826
trainer/policy/mean Min                 -0.993264
trainer/policy/normal/std Mean           0.582242
trainer/policy/normal/std Std            0.193377
trainer/policy/normal/std Max            1.16162
trainer/policy/normal/std Min            0.147982
trainer/policy/normal/log_std Mean      -0.604889
trainer/policy/normal/log_std Std        0.377148
trainer/policy/normal/log_std Max        0.14982
trainer/policy/normal/log_std Min       -1.91066
trainer/Alpha                            0.000202938
trainer/Alpha Loss                      -1.50562
expl/num steps total                165000
expl/num paths total                 10280
expl/path length Mean                    4.11523
expl/path length Std                     1.63145
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.242
expl/Rewards Std                         0.428294
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995885
expl/Returns Std                         0.0640179
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0363275
expl/Actions Std                         0.749699
expl/Actions Max                         0.999345
expl/Actions Min                        -0.999581
expl/Num Paths                         243
expl/Average Returns                     0.995885
eval/num steps total                813047
eval/num paths total                 51510
eval/path length Mean                    3.92465
eval/path length Std                     1.68304
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2548
eval/Rewards Std                         0.435749
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00950143
eval/Actions Std                         0.674452
eval/Actions Max                         0.994955
eval/Actions Min                        -0.994631
eval/Num Paths                        1274
eval/Average Returns                     1
time/data storing (s)                    0.003849
time/evaluation sampling (s)             0.986311
time/exploration sampling (s)            0.350053
time/logging (s)                         0.0184184
time/sac training (s)                   11.3415
time/saving (s)                          0.00469048
time/training (s)                        2.472e-05
time/epoch (s)                          12.7049
time/total (s)                        2162.39
Epoch                                  163
----------------------------------  ----------------
2022-09-09 20:29:06.945735 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 164 finished
----------------------------------  ----------------
epoch                                  164
replay_buffer/size                  166000
trainer/num train calls             165000
trainer/QF1 Loss                         9.45288e-07
trainer/QF2 Loss                         2.97406e-06
trainer/Policy Loss                     -0.95148
trainer/Q1 Predictions Mean              0.943645
trainer/Q1 Predictions Std               0.0221297
trainer/Q1 Predictions Max               0.999991
trainer/Q1 Predictions Min               0.922031
trainer/Q2 Predictions Mean              0.944974
trainer/Q2 Predictions Std               0.0222497
trainer/Q2 Predictions Max               1.00335
trainer/Q2 Predictions Min               0.923816
trainer/Q Targets Mean                   0.943715
trainer/Q Targets Std                    0.0220401
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.922152
trainer/Log Pis Mean                     2.81364
trainer/Log Pis Std                      1.82386
trainer/Log Pis Max                      9.30782
trainer/Log Pis Min                     -2.68182
trainer/policy/mean Mean                 0.0926265
trainer/policy/mean Std                  0.711081
trainer/policy/mean Max                  0.994362
trainer/policy/mean Min                 -0.995765
trainer/policy/normal/std Mean           0.644711
trainer/policy/normal/std Std            0.221975
trainer/policy/normal/std Max            1.20369
trainer/policy/normal/std Min            0.138858
trainer/policy/normal/log_std Mean      -0.51058
trainer/policy/normal/log_std Std        0.40337
trainer/policy/normal/log_std Max        0.185393
trainer/policy/normal/log_std Min       -1.9743
trainer/Alpha                            0.000198024
trainer/Alpha Loss                      -1.58913
expl/num steps total                166000
expl/num paths total                 10524
expl/path length Mean                    4.09836
expl/path length Std                     1.60639
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.243
expl/Rewards Std                         0.428895
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995902
expl/Returns Std                         0.0638871
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00363717
expl/Actions Std                         0.756621
expl/Actions Max                         0.999643
expl/Actions Min                        -0.999047
expl/Num Paths                         244
expl/Average Returns                     0.995902
eval/num steps total                818043
eval/num paths total                 52775
eval/path length Mean                    3.94941
eval/path length Std                     1.68574
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253203
eval/Rewards Std                         0.434846
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00126552
eval/Actions Std                         0.679777
eval/Actions Max                         0.996378
eval/Actions Min                        -0.994998
eval/Num Paths                        1265
eval/Average Returns                     1
time/data storing (s)                    0.00387039
time/evaluation sampling (s)             0.953639
time/exploration sampling (s)            0.29715
time/logging (s)                         0.0204278
time/sac training (s)                   11.3246
time/saving (s)                          0.0038408
time/training (s)                        0.00022509
time/epoch (s)                          12.6037
time/total (s)                        2175.25
Epoch                                  164
----------------------------------  ----------------
2022-09-09 20:29:20.357263 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 165 finished
----------------------------------  ----------------
epoch                                  165
replay_buffer/size                  167000
trainer/num train calls             166000
trainer/QF1 Loss                         1.60047e-06
trainer/QF2 Loss                         7.53147e-06
trainer/Policy Loss                     -0.953442
trainer/Q1 Predictions Mean              0.94644
trainer/Q1 Predictions Std               0.0227876
trainer/Q1 Predictions Max               1.00012
trainer/Q1 Predictions Min               0.922561
trainer/Q2 Predictions Mean              0.949566
trainer/Q2 Predictions Std               0.022651
trainer/Q2 Predictions Max               1.0049
trainer/Q2 Predictions Min               0.925433
trainer/Q Targets Mean                   0.94731
trainer/Q Targets Std                    0.0227862
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.923615
trainer/Log Pis Mean                     2.69721
trainer/Log Pis Std                      1.73608
trainer/Log Pis Max                      8.79619
trainer/Log Pis Min                     -2.86642
trainer/policy/mean Mean                 0.0891212
trainer/policy/mean Std                  0.701036
trainer/policy/mean Max                  0.993398
trainer/policy/mean Min                 -0.992113
trainer/policy/normal/std Mean           0.597844
trainer/policy/normal/std Std            0.220042
trainer/policy/normal/std Max            1.21394
trainer/policy/normal/std Min            0.121934
trainer/policy/normal/log_std Mean      -0.594131
trainer/policy/normal/log_std Std        0.422336
trainer/policy/normal/log_std Max        0.193867
trainer/policy/normal/log_std Min       -2.10427
trainer/Alpha                            0.000201829
trainer/Alpha Loss                      -2.57616
expl/num steps total                167000
expl/num paths total                 10782
expl/path length Mean                    3.87597
expl/path length Std                     1.78281
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.257
expl/Rewards Std                         0.436979
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996124
expl/Returns Std                         0.0621365
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0074209
expl/Actions Std                         0.763362
expl/Actions Max                         0.999133
expl/Actions Min                        -0.999432
expl/Num Paths                         258
expl/Average Returns                     0.996124
eval/num steps total                823042
eval/num paths total                 54027
eval/path length Mean                    3.99281
eval/path length Std                     1.67364
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25045
eval/Rewards Std                         0.433272
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0326833
eval/Actions Std                         0.675188
eval/Actions Max                         0.994879
eval/Actions Min                        -0.994845
eval/Num Paths                        1252
eval/Average Returns                     1
time/data storing (s)                    0.00449274
time/evaluation sampling (s)             0.981788
time/exploration sampling (s)            0.336263
time/logging (s)                         0.0184543
time/sac training (s)                   11.7954
time/saving (s)                          0.00340774
time/training (s)                        1.941e-05
time/epoch (s)                          13.1398
time/total (s)                        2188.65
Epoch                                  165
----------------------------------  ----------------
2022-09-09 20:29:33.195268 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 166 finished
----------------------------------  ----------------
epoch                                  166
replay_buffer/size                  168000
trainer/num train calls             167000
trainer/QF1 Loss                         1.18857e-06
trainer/QF2 Loss                         3.26194e-06
trainer/Policy Loss                     -0.952587
trainer/Q1 Predictions Mean              0.945777
trainer/Q1 Predictions Std               0.0225037
trainer/Q1 Predictions Max               0.999861
trainer/Q1 Predictions Min               0.92159
trainer/Q2 Predictions Mean              0.947082
trainer/Q2 Predictions Std               0.0224008
trainer/Q2 Predictions Max               1.00268
trainer/Q2 Predictions Min               0.923369
trainer/Q Targets Mean                   0.945895
trainer/Q Targets Std                    0.0225425
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.921835
trainer/Log Pis Mean                     3.0348
trainer/Log Pis Std                      1.71074
trainer/Log Pis Max                      8.20621
trainer/Log Pis Min                     -3.51662
trainer/policy/mean Mean                 0.0528813
trainer/policy/mean Std                  0.720385
trainer/policy/mean Max                  0.99541
trainer/policy/mean Min                 -0.993652
trainer/policy/normal/std Mean           0.61365
trainer/policy/normal/std Std            0.207685
trainer/policy/normal/std Max            1.14651
trainer/policy/normal/std Min            0.139005
trainer/policy/normal/log_std Mean      -0.556017
trainer/policy/normal/log_std Std        0.388881
trainer/policy/normal/log_std Max        0.136725
trainer/policy/normal/log_std Min       -1.97325
trainer/Alpha                            0.000199214
trainer/Alpha Loss                       0.296549
expl/num steps total                168000
expl/num paths total                 11029
expl/path length Mean                    4.04858
expl/path length Std                     1.64872
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.246
expl/Rewards Std                         0.430679
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995951
expl/Returns Std                         0.0634995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0106369
expl/Actions Std                         0.752154
expl/Actions Max                         0.999728
expl/Actions Min                        -0.999623
expl/Num Paths                         247
expl/Average Returns                     0.995951
eval/num steps total                828039
eval/num paths total                 55301
eval/path length Mean                    3.92229
eval/path length Std                     1.70586
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254953
eval/Rewards Std                         0.435835
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0281466
eval/Actions Std                         0.679773
eval/Actions Max                         0.99737
eval/Actions Min                        -0.994098
eval/Num Paths                        1274
eval/Average Returns                     1
time/data storing (s)                    0.00392307
time/evaluation sampling (s)             0.956607
time/exploration sampling (s)            0.289823
time/logging (s)                         0.0179036
time/sac training (s)                   11.3069
time/saving (s)                          0.0033188
time/training (s)                        3.566e-05
time/epoch (s)                          12.5785
time/total (s)                        2201.48
Epoch                                  166
----------------------------------  ----------------
2022-09-09 20:29:46.816702 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 167 finished
----------------------------------  ----------------
epoch                                  167
replay_buffer/size                  169000
trainer/num train calls             168000
trainer/QF1 Loss                         1.97131e-06
trainer/QF2 Loss                         3.49764e-06
trainer/Policy Loss                     -0.955987
trainer/Q1 Predictions Mean              0.949464
trainer/Q1 Predictions Std               0.0244555
trainer/Q1 Predictions Max               1.0019
trainer/Q1 Predictions Min               0.924208
trainer/Q2 Predictions Mean              0.949512
trainer/Q2 Predictions Std               0.0247027
trainer/Q2 Predictions Max               1.00383
trainer/Q2 Predictions Min               0.92388
trainer/Q Targets Mean                   0.948329
trainer/Q Targets Std                    0.0245017
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.921887
trainer/Log Pis Mean                     3.00924
trainer/Log Pis Std                      1.88978
trainer/Log Pis Max                      8.12584
trainer/Log Pis Min                     -2.5862
trainer/policy/mean Mean                 0.0150078
trainer/policy/mean Std                  0.717432
trainer/policy/mean Max                  0.995275
trainer/policy/mean Min                 -0.993325
trainer/policy/normal/std Mean           0.616562
trainer/policy/normal/std Std            0.229166
trainer/policy/normal/std Max            1.33787
trainer/policy/normal/std Min            0.107579
trainer/policy/normal/log_std Mean      -0.564656
trainer/policy/normal/log_std Std        0.428429
trainer/policy/normal/log_std Max        0.29108
trainer/policy/normal/log_std Min       -2.22953
trainer/Alpha                            0.000196746
trainer/Alpha Loss                       0.0788084
expl/num steps total                169000
expl/num paths total                 11289
expl/path length Mean                    3.84615
expl/path length Std                     1.71178
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.259
expl/Rewards Std                         0.438086
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996154
expl/Returns Std                         0.061898
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00834972
expl/Actions Std                         0.754178
expl/Actions Max                         0.999266
expl/Actions Min                        -0.999765
expl/Num Paths                         260
expl/Average Returns                     0.996154
eval/num steps total                833038
eval/num paths total                 56548
eval/path length Mean                    4.00882
eval/path length Std                     1.66739
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.24945
eval/Rewards Std                         0.432695
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0125207
eval/Actions Std                         0.681065
eval/Actions Max                         0.994833
eval/Actions Min                        -0.995308
eval/Num Paths                        1247
eval/Average Returns                     1
time/data storing (s)                    0.00412529
time/evaluation sampling (s)             0.959823
time/exploration sampling (s)            0.318276
time/logging (s)                         0.0267453
time/sac training (s)                   12.0022
time/saving (s)                          0.00364212
time/training (s)                        1.917e-05
time/epoch (s)                          13.3148
time/total (s)                        2215.1
Epoch                                  167
----------------------------------  ----------------
2022-09-09 20:30:01.158998 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 168 finished
----------------------------------  ----------------
epoch                                  168
replay_buffer/size                  170000
trainer/num train calls             169000
trainer/QF1 Loss                         1.02231e-06
trainer/QF2 Loss                         1.46314e-06
trainer/Policy Loss                     -0.952606
trainer/Q1 Predictions Mean              0.945848
trainer/Q1 Predictions Std               0.0226628
trainer/Q1 Predictions Max               1.00043
trainer/Q1 Predictions Min               0.922062
trainer/Q2 Predictions Mean              0.946106
trainer/Q2 Predictions Std               0.0227107
trainer/Q2 Predictions Max               1.00173
trainer/Q2 Predictions Min               0.922412
trainer/Q Targets Mean                   0.946485
trainer/Q Targets Std                    0.0227392
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.922626
trainer/Log Pis Mean                     3.19291
trainer/Log Pis Std                      1.98384
trainer/Log Pis Max                      8.11461
trainer/Log Pis Min                     -3.92767
trainer/policy/mean Mean                 0.0306699
trainer/policy/mean Std                  0.719636
trainer/policy/mean Max                  0.996292
trainer/policy/mean Min                 -0.99453
trainer/policy/normal/std Mean           0.611257
trainer/policy/normal/std Std            0.231632
trainer/policy/normal/std Max            1.31411
trainer/policy/normal/std Min            0.123749
trainer/policy/normal/log_std Mean      -0.573164
trainer/policy/normal/log_std Std        0.421911
trainer/policy/normal/log_std Max        0.273163
trainer/policy/normal/log_std Min       -2.0895
trainer/Alpha                            0.00020067
trainer/Alpha Loss                       1.64241
expl/num steps total                170000
expl/num paths total                 11520
expl/path length Mean                    4.329
expl/path length Std                     1.65798
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.231
expl/Rewards Std                         0.421472
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0224513
expl/Actions Std                         0.752782
expl/Actions Max                         0.999108
expl/Actions Min                        -0.999594
expl/Num Paths                         231
expl/Average Returns                     1
eval/num steps total                838038
eval/num paths total                 57791
eval/path length Mean                    4.02253
eval/path length Std                     1.67499
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2486
eval/Rewards Std                         0.432201
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00191044
eval/Actions Std                         0.67613
eval/Actions Max                         0.996389
eval/Actions Min                        -0.995429
eval/Num Paths                        1243
eval/Average Returns                     1
time/data storing (s)                    0.00396934
time/evaluation sampling (s)             0.988018
time/exploration sampling (s)            0.342153
time/logging (s)                         0.0197489
time/sac training (s)                   12.6292
time/saving (s)                          0.00476595
time/training (s)                        2.58e-05
time/epoch (s)                          13.9879
time/total (s)                        2229.42
Epoch                                  168
----------------------------------  ----------------
2022-09-09 20:30:15.320829 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 169 finished
----------------------------------  ----------------
epoch                                  169
replay_buffer/size                  171000
trainer/num train calls             170000
trainer/QF1 Loss                         1.50736e-06
trainer/QF2 Loss                         1.03074e-05
trainer/Policy Loss                     -0.95022
trainer/Q1 Predictions Mean              0.944508
trainer/Q1 Predictions Std               0.0225647
trainer/Q1 Predictions Max               1.00009
trainer/Q1 Predictions Min               0.922041
trainer/Q2 Predictions Mean              0.94248
trainer/Q2 Predictions Std               0.0232722
trainer/Q2 Predictions Max               1.00084
trainer/Q2 Predictions Min               0.918952
trainer/Q Targets Mean                   0.945351
trainer/Q Targets Std                    0.0227483
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.922381
trainer/Log Pis Mean                     2.74494
trainer/Log Pis Std                      2.01089
trainer/Log Pis Max                      6.61136
trainer/Log Pis Min                     -5.11826
trainer/policy/mean Mean                 0.0257338
trainer/policy/mean Std                  0.71365
trainer/policy/mean Max                  0.992695
trainer/policy/mean Min                 -0.993047
trainer/policy/normal/std Mean           0.622883
trainer/policy/normal/std Std            0.215015
trainer/policy/normal/std Max            1.54372
trainer/policy/normal/std Min            0.13223
trainer/policy/normal/log_std Mean      -0.541516
trainer/policy/normal/log_std Std        0.389294
trainer/policy/normal/log_std Max        0.434195
trainer/policy/normal/log_std Min       -2.02321
trainer/Alpha                            0.000195252
trainer/Alpha Loss                      -2.17855
expl/num steps total                171000
expl/num paths total                 11783
expl/path length Mean                    3.80228
expl/path length Std                     1.7676
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.262
expl/Rewards Std                         0.439723
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996198
expl/Returns Std                         0.0615453
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00181092
expl/Actions Std                         0.75113
expl/Actions Max                         0.999887
expl/Actions Min                        -0.999431
expl/Num Paths                         263
expl/Average Returns                     0.996198
eval/num steps total                843035
eval/num paths total                 59045
eval/path length Mean                    3.98485
eval/path length Std                     1.68933
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.250951
eval/Rewards Std                         0.43356
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0158161
eval/Actions Std                         0.67568
eval/Actions Max                         0.994487
eval/Actions Min                        -0.994119
eval/Num Paths                        1254
eval/Average Returns                     1
time/data storing (s)                    0.006034
time/evaluation sampling (s)             1.02148
time/exploration sampling (s)            0.331151
time/logging (s)                         0.0184674
time/sac training (s)                   12.4484
time/saving (s)                          0.00483536
time/training (s)                        2.884e-05
time/epoch (s)                          13.8304
time/total (s)                        2243.56
Epoch                                  169
----------------------------------  ----------------
2022-09-09 20:30:30.375506 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 170 finished
----------------------------------  ----------------
epoch                                  170
replay_buffer/size                  172000
trainer/num train calls             171000
trainer/QF1 Loss                         4.25665e-06
trainer/QF2 Loss                         1.46525e-06
trainer/Policy Loss                     -0.955687
trainer/Q1 Predictions Mean              0.949798
trainer/Q1 Predictions Std               0.0244593
trainer/Q1 Predictions Max               1.0041
trainer/Q1 Predictions Min               0.924536
trainer/Q2 Predictions Mean              0.948186
trainer/Q2 Predictions Std               0.0246272
trainer/Q2 Predictions Max               1.00197
trainer/Q2 Predictions Min               0.923618
trainer/Q Targets Mean                   0.948051
trainer/Q Targets Std                    0.0244577
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92277
trainer/Log Pis Mean                     3.04157
trainer/Log Pis Std                      1.93271
trainer/Log Pis Max                      7.59731
trainer/Log Pis Min                     -2.19773
trainer/policy/mean Mean                 0.0186445
trainer/policy/mean Std                  0.716522
trainer/policy/mean Max                  0.995753
trainer/policy/mean Min                 -0.995755
trainer/policy/normal/std Mean           0.616422
trainer/policy/normal/std Std            0.222313
trainer/policy/normal/std Max            1.21618
trainer/policy/normal/std Min            0.135387
trainer/policy/normal/log_std Mean      -0.557504
trainer/policy/normal/log_std Std        0.401677
trainer/policy/normal/log_std Max        0.195715
trainer/policy/normal/log_std Min       -1.99962
trainer/Alpha                            0.000191275
trainer/Alpha Loss                       0.355919
expl/num steps total                172000
expl/num paths total                 12036
expl/path length Mean                    3.95257
expl/path length Std                     1.73026
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.252
expl/Rewards Std                         0.434161
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996047
expl/Returns Std                         0.0627451
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0404102
expl/Actions Std                         0.752263
expl/Actions Max                         0.999802
expl/Actions Min                        -0.999539
expl/Num Paths                         253
expl/Average Returns                     0.996047
eval/num steps total                848031
eval/num paths total                 60327
eval/path length Mean                    3.89704
eval/path length Std                     1.67024
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.256605
eval/Rewards Std                         0.43676
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0217995
eval/Actions Std                         0.679459
eval/Actions Max                         0.995405
eval/Actions Min                        -0.996347
eval/Num Paths                        1282
eval/Average Returns                     1
time/data storing (s)                    0.00730844
time/evaluation sampling (s)             1.02963
time/exploration sampling (s)            0.339899
time/logging (s)                         0.0231085
time/sac training (s)                   13.3287
time/saving (s)                          0.00376095
time/training (s)                        1.989e-05
time/epoch (s)                          14.7324
time/total (s)                        2258.61
Epoch                                  170
----------------------------------  ----------------
2022-09-09 20:30:45.957371 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 171 finished
----------------------------------  ----------------
epoch                                  171
replay_buffer/size                  173000
trainer/num train calls             172000
trainer/QF1 Loss                         8.80361e-07
trainer/QF2 Loss                         6.77884e-06
trainer/Policy Loss                     -0.952864
trainer/Q1 Predictions Mean              0.948335
trainer/Q1 Predictions Std               0.0238373
trainer/Q1 Predictions Max               1.00259
trainer/Q1 Predictions Min               0.924061
trainer/Q2 Predictions Mean              0.946355
trainer/Q2 Predictions Std               0.0239758
trainer/Q2 Predictions Max               1.00081
trainer/Q2 Predictions Min               0.921188
trainer/Q Targets Mean                   0.948263
trainer/Q Targets Std                    0.0240318
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.923368
trainer/Log Pis Mean                     3.06701
trainer/Log Pis Std                      1.95983
trainer/Log Pis Max                      8.13537
trainer/Log Pis Min                     -4.71518
trainer/policy/mean Mean                 0.0419848
trainer/policy/mean Std                  0.724825
trainer/policy/mean Max                  0.994648
trainer/policy/mean Min                 -0.995115
trainer/policy/normal/std Mean           0.620006
trainer/policy/normal/std Std            0.200826
trainer/policy/normal/std Max            1.43705
trainer/policy/normal/std Min            0.146083
trainer/policy/normal/log_std Mean      -0.539031
trainer/policy/normal/log_std Std        0.368795
trainer/policy/normal/log_std Max        0.362594
trainer/policy/normal/log_std Min       -1.92358
trainer/Alpha                            0.000196353
trainer/Alpha Loss                       0.571979
expl/num steps total                173000
expl/num paths total                 12302
expl/path length Mean                    3.7594
expl/path length Std                     1.73487
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.265
expl/Rewards Std                         0.441333
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996241
expl/Returns Std                         0.0611986
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0256931
expl/Actions Std                         0.758432
expl/Actions Max                         0.999079
expl/Actions Min                        -0.999372
expl/Num Paths                         266
expl/Average Returns                     0.996241
eval/num steps total                853029
eval/num paths total                 61621
eval/path length Mean                    3.86244
eval/path length Std                     1.68811
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.258904
eval/Rewards Std                         0.438033
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00995223
eval/Actions Std                         0.679191
eval/Actions Max                         0.995866
eval/Actions Min                        -0.995081
eval/Num Paths                        1294
eval/Average Returns                     1
time/data storing (s)                    0.00475115
time/evaluation sampling (s)             1.27005
time/exploration sampling (s)            0.33936
time/logging (s)                         0.0278566
time/sac training (s)                   13.6107
time/saving (s)                          0.0051222
time/training (s)                        2.122e-05
time/epoch (s)                          15.2579
time/total (s)                        2274.18
Epoch                                  171
----------------------------------  ----------------
2022-09-09 20:31:01.369705 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 172 finished
----------------------------------  ----------------
epoch                                  172
replay_buffer/size                  174000
trainer/num train calls             173000
trainer/QF1 Loss                         1.90957e-06
trainer/QF2 Loss                         1.78275e-06
trainer/Policy Loss                     -0.954482
trainer/Q1 Predictions Mean              0.947691
trainer/Q1 Predictions Std               0.0236481
trainer/Q1 Predictions Max               0.999793
trainer/Q1 Predictions Min               0.922205
trainer/Q2 Predictions Mean              0.948237
trainer/Q2 Predictions Std               0.0238066
trainer/Q2 Predictions Max               1.0007
trainer/Q2 Predictions Min               0.922329
trainer/Q Targets Mean                   0.94857
trainer/Q Targets Std                    0.0239354
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.922985
trainer/Log Pis Mean                     2.85331
trainer/Log Pis Std                      2.02027
trainer/Log Pis Max                      8.82098
trainer/Log Pis Min                     -3.2304
trainer/policy/mean Mean                 0.015769
trainer/policy/mean Std                  0.729687
trainer/policy/mean Max                  0.993639
trainer/policy/mean Min                 -0.993937
trainer/policy/normal/std Mean           0.63172
trainer/policy/normal/std Std            0.211318
trainer/policy/normal/std Max            1.30954
trainer/policy/normal/std Min            0.160323
trainer/policy/normal/log_std Mean      -0.521074
trainer/policy/normal/log_std Std        0.365863
trainer/policy/normal/log_std Max        0.269678
trainer/policy/normal/log_std Min       -1.83056
trainer/Alpha                            0.000194543
trainer/Alpha Loss                      -1.2534
expl/num steps total                174000
expl/num paths total                 12549
expl/path length Mean                    4.04858
expl/path length Std                     1.71374
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.246
expl/Rewards Std                         0.430679
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995951
expl/Returns Std                         0.0634995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00471212
expl/Actions Std                         0.764765
expl/Actions Max                         0.999397
expl/Actions Min                        -0.999777
expl/Num Paths                         247
expl/Average Returns                     0.995951
eval/num steps total                858026
eval/num paths total                 62858
eval/path length Mean                    4.03961
eval/path length Std                     1.67946
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.247549
eval/Rewards Std                         0.431588
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00123623
eval/Actions Std                         0.678064
eval/Actions Max                         0.994799
eval/Actions Min                        -0.996199
eval/Num Paths                        1237
eval/Average Returns                     1
time/data storing (s)                    0.00699197
time/evaluation sampling (s)             1.15756
time/exploration sampling (s)            0.447601
time/logging (s)                         0.0185503
time/sac training (s)                   13.4319
time/saving (s)                          0.00471435
time/training (s)                        2.518e-05
time/epoch (s)                          15.0674
time/total (s)                        2289.57
Epoch                                  172
----------------------------------  ----------------
2022-09-09 20:31:15.217471 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 173 finished
----------------------------------  ----------------
epoch                                  173
replay_buffer/size                  175000
trainer/num train calls             174000
trainer/QF1 Loss                         1.58039e-06
trainer/QF2 Loss                         6.51986e-06
trainer/Policy Loss                     -0.955535
trainer/Q1 Predictions Mean              0.94911
trainer/Q1 Predictions Std               0.0226557
trainer/Q1 Predictions Max               1.00192
trainer/Q1 Predictions Min               0.92342
trainer/Q2 Predictions Mean              0.950366
trainer/Q2 Predictions Std               0.0221856
trainer/Q2 Predictions Max               1.00269
trainer/Q2 Predictions Min               0.925846
trainer/Q Targets Mean                   0.948224
trainer/Q Targets Std                    0.0225314
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.922862
trainer/Log Pis Mean                     3.05564
trainer/Log Pis Std                      1.84588
trainer/Log Pis Max                      7.09067
trainer/Log Pis Min                     -4.63181
trainer/policy/mean Mean                 0.0976891
trainer/policy/mean Std                  0.706602
trainer/policy/mean Max                  0.996094
trainer/policy/mean Min                 -0.993849
trainer/policy/normal/std Mean           0.610607
trainer/policy/normal/std Std            0.219146
trainer/policy/normal/std Max            1.08487
trainer/policy/normal/std Min            0.147855
trainer/policy/normal/log_std Mean      -0.566943
trainer/policy/normal/log_std Std        0.402434
trainer/policy/normal/log_std Max        0.0814582
trainer/policy/normal/log_std Min       -1.91152
trainer/Alpha                            0.000189129
trainer/Alpha Loss                       0.47699
expl/num steps total                175000
expl/num paths total                 12808
expl/path length Mean                    3.861
expl/path length Std                     1.70282
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.258
expl/Rewards Std                         0.437534
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996139
expl/Returns Std                         0.0620169
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0413349
expl/Actions Std                         0.746911
expl/Actions Max                         0.999452
expl/Actions Min                        -0.999854
expl/Num Paths                         259
expl/Average Returns                     0.996139
eval/num steps total                863025
eval/num paths total                 64124
eval/path length Mean                    3.94866
eval/path length Std                     1.69183
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253251
eval/Rewards Std                         0.434873
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00140258
eval/Actions Std                         0.676922
eval/Actions Max                         0.995763
eval/Actions Min                        -0.995167
eval/Num Paths                        1266
eval/Average Returns                     1
time/data storing (s)                    0.00636068
time/evaluation sampling (s)             1.35444
time/exploration sampling (s)            0.327227
time/logging (s)                         0.018649
time/sac training (s)                   11.851
time/saving (s)                          0.00334045
time/training (s)                        1.909e-05
time/epoch (s)                          13.5611
time/total (s)                        2303.41
Epoch                                  173
----------------------------------  ----------------
2022-09-09 20:31:28.560779 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 174 finished
----------------------------------  ----------------
epoch                                  174
replay_buffer/size                  176000
trainer/num train calls             175000
trainer/QF1 Loss                         2.93559e-06
trainer/QF2 Loss                         2.41623e-06
trainer/Policy Loss                     -0.952906
trainer/Q1 Predictions Mean              0.946109
trainer/Q1 Predictions Std               0.0224532
trainer/Q1 Predictions Max               0.999699
trainer/Q1 Predictions Min               0.921812
trainer/Q2 Predictions Mean              0.948418
trainer/Q2 Predictions Std               0.0226439
trainer/Q2 Predictions Max               1.00324
trainer/Q2 Predictions Min               0.923558
trainer/Q Targets Mean                   0.947508
trainer/Q Targets Std                    0.0225776
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.923447
trainer/Log Pis Mean                     2.99791
trainer/Log Pis Std                      1.86614
trainer/Log Pis Max                      8.11619
trainer/Log Pis Min                     -4.21457
trainer/policy/mean Mean                 0.046182
trainer/policy/mean Std                  0.716112
trainer/policy/mean Max                  0.994535
trainer/policy/mean Min                 -0.99529
trainer/policy/normal/std Mean           0.612995
trainer/policy/normal/std Std            0.215977
trainer/policy/normal/std Max            1.53651
trainer/policy/normal/std Min            0.123461
trainer/policy/normal/log_std Mean      -0.560009
trainer/policy/normal/log_std Std        0.397566
trainer/policy/normal/log_std Max        0.429513
trainer/policy/normal/log_std Min       -2.09183
trainer/Alpha                            0.000191133
trainer/Alpha Loss                      -0.0178907
expl/num steps total                176000
expl/num paths total                 13044
expl/path length Mean                    4.23729
expl/path length Std                     1.81649
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.235
expl/Rewards Std                         0.423999
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995763
expl/Returns Std                         0.0649564
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0194968
expl/Actions Std                         0.753237
expl/Actions Max                         0.999571
expl/Actions Min                        -0.999409
expl/Num Paths                         236
expl/Average Returns                     0.995763
eval/num steps total                868022
eval/num paths total                 65367
eval/path length Mean                    4.02011
eval/path length Std                     1.69911
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.248749
eval/Rewards Std                         0.432288
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0256785
eval/Actions Std                         0.6765
eval/Actions Max                         0.996103
eval/Actions Min                        -0.994465
eval/Num Paths                        1243
eval/Average Returns                     1
time/data storing (s)                    0.00530541
time/evaluation sampling (s)             0.956275
time/exploration sampling (s)            0.317468
time/logging (s)                         0.0192939
time/sac training (s)                   11.7697
time/saving (s)                          0.00355927
time/training (s)                        2.081e-05
time/epoch (s)                          13.0717
time/total (s)                        2316.75
Epoch                                  174
----------------------------------  ----------------
2022-09-09 20:31:42.991581 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 175 finished
----------------------------------  ----------------
epoch                                  175
replay_buffer/size                  177000
trainer/num train calls             176000
trainer/QF1 Loss                         1.48354e-06
trainer/QF2 Loss                         3.39601e-06
trainer/Policy Loss                     -0.953897
trainer/Q1 Predictions Mean              0.94778
trainer/Q1 Predictions Std               0.0228169
trainer/Q1 Predictions Max               1.00002
trainer/Q1 Predictions Min               0.921655
trainer/Q2 Predictions Mean              0.947199
trainer/Q2 Predictions Std               0.0231645
trainer/Q2 Predictions Max               1.00173
trainer/Q2 Predictions Min               0.920273
trainer/Q Targets Mean                   0.948415
trainer/Q Targets Std                    0.0229461
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92317
trainer/Log Pis Mean                     3.0483
trainer/Log Pis Std                      1.78992
trainer/Log Pis Max                      7.24439
trainer/Log Pis Min                     -3.5003
trainer/policy/mean Mean                 0.042711
trainer/policy/mean Std                  0.714316
trainer/policy/mean Max                  0.995266
trainer/policy/mean Min                 -0.994789
trainer/policy/normal/std Mean           0.612926
trainer/policy/normal/std Std            0.223966
trainer/policy/normal/std Max            1.35215
trainer/policy/normal/std Min            0.128807
trainer/policy/normal/log_std Mean      -0.563613
trainer/policy/normal/log_std Std        0.40051
trainer/policy/normal/log_std Max        0.301693
trainer/policy/normal/log_std Min       -2.04944
trainer/Alpha                            0.000187711
trainer/Alpha Loss                       0.414437
expl/num steps total                177000
expl/num paths total                 13298
expl/path length Mean                    3.93701
expl/path length Std                     1.72178
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.253
expl/Rewards Std                         0.434731
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996063
expl/Returns Std                         0.0626219
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0225545
expl/Actions Std                         0.750957
expl/Actions Max                         0.999783
expl/Actions Min                        -0.999404
expl/Num Paths                         254
expl/Average Returns                     0.996063
eval/num steps total                873022
eval/num paths total                 66633
eval/path length Mean                    3.94945
eval/path length Std                     1.70001
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2532
eval/Rewards Std                         0.434845
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0201596
eval/Actions Std                         0.676011
eval/Actions Max                         0.995846
eval/Actions Min                        -0.995083
eval/Num Paths                        1266
eval/Average Returns                     1
time/data storing (s)                    0.00614857
time/evaluation sampling (s)             1.06308
time/exploration sampling (s)            0.377613
time/logging (s)                         0.0178425
time/sac training (s)                   12.6478
time/saving (s)                          0.00325994
time/training (s)                        1.932e-05
time/epoch (s)                          14.1158
time/total (s)                        2331.16
Epoch                                  175
----------------------------------  ----------------
2022-09-09 20:31:56.403279 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 176 finished
----------------------------------  ----------------
epoch                                  176
replay_buffer/size                  178000
trainer/num train calls             177000
trainer/QF1 Loss                         1.1087e-06
trainer/QF2 Loss                         4.85591e-06
trainer/Policy Loss                     -0.955372
trainer/Q1 Predictions Mean              0.94916
trainer/Q1 Predictions Std               0.0241634
trainer/Q1 Predictions Max               0.999962
trainer/Q1 Predictions Min               0.925932
trainer/Q2 Predictions Mean              0.950709
trainer/Q2 Predictions Std               0.0241087
trainer/Q2 Predictions Max               1.00189
trainer/Q2 Predictions Min               0.924385
trainer/Q Targets Mean                   0.949441
trainer/Q Targets Std                    0.0245277
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.924602
trainer/Log Pis Mean                     3.0066
trainer/Log Pis Std                      1.89867
trainer/Log Pis Max                      7.20676
trainer/Log Pis Min                     -3.93876
trainer/policy/mean Mean                 0.042538
trainer/policy/mean Std                  0.712952
trainer/policy/mean Max                  0.995432
trainer/policy/mean Min                 -0.993317
trainer/policy/normal/std Mean           0.602095
trainer/policy/normal/std Std            0.189567
trainer/policy/normal/std Max            1.18415
trainer/policy/normal/std Min            0.150003
trainer/policy/normal/log_std Mean      -0.564812
trainer/policy/normal/log_std Std        0.356355
trainer/policy/normal/log_std Max        0.169022
trainer/policy/normal/log_std Min       -1.8971
trainer/Alpha                            0.000183327
trainer/Alpha Loss                       0.0567445
expl/num steps total                178000
expl/num paths total                 13569
expl/path length Mean                    3.69004
expl/path length Std                     1.71811
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.27
expl/Rewards Std                         0.443959
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.99631
expl/Returns Std                         0.0606335
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0437973
expl/Actions Std                         0.758977
expl/Actions Max                         0.99926
expl/Actions Min                        -0.999557
expl/Num Paths                         271
expl/Average Returns                     0.99631
eval/num steps total                878020
eval/num paths total                 67890
eval/path length Mean                    3.97613
eval/path length Std                     1.67847
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251501
eval/Rewards Std                         0.433876
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0139937
eval/Actions Std                         0.675989
eval/Actions Max                         0.997749
eval/Actions Min                        -0.994246
eval/Num Paths                        1257
eval/Average Returns                     1
time/data storing (s)                    0.0068926
time/evaluation sampling (s)             0.954298
time/exploration sampling (s)            0.344521
time/logging (s)                         0.0202358
time/sac training (s)                   11.782
time/saving (s)                          0.0047485
time/training (s)                        2.725e-05
time/epoch (s)                          13.1127
time/total (s)                        2344.57
Epoch                                  176
----------------------------------  ----------------
2022-09-09 20:32:09.732128 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 177 finished
----------------------------------  ----------------
epoch                                  177
replay_buffer/size                  179000
trainer/num train calls             178000
trainer/QF1 Loss                         7.79733e-07
trainer/QF2 Loss                         2.26845e-06
trainer/Policy Loss                     -0.955789
trainer/Q1 Predictions Mean              0.950074
trainer/Q1 Predictions Std               0.0247222
trainer/Q1 Predictions Max               1.00187
trainer/Q1 Predictions Min               0.924813
trainer/Q2 Predictions Mean              0.94922
trainer/Q2 Predictions Std               0.0244617
trainer/Q2 Predictions Max               1.00335
trainer/Q2 Predictions Min               0.924387
trainer/Q Targets Mean                   0.949856
trainer/Q Targets Std                    0.0246495
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.924638
trainer/Log Pis Mean                     2.98044
trainer/Log Pis Std                      2.05931
trainer/Log Pis Max                      7.83804
trainer/Log Pis Min                     -4.40785
trainer/policy/mean Mean                -0.0118169
trainer/policy/mean Std                  0.713797
trainer/policy/mean Max                  0.994079
trainer/policy/mean Min                 -0.994989
trainer/policy/normal/std Mean           0.594335
trainer/policy/normal/std Std            0.211546
trainer/policy/normal/std Max            1.20229
trainer/policy/normal/std Min            0.131257
trainer/policy/normal/log_std Mean      -0.592729
trainer/policy/normal/log_std Std        0.398314
trainer/policy/normal/log_std Max        0.184227
trainer/policy/normal/log_std Min       -2.0306
trainer/Alpha                            0.000181818
trainer/Alpha Loss                      -0.168497
expl/num steps total                179000
expl/num paths total                 13819
expl/path length Mean                    4
expl/path length Std                     1.66373
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996
expl/Returns Std                         0.0631189
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0307833
expl/Actions Std                         0.758015
expl/Actions Max                         0.999503
expl/Actions Min                        -0.999596
expl/Num Paths                         250
expl/Average Returns                     0.996
eval/num steps total                883020
eval/num paths total                 69160
eval/path length Mean                    3.93701
eval/path length Std                     1.70847
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254
eval/Rewards Std                         0.435298
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0177911
eval/Actions Std                         0.683446
eval/Actions Max                         0.996301
eval/Actions Min                        -0.997444
eval/Num Paths                        1270
eval/Average Returns                     1
time/data storing (s)                    0.00627351
time/evaluation sampling (s)             0.991106
time/exploration sampling (s)            0.333828
time/logging (s)                         0.0203718
time/sac training (s)                   11.6746
time/saving (s)                          0.00473833
time/training (s)                        2.75e-05
time/epoch (s)                          13.0309
time/total (s)                        2357.89
Epoch                                  177
----------------------------------  ----------------
2022-09-09 20:32:22.838855 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 178 finished
----------------------------------  ----------------
epoch                                  178
replay_buffer/size                  180000
trainer/num train calls             179000
trainer/QF1 Loss                         1.5122e-06
trainer/QF2 Loss                         7.08928e-06
trainer/Policy Loss                     -0.955025
trainer/Q1 Predictions Mean              0.948523
trainer/Q1 Predictions Std               0.0239703
trainer/Q1 Predictions Max               1.00031
trainer/Q1 Predictions Min               0.922208
trainer/Q2 Predictions Mean              0.95118
trainer/Q2 Predictions Std               0.0232646
trainer/Q2 Predictions Max               1.0055
trainer/Q2 Predictions Min               0.929415
trainer/Q Targets Mean                   0.949142
trainer/Q Targets Std                    0.0239285
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.923591
trainer/Log Pis Mean                     3.02897
trainer/Log Pis Std                      1.80507
trainer/Log Pis Max                      7.75692
trainer/Log Pis Min                     -2.0301
trainer/policy/mean Mean                 0.0441756
trainer/policy/mean Std                  0.71383
trainer/policy/mean Max                  0.995229
trainer/policy/mean Min                 -0.995934
trainer/policy/normal/std Mean           0.601111
trainer/policy/normal/std Std            0.21458
trainer/policy/normal/std Max            1.32591
trainer/policy/normal/std Min            0.167381
trainer/policy/normal/log_std Mean      -0.576616
trainer/policy/normal/log_std Std        0.376966
trainer/policy/normal/log_std Max        0.2821
trainer/policy/normal/log_std Min       -1.78748
trainer/Alpha                            0.000180494
trainer/Alpha Loss                       0.249742
expl/num steps total                180000
expl/num paths total                 14060
expl/path length Mean                    4.14938
expl/path length Std                     1.77187
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.24
expl/Rewards Std                         0.427083
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995851
expl/Returns Std                         0.0642819
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0274063
expl/Actions Std                         0.751079
expl/Actions Max                         0.999312
expl/Actions Min                        -0.999366
expl/Num Paths                         241
expl/Average Returns                     0.995851
eval/num steps total                888015
eval/num paths total                 70433
eval/path length Mean                    3.9238
eval/path length Std                     1.66937
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254855
eval/Rewards Std                         0.43578
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00342326
eval/Actions Std                         0.676459
eval/Actions Max                         0.996148
eval/Actions Min                        -0.995076
eval/Num Paths                        1273
eval/Average Returns                     1
time/data storing (s)                    0.00629892
time/evaluation sampling (s)             0.963619
time/exploration sampling (s)            0.310197
time/logging (s)                         0.0191926
time/sac training (s)                   11.5239
time/saving (s)                          0.00479739
time/training (s)                        0.0002366
time/epoch (s)                          12.8282
time/total (s)                        2370.98
Epoch                                  178
----------------------------------  ----------------
2022-09-09 20:32:36.302953 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 179 finished
----------------------------------  ----------------
epoch                                  179
replay_buffer/size                  181000
trainer/num train calls             180000
trainer/QF1 Loss                         1.09645e-06
trainer/QF2 Loss                         3.53647e-06
trainer/Policy Loss                     -0.95608
trainer/Q1 Predictions Mean              0.951507
trainer/Q1 Predictions Std               0.0243629
trainer/Q1 Predictions Max               1.00179
trainer/Q1 Predictions Min               0.924421
trainer/Q2 Predictions Mean              0.949874
trainer/Q2 Predictions Std               0.0242473
trainer/Q2 Predictions Max               1.00168
trainer/Q2 Predictions Min               0.922376
trainer/Q Targets Mean                   0.951235
trainer/Q Targets Std                    0.0241063
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.924566
trainer/Log Pis Mean                     2.9821
trainer/Log Pis Std                      1.94309
trainer/Log Pis Max                      7.68541
trainer/Log Pis Min                     -4.11375
trainer/policy/mean Mean                 0.0521931
trainer/policy/mean Std                  0.70822
trainer/policy/mean Max                  0.994598
trainer/policy/mean Min                 -0.99494
trainer/policy/normal/std Mean           0.61064
trainer/policy/normal/std Std            0.21763
trainer/policy/normal/std Max            1.31041
trainer/policy/normal/std Min            0.140486
trainer/policy/normal/log_std Mean      -0.565259
trainer/policy/normal/log_std Std        0.397435
trainer/policy/normal/log_std Max        0.270343
trainer/policy/normal/log_std Min       -1.96265
trainer/Alpha                            0.000179591
trainer/Alpha Loss                      -0.154388
expl/num steps total                181000
expl/num paths total                 14308
expl/path length Mean                    4.03226
expl/path length Std                     1.78901
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.247
expl/Rewards Std                         0.431267
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995968
expl/Returns Std                         0.0633719
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00262085
expl/Actions Std                         0.763585
expl/Actions Max                         0.999506
expl/Actions Min                        -0.999496
expl/Num Paths                         248
expl/Average Returns                     0.995968
eval/num steps total                893015
eval/num paths total                 71718
eval/path length Mean                    3.89105
eval/path length Std                     1.71211
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.257
eval/Rewards Std                         0.436979
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0277851
eval/Actions Std                         0.678016
eval/Actions Max                         0.995279
eval/Actions Min                        -0.995843
eval/Num Paths                        1285
eval/Average Returns                     1
time/data storing (s)                    0.00617223
time/evaluation sampling (s)             0.967803
time/exploration sampling (s)            0.337535
time/logging (s)                         0.0184565
time/sac training (s)                   11.8517
time/saving (s)                          0.00469945
time/training (s)                        2.511e-05
time/epoch (s)                          13.1864
time/total (s)                        2384.43
Epoch                                  179
----------------------------------  ----------------
2022-09-09 20:32:49.973575 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 180 finished
----------------------------------  ----------------
epoch                                  180
replay_buffer/size                  182000
trainer/num train calls             181000
trainer/QF1 Loss                         1.52263e-06
trainer/QF2 Loss                         1.40066e-05
trainer/Policy Loss                     -0.956551
trainer/Q1 Predictions Mean              0.949934
trainer/Q1 Predictions Std               0.0242314
trainer/Q1 Predictions Max               1.0015
trainer/Q1 Predictions Min               0.925003
trainer/Q2 Predictions Mean              0.952609
trainer/Q2 Predictions Std               0.0245757
trainer/Q2 Predictions Max               1.00679
trainer/Q2 Predictions Min               0.927129
trainer/Q Targets Mean                   0.949534
trainer/Q Targets Std                    0.0243668
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.923209
trainer/Log Pis Mean                     2.76051
trainer/Log Pis Std                      1.802
trainer/Log Pis Max                      7.84802
trainer/Log Pis Min                     -2.71438
trainer/policy/mean Mean                 0.105229
trainer/policy/mean Std                  0.690467
trainer/policy/mean Max                  0.99332
trainer/policy/mean Min                 -0.99602
trainer/policy/normal/std Mean           0.629242
trainer/policy/normal/std Std            0.210934
trainer/policy/normal/std Max            1.34511
trainer/policy/normal/std Min            0.176489
trainer/policy/normal/log_std Mean      -0.522947
trainer/policy/normal/log_std Std        0.354631
trainer/policy/normal/log_std Max        0.296479
trainer/policy/normal/log_std Min       -1.7345
trainer/Alpha                            0.000170327
trainer/Alpha Loss                      -2.07821
expl/num steps total                182000
expl/num paths total                 14558
expl/path length Mean                    4
expl/path length Std                     1.68048
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996
expl/Returns Std                         0.0631189
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0496664
expl/Actions Std                         0.76614
expl/Actions Max                         0.999672
expl/Actions Min                        -0.99966
expl/Num Paths                         250
expl/Average Returns                     0.996
eval/num steps total                898014
eval/num paths total                 73011
eval/path length Mean                    3.8662
eval/path length Std                     1.70479
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.258652
eval/Rewards Std                         0.437894
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0533777
eval/Actions Std                         0.683339
eval/Actions Max                         0.995843
eval/Actions Min                        -0.995829
eval/Num Paths                        1293
eval/Average Returns                     1
time/data storing (s)                    0.004799
time/evaluation sampling (s)             0.99227
time/exploration sampling (s)            0.318039
time/logging (s)                         0.0203888
time/sac training (s)                   12.0131
time/saving (s)                          0.00471634
time/training (s)                        4.873e-05
time/epoch (s)                          13.3534
time/total (s)                        2398.09
Epoch                                  180
----------------------------------  ----------------
2022-09-09 20:33:03.406776 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 181 finished
----------------------------------  ----------------
epoch                                  181
replay_buffer/size                  183000
trainer/num train calls             182000
trainer/QF1 Loss                         2.17293e-06
trainer/QF2 Loss                         5.33601e-06
trainer/Policy Loss                     -0.956684
trainer/Q1 Predictions Mean              0.951775
trainer/Q1 Predictions Std               0.0249109
trainer/Q1 Predictions Max               0.999485
trainer/Q1 Predictions Min               0.924181
trainer/Q2 Predictions Mean              0.950846
trainer/Q2 Predictions Std               0.0252656
trainer/Q2 Predictions Max               1.00056
trainer/Q2 Predictions Min               0.921807
trainer/Q Targets Mean                   0.952678
trainer/Q Targets Std                    0.0253089
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.924017
trainer/Log Pis Mean                     2.889
trainer/Log Pis Std                      1.80423
trainer/Log Pis Max                      7.64799
trainer/Log Pis Min                     -3.75864
trainer/policy/mean Mean                 0.0813114
trainer/policy/mean Std                  0.6983
trainer/policy/mean Max                  0.99477
trainer/policy/mean Min                 -0.99404
trainer/policy/normal/std Mean           0.622392
trainer/policy/normal/std Std            0.213092
trainer/policy/normal/std Max            1.99019
trainer/policy/normal/std Min            0.155196
trainer/policy/normal/log_std Mean      -0.536126
trainer/policy/normal/log_std Std        0.364976
trainer/policy/normal/log_std Max        0.688231
trainer/policy/normal/log_std Min       -1.86307
trainer/Alpha                            0.000169735
trainer/Alpha Loss                      -0.963597
expl/num steps total                183000
expl/num paths total                 14807
expl/path length Mean                    4.01606
expl/path length Std                     1.73314
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.248
expl/Rewards Std                         0.431852
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995984
expl/Returns Std                         0.063245
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0158549
expl/Actions Std                         0.761157
expl/Actions Max                         0.999879
expl/Actions Min                        -0.999663
expl/Num Paths                         249
expl/Average Returns                     0.995984
eval/num steps total                903012
eval/num paths total                 74260
eval/path length Mean                    4.0016
eval/path length Std                     1.69254
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2499
eval/Rewards Std                         0.432955
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0468528
eval/Actions Std                         0.67132
eval/Actions Max                         0.997132
eval/Actions Min                        -0.995664
eval/Num Paths                        1249
eval/Average Returns                     1
time/data storing (s)                    0.00449716
time/evaluation sampling (s)             0.961382
time/exploration sampling (s)            0.334433
time/logging (s)                         0.0202257
time/sac training (s)                   11.8008
time/saving (s)                          0.00343437
time/training (s)                        2.285e-05
time/epoch (s)                          13.1248
time/total (s)                        2411.52
Epoch                                  181
----------------------------------  ----------------
2022-09-09 20:33:16.374545 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 182 finished
----------------------------------  ----------------
epoch                                  182
replay_buffer/size                  184000
trainer/num train calls             183000
trainer/QF1 Loss                         1.01422e-06
trainer/QF2 Loss                         1.40498e-06
trainer/Policy Loss                     -0.956258
trainer/Q1 Predictions Mean              0.950463
trainer/Q1 Predictions Std               0.023408
trainer/Q1 Predictions Max               1.00435
trainer/Q1 Predictions Min               0.924605
trainer/Q2 Predictions Mean              0.949966
trainer/Q2 Predictions Std               0.0232322
trainer/Q2 Predictions Max               1.00056
trainer/Q2 Predictions Min               0.925155
trainer/Q Targets Mean                   0.949969
trainer/Q Targets Std                    0.0234806
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.923821
trainer/Log Pis Mean                     2.8753
trainer/Log Pis Std                      2.06091
trainer/Log Pis Max                      8.50557
trainer/Log Pis Min                     -4.56553
trainer/policy/mean Mean                 0.0227066
trainer/policy/mean Std                  0.7086
trainer/policy/mean Max                  0.995107
trainer/policy/mean Min                 -0.996104
trainer/policy/normal/std Mean           0.590332
trainer/policy/normal/std Std            0.19756
trainer/policy/normal/std Max            1.12699
trainer/policy/normal/std Min            0.166215
trainer/policy/normal/log_std Mean      -0.588374
trainer/policy/normal/log_std Std        0.361693
trainer/policy/normal/log_std Max        0.119549
trainer/policy/normal/log_std Min       -1.79448
trainer/Alpha                            0.00016652
trainer/Alpha Loss                      -1.08495
expl/num steps total                184000
expl/num paths total                 15060
expl/path length Mean                    3.95257
expl/path length Std                     1.77981
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.252
expl/Rewards Std                         0.434161
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996047
expl/Returns Std                         0.0627451
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0531369
expl/Actions Std                         0.753839
expl/Actions Max                         0.999165
expl/Actions Min                        -0.999579
expl/Num Paths                         253
expl/Average Returns                     0.996047
eval/num steps total                908010
eval/num paths total                 75502
eval/path length Mean                    4.02415
eval/path length Std                     1.65534
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.248499
eval/Rewards Std                         0.432143
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0101636
eval/Actions Std                         0.680508
eval/Actions Max                         0.996261
eval/Actions Min                        -0.995237
eval/Num Paths                        1242
eval/Average Returns                     1
time/data storing (s)                    0.00504441
time/evaluation sampling (s)             0.977551
time/exploration sampling (s)            0.319085
time/logging (s)                         0.0182272
time/sac training (s)                   11.3741
time/saving (s)                          0.00463013
time/training (s)                        2.494e-05
time/epoch (s)                          12.6987
time/total (s)                        2424.47
Epoch                                  182
----------------------------------  ----------------
2022-09-09 20:33:29.393456 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 183 finished
----------------------------------  ----------------
epoch                                  183
replay_buffer/size                  185000
trainer/num train calls             184000
trainer/QF1 Loss                         1.13639e-06
trainer/QF2 Loss                         2.16426e-06
trainer/Policy Loss                     -0.955845
trainer/Q1 Predictions Mean              0.949801
trainer/Q1 Predictions Std               0.0239725
trainer/Q1 Predictions Max               1.00184
trainer/Q1 Predictions Min               0.925665
trainer/Q2 Predictions Mean              0.949608
trainer/Q2 Predictions Std               0.0237089
trainer/Q2 Predictions Max               1.00218
trainer/Q2 Predictions Min               0.923473
trainer/Q Targets Mean                   0.949709
trainer/Q Targets Std                    0.0237241
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.924738
trainer/Log Pis Mean                     3.11547
trainer/Log Pis Std                      1.88526
trainer/Log Pis Max                      7.65477
trainer/Log Pis Min                     -2.47879
trainer/policy/mean Mean                -0.0195109
trainer/policy/mean Std                  0.710294
trainer/policy/mean Max                  0.995003
trainer/policy/mean Min                 -0.997404
trainer/policy/normal/std Mean           0.622995
trainer/policy/normal/std Std            0.204469
trainer/policy/normal/std Max            1.34178
trainer/policy/normal/std Min            0.141042
trainer/policy/normal/log_std Mean      -0.530035
trainer/policy/normal/log_std Std        0.345288
trainer/policy/normal/log_std Max        0.294
trainer/policy/normal/log_std Min       -1.9587
trainer/Alpha                            0.000165647
trainer/Alpha Loss                       1.00527
expl/num steps total                185000
expl/num paths total                 15301
expl/path length Mean                    4.14938
expl/path length Std                     1.70504
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.24
expl/Rewards Std                         0.427083
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995851
expl/Returns Std                         0.0642819
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0125567
expl/Actions Std                         0.758422
expl/Actions Max                         0.999303
expl/Actions Min                        -0.999481
expl/Num Paths                         241
expl/Average Returns                     0.995851
eval/num steps total                913008
eval/num paths total                 76762
eval/path length Mean                    3.96667
eval/path length Std                     1.67204
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252101
eval/Rewards Std                         0.434219
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00131414
eval/Actions Std                         0.67411
eval/Actions Max                         0.995335
eval/Actions Min                        -0.996577
eval/Num Paths                        1260
eval/Average Returns                     1
time/data storing (s)                    0.00399965
time/evaluation sampling (s)             0.961143
time/exploration sampling (s)            0.324527
time/logging (s)                         0.0204903
time/sac training (s)                   11.4444
time/saving (s)                          0.00336711
time/training (s)                        2.84e-05
time/epoch (s)                          12.758
time/total (s)                        2437.48
Epoch                                  183
----------------------------------  ----------------
2022-09-09 20:33:42.845750 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 184 finished
----------------------------------  ----------------
epoch                                  184
replay_buffer/size                  186000
trainer/num train calls             185000
trainer/QF1 Loss                         9.45965e-07
trainer/QF2 Loss                         1.92617e-06
trainer/Policy Loss                     -0.954487
trainer/Q1 Predictions Mean              0.948417
trainer/Q1 Predictions Std               0.0239357
trainer/Q1 Predictions Max               1.00068
trainer/Q1 Predictions Min               0.923872
trainer/Q2 Predictions Mean              0.948465
trainer/Q2 Predictions Std               0.0234881
trainer/Q2 Predictions Max               1.00129
trainer/Q2 Predictions Min               0.924664
trainer/Q Targets Mean                   0.94888
trainer/Q Targets Std                    0.0239495
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.924693
trainer/Log Pis Mean                     2.96597
trainer/Log Pis Std                      1.79765
trainer/Log Pis Max                      7.62418
trainer/Log Pis Min                     -2.41809
trainer/policy/mean Mean                 0.102265
trainer/policy/mean Std                  0.701062
trainer/policy/mean Max                  0.994661
trainer/policy/mean Min                 -0.994952
trainer/policy/normal/std Mean           0.625922
trainer/policy/normal/std Std            0.207043
trainer/policy/normal/std Max            1.19047
trainer/policy/normal/std Min            0.147425
trainer/policy/normal/log_std Mean      -0.531006
trainer/policy/normal/log_std Std        0.371004
trainer/policy/normal/log_std Max        0.174349
trainer/policy/normal/log_std Min       -1.91443
trainer/Alpha                            0.000163233
trainer/Alpha Loss                      -0.296758
expl/num steps total                186000
expl/num paths total                 15553
expl/path length Mean                    3.96825
expl/path length Std                     1.69236
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996032
expl/Returns Std                         0.062869
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0406839
expl/Actions Std                         0.756011
expl/Actions Max                         0.99958
expl/Actions Min                        -0.999768
expl/Num Paths                         252
expl/Average Returns                     0.996032
eval/num steps total                918005
eval/num paths total                 78046
eval/path length Mean                    3.89174
eval/path length Std                     1.6874
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.256954
eval/Rewards Std                         0.436954
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0360844
eval/Actions Std                         0.676459
eval/Actions Max                         0.995714
eval/Actions Min                        -0.995883
eval/Num Paths                        1284
eval/Average Returns                     1
time/data storing (s)                    0.0063024
time/evaluation sampling (s)             0.987945
time/exploration sampling (s)            0.304846
time/logging (s)                         0.0190048
time/sac training (s)                   11.8369
time/saving (s)                          0.00463501
time/training (s)                        0.00012851
time/epoch (s)                          13.1597
time/total (s)                        2450.92
Epoch                                  184
----------------------------------  ----------------
2022-09-09 20:33:56.214640 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 185 finished
----------------------------------  ----------------
epoch                                  185
replay_buffer/size                  187000
trainer/num train calls             186000
trainer/QF1 Loss                         6.86165e-07
trainer/QF2 Loss                         2.98991e-06
trainer/Policy Loss                     -0.95685
trainer/Q1 Predictions Mean              0.951164
trainer/Q1 Predictions Std               0.0242004
trainer/Q1 Predictions Max               1.00092
trainer/Q1 Predictions Min               0.924712
trainer/Q2 Predictions Mean              0.950388
trainer/Q2 Predictions Std               0.0241994
trainer/Q2 Predictions Max               1.0016
trainer/Q2 Predictions Min               0.922302
trainer/Q Targets Mean                   0.951382
trainer/Q Targets Std                    0.0242286
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.924327
trainer/Log Pis Mean                     2.916
trainer/Log Pis Std                      1.79661
trainer/Log Pis Max                      8.1527
trainer/Log Pis Min                     -3.39458
trainer/policy/mean Mean                 0.178208
trainer/policy/mean Std                  0.677367
trainer/policy/mean Max                  0.994451
trainer/policy/mean Min                 -0.995951
trainer/policy/normal/std Mean           0.611221
trainer/policy/normal/std Std            0.192769
trainer/policy/normal/std Max            1.13041
trainer/policy/normal/std Min            0.149068
trainer/policy/normal/log_std Mean      -0.548114
trainer/policy/normal/log_std Std        0.347824
trainer/policy/normal/log_std Max        0.122578
trainer/policy/normal/log_std Min       -1.90336
trainer/Alpha                            0.000163252
trainer/Alpha Loss                      -0.732534
expl/num steps total                187000
expl/num paths total                 15809
expl/path length Mean                    3.90625
expl/path length Std                     1.66507
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.255
expl/Rewards Std                         0.435861
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996094
expl/Returns Std                         0.0623778
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0561928
expl/Actions Std                         0.75199
expl/Actions Max                         0.999811
expl/Actions Min                        -0.999593
expl/Num Paths                         256
expl/Average Returns                     0.996094
eval/num steps total                923001
eval/num paths total                 79307
eval/path length Mean                    3.96193
eval/path length Std                     1.67365
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252402
eval/Rewards Std                         0.434391
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.056518
eval/Actions Std                         0.673345
eval/Actions Max                         0.996159
eval/Actions Min                        -0.995063
eval/Num Paths                        1261
eval/Average Returns                     1
time/data storing (s)                    0.00635375
time/evaluation sampling (s)             0.957055
time/exploration sampling (s)            0.306863
time/logging (s)                         0.0183203
time/sac training (s)                   11.7921
time/saving (s)                          0.00449165
time/training (s)                        2.582e-05
time/epoch (s)                          13.0852
time/total (s)                        2464.28
Epoch                                  185
----------------------------------  ----------------
2022-09-09 20:34:09.812535 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 186 finished
----------------------------------  ----------------
epoch                                  186
replay_buffer/size                  188000
trainer/num train calls             187000
trainer/QF1 Loss                         3.64128e-06
trainer/QF2 Loss                         1.60647e-06
trainer/Policy Loss                     -0.95755
trainer/Q1 Predictions Mean              0.95329
trainer/Q1 Predictions Std               0.0237162
trainer/Q1 Predictions Max               1.00151
trainer/Q1 Predictions Min               0.927457
trainer/Q2 Predictions Mean              0.951528
trainer/Q2 Predictions Std               0.0241501
trainer/Q2 Predictions Max               1.00331
trainer/Q2 Predictions Min               0.924485
trainer/Q Targets Mean                   0.951685
trainer/Q Targets Std                    0.0239619
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.925084
trainer/Log Pis Mean                     2.91464
trainer/Log Pis Std                      1.89225
trainer/Log Pis Max                      8.46109
trainer/Log Pis Min                     -3.19484
trainer/policy/mean Mean                 0.070182
trainer/policy/mean Std                  0.696767
trainer/policy/mean Max                  0.994219
trainer/policy/mean Min                 -0.993524
trainer/policy/normal/std Mean           0.617438
trainer/policy/normal/std Std            0.199414
trainer/policy/normal/std Max            1.19969
trainer/policy/normal/std Min            0.159572
trainer/policy/normal/log_std Mean      -0.539177
trainer/policy/normal/log_std Std        0.349159
trainer/policy/normal/log_std Max        0.182062
trainer/policy/normal/log_std Min       -1.83526
trainer/Alpha                            0.000160809
trainer/Alpha Loss                      -0.745655
expl/num steps total                188000
expl/num paths total                 16057
expl/path length Mean                    4.03226
expl/path length Std                     1.69409
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.248
expl/Rewards Std                         0.431852
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0129305
expl/Actions Std                         0.755997
expl/Actions Max                         0.999604
expl/Actions Min                        -0.999577
expl/Num Paths                         248
expl/Average Returns                     1
eval/num steps total                928001
eval/num paths total                 80547
eval/path length Mean                    4.03226
eval/path length Std                     1.6399
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.248
eval/Rewards Std                         0.431852
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0105483
eval/Actions Std                         0.674503
eval/Actions Max                         0.994817
eval/Actions Min                        -0.995301
eval/Num Paths                        1240
eval/Average Returns                     1
time/data storing (s)                    0.00637202
time/evaluation sampling (s)             0.953871
time/exploration sampling (s)            0.302528
time/logging (s)                         0.0185694
time/sac training (s)                   12.0109
time/saving (s)                          0.00615828
time/training (s)                        0.00010792
time/epoch (s)                          13.2985
time/total (s)                        2477.87
Epoch                                  186
----------------------------------  ----------------
2022-09-09 20:34:23.853722 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 187 finished
----------------------------------  ----------------
epoch                                  187
replay_buffer/size                  189000
trainer/num train calls             188000
trainer/QF1 Loss                         2.5429e-06
trainer/QF2 Loss                         2.44431e-06
trainer/Policy Loss                     -0.955915
trainer/Q1 Predictions Mean              0.949688
trainer/Q1 Predictions Std               0.0233624
trainer/Q1 Predictions Max               0.999127
trainer/Q1 Predictions Min               0.923741
trainer/Q2 Predictions Mean              0.949973
trainer/Q2 Predictions Std               0.0235031
trainer/Q2 Predictions Max               1.00109
trainer/Q2 Predictions Min               0.924153
trainer/Q Targets Mean                   0.951025
trainer/Q Targets Std                    0.0234052
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.924516
trainer/Log Pis Mean                     3.02005
trainer/Log Pis Std                      1.62374
trainer/Log Pis Max                      7.66595
trainer/Log Pis Min                     -2.57022
trainer/policy/mean Mean                 0.0538988
trainer/policy/mean Std                  0.69433
trainer/policy/mean Max                  0.994599
trainer/policy/mean Min                 -0.994901
trainer/policy/normal/std Mean           0.609152
trainer/policy/normal/std Std            0.200128
trainer/policy/normal/std Max            1.10063
trainer/policy/normal/std Min            0.162739
trainer/policy/normal/log_std Mean      -0.555118
trainer/policy/normal/log_std Std        0.356479
trainer/policy/normal/log_std Max        0.0958824
trainer/policy/normal/log_std Min       -1.81561
trainer/Alpha                            0.000160725
trainer/Alpha Loss                       0.175196
expl/num steps total                189000
expl/num paths total                 16314
expl/path length Mean                    3.89105
expl/path length Std                     1.65149
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.257
expl/Rewards Std                         0.436979
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0244059
expl/Actions Std                         0.753059
expl/Actions Max                         0.999561
expl/Actions Min                        -0.999634
expl/Num Paths                         257
expl/Average Returns                     1
eval/num steps total                932999
eval/num paths total                 81811
eval/path length Mean                    3.95411
eval/path length Std                     1.72916
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252901
eval/Rewards Std                         0.434675
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00665552
eval/Actions Std                         0.677585
eval/Actions Max                         0.995706
eval/Actions Min                        -0.99598
eval/Num Paths                        1264
eval/Average Returns                     1
time/data storing (s)                    0.00420403
time/evaluation sampling (s)             1.02559
time/exploration sampling (s)            0.343074
time/logging (s)                         0.0185408
time/sac training (s)                   12.3095
time/saving (s)                          0.00468644
time/training (s)                        2.435e-05
time/epoch (s)                          13.7056
time/total (s)                        2491.9
Epoch                                  187
----------------------------------  ----------------
2022-09-09 20:34:37.096276 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 188 finished
----------------------------------  ----------------
epoch                                  188
replay_buffer/size                  190000
trainer/num train calls             189000
trainer/QF1 Loss                         2.3546e-06
trainer/QF2 Loss                         4.21469e-06
trainer/Policy Loss                     -0.955696
trainer/Q1 Predictions Mean              0.950237
trainer/Q1 Predictions Std               0.0243914
trainer/Q1 Predictions Max               1.00077
trainer/Q1 Predictions Min               0.923028
trainer/Q2 Predictions Mean              0.950067
trainer/Q2 Predictions Std               0.0246093
trainer/Q2 Predictions Max               1.00025
trainer/Q2 Predictions Min               0.922927
trainer/Q Targets Mean                   0.951236
trainer/Q Targets Std                    0.0243828
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.924286
trainer/Log Pis Mean                     3.15918
trainer/Log Pis Std                      1.8243
trainer/Log Pis Max                      7.50222
trainer/Log Pis Min                     -2.9526
trainer/policy/mean Mean                 0.00984973
trainer/policy/mean Std                  0.715301
trainer/policy/mean Max                  0.995019
trainer/policy/mean Min                 -0.99541
trainer/policy/normal/std Mean           0.610205
trainer/policy/normal/std Std            0.186495
trainer/policy/normal/std Max            1.20151
trainer/policy/normal/std Min            0.121948
trainer/policy/normal/log_std Mean      -0.548422
trainer/policy/normal/log_std Std        0.348163
trainer/policy/normal/log_std Max        0.183581
trainer/policy/normal/log_std Min       -2.10416
trainer/Alpha                            0.00016308
trainer/Alpha Loss                       1.38821
expl/num steps total                190000
expl/num paths total                 16551
expl/path length Mean                    4.21941
expl/path length Std                     1.65684
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.236
expl/Rewards Std                         0.424622
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995781
expl/Returns Std                         0.0648198
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0142169
expl/Actions Std                         0.750302
expl/Actions Max                         0.999813
expl/Actions Min                        -0.999829
expl/Num Paths                         237
expl/Average Returns                     0.995781
eval/num steps total                937997
eval/num paths total                 83068
eval/path length Mean                    3.97613
eval/path length Std                     1.66036
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251501
eval/Rewards Std                         0.433876
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0161779
eval/Actions Std                         0.68061
eval/Actions Max                         0.996117
eval/Actions Min                        -0.99541
eval/Num Paths                        1257
eval/Average Returns                     1
time/data storing (s)                    0.00596659
time/evaluation sampling (s)             0.994846
time/exploration sampling (s)            0.326871
time/logging (s)                         0.0184761
time/sac training (s)                   11.6256
time/saving (s)                          0.00330671
time/training (s)                        2.312e-05
time/epoch (s)                          12.9751
time/total (s)                        2505.13
Epoch                                  188
----------------------------------  ----------------
2022-09-09 20:34:50.288957 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 189 finished
----------------------------------  ----------------
epoch                                  189
replay_buffer/size                  191000
trainer/num train calls             190000
trainer/QF1 Loss                         8.0765e-07
trainer/QF2 Loss                         3.12445e-06
trainer/Policy Loss                     -0.958296
trainer/Q1 Predictions Mean              0.952419
trainer/Q1 Predictions Std               0.0253597
trainer/Q1 Predictions Max               1.00164
trainer/Q1 Predictions Min               0.925315
trainer/Q2 Predictions Mean              0.953449
trainer/Q2 Predictions Std               0.0252802
trainer/Q2 Predictions Max               1.00335
trainer/Q2 Predictions Min               0.926335
trainer/Q Targets Mean                   0.952143
trainer/Q Targets Std                    0.0253924
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.924661
trainer/Log Pis Mean                     2.95262
trainer/Log Pis Std                      1.82206
trainer/Log Pis Max                      7.34919
trainer/Log Pis Min                     -2.55954
trainer/policy/mean Mean                 0.0662229
trainer/policy/mean Std                  0.703361
trainer/policy/mean Max                  0.995696
trainer/policy/mean Min                 -0.994068
trainer/policy/normal/std Mean           0.622635
trainer/policy/normal/std Std            0.188439
trainer/policy/normal/std Max            1.11826
trainer/policy/normal/std Min            0.169498
trainer/policy/normal/log_std Mean      -0.526418
trainer/policy/normal/log_std Std        0.339483
trainer/policy/normal/log_std Max        0.111772
trainer/policy/normal/log_std Min       -1.77491
trainer/Alpha                            0.000162303
trainer/Alpha Loss                      -0.413462
expl/num steps total                191000
expl/num paths total                 16802
expl/path length Mean                    3.98406
expl/path length Std                     1.65794
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.00827257
expl/Actions Std                         0.768696
expl/Actions Max                         0.999853
expl/Actions Min                        -0.999641
expl/Num Paths                         251
expl/Average Returns                     1
eval/num steps total                942993
eval/num paths total                 84348
eval/path length Mean                    3.90313
eval/path length Std                     1.71619
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.256205
eval/Rewards Std                         0.436536
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00166646
eval/Actions Std                         0.683525
eval/Actions Max                         0.996093
eval/Actions Min                        -0.995816
eval/Num Paths                        1280
eval/Average Returns                     1
time/data storing (s)                    0.00635051
time/evaluation sampling (s)             0.977344
time/exploration sampling (s)            0.331407
time/logging (s)                         0.0186066
time/sac training (s)                   11.5867
time/saving (s)                          0.00485436
time/training (s)                        2.569e-05
time/epoch (s)                          12.9252
time/total (s)                        2518.31
Epoch                                  189
----------------------------------  ----------------
2022-09-09 20:35:03.611597 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 190 finished
----------------------------------  ----------------
epoch                                  190
replay_buffer/size                  192000
trainer/num train calls             191000
trainer/QF1 Loss                         5.88743e-07
trainer/QF2 Loss                         2.45787e-06
trainer/Policy Loss                     -0.957752
trainer/Q1 Predictions Mean              0.951823
trainer/Q1 Predictions Std               0.0245491
trainer/Q1 Predictions Max               1.00138
trainer/Q1 Predictions Min               0.924771
trainer/Q2 Predictions Mean              0.952808
trainer/Q2 Predictions Std               0.0244265
trainer/Q2 Predictions Max               1.00327
trainer/Q2 Predictions Min               0.926095
trainer/Q Targets Mean                   0.952012
trainer/Q Targets Std                    0.0245598
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.925633
trainer/Log Pis Mean                     2.86179
trainer/Log Pis Std                      1.90847
trainer/Log Pis Max                      7.05413
trainer/Log Pis Min                     -3.89722
trainer/policy/mean Mean                 0.103594
trainer/policy/mean Std                  0.69838
trainer/policy/mean Max                  0.995841
trainer/policy/mean Min                 -0.995292
trainer/policy/normal/std Mean           0.618062
trainer/policy/normal/std Std            0.188441
trainer/policy/normal/std Max            1.21368
trainer/policy/normal/std Min            0.154597
trainer/policy/normal/log_std Mean      -0.533448
trainer/policy/normal/log_std Std        0.336892
trainer/policy/normal/log_std Max        0.193656
trainer/policy/normal/log_std Min       -1.86694
trainer/Alpha                            0.000156628
trainer/Alpha Loss                      -1.21094
expl/num steps total                192000
expl/num paths total                 17043
expl/path length Mean                    4.14938
expl/path length Std                     1.66065
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.24
expl/Rewards Std                         0.427083
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995851
expl/Returns Std                         0.0642819
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0168807
expl/Actions Std                         0.756585
expl/Actions Max                         0.999528
expl/Actions Min                        -0.999652
expl/Num Paths                         241
expl/Average Returns                     0.995851
eval/num steps total                947990
eval/num paths total                 85615
eval/path length Mean                    3.94396
eval/path length Std                     1.73752
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253552
eval/Rewards Std                         0.435044
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0223292
eval/Actions Std                         0.67898
eval/Actions Max                         0.996514
eval/Actions Min                        -0.99588
eval/Num Paths                        1267
eval/Average Returns                     1
time/data storing (s)                    0.00394505
time/evaluation sampling (s)             0.970953
time/exploration sampling (s)            0.336878
time/logging (s)                         0.0203947
time/sac training (s)                   11.7112
time/saving (s)                          0.00355434
time/training (s)                        1.935e-05
time/epoch (s)                          13.047
time/total (s)                        2531.63
Epoch                                  190
----------------------------------  ----------------
2022-09-09 20:35:17.276996 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 191 finished
----------------------------------  ----------------
epoch                                  191
replay_buffer/size                  193000
trainer/num train calls             192000
trainer/QF1 Loss                         9.00855e-07
trainer/QF2 Loss                         1.51236e-06
trainer/Policy Loss                     -0.957245
trainer/Q1 Predictions Mean              0.951578
trainer/Q1 Predictions Std               0.0243362
trainer/Q1 Predictions Max               1.00204
trainer/Q1 Predictions Min               0.925746
trainer/Q2 Predictions Mean              0.951434
trainer/Q2 Predictions Std               0.0240158
trainer/Q2 Predictions Max               1.00146
trainer/Q2 Predictions Min               0.925517
trainer/Q Targets Mean                   0.951302
trainer/Q Targets Std                    0.0241247
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.925702
trainer/Log Pis Mean                     3.04059
trainer/Log Pis Std                      1.78725
trainer/Log Pis Max                      7.36562
trainer/Log Pis Min                     -3.21249
trainer/policy/mean Mean                 0.0848004
trainer/policy/mean Std                  0.695497
trainer/policy/mean Max                  0.995636
trainer/policy/mean Min                 -0.994002
trainer/policy/normal/std Mean           0.626549
trainer/policy/normal/std Std            0.198688
trainer/policy/normal/std Max            1.17278
trainer/policy/normal/std Min            0.185614
trainer/policy/normal/log_std Mean      -0.522121
trainer/policy/normal/log_std Std        0.339875
trainer/policy/normal/log_std Max        0.159374
trainer/policy/normal/log_std Min       -1.68409
trainer/Alpha                            0.000153456
trainer/Alpha Loss                       0.356485
expl/num steps total                193000
expl/num paths total                 17312
expl/path length Mean                    3.71747
expl/path length Std                     1.66366
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.268
expl/Rewards Std                         0.442918
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996283
expl/Returns Std                         0.0608576
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.063344
expl/Actions Std                         0.759331
expl/Actions Max                         0.999669
expl/Actions Min                        -0.999458
expl/Num Paths                         269
expl/Average Returns                     0.996283
eval/num steps total                952989
eval/num paths total                 86878
eval/path length Mean                    3.95804
eval/path length Std                     1.6582
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252651
eval/Rewards Std                         0.434532
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00108347
eval/Actions Std                         0.675597
eval/Actions Max                         0.996015
eval/Actions Min                        -0.99509
eval/Num Paths                        1263
eval/Average Returns                     1
time/data storing (s)                    0.00397393
time/evaluation sampling (s)             0.975877
time/exploration sampling (s)            0.331342
time/logging (s)                         0.0186346
time/sac training (s)                   12.0407
time/saving (s)                          0.0037849
time/training (s)                        2.017e-05
time/epoch (s)                          13.3743
time/total (s)                        2545.28
Epoch                                  191
----------------------------------  ----------------
2022-09-09 20:35:30.847196 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 192 finished
----------------------------------  ----------------
epoch                                  192
replay_buffer/size                  194000
trainer/num train calls             193000
trainer/QF1 Loss                         8.66201e-07
trainer/QF2 Loss                         1.49641e-06
trainer/Policy Loss                     -0.957911
trainer/Q1 Predictions Mean              0.952423
trainer/Q1 Predictions Std               0.0247043
trainer/Q1 Predictions Max               1.0014
trainer/Q1 Predictions Min               0.925824
trainer/Q2 Predictions Mean              0.952197
trainer/Q2 Predictions Std               0.0249513
trainer/Q2 Predictions Max               1.00115
trainer/Q2 Predictions Min               0.924256
trainer/Q Targets Mean                   0.952529
trainer/Q Targets Std                    0.0248257
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.925927
trainer/Log Pis Mean                     3.10471
trainer/Log Pis Std                      1.71701
trainer/Log Pis Max                      7.7481
trainer/Log Pis Min                     -3.89302
trainer/policy/mean Mean                 0.152436
trainer/policy/mean Std                  0.682038
trainer/policy/mean Max                  0.995306
trainer/policy/mean Min                 -0.994831
trainer/policy/normal/std Mean           0.616777
trainer/policy/normal/std Std            0.199556
trainer/policy/normal/std Max            1.08841
trainer/policy/normal/std Min            0.162448
trainer/policy/normal/log_std Mean      -0.541146
trainer/policy/normal/log_std Std        0.351949
trainer/policy/normal/log_std Max        0.0847167
trainer/policy/normal/log_std Min       -1.8174
trainer/Alpha                            0.000151706
trainer/Alpha Loss                       0.92076
expl/num steps total                194000
expl/num paths total                 17567
expl/path length Mean                    3.92157
expl/path length Std                     1.61662
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.254
expl/Rewards Std                         0.435298
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996078
expl/Returns Std                         0.0624995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0699962
expl/Actions Std                         0.754596
expl/Actions Max                         0.99954
expl/Actions Min                        -0.999548
expl/Num Paths                         255
expl/Average Returns                     0.996078
eval/num steps total                957987
eval/num paths total                 88135
eval/path length Mean                    3.97613
eval/path length Std                     1.67894
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251501
eval/Rewards Std                         0.433876
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0681633
eval/Actions Std                         0.678014
eval/Actions Max                         0.996512
eval/Actions Min                        -0.995713
eval/Num Paths                        1257
eval/Average Returns                     1
time/data storing (s)                    0.0063046
time/evaluation sampling (s)             0.974167
time/exploration sampling (s)            0.309322
time/logging (s)                         0.0201697
time/sac training (s)                   11.9703
time/saving (s)                          0.00501977
time/training (s)                        2.66e-05
time/epoch (s)                          13.2853
time/total (s)                        2558.84
Epoch                                  192
----------------------------------  ----------------
2022-09-09 20:35:44.581209 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 193 finished
----------------------------------  ----------------
epoch                                  193
replay_buffer/size                  195000
trainer/num train calls             194000
trainer/QF1 Loss                         2.49474e-06
trainer/QF2 Loss                         1.60981e-06
trainer/Policy Loss                     -0.955393
trainer/Q1 Predictions Mean              0.949178
trainer/Q1 Predictions Std               0.0234069
trainer/Q1 Predictions Max               0.998866
trainer/Q1 Predictions Min               0.923813
trainer/Q2 Predictions Mean              0.950235
trainer/Q2 Predictions Std               0.0236211
trainer/Q2 Predictions Max               1.00104
trainer/Q2 Predictions Min               0.925963
trainer/Q Targets Mean                   0.950384
trainer/Q Targets Std                    0.0235653
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92571
trainer/Log Pis Mean                     3.23374
trainer/Log Pis Std                      1.66383
trainer/Log Pis Max                      7.47497
trainer/Log Pis Min                     -2.83854
trainer/policy/mean Mean                 0.0722339
trainer/policy/mean Std                  0.700235
trainer/policy/mean Max                  0.996351
trainer/policy/mean Min                 -0.995076
trainer/policy/normal/std Mean           0.61636
trainer/policy/normal/std Std            0.207186
trainer/policy/normal/std Max            1.17174
trainer/policy/normal/std Min            0.169942
trainer/policy/normal/log_std Mean      -0.547433
trainer/policy/normal/log_std Std        0.371594
trainer/policy/normal/log_std Max        0.158491
trainer/policy/normal/log_std Min       -1.7723
trainer/Alpha                            0.00015384
trainer/Alpha Loss                       2.05217
expl/num steps total                195000
expl/num paths total                 17807
expl/path length Mean                    4.16667
expl/path length Std                     1.61675
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.239
expl/Rewards Std                         0.426473
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995833
expl/Returns Std                         0.0644151
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0255414
expl/Actions Std                         0.76766
expl/Actions Max                         0.999639
expl/Actions Min                        -0.999558
expl/Num Paths                         240
expl/Average Returns                     0.995833
eval/num steps total                962986
eval/num paths total                 89396
eval/path length Mean                    3.96431
eval/path length Std                     1.66824
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25225
eval/Rewards Std                         0.434304
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0194571
eval/Actions Std                         0.677452
eval/Actions Max                         0.996765
eval/Actions Min                        -0.99625
eval/Num Paths                        1261
eval/Average Returns                     1
time/data storing (s)                    0.00424064
time/evaluation sampling (s)             1.06607
time/exploration sampling (s)            0.329025
time/logging (s)                         0.0191822
time/sac training (s)                   11.9968
time/saving (s)                          0.00450224
time/training (s)                        0.00028108
time/epoch (s)                          13.4201
time/total (s)                        2572.56
Epoch                                  193
----------------------------------  ----------------
2022-09-09 20:35:58.365621 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 194 finished
----------------------------------  ----------------
epoch                                  194
replay_buffer/size                  196000
trainer/num train calls             195000
trainer/QF1 Loss                         9.50945e-07
trainer/QF2 Loss                         4.26815e-06
trainer/Policy Loss                     -0.956552
trainer/Q1 Predictions Mean              0.952033
trainer/Q1 Predictions Std               0.0240854
trainer/Q1 Predictions Max               1.00142
trainer/Q1 Predictions Min               0.926125
trainer/Q2 Predictions Mean              0.950245
trainer/Q2 Predictions Std               0.024198
trainer/Q2 Predictions Max               1.00062
trainer/Q2 Predictions Min               0.924377
trainer/Q Targets Mean                   0.951457
trainer/Q Targets Std                    0.0242296
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.925829
trainer/Log Pis Mean                     3.01367
trainer/Log Pis Std                      2.0354
trainer/Log Pis Max                      7.81917
trainer/Log Pis Min                     -7.43151
trainer/policy/mean Mean                 0.0809194
trainer/policy/mean Std                  0.695875
trainer/policy/mean Max                  0.995298
trainer/policy/mean Min                 -0.994408
trainer/policy/normal/std Mean           0.592346
trainer/policy/normal/std Std            0.171478
trainer/policy/normal/std Max            1.14284
trainer/policy/normal/std Min            0.175533
trainer/policy/normal/log_std Mean      -0.571433
trainer/policy/normal/log_std Std        0.322874
trainer/policy/normal/log_std Max        0.133519
trainer/policy/normal/log_std Min       -1.73993
trainer/Alpha                            0.000151496
trainer/Alpha Loss                       0.120234
expl/num steps total                196000
expl/num paths total                 18053
expl/path length Mean                    4.06504
expl/path length Std                     1.7048
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.245
expl/Rewards Std                         0.430087
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995935
expl/Returns Std                         0.063628
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0463577
expl/Actions Std                         0.762453
expl/Actions Max                         0.999805
expl/Actions Min                        -0.999583
expl/Num Paths                         246
expl/Average Returns                     0.995935
eval/num steps total                967986
eval/num paths total                 90653
eval/path length Mean                    3.97772
eval/path length Std                     1.69593
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2514
eval/Rewards Std                         0.433818
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0598323
eval/Actions Std                         0.678687
eval/Actions Max                         0.996162
eval/Actions Min                        -0.995794
eval/Num Paths                        1257
eval/Average Returns                     1
time/data storing (s)                    0.00445638
time/evaluation sampling (s)             0.980353
time/exploration sampling (s)            0.31822
time/logging (s)                         0.019179
time/sac training (s)                   12.1449
time/saving (s)                          0.00354791
time/training (s)                        2.736e-05
time/epoch (s)                          13.4706
time/total (s)                        2586.33
Epoch                                  194
----------------------------------  ----------------
2022-09-09 20:36:11.826637 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 195 finished
----------------------------------  ----------------
epoch                                  195
replay_buffer/size                  197000
trainer/num train calls             196000
trainer/QF1 Loss                         9.74497e-07
trainer/QF2 Loss                         1.70094e-06
trainer/Policy Loss                     -0.957872
trainer/Q1 Predictions Mean              0.952928
trainer/Q1 Predictions Std               0.0237415
trainer/Q1 Predictions Max               1.00102
trainer/Q1 Predictions Min               0.926812
trainer/Q2 Predictions Mean              0.952203
trainer/Q2 Predictions Std               0.0235585
trainer/Q2 Predictions Max               1.00044
trainer/Q2 Predictions Min               0.926049
trainer/Q Targets Mean                   0.952384
trainer/Q Targets Std                    0.0238292
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92593
trainer/Log Pis Mean                     2.92809
trainer/Log Pis Std                      1.64438
trainer/Log Pis Max                      7.30465
trainer/Log Pis Min                     -1.74284
trainer/policy/mean Mean                 0.0880347
trainer/policy/mean Std                  0.685826
trainer/policy/mean Max                  0.994668
trainer/policy/mean Min                 -0.994549
trainer/policy/normal/std Mean           0.631567
trainer/policy/normal/std Std            0.214112
trainer/policy/normal/std Max            1.83342
trainer/policy/normal/std Min            0.141416
trainer/policy/normal/log_std Mean      -0.521609
trainer/policy/normal/log_std Std        0.364105
trainer/policy/normal/log_std Max        0.606184
trainer/policy/normal/log_std Min       -1.95605
trainer/Alpha                            0.000153569
trainer/Alpha Loss                      -0.631433
expl/num steps total                197000
expl/num paths total                 18315
expl/path length Mean                    3.81679
expl/path length Std                     1.70675
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.262
expl/Rewards Std                         0.439723
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0322305
expl/Actions Std                         0.756906
expl/Actions Max                         0.999482
expl/Actions Min                        -0.999699
expl/Num Paths                         262
expl/Average Returns                     1
eval/num steps total                972985
eval/num paths total                 91903
eval/path length Mean                    3.9992
eval/path length Std                     1.63242
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25005
eval/Rewards Std                         0.433042
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0171075
eval/Actions Std                         0.676294
eval/Actions Max                         0.995562
eval/Actions Min                        -0.996123
eval/Num Paths                        1250
eval/Average Returns                     1
time/data storing (s)                    0.00630655
time/evaluation sampling (s)             0.993608
time/exploration sampling (s)            0.329175
time/logging (s)                         0.0184289
time/sac training (s)                   11.8252
time/saving (s)                          0.00341784
time/training (s)                        2.229e-05
time/epoch (s)                          13.1762
time/total (s)                        2599.78
Epoch                                  195
----------------------------------  ----------------
2022-09-09 20:36:25.735685 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 196 finished
----------------------------------  ----------------
epoch                                  196
replay_buffer/size                  198000
trainer/num train calls             197000
trainer/QF1 Loss                         8.94726e-07
trainer/QF2 Loss                         1.64953e-06
trainer/Policy Loss                     -0.958092
trainer/Q1 Predictions Mean              0.952422
trainer/Q1 Predictions Std               0.0247946
trainer/Q1 Predictions Max               1.00178
trainer/Q1 Predictions Min               0.924935
trainer/Q2 Predictions Mean              0.952886
trainer/Q2 Predictions Std               0.0245181
trainer/Q2 Predictions Max               1.0016
trainer/Q2 Predictions Min               0.925251
trainer/Q Targets Mean                   0.952557
trainer/Q Targets Std                    0.0246308
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92607
trainer/Log Pis Mean                     3.04994
trainer/Log Pis Std                      1.81965
trainer/Log Pis Max                      7.25174
trainer/Log Pis Min                     -3.88537
trainer/policy/mean Mean                 0.0695852
trainer/policy/mean Std                  0.697446
trainer/policy/mean Max                  0.994427
trainer/policy/mean Min                 -0.993927
trainer/policy/normal/std Mean           0.606787
trainer/policy/normal/std Std            0.211212
trainer/policy/normal/std Max            1.44707
trainer/policy/normal/std Min            0.118161
trainer/policy/normal/log_std Mean      -0.566248
trainer/policy/normal/log_std Std        0.379135
trainer/policy/normal/log_std Max        0.369541
trainer/policy/normal/log_std Min       -2.13571
trainer/Alpha                            0.000151235
trainer/Alpha Loss                       0.439274
expl/num steps total                198000
expl/num paths total                 18560
expl/path length Mean                    4.08163
expl/path length Std                     1.66153
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.244
expl/Rewards Std                         0.429493
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995918
expl/Returns Std                         0.0637571
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0243348
expl/Actions Std                         0.754701
expl/Actions Max                         0.999402
expl/Actions Min                        -0.999727
expl/Num Paths                         245
expl/Average Returns                     0.995918
eval/num steps total                977984
eval/num paths total                 93172
eval/path length Mean                    3.93932
eval/path length Std                     1.7016
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253851
eval/Rewards Std                         0.435213
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.016265
eval/Actions Std                         0.675917
eval/Actions Max                         0.99589
eval/Actions Min                        -0.994868
eval/Num Paths                        1269
eval/Average Returns                     1
time/data storing (s)                    0.00633379
time/evaluation sampling (s)             0.996541
time/exploration sampling (s)            0.327249
time/logging (s)                         0.0189889
time/sac training (s)                   12.2465
time/saving (s)                          0.00487521
time/training (s)                        3.109e-05
time/epoch (s)                          13.6006
time/total (s)                        2613.68
Epoch                                  196
----------------------------------  ----------------
2022-09-09 20:36:39.701926 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 197 finished
----------------------------------  ----------------
epoch                                  197
replay_buffer/size                  199000
trainer/num train calls             198000
trainer/QF1 Loss                         3.11996e-06
trainer/QF2 Loss                         5.55765e-06
trainer/Policy Loss                     -0.956231
trainer/Q1 Predictions Mean              0.950894
trainer/Q1 Predictions Std               0.0235774
trainer/Q1 Predictions Max               1.00069
trainer/Q1 Predictions Min               0.925143
trainer/Q2 Predictions Mean              0.950397
trainer/Q2 Predictions Std               0.0235693
trainer/Q2 Predictions Max               0.999814
trainer/Q2 Predictions Min               0.923721
trainer/Q Targets Mean                   0.952321
trainer/Q Targets Std                    0.0235563
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.926496
trainer/Log Pis Mean                     3.10855
trainer/Log Pis Std                      1.62119
trainer/Log Pis Max                      7.34366
trainer/Log Pis Min                     -3.54881
trainer/policy/mean Mean                 0.0819946
trainer/policy/mean Std                  0.682035
trainer/policy/mean Max                  0.995294
trainer/policy/mean Min                 -0.995533
trainer/policy/normal/std Mean           0.617791
trainer/policy/normal/std Std            0.222996
trainer/policy/normal/std Max            2.39346
trainer/policy/normal/std Min            0.126313
trainer/policy/normal/log_std Mean      -0.548485
trainer/policy/normal/log_std Std        0.375561
trainer/policy/normal/log_std Max        0.87274
trainer/policy/normal/log_std Min       -2.069
trainer/Alpha                            0.000151804
trainer/Alpha Loss                       0.954456
expl/num steps total                199000
expl/num paths total                 18812
expl/path length Mean                    3.96825
expl/path length Std                     1.59332
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996032
expl/Returns Std                         0.062869
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0127042
expl/Actions Std                         0.757883
expl/Actions Max                         0.999818
expl/Actions Min                        -0.999869
expl/Num Paths                         252
expl/Average Returns                     0.996032
eval/num steps total                982984
eval/num paths total                 94437
eval/path length Mean                    3.95257
eval/path length Std                     1.69565
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253
eval/Rewards Std                         0.434731
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00769261
eval/Actions Std                         0.674748
eval/Actions Max                         0.996032
eval/Actions Min                        -0.996546
eval/Num Paths                        1265
eval/Average Returns                     1
time/data storing (s)                    0.00403443
time/evaluation sampling (s)             1.08941
time/exploration sampling (s)            0.342789
time/logging (s)                         0.0200794
time/sac training (s)                   12.2041
time/saving (s)                          0.00356681
time/training (s)                        1.969e-05
time/epoch (s)                          13.664
time/total (s)                        2627.63
Epoch                                  197
----------------------------------  ----------------
2022-09-09 20:36:53.204744 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 198 finished
----------------------------------  ----------------
epoch                                  198
replay_buffer/size                  200000
trainer/num train calls             199000
trainer/QF1 Loss                         8.43408e-07
trainer/QF2 Loss                         2.31472e-06
trainer/Policy Loss                     -0.957706
trainer/Q1 Predictions Mean              0.952909
trainer/Q1 Predictions Std               0.023972
trainer/Q1 Predictions Max               1.00142
trainer/Q1 Predictions Min               0.926229
trainer/Q2 Predictions Mean              0.95195
trainer/Q2 Predictions Std               0.0239789
trainer/Q2 Predictions Max               1.00107
trainer/Q2 Predictions Min               0.92471
trainer/Q Targets Mean                   0.952672
trainer/Q Targets Std                    0.0238728
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.926134
trainer/Log Pis Mean                     2.9121
trainer/Log Pis Std                      1.82577
trainer/Log Pis Max                      6.98514
trainer/Log Pis Min                     -4.09177
trainer/policy/mean Mean                 0.0846303
trainer/policy/mean Std                  0.679545
trainer/policy/mean Max                  0.994579
trainer/policy/mean Min                 -0.99646
trainer/policy/normal/std Mean           0.610312
trainer/policy/normal/std Std            0.196007
trainer/policy/normal/std Max            1.20538
trainer/policy/normal/std Min            0.120407
trainer/policy/normal/log_std Mean      -0.551582
trainer/policy/normal/log_std Std        0.354055
trainer/policy/normal/log_std Max        0.186793
trainer/policy/normal/log_std Min       -2.11688
trainer/Alpha                            0.000151293
trainer/Alpha Loss                      -0.773171
expl/num steps total                200000
expl/num paths total                 19067
expl/path length Mean                    3.92157
expl/path length Std                     1.72914
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.254
expl/Rewards Std                         0.435298
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996078
expl/Returns Std                         0.0624995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0122207
expl/Actions Std                         0.760515
expl/Actions Max                         0.999709
expl/Actions Min                        -0.999643
expl/Num Paths                         255
expl/Average Returns                     0.996078
eval/num steps total                987984
eval/num paths total                 95730
eval/path length Mean                    3.86698
eval/path length Std                     1.72761
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2586
eval/Rewards Std                         0.437865
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00713083
eval/Actions Std                         0.671912
eval/Actions Max                         0.995974
eval/Actions Min                        -0.997065
eval/Num Paths                        1293
eval/Average Returns                     1
time/data storing (s)                    0.00640191
time/evaluation sampling (s)             0.976876
time/exploration sampling (s)            0.312071
time/logging (s)                         0.0181607
time/sac training (s)                   11.8938
time/saving (s)                          0.00365128
time/training (s)                        1.904e-05
time/epoch (s)                          13.211
time/total (s)                        2641.12
Epoch                                  198
----------------------------------  ----------------
2022-09-09 20:37:07.101962 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 199 finished
----------------------------------  ----------------
epoch                                  199
replay_buffer/size                  201000
trainer/num train calls             200000
trainer/QF1 Loss                         7.03782e-06
trainer/QF2 Loss                         1.2399e-06
trainer/Policy Loss                     -0.955298
trainer/Q1 Predictions Mean              0.949291
trainer/Q1 Predictions Std               0.0235663
trainer/Q1 Predictions Max               0.997046
trainer/Q1 Predictions Min               0.921933
trainer/Q2 Predictions Mean              0.95152
trainer/Q2 Predictions Std               0.0238073
trainer/Q2 Predictions Max               1.00091
trainer/Q2 Predictions Min               0.925039
trainer/Q Targets Mean                   0.951788
trainer/Q Targets Std                    0.0238046
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.926001
trainer/Log Pis Mean                     3.08982
trainer/Log Pis Std                      1.6893
trainer/Log Pis Max                      7.40143
trainer/Log Pis Min                     -2.64344
trainer/policy/mean Mean                 0.0858936
trainer/policy/mean Std                  0.678302
trainer/policy/mean Max                  0.995552
trainer/policy/mean Min                 -0.995669
trainer/policy/normal/std Mean           0.613157
trainer/policy/normal/std Std            0.207519
trainer/policy/normal/std Max            1.35193
trainer/policy/normal/std Min            0.151045
trainer/policy/normal/log_std Mean      -0.552595
trainer/policy/normal/log_std Std        0.369969
trainer/policy/normal/log_std Max        0.301531
trainer/policy/normal/log_std Min       -1.89018
trainer/Alpha                            0.000151504
trainer/Alpha Loss                       0.789991
expl/num steps total                201000
expl/num paths total                 19323
expl/path length Mean                    3.90625
expl/path length Std                     1.69299
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.255
expl/Rewards Std                         0.435861
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996094
expl/Returns Std                         0.0623778
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00574896
expl/Actions Std                         0.75605
expl/Actions Max                         0.999718
expl/Actions Min                        -0.999679
expl/Num Paths                         256
expl/Average Returns                     0.996094
eval/num steps total                992983
eval/num paths total                 96993
eval/path length Mean                    3.95804
eval/path length Std                     1.6983
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252651
eval/Rewards Std                         0.434532
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00715167
eval/Actions Std                         0.666677
eval/Actions Max                         0.996748
eval/Actions Min                        -0.996649
eval/Num Paths                        1263
eval/Average Returns                     1
time/data storing (s)                    0.00615539
time/evaluation sampling (s)             1.00181
time/exploration sampling (s)            0.315049
time/logging (s)                         0.0186895
time/sac training (s)                   12.2366
time/saving (s)                          0.00379071
time/training (s)                        2.095e-05
time/epoch (s)                          13.5821
time/total (s)                        2655.01
Epoch                                  199
----------------------------------  ----------------
2022-09-09 20:37:20.911560 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 200 finished
----------------------------------  ----------------
epoch                                  200
replay_buffer/size                  202000
trainer/num train calls             201000
trainer/QF1 Loss                         1.00156e-06
trainer/QF2 Loss                         4.06669e-06
trainer/Policy Loss                     -0.958869
trainer/Q1 Predictions Mean              0.954514
trainer/Q1 Predictions Std               0.0256705
trainer/Q1 Predictions Max               1.00027
trainer/Q1 Predictions Min               0.925586
trainer/Q2 Predictions Mean              0.953366
trainer/Q2 Predictions Std               0.0252991
trainer/Q2 Predictions Max               1.00064
trainer/Q2 Predictions Min               0.924004
trainer/Q Targets Mean                   0.95493
trainer/Q Targets Std                    0.025579
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927037
trainer/Log Pis Mean                     2.86089
trainer/Log Pis Std                      1.71637
trainer/Log Pis Max                      8.06266
trainer/Log Pis Min                     -2.22076
trainer/policy/mean Mean                 0.0762164
trainer/policy/mean Std                  0.679654
trainer/policy/mean Max                  0.995002
trainer/policy/mean Min                 -0.995274
trainer/policy/normal/std Mean           0.597738
trainer/policy/normal/std Std            0.208711
trainer/policy/normal/std Max            1.25569
trainer/policy/normal/std Min            0.107847
trainer/policy/normal/log_std Mean      -0.583695
trainer/policy/normal/log_std Std        0.388855
trainer/policy/normal/log_std Max        0.227687
trainer/policy/normal/log_std Min       -2.22704
trainer/Alpha                            0.000149232
trainer/Alpha Loss                      -1.22552
expl/num steps total                202000
expl/num paths total                 19582
expl/path length Mean                    3.861
expl/path length Std                     1.70735
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.259
expl/Rewards Std                         0.438086
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.020117
expl/Actions Std                         0.756627
expl/Actions Max                         0.999377
expl/Actions Min                        -0.999775
expl/Num Paths                         259
expl/Average Returns                     1
eval/num steps total                997982
eval/num paths total                 98255
eval/path length Mean                    3.96117
eval/path length Std                     1.6817
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25245
eval/Rewards Std                         0.434418
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0370368
eval/Actions Std                         0.675839
eval/Actions Max                         0.99683
eval/Actions Min                        -0.995083
eval/Num Paths                        1262
eval/Average Returns                     1
time/data storing (s)                    0.00408215
time/evaluation sampling (s)             0.978935
time/exploration sampling (s)            0.310879
time/logging (s)                         0.0194949
time/sac training (s)                   12.1931
time/saving (s)                          0.00469804
time/training (s)                        2.483e-05
time/epoch (s)                          13.5112
time/total (s)                        2668.81
Epoch                                  200
----------------------------------  ----------------
2022-09-09 20:37:34.678100 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 201 finished
----------------------------------  ----------------
epoch                                  201
replay_buffer/size                  203000
trainer/num train calls             202000
trainer/QF1 Loss                         6.80467e-07
trainer/QF2 Loss                         2.33896e-06
trainer/Policy Loss                     -0.956674
trainer/Q1 Predictions Mean              0.95043
trainer/Q1 Predictions Std               0.023153
trainer/Q1 Predictions Max               1.00174
trainer/Q1 Predictions Min               0.926812
trainer/Q2 Predictions Mean              0.950942
trainer/Q2 Predictions Std               0.0230155
trainer/Q2 Predictions Max               1.00207
trainer/Q2 Predictions Min               0.925951
trainer/Q Targets Mean                   0.95009
trainer/Q Targets Std                    0.023245
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.926391
trainer/Log Pis Mean                     2.90602
trainer/Log Pis Std                      1.7042
trainer/Log Pis Max                      7.23533
trainer/Log Pis Min                     -2.26564
trainer/policy/mean Mean                 0.0814122
trainer/policy/mean Std                  0.687147
trainer/policy/mean Max                  0.995366
trainer/policy/mean Min                 -0.995268
trainer/policy/normal/std Mean           0.636388
trainer/policy/normal/std Std            0.194445
trainer/policy/normal/std Max            1.18282
trainer/policy/normal/std Min            0.139739
trainer/policy/normal/log_std Mean      -0.503401
trainer/policy/normal/log_std Std        0.332132
trainer/policy/normal/log_std Max        0.167898
trainer/policy/normal/log_std Min       -1.96798
trainer/Alpha                            0.000150717
trainer/Alpha Loss                      -0.827022
expl/num steps total                203000
expl/num paths total                 19833
expl/path length Mean                    3.98406
expl/path length Std                     1.71464
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.25
expl/Rewards Std                         0.433013
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996016
expl/Returns Std                         0.0629936
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00462668
expl/Actions Std                         0.760659
expl/Actions Max                         0.999642
expl/Actions Min                        -0.999662
expl/Num Paths                         251
expl/Average Returns                     0.996016
eval/num steps total                     1.00298e+06
eval/num paths total                 99525
eval/path length Mean                    3.93465
eval/path length Std                     1.72786
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254152
eval/Rewards Std                         0.435384
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0303505
eval/Actions Std                         0.673805
eval/Actions Max                         0.997004
eval/Actions Min                        -0.995977
eval/Num Paths                        1270
eval/Average Returns                     1
time/data storing (s)                    0.00414303
time/evaluation sampling (s)             1.00458
time/exploration sampling (s)            0.320251
time/logging (s)                         0.0188606
time/sac training (s)                   12.1055
time/saving (s)                          0.00482372
time/training (s)                        2.93e-05
time/epoch (s)                          13.4582
time/total (s)                        2682.56
Epoch                                  201
----------------------------------  ----------------
2022-09-09 20:37:48.896163 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 202 finished
----------------------------------  ----------------
epoch                                  202
replay_buffer/size                  204000
trainer/num train calls             203000
trainer/QF1 Loss                         1.13572e-06
trainer/QF2 Loss                         2.911e-06
trainer/Policy Loss                     -0.960822
trainer/Q1 Predictions Mean              0.955417
trainer/Q1 Predictions Std               0.0256551
trainer/Q1 Predictions Max               1.00167
trainer/Q1 Predictions Min               0.926167
trainer/Q2 Predictions Mean              0.956163
trainer/Q2 Predictions Std               0.0252874
trainer/Q2 Predictions Max               1.00335
trainer/Q2 Predictions Min               0.924907
trainer/Q Targets Mean                   0.955846
trainer/Q Targets Std                    0.0253787
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.926924
trainer/Log Pis Mean                     3.00907
trainer/Log Pis Std                      1.97938
trainer/Log Pis Max                      8.58752
trainer/Log Pis Min                     -3.79286
trainer/policy/mean Mean                 0.0610869
trainer/policy/mean Std                  0.701855
trainer/policy/mean Max                  0.996673
trainer/policy/mean Min                 -0.994796
trainer/policy/normal/std Mean           0.609573
trainer/policy/normal/std Std            0.195274
trainer/policy/normal/std Max            1.4497
trainer/policy/normal/std Min            0.138907
trainer/policy/normal/log_std Mean      -0.552428
trainer/policy/normal/log_std Std        0.352842
trainer/policy/normal/log_std Max        0.371354
trainer/policy/normal/log_std Min       -1.97395
trainer/Alpha                            0.000148144
trainer/Alpha Loss                       0.0799811
expl/num steps total                204000
expl/num paths total                 20079
expl/path length Mean                    4.06504
expl/path length Std                     1.78403
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.245
expl/Rewards Std                         0.430087
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995935
expl/Returns Std                         0.063628
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00730268
expl/Actions Std                         0.757503
expl/Actions Max                         0.999654
expl/Actions Min                        -0.999574
expl/Num Paths                         246
expl/Average Returns                     0.995935
eval/num steps total                     1.00798e+06
eval/num paths total                100793
eval/path length Mean                    3.94085
eval/path length Std                     1.69164
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253752
eval/Rewards Std                         0.435157
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0205302
eval/Actions Std                         0.682976
eval/Actions Max                         0.99686
eval/Actions Min                        -0.995976
eval/Num Paths                        1268
eval/Average Returns                     1
time/data storing (s)                    0.00563833
time/evaluation sampling (s)             0.985127
time/exploration sampling (s)            0.439931
time/logging (s)                         0.0183627
time/sac training (s)                   12.4335
time/saving (s)                          0.00347834
time/training (s)                        2.132e-05
time/epoch (s)                          13.8861
time/total (s)                        2696.76
Epoch                                  202
----------------------------------  ----------------
2022-09-09 20:38:02.572403 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 203 finished
----------------------------------  ----------------
epoch                                  203
replay_buffer/size                  205000
trainer/num train calls             204000
trainer/QF1 Loss                         7.91324e-07
trainer/QF2 Loss                         3.28905e-06
trainer/Policy Loss                     -0.959674
trainer/Q1 Predictions Mean              0.955371
trainer/Q1 Predictions Std               0.0253893
trainer/Q1 Predictions Max               1.00113
trainer/Q1 Predictions Min               0.926333
trainer/Q2 Predictions Mean              0.954334
trainer/Q2 Predictions Std               0.0253969
trainer/Q2 Predictions Max               0.999666
trainer/Q2 Predictions Min               0.924457
trainer/Q Targets Mean                   0.955492
trainer/Q Targets Std                    0.0253064
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.926239
trainer/Log Pis Mean                     3.08227
trainer/Log Pis Std                      1.606
trainer/Log Pis Max                      6.94152
trainer/Log Pis Min                     -4.17227
trainer/policy/mean Mean                 0.0449745
trainer/policy/mean Std                  0.683444
trainer/policy/mean Max                  0.996201
trainer/policy/mean Min                 -0.995717
trainer/policy/normal/std Mean           0.597159
trainer/policy/normal/std Std            0.203132
trainer/policy/normal/std Max            1.00716
trainer/policy/normal/std Min            0.151797
trainer/policy/normal/log_std Mean      -0.579851
trainer/policy/normal/log_std Std        0.371455
trainer/policy/normal/log_std Max        0.0071303
trainer/policy/normal/log_std Min       -1.88521
trainer/Alpha                            0.000147323
trainer/Alpha Loss                       0.725871
expl/num steps total                205000
expl/num paths total                 20325
expl/path length Mean                    4.06504
expl/path length Std                     1.66377
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.245
expl/Rewards Std                         0.430087
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995935
expl/Returns Std                         0.063628
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0105748
expl/Actions Std                         0.7603
expl/Actions Max                         0.999781
expl/Actions Min                        -0.99973
expl/Num Paths                         246
expl/Average Returns                     0.995935
eval/num steps total                     1.01298e+06
eval/num paths total                102034
eval/path length Mean                    4.0282
eval/path length Std                     1.62921
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.24825
eval/Rewards Std                         0.431997
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0142856
eval/Actions Std                         0.670939
eval/Actions Max                         0.997063
eval/Actions Min                        -0.99685
eval/Num Paths                        1241
eval/Average Returns                     1
time/data storing (s)                    0.00467885
time/evaluation sampling (s)             0.99274
time/exploration sampling (s)            0.397796
time/logging (s)                         0.0180408
time/sac training (s)                   11.9672
time/saving (s)                          0.00470002
time/training (s)                        2.731e-05
time/epoch (s)                          13.3852
time/total (s)                        2710.43
Epoch                                  203
----------------------------------  ----------------
2022-09-09 20:38:16.187593 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 204 finished
----------------------------------  ----------------
epoch                                  204
replay_buffer/size                  206000
trainer/num train calls             205000
trainer/QF1 Loss                         2.11923e-06
trainer/QF2 Loss                         2.51329e-06
trainer/Policy Loss                     -0.960283
trainer/Q1 Predictions Mean              0.955221
trainer/Q1 Predictions Std               0.0252271
trainer/Q1 Predictions Max               1
trainer/Q1 Predictions Min               0.92614
trainer/Q2 Predictions Mean              0.955332
trainer/Q2 Predictions Std               0.025513
trainer/Q2 Predictions Max               1.00022
trainer/Q2 Predictions Min               0.925933
trainer/Q Targets Mean                   0.956444
trainer/Q Targets Std                    0.0252164
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927303
trainer/Log Pis Mean                     2.94296
trainer/Log Pis Std                      1.82829
trainer/Log Pis Max                      7.63621
trainer/Log Pis Min                     -6.50033
trainer/policy/mean Mean                 0.0981231
trainer/policy/mean Std                  0.672413
trainer/policy/mean Max                  0.995972
trainer/policy/mean Min                 -0.995467
trainer/policy/normal/std Mean           0.604943
trainer/policy/normal/std Std            0.207627
trainer/policy/normal/std Max            1.14116
trainer/policy/normal/std Min            0.149838
trainer/policy/normal/log_std Mean      -0.565631
trainer/policy/normal/log_std Std        0.3642
trainer/policy/normal/log_std Max        0.132049
trainer/policy/normal/log_std Min       -1.8982
trainer/Alpha                            0.000146135
trainer/Alpha Loss                      -0.503707
expl/num steps total                206000
expl/num paths total                 20583
expl/path length Mean                    3.87597
expl/path length Std                     1.66825
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.258
expl/Rewards Std                         0.437534
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0471623
expl/Actions Std                         0.767626
expl/Actions Max                         0.99947
expl/Actions Min                        -0.999512
expl/Num Paths                         258
expl/Average Returns                     1
eval/num steps total                     1.01797e+06
eval/num paths total                103311
eval/path length Mean                    3.91229
eval/path length Std                     1.6231
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.255604
eval/Rewards Std                         0.4362
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0286023
eval/Actions Std                         0.67279
eval/Actions Max                         0.99675
eval/Actions Min                        -0.995451
eval/Num Paths                        1277
eval/Average Returns                     1
time/data storing (s)                    0.00640836
time/evaluation sampling (s)             1.04149
time/exploration sampling (s)            0.327373
time/logging (s)                         0.0213684
time/sac training (s)                   11.9231
time/saving (s)                          0.00361986
time/training (s)                        3.5e-05
time/epoch (s)                          13.3234
time/total (s)                        2724.04
Epoch                                  204
----------------------------------  ----------------
2022-09-09 20:38:29.724117 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 205 finished
----------------------------------  ----------------
epoch                                  205
replay_buffer/size                  207000
trainer/num train calls             206000
trainer/QF1 Loss                         1.11692e-06
trainer/QF2 Loss                         2.71697e-06
trainer/Policy Loss                     -0.958948
trainer/Q1 Predictions Mean              0.953461
trainer/Q1 Predictions Std               0.0248498
trainer/Q1 Predictions Max               1.00122
trainer/Q1 Predictions Min               0.926726
trainer/Q2 Predictions Mean              0.954058
trainer/Q2 Predictions Std               0.0251129
trainer/Q2 Predictions Max               1.00268
trainer/Q2 Predictions Min               0.9267
trainer/Q Targets Mean                   0.953506
trainer/Q Targets Std                    0.0248948
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927578
trainer/Log Pis Mean                     2.83143
trainer/Log Pis Std                      1.86354
trainer/Log Pis Max                      8.04933
trainer/Log Pis Min                     -3.40747
trainer/policy/mean Mean                 0.0914874
trainer/policy/mean Std                  0.678616
trainer/policy/mean Max                  0.996065
trainer/policy/mean Min                 -0.996377
trainer/policy/normal/std Mean           0.60551
trainer/policy/normal/std Std            0.198531
trainer/policy/normal/std Max            1.38516
trainer/policy/normal/std Min            0.109388
trainer/policy/normal/log_std Mean      -0.561217
trainer/policy/normal/log_std Std        0.35789
trainer/policy/normal/log_std Max        0.325817
trainer/policy/normal/log_std Min       -2.21285
trainer/Alpha                            0.000149047
trainer/Alpha Loss                      -1.48535
expl/num steps total                207000
expl/num paths total                 20827
expl/path length Mean                    4.09836
expl/path length Std                     1.67386
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.244
expl/Rewards Std                         0.429493
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.00820849
expl/Actions Std                         0.762781
expl/Actions Max                         0.999568
expl/Actions Min                        -0.99981
expl/Num Paths                         244
expl/Average Returns                     1
eval/num steps total                     1.02297e+06
eval/num paths total                104576
eval/path length Mean                    3.9502
eval/path length Std                     1.68553
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253152
eval/Rewards Std                         0.434817
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00563115
eval/Actions Std                         0.671518
eval/Actions Max                         0.996875
eval/Actions Min                        -0.996426
eval/Num Paths                        1265
eval/Average Returns                     1
time/data storing (s)                    0.00401584
time/evaluation sampling (s)             1.08337
time/exploration sampling (s)            0.330134
time/logging (s)                         0.0210059
time/sac training (s)                   11.8027
time/saving (s)                          0.00371632
time/training (s)                        1.936e-05
time/epoch (s)                          13.245
time/total (s)                        2737.56
Epoch                                  205
----------------------------------  ----------------
2022-09-09 20:38:44.221689 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 206 finished
----------------------------------  ----------------
epoch                                  206
replay_buffer/size                  208000
trainer/num train calls             207000
trainer/QF1 Loss                         1.10916e-06
trainer/QF2 Loss                         1.54261e-06
trainer/Policy Loss                     -0.959185
trainer/Q1 Predictions Mean              0.953934
trainer/Q1 Predictions Std               0.0248861
trainer/Q1 Predictions Max               1.00215
trainer/Q1 Predictions Min               0.926372
trainer/Q2 Predictions Mean              0.953762
trainer/Q2 Predictions Std               0.0243923
trainer/Q2 Predictions Max               1.00121
trainer/Q2 Predictions Min               0.926994
trainer/Q Targets Mean                   0.953627
trainer/Q Targets Std                    0.0245228
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.926714
trainer/Log Pis Mean                     2.95832
trainer/Log Pis Std                      1.79033
trainer/Log Pis Max                      8.58872
trainer/Log Pis Min                     -1.9929
trainer/policy/mean Mean                 0.0977835
trainer/policy/mean Std                  0.677937
trainer/policy/mean Max                  0.995395
trainer/policy/mean Min                 -0.995904
trainer/policy/normal/std Mean           0.597895
trainer/policy/normal/std Std            0.200665
trainer/policy/normal/std Max            1.09477
trainer/policy/normal/std Min            0.136056
trainer/policy/normal/log_std Mean      -0.57643
trainer/policy/normal/log_std Std        0.364657
trainer/policy/normal/log_std Max        0.0905432
trainer/policy/normal/log_std Min       -1.99469
trainer/Alpha                            0.00014655
trainer/Alpha Loss                      -0.367957
expl/num steps total                208000
expl/num paths total                 21081
expl/path length Mean                    3.93701
expl/path length Std                     1.7057
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.253
expl/Rewards Std                         0.434731
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996063
expl/Returns Std                         0.0626219
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0115575
expl/Actions Std                         0.762351
expl/Actions Max                         0.999815
expl/Actions Min                        -0.999614
expl/Num Paths                         254
expl/Average Returns                     0.996063
eval/num steps total                     1.02797e+06
eval/num paths total                105846
eval/path length Mean                    3.93543
eval/path length Std                     1.66736
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254102
eval/Rewards Std                         0.435355
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00888757
eval/Actions Std                         0.670969
eval/Actions Max                         0.996658
eval/Actions Min                        -0.996656
eval/Num Paths                        1270
eval/Average Returns                     1
time/data storing (s)                    0.00540681
time/evaluation sampling (s)             0.995927
time/exploration sampling (s)            0.326584
time/logging (s)                         0.0182475
time/sac training (s)                   12.7962
time/saving (s)                          0.00358369
time/training (s)                        2.05e-05
time/epoch (s)                          14.146
time/total (s)                        2752.04
Epoch                                  206
----------------------------------  ----------------
2022-09-09 20:38:58.127018 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 207 finished
----------------------------------  ----------------
epoch                                  207
replay_buffer/size                  209000
trainer/num train calls             208000
trainer/QF1 Loss                         6.45115e-07
trainer/QF2 Loss                         3.88592e-06
trainer/Policy Loss                     -0.959192
trainer/Q1 Predictions Mean              0.95354
trainer/Q1 Predictions Std               0.0248366
trainer/Q1 Predictions Max               1.00081
trainer/Q1 Predictions Min               0.927219
trainer/Q2 Predictions Mean              0.95461
trainer/Q2 Predictions Std               0.0248642
trainer/Q2 Predictions Max               1.00216
trainer/Q2 Predictions Min               0.926644
trainer/Q Targets Mean                   0.95344
trainer/Q Targets Std                    0.0249951
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927136
trainer/Log Pis Mean                     3.08321
trainer/Log Pis Std                      1.89788
trainer/Log Pis Max                      7.56995
trainer/Log Pis Min                     -5.58128
trainer/policy/mean Mean                 0.0625183
trainer/policy/mean Std                  0.698696
trainer/policy/mean Max                  0.995434
trainer/policy/mean Min                 -0.9952
trainer/policy/normal/std Mean           0.609082
trainer/policy/normal/std Std            0.191457
trainer/policy/normal/std Max            1.3517
trainer/policy/normal/std Min            0.129941
trainer/policy/normal/log_std Mean      -0.550291
trainer/policy/normal/log_std Std        0.34236
trainer/policy/normal/log_std Max        0.30136
trainer/policy/normal/log_std Min       -2.04068
trainer/Alpha                            0.000146803
trainer/Alpha Loss                       0.734454
expl/num steps total                209000
expl/num paths total                 21334
expl/path length Mean                    3.95257
expl/path length Std                     1.68864
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.252
expl/Rewards Std                         0.434161
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996047
expl/Returns Std                         0.0627451
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0116806
expl/Actions Std                         0.757402
expl/Actions Max                         0.999805
expl/Actions Min                        -0.999483
expl/Num Paths                         253
expl/Average Returns                     0.996047
eval/num steps total                     1.03296e+06
eval/num paths total                107109
eval/path length Mean                    3.95724
eval/path length Std                     1.71013
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252701
eval/Rewards Std                         0.434561
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0328102
eval/Actions Std                         0.671215
eval/Actions Max                         0.996976
eval/Actions Min                        -0.995397
eval/Num Paths                        1263
eval/Average Returns                     1
time/data storing (s)                    0.00620283
time/evaluation sampling (s)             0.977741
time/exploration sampling (s)            0.335153
time/logging (s)                         0.0261019
time/sac training (s)                   12.2592
time/saving (s)                          0.00384142
time/training (s)                        2.147e-05
time/epoch (s)                          13.6082
time/total (s)                        2765.94
Epoch                                  207
----------------------------------  ----------------
2022-09-09 20:39:12.549652 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 208 finished
----------------------------------  ----------------
epoch                                  208
replay_buffer/size                  210000
trainer/num train calls             209000
trainer/QF1 Loss                         9.71072e-07
trainer/QF2 Loss                         4.07459e-06
trainer/Policy Loss                     -0.959024
trainer/Q1 Predictions Mean              0.954626
trainer/Q1 Predictions Std               0.0256071
trainer/Q1 Predictions Max               0.999331
trainer/Q1 Predictions Min               0.926948
trainer/Q2 Predictions Mean              0.953573
trainer/Q2 Predictions Std               0.0258007
trainer/Q2 Predictions Max               1.00016
trainer/Q2 Predictions Min               0.925309
trainer/Q Targets Mean                   0.955219
trainer/Q Targets Std                    0.0260133
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92724
trainer/Log Pis Mean                     3.08191
trainer/Log Pis Std                      1.90786
trainer/Log Pis Max                      8.17057
trainer/Log Pis Min                     -3.70235
trainer/policy/mean Mean                 0.0502079
trainer/policy/mean Std                  0.693072
trainer/policy/mean Max                  0.99524
trainer/policy/mean Min                 -0.996944
trainer/policy/normal/std Mean           0.593875
trainer/policy/normal/std Std            0.202213
trainer/policy/normal/std Max            1.26928
trainer/policy/normal/std Min            0.157914
trainer/policy/normal/log_std Mean      -0.584234
trainer/policy/normal/log_std Std        0.366435
trainer/policy/normal/log_std Max        0.238453
trainer/policy/normal/log_std Min       -1.8457
trainer/Alpha                            0.000146971
trainer/Alpha Loss                       0.722882
expl/num steps total                210000
expl/num paths total                 21610
expl/path length Mean                    3.62319
expl/path length Std                     1.65373
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.275
expl/Rewards Std                         0.446514
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996377
expl/Returns Std                         0.0600838
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0191542
expl/Actions Std                         0.75826
expl/Actions Max                         0.999361
expl/Actions Min                        -0.999474
expl/Num Paths                         276
expl/Average Returns                     0.996377
eval/num steps total                     1.03796e+06
eval/num paths total                108385
eval/path length Mean                    3.91536
eval/path length Std                     1.70993
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.255404
eval/Rewards Std                         0.436088
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0111991
eval/Actions Std                         0.67748
eval/Actions Max                         0.996472
eval/Actions Min                        -0.997172
eval/Num Paths                        1276
eval/Average Returns                     1
time/data storing (s)                    0.00631102
time/evaluation sampling (s)             0.984876
time/exploration sampling (s)            0.333453
time/logging (s)                         0.0187157
time/sac training (s)                   12.7073
time/saving (s)                          0.00465837
time/training (s)                        2.819e-05
time/epoch (s)                          14.0553
time/total (s)                        2780.34
Epoch                                  208
----------------------------------  ----------------
2022-09-09 20:39:26.070671 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 209 finished
----------------------------------  ----------------
epoch                                  209
replay_buffer/size                  211000
trainer/num train calls             210000
trainer/QF1 Loss                         7.85679e-07
trainer/QF2 Loss                         2.9678e-06
trainer/Policy Loss                     -0.959597
trainer/Q1 Predictions Mean              0.955308
trainer/Q1 Predictions Std               0.0244742
trainer/Q1 Predictions Max               1.00059
trainer/Q1 Predictions Min               0.927403
trainer/Q2 Predictions Mean              0.954426
trainer/Q2 Predictions Std               0.0243884
trainer/Q2 Predictions Max               1.00113
trainer/Q2 Predictions Min               0.925953
trainer/Q Targets Mean                   0.954956
trainer/Q Targets Std                    0.0243998
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927326
trainer/Log Pis Mean                     2.88234
trainer/Log Pis Std                      1.89851
trainer/Log Pis Max                      7.4935
trainer/Log Pis Min                     -3.0549
trainer/policy/mean Mean                 0.11473
trainer/policy/mean Std                  0.679974
trainer/policy/mean Max                  0.99541
trainer/policy/mean Min                 -0.995554
trainer/policy/normal/std Mean           0.608849
trainer/policy/normal/std Std            0.19608
trainer/policy/normal/std Max            1.20311
trainer/policy/normal/std Min            0.166444
trainer/policy/normal/log_std Mean      -0.551334
trainer/policy/normal/log_std Std        0.33965
trainer/policy/normal/log_std Max        0.184909
trainer/policy/normal/log_std Min       -1.7931
trainer/Alpha                            0.00014638
trainer/Alpha Loss                      -1.03883
expl/num steps total                211000
expl/num paths total                 21865
expl/path length Mean                    3.92157
expl/path length Std                     1.7246
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.254
expl/Rewards Std                         0.435298
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996078
expl/Returns Std                         0.0624995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0333292
expl/Actions Std                         0.75381
expl/Actions Max                         0.999606
expl/Actions Min                        -0.999766
expl/Num Paths                         255
expl/Average Returns                     0.996078
eval/num steps total                     1.04296e+06
eval/num paths total                109644
eval/path length Mean                    3.97061
eval/path length Std                     1.69049
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25185
eval/Rewards Std                         0.434076
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0474717
eval/Actions Std                         0.67248
eval/Actions Max                         0.996547
eval/Actions Min                        -0.994769
eval/Num Paths                        1259
eval/Average Returns                     1
time/data storing (s)                    0.00615624
time/evaluation sampling (s)             0.984375
time/exploration sampling (s)            0.317979
time/logging (s)                         0.0194454
time/sac training (s)                   11.8877
time/saving (s)                          0.00510445
time/training (s)                        4.236e-05
time/epoch (s)                          13.2208
time/total (s)                        2793.85
Epoch                                  209
----------------------------------  ----------------
2022-09-09 20:39:40.027741 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 210 finished
----------------------------------  ----------------
epoch                                  210
replay_buffer/size                  212000
trainer/num train calls             211000
trainer/QF1 Loss                         1.08412e-06
trainer/QF2 Loss                         2.10825e-06
trainer/Policy Loss                     -0.960642
trainer/Q1 Predictions Mean              0.955684
trainer/Q1 Predictions Std               0.0255636
trainer/Q1 Predictions Max               1.00153
trainer/Q1 Predictions Min               0.927101
trainer/Q2 Predictions Mean              0.955807
trainer/Q2 Predictions Std               0.025174
trainer/Q2 Predictions Max               1.00151
trainer/Q2 Predictions Min               0.927088
trainer/Q Targets Mean                   0.95551
trainer/Q Targets Std                    0.0255579
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927279
trainer/Log Pis Mean                     3.02828
trainer/Log Pis Std                      1.76746
trainer/Log Pis Max                      7.71864
trainer/Log Pis Min                     -3.56834
trainer/policy/mean Mean                 0.111086
trainer/policy/mean Std                  0.68417
trainer/policy/mean Max                  0.995957
trainer/policy/mean Min                 -0.995704
trainer/policy/normal/std Mean           0.592259
trainer/policy/normal/std Std            0.187819
trainer/policy/normal/std Max            1.25493
trainer/policy/normal/std Min            0.158233
trainer/policy/normal/log_std Mean      -0.578267
trainer/policy/normal/log_std Std        0.339819
trainer/policy/normal/log_std Max        0.227083
trainer/policy/normal/log_std Min       -1.84369
trainer/Alpha                            0.000145433
trainer/Alpha Loss                       0.249912
expl/num steps total                212000
expl/num paths total                 22115
expl/path length Mean                    4
expl/path length Std                     1.76409
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996
expl/Returns Std                         0.0631189
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0184121
expl/Actions Std                         0.757024
expl/Actions Max                         0.999494
expl/Actions Min                        -0.999652
expl/Num Paths                         250
expl/Average Returns                     0.996
eval/num steps total                     1.04796e+06
eval/num paths total                110935
eval/path length Mean                    3.87142
eval/path length Std                     1.6719
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.258303
eval/Rewards Std                         0.437702
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0219067
eval/Actions Std                         0.671003
eval/Actions Max                         0.99649
eval/Actions Min                        -0.99741
eval/Num Paths                        1291
eval/Average Returns                     1
time/data storing (s)                    0.00622949
time/evaluation sampling (s)             0.983271
time/exploration sampling (s)            0.376126
time/logging (s)                         0.0223588
time/sac training (s)                   12.2459
time/saving (s)                          0.00421916
time/training (s)                        2.751e-05
time/epoch (s)                          13.6381
time/total (s)                        2807.8
Epoch                                  210
----------------------------------  ----------------
2022-09-09 20:39:53.703263 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 211 finished
----------------------------------  ----------------
epoch                                  211
replay_buffer/size                  213000
trainer/num train calls             212000
trainer/QF1 Loss                         7.79044e-07
trainer/QF2 Loss                         3.72389e-06
trainer/Policy Loss                     -0.959411
trainer/Q1 Predictions Mean              0.95388
trainer/Q1 Predictions Std               0.0247129
trainer/Q1 Predictions Max               1.00057
trainer/Q1 Predictions Min               0.926663
trainer/Q2 Predictions Mean              0.955679
trainer/Q2 Predictions Std               0.0244611
trainer/Q2 Predictions Max               1.00355
trainer/Q2 Predictions Min               0.929199
trainer/Q Targets Mean                   0.954286
trainer/Q Targets Std                    0.0247507
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.926936
trainer/Log Pis Mean                     3.31358
trainer/Log Pis Std                      1.72988
trainer/Log Pis Max                      8.11945
trainer/Log Pis Min                     -2.28005
trainer/policy/mean Mean                 0.145777
trainer/policy/mean Std                  0.676426
trainer/policy/mean Max                  0.995833
trainer/policy/mean Min                 -0.996261
trainer/policy/normal/std Mean           0.601032
trainer/policy/normal/std Std            0.193262
trainer/policy/normal/std Max            1.33662
trainer/policy/normal/std Min            0.115264
trainer/policy/normal/log_std Mean      -0.565126
trainer/policy/normal/log_std Std        0.346053
trainer/policy/normal/log_std Max        0.290141
trainer/policy/normal/log_std Min       -2.16053
trainer/Alpha                            0.000145447
trainer/Alpha Loss                       2.7707
expl/num steps total                213000
expl/num paths total                 22360
expl/path length Mean                    4.08163
expl/path length Std                     1.67864
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.244
expl/Rewards Std                         0.429493
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995918
expl/Returns Std                         0.0637571
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0477296
expl/Actions Std                         0.75869
expl/Actions Max                         0.999618
expl/Actions Min                        -0.999721
expl/Num Paths                         245
expl/Average Returns                     0.995918
eval/num steps total                     1.05296e+06
eval/num paths total                112173
eval/path length Mean                    4.03716
eval/path length Std                     1.67474
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.247699
eval/Rewards Std                         0.431676
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00574758
eval/Actions Std                         0.676519
eval/Actions Max                         0.996513
eval/Actions Min                        -0.997172
eval/Num Paths                        1238
eval/Average Returns                     1
time/data storing (s)                    0.00636872
time/evaluation sampling (s)             1.02779
time/exploration sampling (s)            0.32913
time/logging (s)                         0.0203285
time/sac training (s)                   11.9779
time/saving (s)                          0.00373205
time/training (s)                        2.584e-05
time/epoch (s)                          13.3652
time/total (s)                        2821.46
Epoch                                  211
----------------------------------  ----------------
2022-09-09 20:40:07.387408 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 212 finished
----------------------------------  ----------------
epoch                                  212
replay_buffer/size                  214000
trainer/num train calls             213000
trainer/QF1 Loss                         1.26838e-06
trainer/QF2 Loss                         2.77202e-06
trainer/Policy Loss                     -0.958562
trainer/Q1 Predictions Mean              0.953361
trainer/Q1 Predictions Std               0.0240461
trainer/Q1 Predictions Max               1.00019
trainer/Q1 Predictions Min               0.926733
trainer/Q2 Predictions Mean              0.954727
trainer/Q2 Predictions Std               0.0240424
trainer/Q2 Predictions Max               1.00212
trainer/Q2 Predictions Min               0.928754
trainer/Q Targets Mean                   0.953916
trainer/Q Targets Std                    0.0242375
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927601
trainer/Log Pis Mean                     2.94563
trainer/Log Pis Std                      1.79337
trainer/Log Pis Max                      8.26657
trainer/Log Pis Min                     -3.72329
trainer/policy/mean Mean                 0.103483
trainer/policy/mean Std                  0.671853
trainer/policy/mean Max                  0.99509
trainer/policy/mean Min                 -0.99492
trainer/policy/normal/std Mean           0.60578
trainer/policy/normal/std Std            0.208873
trainer/policy/normal/std Max            1.68759
trainer/policy/normal/std Min            0.160638
trainer/policy/normal/log_std Mean      -0.561924
trainer/policy/normal/log_std Std        0.352502
trainer/policy/normal/log_std Max        0.523303
trainer/policy/normal/log_std Min       -1.8286
trainer/Alpha                            0.000142754
trainer/Alpha Loss                      -0.481435
expl/num steps total                214000
expl/num paths total                 22612
expl/path length Mean                    3.96825
expl/path length Std                     1.66874
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996032
expl/Returns Std                         0.062869
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0278148
expl/Actions Std                         0.759092
expl/Actions Max                         0.999522
expl/Actions Min                        -0.999795
expl/Num Paths                         252
expl/Average Returns                     0.996032
eval/num steps total                     1.05796e+06
eval/num paths total                113435
eval/path length Mean                    3.96197
eval/path length Std                     1.67156
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2524
eval/Rewards Std                         0.43439
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0147434
eval/Actions Std                         0.669442
eval/Actions Max                         0.995962
eval/Actions Min                        -0.996089
eval/Num Paths                        1262
eval/Average Returns                     1
time/data storing (s)                    0.0049675
time/evaluation sampling (s)             0.989617
time/exploration sampling (s)            0.321837
time/logging (s)                         0.0201938
time/sac training (s)                   12.0545
time/saving (s)                          0.00337679
time/training (s)                        2.954e-05
time/epoch (s)                          13.3946
time/total (s)                        2835.13
Epoch                                  212
----------------------------------  ----------------
2022-09-09 20:40:21.575404 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 213 finished
----------------------------------  ----------------
epoch                                  213
replay_buffer/size                  215000
trainer/num train calls             214000
trainer/QF1 Loss                         8.69061e-07
trainer/QF2 Loss                         1.80589e-06
trainer/Policy Loss                     -0.960198
trainer/Q1 Predictions Mean              0.954995
trainer/Q1 Predictions Std               0.0253225
trainer/Q1 Predictions Max               1.0009
trainer/Q1 Predictions Min               0.927548
trainer/Q2 Predictions Mean              0.955097
trainer/Q2 Predictions Std               0.0254143
trainer/Q2 Predictions Max               1.00156
trainer/Q2 Predictions Min               0.926877
trainer/Q Targets Mean                   0.954636
trainer/Q Targets Std                    0.0253808
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927339
trainer/Log Pis Mean                     3.10859
trainer/Log Pis Std                      1.75361
trainer/Log Pis Max                      7.53201
trainer/Log Pis Min                     -3.15982
trainer/policy/mean Mean                 0.124717
trainer/policy/mean Std                  0.690168
trainer/policy/mean Max                  0.995196
trainer/policy/mean Min                 -0.996098
trainer/policy/normal/std Mean           0.596646
trainer/policy/normal/std Std            0.194893
trainer/policy/normal/std Max            1.23285
trainer/policy/normal/std Min            0.136136
trainer/policy/normal/log_std Mean      -0.572986
trainer/policy/normal/log_std Std        0.344034
trainer/policy/normal/log_std Max        0.209326
trainer/policy/normal/log_std Min       -1.9941
trainer/Alpha                            0.00014306
trainer/Alpha Loss                       0.961293
expl/num steps total                215000
expl/num paths total                 22870
expl/path length Mean                    3.87597
expl/path length Std                     1.62589
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.257
expl/Rewards Std                         0.436979
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996124
expl/Returns Std                         0.0621365
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0468834
expl/Actions Std                         0.751582
expl/Actions Max                         0.999641
expl/Actions Min                        -0.999469
expl/Num Paths                         258
expl/Average Returns                     0.996124
eval/num steps total                     1.06296e+06
eval/num paths total                114719
eval/path length Mean                    3.89408
eval/path length Std                     1.69423
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2568
eval/Rewards Std                         0.436868
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0244997
eval/Actions Std                         0.662476
eval/Actions Max                         0.996722
eval/Actions Min                        -0.995567
eval/Num Paths                        1284
eval/Average Returns                     1
time/data storing (s)                    0.00634413
time/evaluation sampling (s)             0.982904
time/exploration sampling (s)            0.322031
time/logging (s)                         0.0194365
time/sac training (s)                   12.527
time/saving (s)                          0.00394432
time/training (s)                        3.2581e-05
time/epoch (s)                          13.8617
time/total (s)                        2849.31
Epoch                                  213
----------------------------------  ----------------
2022-09-09 20:40:35.752763 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 214 finished
----------------------------------  ----------------
epoch                                  214
replay_buffer/size                  216000
trainer/num train calls             215000
trainer/QF1 Loss                         8.25039e-07
trainer/QF2 Loss                         2.57535e-06
trainer/Policy Loss                     -0.95979
trainer/Q1 Predictions Mean              0.95559
trainer/Q1 Predictions Std               0.0250691
trainer/Q1 Predictions Max               1.00079
trainer/Q1 Predictions Min               0.927012
trainer/Q2 Predictions Mean              0.954639
trainer/Q2 Predictions Std               0.025344
trainer/Q2 Predictions Max               1.00085
trainer/Q2 Predictions Min               0.925666
trainer/Q Targets Mean                   0.955603
trainer/Q Targets Std                    0.0251706
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927096
trainer/Log Pis Mean                     3.26204
trainer/Log Pis Std                      1.9372
trainer/Log Pis Max                      8.21004
trainer/Log Pis Min                     -3.82691
trainer/policy/mean Mean                 0.0622487
trainer/policy/mean Std                  0.691788
trainer/policy/mean Max                  0.995394
trainer/policy/mean Min                 -0.996363
trainer/policy/normal/std Mean           0.579872
trainer/policy/normal/std Std            0.183348
trainer/policy/normal/std Max            1.30434
trainer/policy/normal/std Min            0.11098
trainer/policy/normal/log_std Mean      -0.598285
trainer/policy/normal/log_std Std        0.335345
trainer/policy/normal/log_std Max        0.265701
trainer/policy/normal/log_std Min       -2.1984
trainer/Alpha                            0.000144208
trainer/Alpha Loss                       2.31751
expl/num steps total                216000
expl/num paths total                 23128
expl/path length Mean                    3.87597
expl/path length Std                     1.7276
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.257
expl/Rewards Std                         0.436979
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996124
expl/Returns Std                         0.0621365
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00679932
expl/Actions Std                         0.752981
expl/Actions Max                         0.999663
expl/Actions Min                        -0.999553
expl/Num Paths                         258
expl/Average Returns                     0.996124
eval/num steps total                     1.06795e+06
eval/num paths total                115982
eval/path length Mean                    3.95724
eval/path length Std                     1.67173
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252701
eval/Rewards Std                         0.434561
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0160877
eval/Actions Std                         0.674776
eval/Actions Max                         0.996343
eval/Actions Min                        -0.996631
eval/Num Paths                        1263
eval/Average Returns                     1
time/data storing (s)                    0.00468743
time/evaluation sampling (s)             1.08748
time/exploration sampling (s)            0.327661
time/logging (s)                         0.0188477
time/sac training (s)                   12.3971
time/saving (s)                          0.00465773
time/training (s)                        3.862e-05
time/epoch (s)                          13.8404
time/total (s)                        2863.47
Epoch                                  214
----------------------------------  ----------------
2022-09-09 20:40:49.049744 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 215 finished
----------------------------------  ----------------
epoch                                  215
replay_buffer/size                  217000
trainer/num train calls             216000
trainer/QF1 Loss                         6.5396e-07
trainer/QF2 Loss                         1.61278e-06
trainer/Policy Loss                     -0.960796
trainer/Q1 Predictions Mean              0.955694
trainer/Q1 Predictions Std               0.0251243
trainer/Q1 Predictions Max               1.00074
trainer/Q1 Predictions Min               0.927498
trainer/Q2 Predictions Mean              0.955702
trainer/Q2 Predictions Std               0.0253888
trainer/Q2 Predictions Max               1.00161
trainer/Q2 Predictions Min               0.926059
trainer/Q Targets Mean                   0.955491
trainer/Q Targets Std                    0.0250901
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927051
trainer/Log Pis Mean                     3.08906
trainer/Log Pis Std                      1.73578
trainer/Log Pis Max                      7.25166
trainer/Log Pis Min                     -3.20414
trainer/policy/mean Mean                 0.12093
trainer/policy/mean Std                  0.674434
trainer/policy/mean Max                  0.994744
trainer/policy/mean Min                 -0.996802
trainer/policy/normal/std Mean           0.60903
trainer/policy/normal/std Std            0.204447
trainer/policy/normal/std Max            1.37029
trainer/policy/normal/std Min            0.117293
trainer/policy/normal/log_std Mean      -0.557768
trainer/policy/normal/log_std Std        0.363583
trainer/policy/normal/log_std Max        0.315024
trainer/policy/normal/log_std Min       -2.14308
trainer/Alpha                            0.00014673
trainer/Alpha Loss                       0.786125
expl/num steps total                217000
expl/num paths total                 23380
expl/path length Mean                    3.96825
expl/path length Std                     1.70404
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996032
expl/Returns Std                         0.062869
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0549286
expl/Actions Std                         0.755786
expl/Actions Max                         0.999535
expl/Actions Min                        -0.999824
expl/Num Paths                         252
expl/Average Returns                     0.996032
eval/num steps total                     1.07295e+06
eval/num paths total                117260
eval/path length Mean                    3.91236
eval/path length Std                     1.68909
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2556
eval/Rewards Std                         0.436198
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0193923
eval/Actions Std                         0.673955
eval/Actions Max                         0.996621
eval/Actions Min                        -0.997219
eval/Num Paths                        1278
eval/Average Returns                     1
time/data storing (s)                    0.0061833
time/evaluation sampling (s)             1.00051
time/exploration sampling (s)            0.336751
time/logging (s)                         0.0210567
time/sac training (s)                   11.6407
time/saving (s)                          0.00478089
time/training (s)                        2.076e-05
time/epoch (s)                          13.01
time/total (s)                        2876.76
Epoch                                  215
----------------------------------  ----------------
2022-09-09 20:41:02.639293 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 216 finished
----------------------------------  ----------------
epoch                                  216
replay_buffer/size                  218000
trainer/num train calls             217000
trainer/QF1 Loss                         4.81496e-07
trainer/QF2 Loss                         1.55929e-06
trainer/Policy Loss                     -0.959992
trainer/Q1 Predictions Mean              0.954743
trainer/Q1 Predictions Std               0.0239616
trainer/Q1 Predictions Max               1.00078
trainer/Q1 Predictions Min               0.927258
trainer/Q2 Predictions Mean              0.955121
trainer/Q2 Predictions Std               0.0238857
trainer/Q2 Predictions Max               1.00242
trainer/Q2 Predictions Min               0.92711
trainer/Q Targets Mean                   0.954733
trainer/Q Targets Std                    0.023963
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927015
trainer/Log Pis Mean                     2.94916
trainer/Log Pis Std                      1.89148
trainer/Log Pis Max                      7.60829
trainer/Log Pis Min                     -5.4633
trainer/policy/mean Mean                 0.143464
trainer/policy/mean Std                  0.674578
trainer/policy/mean Max                  0.995039
trainer/policy/mean Min                 -0.994425
trainer/policy/normal/std Mean           0.587877
trainer/policy/normal/std Std            0.195609
trainer/policy/normal/std Max            1.30677
trainer/policy/normal/std Min            0.113363
trainer/policy/normal/log_std Mean      -0.592139
trainer/policy/normal/log_std Std        0.362022
trainer/policy/normal/log_std Max        0.26756
trainer/policy/normal/log_std Min       -2.17716
trainer/Alpha                            0.00014338
trainer/Alpha Loss                      -0.44993
expl/num steps total                218000
expl/num paths total                 23617
expl/path length Mean                    4.21941
expl/path length Std                     1.72667
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.236
expl/Rewards Std                         0.424622
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995781
expl/Returns Std                         0.0648198
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0437762
expl/Actions Std                         0.758665
expl/Actions Max                         0.999775
expl/Actions Min                        -0.999576
expl/Num Paths                         237
expl/Average Returns                     0.995781
eval/num steps total                     1.07795e+06
eval/num paths total                118537
eval/path length Mean                    3.91151
eval/path length Std                     1.66614
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.255656
eval/Rewards Std                         0.436229
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0541057
eval/Actions Std                         0.676967
eval/Actions Max                         0.996765
eval/Actions Min                        -0.995619
eval/Num Paths                        1277
eval/Average Returns                     1
time/data storing (s)                    0.00481336
time/evaluation sampling (s)             0.972205
time/exploration sampling (s)            0.306045
time/logging (s)                         0.0199173
time/sac training (s)                   11.9742
time/saving (s)                          0.00473363
time/training (s)                        3.448e-05
time/epoch (s)                          13.2819
time/total (s)                        2890.33
Epoch                                  216
----------------------------------  ----------------
2022-09-09 20:41:16.075094 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 217 finished
----------------------------------  ----------------
epoch                                  217
replay_buffer/size                  219000
trainer/num train calls             218000
trainer/QF1 Loss                         1.43419e-06
trainer/QF2 Loss                         1.72688e-06
trainer/Policy Loss                     -0.960651
trainer/Q1 Predictions Mean              0.956369
trainer/Q1 Predictions Std               0.0248986
trainer/Q1 Predictions Max               1.00129
trainer/Q1 Predictions Min               0.927421
trainer/Q2 Predictions Mean              0.955568
trainer/Q2 Predictions Std               0.0250756
trainer/Q2 Predictions Max               1.00106
trainer/Q2 Predictions Min               0.926337
trainer/Q Targets Mean                   0.955666
trainer/Q Targets Std                    0.0250402
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927226
trainer/Log Pis Mean                     3.01788
trainer/Log Pis Std                      1.88322
trainer/Log Pis Max                      7.85007
trainer/Log Pis Min                     -3.07681
trainer/policy/mean Mean                 0.079484
trainer/policy/mean Std                  0.699597
trainer/policy/mean Max                  0.995854
trainer/policy/mean Min                 -0.994703
trainer/policy/normal/std Mean           0.598653
trainer/policy/normal/std Std            0.190795
trainer/policy/normal/std Max            1.09415
trainer/policy/normal/std Min            0.129503
trainer/policy/normal/log_std Mean      -0.568329
trainer/policy/normal/log_std Std        0.342141
trainer/policy/normal/log_std Max        0.0899804
trainer/policy/normal/log_std Min       -2.04405
trainer/Alpha                            0.000142551
trainer/Alpha Loss                       0.158352
expl/num steps total                219000
expl/num paths total                 23873
expl/path length Mean                    3.90625
expl/path length Std                     1.64382
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.256
expl/Rewards Std                         0.436422
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.000573809
expl/Actions Std                         0.759507
expl/Actions Max                         0.999858
expl/Actions Min                        -0.999807
expl/Num Paths                         256
expl/Average Returns                     1
eval/num steps total                     1.08295e+06
eval/num paths total                119784
eval/path length Mean                    4.00962
eval/path length Std                     1.64633
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2494
eval/Rewards Std                         0.432666
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0528493
eval/Actions Std                         0.676427
eval/Actions Max                         0.995875
eval/Actions Min                        -0.995349
eval/Num Paths                        1247
eval/Average Returns                     1
time/data storing (s)                    0.0071723
time/evaluation sampling (s)             1.03966
time/exploration sampling (s)            0.30339
time/logging (s)                         0.0196562
time/sac training (s)                   11.7666
time/saving (s)                          0.00359095
time/training (s)                        1.887e-05
time/epoch (s)                          13.1401
time/total (s)                        2903.76
Epoch                                  217
----------------------------------  ----------------
2022-09-09 20:41:29.264047 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 218 finished
----------------------------------  ----------------
epoch                                  218
replay_buffer/size                  220000
trainer/num train calls             219000
trainer/QF1 Loss                         1.98435e-06
trainer/QF2 Loss                         3.18456e-06
trainer/Policy Loss                     -0.960903
trainer/Q1 Predictions Mean              0.954901
trainer/Q1 Predictions Std               0.0248135
trainer/Q1 Predictions Max               1.00222
trainer/Q1 Predictions Min               0.928158
trainer/Q2 Predictions Mean              0.955203
trainer/Q2 Predictions Std               0.0249039
trainer/Q2 Predictions Max               1.00302
trainer/Q2 Predictions Min               0.928396
trainer/Q Targets Mean                   0.9539
trainer/Q Targets Std                    0.0248474
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927739
trainer/Log Pis Mean                     3.08258
trainer/Log Pis Std                      1.72122
trainer/Log Pis Max                      7.09877
trainer/Log Pis Min                     -4.87365
trainer/policy/mean Mean                 0.075885
trainer/policy/mean Std                  0.685206
trainer/policy/mean Max                  0.994801
trainer/policy/mean Min                 -0.996614
trainer/policy/normal/std Mean           0.605423
trainer/policy/normal/std Std            0.200709
trainer/policy/normal/std Max            1.28352
trainer/policy/normal/std Min            0.153357
trainer/policy/normal/log_std Mean      -0.560429
trainer/policy/normal/log_std Std        0.350847
trainer/policy/normal/log_std Max        0.249603
trainer/policy/normal/log_std Min       -1.87499
trainer/Alpha                            0.000139811
trainer/Alpha Loss                       0.732925
expl/num steps total                220000
expl/num paths total                 24128
expl/path length Mean                    3.92157
expl/path length Std                     1.81327
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.254
expl/Rewards Std                         0.435298
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996078
expl/Returns Std                         0.0624995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0350235
expl/Actions Std                         0.755176
expl/Actions Max                         0.999491
expl/Actions Min                        -0.999597
expl/Num Paths                         255
expl/Average Returns                     0.996078
eval/num steps total                     1.08795e+06
eval/num paths total                121035
eval/path length Mean                    3.9968
eval/path length Std                     1.66546
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2502
eval/Rewards Std                         0.433128
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0180484
eval/Actions Std                         0.669873
eval/Actions Max                         0.995806
eval/Actions Min                        -0.996742
eval/Num Paths                        1251
eval/Average Returns                     1
time/data storing (s)                    0.00397582
time/evaluation sampling (s)             0.963672
time/exploration sampling (s)            0.324738
time/logging (s)                         0.0188347
time/sac training (s)                   11.5971
time/saving (s)                          0.00471298
time/training (s)                        2.516e-05
time/epoch (s)                          12.9131
time/total (s)                        2916.94
Epoch                                  218
----------------------------------  ----------------
2022-09-09 20:41:42.736785 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 219 finished
----------------------------------  ----------------
epoch                                  219
replay_buffer/size                  221000
trainer/num train calls             220000
trainer/QF1 Loss                         1.23317e-06
trainer/QF2 Loss                         1.83284e-06
trainer/Policy Loss                     -0.961036
trainer/Q1 Predictions Mean              0.955778
trainer/Q1 Predictions Std               0.0254572
trainer/Q1 Predictions Max               0.999747
trainer/Q1 Predictions Min               0.926776
trainer/Q2 Predictions Mean              0.956549
trainer/Q2 Predictions Std               0.0255634
trainer/Q2 Predictions Max               1.00118
trainer/Q2 Predictions Min               0.925501
trainer/Q Targets Mean                   0.95662
trainer/Q Targets Std                    0.0256287
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92674
trainer/Log Pis Mean                     3.13005
trainer/Log Pis Std                      1.85002
trainer/Log Pis Max                      7.41776
trainer/Log Pis Min                     -8.3343
trainer/policy/mean Mean                 0.141888
trainer/policy/mean Std                  0.679488
trainer/policy/mean Max                  0.995552
trainer/policy/mean Min                 -0.995633
trainer/policy/normal/std Mean           0.597059
trainer/policy/normal/std Std            0.183865
trainer/policy/normal/std Max            0.952667
trainer/policy/normal/std Min            0.137052
trainer/policy/normal/log_std Mean      -0.56694
trainer/policy/normal/log_std Std        0.328747
trainer/policy/normal/log_std Max       -0.0484903
trainer/policy/normal/log_std Min       -1.98739
trainer/Alpha                            0.000140301
trainer/Alpha Loss                       1.15376
expl/num steps total                221000
expl/num paths total                 24390
expl/path length Mean                    3.81679
expl/path length Std                     1.63829
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.261
expl/Rewards Std                         0.43918
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996183
expl/Returns Std                         0.0616622
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0177511
expl/Actions Std                         0.754867
expl/Actions Max                         0.99934
expl/Actions Min                        -0.999784
expl/Num Paths                         262
expl/Average Returns                     0.996183
eval/num steps total                     1.09295e+06
eval/num paths total                122278
eval/path length Mean                    4.02253
eval/path length Std                     1.65373
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2486
eval/Rewards Std                         0.432201
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0181277
eval/Actions Std                         0.671591
eval/Actions Max                         0.996895
eval/Actions Min                        -0.996763
eval/Num Paths                        1243
eval/Average Returns                     1
time/data storing (s)                    0.0063544
time/evaluation sampling (s)             0.96261
time/exploration sampling (s)            0.355461
time/logging (s)                         0.018974
time/sac training (s)                   11.8364
time/saving (s)                          0.00340813
time/training (s)                        2.329e-05
time/epoch (s)                          13.1832
time/total (s)                        2930.4
Epoch                                  219
----------------------------------  ----------------
2022-09-09 20:41:56.105011 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 220 finished
----------------------------------  ----------------
epoch                                  220
replay_buffer/size                  222000
trainer/num train calls             221000
trainer/QF1 Loss                         1.80211e-06
trainer/QF2 Loss                         1.67792e-06
trainer/Policy Loss                     -0.96071
trainer/Q1 Predictions Mean              0.956972
trainer/Q1 Predictions Std               0.0244881
trainer/Q1 Predictions Max               1.00204
trainer/Q1 Predictions Min               0.928167
trainer/Q2 Predictions Mean              0.955488
trainer/Q2 Predictions Std               0.0245271
trainer/Q2 Predictions Max               1.00038
trainer/Q2 Predictions Min               0.92514
trainer/Q Targets Mean                   0.956008
trainer/Q Targets Std                    0.0247243
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927222
trainer/Log Pis Mean                     3.0999
trainer/Log Pis Std                      1.84744
trainer/Log Pis Max                      7.99188
trainer/Log Pis Min                     -2.33311
trainer/policy/mean Mean                 0.0878993
trainer/policy/mean Std                  0.68203
trainer/policy/mean Max                  0.995406
trainer/policy/mean Min                 -0.995448
trainer/policy/normal/std Mean           0.595433
trainer/policy/normal/std Std            0.185541
trainer/policy/normal/std Max            0.889203
trainer/policy/normal/std Min            0.173048
trainer/policy/normal/log_std Mean      -0.570243
trainer/policy/normal/log_std Std        0.329196
trainer/policy/normal/log_std Max       -0.11743
trainer/policy/normal/log_std Min       -1.75419
trainer/Alpha                            0.000138663
trainer/Alpha Loss                       0.887416
expl/num steps total                222000
expl/num paths total                 24631
expl/path length Mean                    4.14938
expl/path length Std                     1.74116
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.241
expl/Rewards Std                         0.42769
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.022162
expl/Actions Std                         0.751975
expl/Actions Max                         0.999444
expl/Actions Min                        -0.99958
expl/Num Paths                         241
expl/Average Returns                     1
eval/num steps total                     1.09794e+06
eval/num paths total                123530
eval/path length Mean                    3.99121
eval/path length Std                     1.67268
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25055
eval/Rewards Std                         0.43333
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0139824
eval/Actions Std                         0.673876
eval/Actions Max                         0.996888
eval/Actions Min                        -0.996524
eval/Num Paths                        1252
eval/Average Returns                     1
time/data storing (s)                    0.00607451
time/evaluation sampling (s)             0.9807
time/exploration sampling (s)            0.323848
time/logging (s)                         0.0180024
time/sac training (s)                   11.7527
time/saving (s)                          0.00359268
time/training (s)                        1.89e-05
time/epoch (s)                          13.0849
time/total (s)                        2943.75
Epoch                                  220
----------------------------------  ----------------
2022-09-09 20:42:09.365868 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 221 finished
----------------------------------  ----------------
epoch                                  221
replay_buffer/size                  223000
trainer/num train calls             222000
trainer/QF1 Loss                         8.10155e-07
trainer/QF2 Loss                         5.06095e-06
trainer/Policy Loss                     -0.960546
trainer/Q1 Predictions Mean              0.955188
trainer/Q1 Predictions Std               0.0248722
trainer/Q1 Predictions Max               1.00084
trainer/Q1 Predictions Min               0.927198
trainer/Q2 Predictions Mean              0.956931
trainer/Q2 Predictions Std               0.0247445
trainer/Q2 Predictions Max               1.00374
trainer/Q2 Predictions Min               0.927972
trainer/Q Targets Mean                   0.955192
trainer/Q Targets Std                    0.0250344
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927021
trainer/Log Pis Mean                     3.06719
trainer/Log Pis Std                      1.82928
trainer/Log Pis Max                      7.73724
trainer/Log Pis Min                     -4.66381
trainer/policy/mean Mean                 0.115015
trainer/policy/mean Std                  0.675505
trainer/policy/mean Max                  0.995299
trainer/policy/mean Min                 -0.99489
trainer/policy/normal/std Mean           0.606276
trainer/policy/normal/std Std            0.19598
trainer/policy/normal/std Max            1.08414
trainer/policy/normal/std Min            0.167457
trainer/policy/normal/log_std Mean      -0.555997
trainer/policy/normal/log_std Std        0.340934
trainer/policy/normal/log_std Max        0.080791
trainer/policy/normal/log_std Min       -1.78703
trainer/Alpha                            0.000139859
trainer/Alpha Loss                       0.596266
expl/num steps total                223000
expl/num paths total                 24896
expl/path length Mean                    3.77358
expl/path length Std                     1.69618
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.264
expl/Rewards Std                         0.440799
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996226
expl/Returns Std                         0.0613135
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00814176
expl/Actions Std                         0.766946
expl/Actions Max                         0.999776
expl/Actions Min                        -0.999762
expl/Num Paths                         265
expl/Average Returns                     0.996226
eval/num steps total                     1.10294e+06
eval/num paths total                124806
eval/path length Mean                    3.91614
eval/path length Std                     1.62418
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.255353
eval/Rewards Std                         0.43606
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0103816
eval/Actions Std                         0.674339
eval/Actions Max                         0.99673
eval/Actions Min                        -0.996393
eval/Num Paths                        1276
eval/Average Returns                     1
time/data storing (s)                    0.00624533
time/evaluation sampling (s)             0.970421
time/exploration sampling (s)            0.324085
time/logging (s)                         0.0317397
time/sac training (s)                   11.6545
time/saving (s)                          0.00500331
time/training (s)                        5.233e-05
time/epoch (s)                          12.992
time/total (s)                        2957.02
Epoch                                  221
----------------------------------  ----------------
2022-09-09 20:42:22.995058 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 222 finished
----------------------------------  ----------------
epoch                                  222
replay_buffer/size                  224000
trainer/num train calls             223000
trainer/QF1 Loss                         5.991e-07
trainer/QF2 Loss                         2.6793e-06
trainer/Policy Loss                     -0.959969
trainer/Q1 Predictions Mean              0.954944
trainer/Q1 Predictions Std               0.0246886
trainer/Q1 Predictions Max               1.00104
trainer/Q1 Predictions Min               0.927578
trainer/Q2 Predictions Mean              0.955641
trainer/Q2 Predictions Std               0.0247295
trainer/Q2 Predictions Max               1.0029
trainer/Q2 Predictions Min               0.927477
trainer/Q Targets Mean                   0.954899
trainer/Q Targets Std                    0.0247286
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927581
trainer/Log Pis Mean                     3.26918
trainer/Log Pis Std                      1.80095
trainer/Log Pis Max                      7.31634
trainer/Log Pis Min                     -4.19839
trainer/policy/mean Mean                 0.0815357
trainer/policy/mean Std                  0.692864
trainer/policy/mean Max                  0.995696
trainer/policy/mean Min                 -0.995117
trainer/policy/normal/std Mean           0.606527
trainer/policy/normal/std Std            0.193078
trainer/policy/normal/std Max            1.05691
trainer/policy/normal/std Min            0.167882
trainer/policy/normal/log_std Mean      -0.553323
trainer/policy/normal/log_std Std        0.332412
trainer/policy/normal/log_std Max        0.0553527
trainer/policy/normal/log_std Min       -1.78449
trainer/Alpha                            0.000141106
trainer/Alpha Loss                       2.38659
expl/num steps total                224000
expl/num paths total                 25143
expl/path length Mean                    4.04858
expl/path length Std                     1.73254
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.246
expl/Rewards Std                         0.430679
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995951
expl/Returns Std                         0.0634995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0240725
expl/Actions Std                         0.765585
expl/Actions Max                         0.999516
expl/Actions Min                        -0.999605
expl/Num Paths                         247
expl/Average Returns                     0.995951
eval/num steps total                     1.10794e+06
eval/num paths total                126064
eval/path length Mean                    3.97377
eval/path length Std                     1.6761
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25165
eval/Rewards Std                         0.433961
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.000129352
eval/Actions Std                         0.677619
eval/Actions Max                         0.997103
eval/Actions Min                        -0.995856
eval/Num Paths                        1258
eval/Average Returns                     1
time/data storing (s)                    0.00623228
time/evaluation sampling (s)             0.965713
time/exploration sampling (s)            0.31535
time/logging (s)                         0.0185916
time/sac training (s)                   11.9997
time/saving (s)                          0.00470414
time/training (s)                        0.00013424
time/epoch (s)                          13.3105
time/total (s)                        2970.62
Epoch                                  222
----------------------------------  ----------------
2022-09-09 20:42:36.481336 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 223 finished
----------------------------------  ----------------
epoch                                  223
replay_buffer/size                  225000
trainer/num train calls             224000
trainer/QF1 Loss                         6.58355e-07
trainer/QF2 Loss                         1.70881e-06
trainer/Policy Loss                     -0.958852
trainer/Q1 Predictions Mean              0.953756
trainer/Q1 Predictions Std               0.0248011
trainer/Q1 Predictions Max               1.00142
trainer/Q1 Predictions Min               0.92745
trainer/Q2 Predictions Mean              0.953307
trainer/Q2 Predictions Std               0.0245325
trainer/Q2 Predictions Max               1.00109
trainer/Q2 Predictions Min               0.926524
trainer/Q Targets Mean                   0.953664
trainer/Q Targets Std                    0.0247265
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927695
trainer/Log Pis Mean                     2.97428
trainer/Log Pis Std                      1.73302
trainer/Log Pis Max                      7.10341
trainer/Log Pis Min                     -4.0578
trainer/policy/mean Mean                 0.0720212
trainer/policy/mean Std                  0.690853
trainer/policy/mean Max                  0.995058
trainer/policy/mean Min                 -0.996106
trainer/policy/normal/std Mean           0.592137
trainer/policy/normal/std Std            0.192343
trainer/policy/normal/std Max            0.922545
trainer/policy/normal/std Min            0.18725
trainer/policy/normal/log_std Mean      -0.581199
trainer/policy/normal/log_std Std        0.347547
trainer/policy/normal/log_std Max       -0.0806192
trainer/policy/normal/log_std Min       -1.67531
trainer/Alpha                            0.000136834
trainer/Alpha Loss                      -0.228861
expl/num steps total                225000
expl/num paths total                 25379
expl/path length Mean                    4.23729
expl/path length Std                     1.67321
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.236
expl/Rewards Std                         0.424622
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0212121
expl/Actions Std                         0.756851
expl/Actions Max                         0.999842
expl/Actions Min                        -0.999547
expl/Num Paths                         236
expl/Average Returns                     1
eval/num steps total                     1.11294e+06
eval/num paths total                127348
eval/path length Mean                    3.89174
eval/path length Std                     1.68832
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.256954
eval/Rewards Std                         0.436954
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0164766
eval/Actions Std                         0.677604
eval/Actions Max                         0.996678
eval/Actions Min                        -0.995921
eval/Num Paths                        1284
eval/Average Returns                     1
time/data storing (s)                    0.0062168
time/evaluation sampling (s)             0.971493
time/exploration sampling (s)            0.355215
time/logging (s)                         0.0181747
time/sac training (s)                   11.8308
time/saving (s)                          0.00464641
time/training (s)                        2.76e-05
time/epoch (s)                          13.1866
time/total (s)                        2984.1
Epoch                                  223
----------------------------------  ----------------
2022-09-09 20:42:49.818580 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 224 finished
----------------------------------  ----------------
epoch                                  224
replay_buffer/size                  226000
trainer/num train calls             225000
trainer/QF1 Loss                         1.6281e-06
trainer/QF2 Loss                         1.8007e-06
trainer/Policy Loss                     -0.959807
trainer/Q1 Predictions Mean              0.95481
trainer/Q1 Predictions Std               0.0257615
trainer/Q1 Predictions Max               1.00011
trainer/Q1 Predictions Min               0.926464
trainer/Q2 Predictions Mean              0.955381
trainer/Q2 Predictions Std               0.0253548
trainer/Q2 Predictions Max               1.00275
trainer/Q2 Predictions Min               0.926742
trainer/Q Targets Mean                   0.955835
trainer/Q Targets Std                    0.0256837
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928066
trainer/Log Pis Mean                     2.78712
trainer/Log Pis Std                      1.90092
trainer/Log Pis Max                      6.95725
trainer/Log Pis Min                     -5.58549
trainer/policy/mean Mean                 0.0586576
trainer/policy/mean Std                  0.679282
trainer/policy/mean Max                  0.995354
trainer/policy/mean Min                 -0.995944
trainer/policy/normal/std Mean           0.624799
trainer/policy/normal/std Std            0.191359
trainer/policy/normal/std Max            1.05151
trainer/policy/normal/std Min            0.131783
trainer/policy/normal/log_std Mean      -0.523549
trainer/policy/normal/log_std Std        0.340886
trainer/policy/normal/log_std Max        0.0502316
trainer/policy/normal/log_std Min       -2.0266
trainer/Alpha                            0.000140124
trainer/Alpha Loss                      -1.88891
expl/num steps total                226000
expl/num paths total                 25650
expl/path length Mean                    3.69004
expl/path length Std                     1.72668
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.27
expl/Rewards Std                         0.443959
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.99631
expl/Returns Std                         0.0606335
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0218138
expl/Actions Std                         0.759027
expl/Actions Max                         0.999783
expl/Actions Min                        -0.999763
expl/Num Paths                         271
expl/Average Returns                     0.99631
eval/num steps total                     1.11794e+06
eval/num paths total                128590
eval/path length Mean                    4.02576
eval/path length Std                     1.68855
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2484
eval/Rewards Std                         0.432085
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0375036
eval/Actions Std                         0.668743
eval/Actions Max                         0.995586
eval/Actions Min                        -0.996106
eval/Num Paths                        1242
eval/Average Returns                     1
time/data storing (s)                    0.00383373
time/evaluation sampling (s)             0.970744
time/exploration sampling (s)            0.321137
time/logging (s)                         0.0191957
time/sac training (s)                   11.7326
time/saving (s)                          0.00458358
time/training (s)                        2.498e-05
time/epoch (s)                          13.0521
time/total (s)                        2997.42
Epoch                                  224
----------------------------------  ----------------
2022-09-09 20:43:03.403141 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 225 finished
----------------------------------  ----------------
epoch                                  225
replay_buffer/size                  227000
trainer/num train calls             226000
trainer/QF1 Loss                         1.00675e-06
trainer/QF2 Loss                         1.74494e-06
trainer/Policy Loss                     -0.960216
trainer/Q1 Predictions Mean              0.955697
trainer/Q1 Predictions Std               0.0233258
trainer/Q1 Predictions Max               1.00058
trainer/Q1 Predictions Min               0.928095
trainer/Q2 Predictions Mean              0.956006
trainer/Q2 Predictions Std               0.0235785
trainer/Q2 Predictions Max               1.00175
trainer/Q2 Predictions Min               0.92754
trainer/Q Targets Mean                   0.955837
trainer/Q Targets Std                    0.0237034
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927293
trainer/Log Pis Mean                     2.84477
trainer/Log Pis Std                      2.01169
trainer/Log Pis Max                      7.59643
trainer/Log Pis Min                     -6.02965
trainer/policy/mean Mean                 0.11464
trainer/policy/mean Std                  0.674385
trainer/policy/mean Max                  0.995798
trainer/policy/mean Min                 -0.99705
trainer/policy/normal/std Mean           0.58057
trainer/policy/normal/std Std            0.166615
trainer/policy/normal/std Max            1.0989
trainer/policy/normal/std Min            0.163454
trainer/policy/normal/log_std Mean      -0.588528
trainer/policy/normal/log_std Std        0.308155
trainer/policy/normal/log_std Max        0.0943062
trainer/policy/normal/log_std Min       -1.81122
trainer/Alpha                            0.000138107
trainer/Alpha Loss                      -1.37962
expl/num steps total                227000
expl/num paths total                 25896
expl/path length Mean                    4.06504
expl/path length Std                     1.61164
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.245
expl/Rewards Std                         0.430087
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995935
expl/Returns Std                         0.063628
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0448086
expl/Actions Std                         0.754643
expl/Actions Max                         0.999876
expl/Actions Min                        -0.999577
expl/Num Paths                         246
expl/Average Returns                     0.995935
eval/num steps total                     1.12294e+06
eval/num paths total                129851
eval/path length Mean                    3.96273
eval/path length Std                     1.68946
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252351
eval/Rewards Std                         0.434362
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0249968
eval/Actions Std                         0.670138
eval/Actions Max                         0.996504
eval/Actions Min                        -0.997074
eval/Num Paths                        1261
eval/Average Returns                     1
time/data storing (s)                    0.00626537
time/evaluation sampling (s)             0.955007
time/exploration sampling (s)            0.318556
time/logging (s)                         0.0179932
time/sac training (s)                   11.9822
time/saving (s)                          0.00360321
time/training (s)                        2.229e-05
time/epoch (s)                          13.2836
time/total (s)                        3011
Epoch                                  225
----------------------------------  ----------------
2022-09-09 20:43:16.747344 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 226 finished
----------------------------------  ----------------
epoch                                  226
replay_buffer/size                  228000
trainer/num train calls             227000
trainer/QF1 Loss                         1.00298e-06
trainer/QF2 Loss                         3.84925e-06
trainer/Policy Loss                     -0.961767
trainer/Q1 Predictions Mean              0.956683
trainer/Q1 Predictions Std               0.0251388
trainer/Q1 Predictions Max               1.00151
trainer/Q1 Predictions Min               0.927845
trainer/Q2 Predictions Mean              0.957591
trainer/Q2 Predictions Std               0.0248476
trainer/Q2 Predictions Max               1.0032
trainer/Q2 Predictions Min               0.927721
trainer/Q Targets Mean                   0.956235
trainer/Q Targets Std                    0.0251245
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928227
trainer/Log Pis Mean                     2.76413
trainer/Log Pis Std                      1.78543
trainer/Log Pis Max                      7.72034
trainer/Log Pis Min                     -5.3455
trainer/policy/mean Mean                 0.091178
trainer/policy/mean Std                  0.676099
trainer/policy/mean Max                  0.995649
trainer/policy/mean Min                 -0.996578
trainer/policy/normal/std Mean           0.594527
trainer/policy/normal/std Std            0.194921
trainer/policy/normal/std Max            1.14143
trainer/policy/normal/std Min            0.219485
trainer/policy/normal/log_std Mean      -0.576577
trainer/policy/normal/log_std Std        0.342312
trainer/policy/normal/log_std Max        0.132281
trainer/policy/normal/log_std Min       -1.51647
trainer/Alpha                            0.000140699
trainer/Alpha Loss                      -2.09188
expl/num steps total                228000
expl/num paths total                 26149
expl/path length Mean                    3.95257
expl/path length Std                     1.68864
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.253
expl/Rewards Std                         0.434731
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0150177
expl/Actions Std                         0.75569
expl/Actions Max                         0.999607
expl/Actions Min                        -0.999668
expl/Num Paths                         253
expl/Average Returns                     1
eval/num steps total                     1.12793e+06
eval/num paths total                131104
eval/path length Mean                    3.98962
eval/path length Std                     1.64457
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25065
eval/Rewards Std                         0.433387
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00648726
eval/Actions Std                         0.672395
eval/Actions Max                         0.996599
eval/Actions Min                        -0.997234
eval/Num Paths                        1253
eval/Average Returns                     1
time/data storing (s)                    0.00393699
time/evaluation sampling (s)             0.977202
time/exploration sampling (s)            0.302074
time/logging (s)                         0.0180335
time/sac training (s)                   11.7574
time/saving (s)                          0.00334777
time/training (s)                        2.018e-05
time/epoch (s)                          13.062
time/total (s)                        3024.33
Epoch                                  226
----------------------------------  ----------------
2022-09-09 20:43:29.981576 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 227 finished
----------------------------------  ----------------
epoch                                  227
replay_buffer/size                  229000
trainer/num train calls             228000
trainer/QF1 Loss                         9.3386e-07
trainer/QF2 Loss                         5.03115e-06
trainer/Policy Loss                     -0.962603
trainer/Q1 Predictions Mean              0.95752
trainer/Q1 Predictions Std               0.025329
trainer/Q1 Predictions Max               1.00203
trainer/Q1 Predictions Min               0.927908
trainer/Q2 Predictions Mean              0.958787
trainer/Q2 Predictions Std               0.025264
trainer/Q2 Predictions Max               1.00398
trainer/Q2 Predictions Min               0.927453
trainer/Q Targets Mean                   0.957205
trainer/Q Targets Std                    0.0252143
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927518
trainer/Log Pis Mean                     2.96993
trainer/Log Pis Std                      1.96609
trainer/Log Pis Max                      8.22255
trainer/Log Pis Min                     -4.7131
trainer/policy/mean Mean                 0.119014
trainer/policy/mean Std                  0.680937
trainer/policy/mean Max                  0.996745
trainer/policy/mean Min                 -0.99727
trainer/policy/normal/std Mean           0.603535
trainer/policy/normal/std Std            0.189549
trainer/policy/normal/std Max            1.08575
trainer/policy/normal/std Min            0.157326
trainer/policy/normal/log_std Mean      -0.559208
trainer/policy/normal/log_std Std        0.340709
trainer/policy/normal/log_std Max        0.0822683
trainer/policy/normal/log_std Min       -1.84944
trainer/Alpha                            0.000135202
trainer/Alpha Loss                      -0.267897
expl/num steps total                229000
expl/num paths total                 26413
expl/path length Mean                    3.78788
expl/path length Std                     1.64239
expl/path length Max                     6
expl/path length Min                     1
expl/Rewards Mean                        0.263
expl/Rewards Std                         0.440262
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996212
expl/Returns Std                         0.0614291
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0121315
expl/Actions Std                         0.758575
expl/Actions Max                         0.999654
expl/Actions Min                        -0.999581
expl/Num Paths                         264
expl/Average Returns                     0.996212
eval/num steps total                     1.13293e+06
eval/num paths total                132362
eval/path length Mean                    3.97138
eval/path length Std                     1.65962
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251801
eval/Rewards Std                         0.434048
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0317376
eval/Actions Std                         0.671617
eval/Actions Max                         0.995909
eval/Actions Min                        -0.997134
eval/Num Paths                        1258
eval/Average Returns                     1
time/data storing (s)                    0.00401454
time/evaluation sampling (s)             0.960907
time/exploration sampling (s)            0.363015
time/logging (s)                         0.0189683
time/sac training (s)                   11.612
time/saving (s)                          0.00337246
time/training (s)                        1.897e-05
time/epoch (s)                          12.9623
time/total (s)                        3037.55
Epoch                                  227
----------------------------------  ----------------
2022-09-09 20:43:43.139763 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 228 finished
----------------------------------  ----------------
epoch                                  228
replay_buffer/size                  230000
trainer/num train calls             229000
trainer/QF1 Loss                         5.99734e-07
trainer/QF2 Loss                         3.46938e-06
trainer/Policy Loss                     -0.96028
trainer/Q1 Predictions Mean              0.954731
trainer/Q1 Predictions Std               0.0235339
trainer/Q1 Predictions Max               1.00103
trainer/Q1 Predictions Min               0.927403
trainer/Q2 Predictions Mean              0.955968
trainer/Q2 Predictions Std               0.0238239
trainer/Q2 Predictions Max               1.0032
trainer/Q2 Predictions Min               0.928521
trainer/Q Targets Mean                   0.954574
trainer/Q Targets Std                    0.0236798
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928058
trainer/Log Pis Mean                     3.06584
trainer/Log Pis Std                      1.93684
trainer/Log Pis Max                      7.16164
trainer/Log Pis Min                     -3.58008
trainer/policy/mean Mean                 0.074883
trainer/policy/mean Std                  0.693218
trainer/policy/mean Max                  0.995219
trainer/policy/mean Min                 -0.995079
trainer/policy/normal/std Mean           0.592376
trainer/policy/normal/std Std            0.173405
trainer/policy/normal/std Max            1.11072
trainer/policy/normal/std Min            0.17623
trainer/policy/normal/log_std Mean      -0.569454
trainer/policy/normal/log_std Std        0.309548
trainer/policy/normal/log_std Max        0.105009
trainer/policy/normal/log_std Min       -1.73596
trainer/Alpha                            0.000132266
trainer/Alpha Loss                       0.588001
expl/num steps total                230000
expl/num paths total                 26658
expl/path length Mean                    4.08163
expl/path length Std                     1.60912
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.244
expl/Rewards Std                         0.429493
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995918
expl/Returns Std                         0.0637571
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00620324
expl/Actions Std                         0.754683
expl/Actions Max                         0.999432
expl/Actions Min                        -0.999686
expl/Num Paths                         245
expl/Average Returns                     0.995918
eval/num steps total                     1.13793e+06
eval/num paths total                133650
eval/path length Mean                    3.87966
eval/path length Std                     1.68533
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.257755
eval/Rewards Std                         0.437398
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00120088
eval/Actions Std                         0.667191
eval/Actions Max                         0.996632
eval/Actions Min                        -0.995524
eval/Num Paths                        1288
eval/Average Returns                     1
time/data storing (s)                    0.00558592
time/evaluation sampling (s)             0.9605
time/exploration sampling (s)            0.323352
time/logging (s)                         0.0194002
time/sac training (s)                   11.5654
time/saving (s)                          0.00332085
time/training (s)                        2.207e-05
time/epoch (s)                          12.8775
time/total (s)                        3050.7
Epoch                                  228
----------------------------------  ----------------
2022-09-09 20:43:56.558448 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 229 finished
----------------------------------  ----------------
epoch                                  229
replay_buffer/size                  231000
trainer/num train calls             230000
trainer/QF1 Loss                         1.6168e-06
trainer/QF2 Loss                         1.63957e-06
trainer/Policy Loss                     -0.96207
trainer/Q1 Predictions Mean              0.957912
trainer/Q1 Predictions Std               0.0251429
trainer/Q1 Predictions Max               1.00211
trainer/Q1 Predictions Min               0.928698
trainer/Q2 Predictions Mean              0.956719
trainer/Q2 Predictions Std               0.0252858
trainer/Q2 Predictions Max               1.00175
trainer/Q2 Predictions Min               0.926724
trainer/Q Targets Mean                   0.956965
trainer/Q Targets Std                    0.0252296
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928323
trainer/Log Pis Mean                     3.00876
trainer/Log Pis Std                      1.89802
trainer/Log Pis Max                      8.18591
trainer/Log Pis Min                     -4.43724
trainer/policy/mean Mean                 0.0778273
trainer/policy/mean Std                  0.680643
trainer/policy/mean Max                  0.996879
trainer/policy/mean Min                 -0.995793
trainer/policy/normal/std Mean           0.593208
trainer/policy/normal/std Std            0.171927
trainer/policy/normal/std Max            1.07417
trainer/policy/normal/std Min            0.207864
trainer/policy/normal/log_std Mean      -0.566861
trainer/policy/normal/log_std Std        0.304941
trainer/policy/normal/log_std Max        0.0715516
trainer/policy/normal/log_std Min       -1.57087
trainer/Alpha                            0.000133131
trainer/Alpha Loss                       0.0781792
expl/num steps total                231000
expl/num paths total                 26908
expl/path length Mean                    4
expl/path length Std                     1.68048
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996
expl/Returns Std                         0.0631189
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0589342
expl/Actions Std                         0.752987
expl/Actions Max                         0.999726
expl/Actions Min                        -0.999568
expl/Num Paths                         250
expl/Average Returns                     0.996
eval/num steps total                     1.14292e+06
eval/num paths total                134919
eval/path length Mean                    3.93696
eval/path length Std                     1.66666
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254003
eval/Rewards Std                         0.435299
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0159109
eval/Actions Std                         0.66797
eval/Actions Max                         0.997094
eval/Actions Min                        -0.996044
eval/Num Paths                        1269
eval/Average Returns                     1
time/data storing (s)                    0.0062613
time/evaluation sampling (s)             0.956754
time/exploration sampling (s)            0.355609
time/logging (s)                         0.0181024
time/sac training (s)                   11.7862
time/saving (s)                          0.00471435
time/training (s)                        2.586e-05
time/epoch (s)                          13.1277
time/total (s)                        3064.11
Epoch                                  229
----------------------------------  ----------------
2022-09-09 20:44:10.128830 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 230 finished
----------------------------------  ----------------
epoch                                  230
replay_buffer/size                  232000
trainer/num train calls             231000
trainer/QF1 Loss                         6.8047e-07
trainer/QF2 Loss                         1.59497e-06
trainer/Policy Loss                     -0.961172
trainer/Q1 Predictions Mean              0.956166
trainer/Q1 Predictions Std               0.0257951
trainer/Q1 Predictions Max               1.00068
trainer/Q1 Predictions Min               0.928483
trainer/Q2 Predictions Mean              0.956329
trainer/Q2 Predictions Std               0.0256682
trainer/Q2 Predictions Max               1.00117
trainer/Q2 Predictions Min               0.928534
trainer/Q Targets Mean                   0.955924
trainer/Q Targets Std                    0.0257744
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928492
trainer/Log Pis Mean                     3.23586
trainer/Log Pis Std                      1.9215
trainer/Log Pis Max                      8.42393
trainer/Log Pis Min                     -3.34285
trainer/policy/mean Mean                 0.102638
trainer/policy/mean Std                  0.686488
trainer/policy/mean Max                  0.995343
trainer/policy/mean Min                 -0.997107
trainer/policy/normal/std Mean           0.612834
trainer/policy/normal/std Std            0.188625
trainer/policy/normal/std Max            1.14847
trainer/policy/normal/std Min            0.189304
trainer/policy/normal/log_std Mean      -0.53999
trainer/policy/normal/log_std Std        0.323884
trainer/policy/normal/log_std Max        0.138428
trainer/policy/normal/log_std Min       -1.6644
trainer/Alpha                            0.000131423
trainer/Alpha Loss                       2.10789
expl/num steps total                232000
expl/num paths total                 27158
expl/path length Mean                    4
expl/path length Std                     1.67093
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996
expl/Returns Std                         0.0631189
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00559951
expl/Actions Std                         0.758361
expl/Actions Max                         0.999779
expl/Actions Min                        -0.999662
expl/Num Paths                         250
expl/Average Returns                     0.996
eval/num steps total                     1.14792e+06
eval/num paths total                136210
eval/path length Mean                    3.87297
eval/path length Std                     1.72851
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2582
eval/Rewards Std                         0.437645
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0281385
eval/Actions Std                         0.673077
eval/Actions Max                         0.996421
eval/Actions Min                        -0.997426
eval/Num Paths                        1291
eval/Average Returns                     1
time/data storing (s)                    0.00618822
time/evaluation sampling (s)             0.997724
time/exploration sampling (s)            0.331809
time/logging (s)                         0.0195781
time/sac training (s)                   11.9257
time/saving (s)                          0.00473425
time/training (s)                        2.514e-05
time/epoch (s)                          13.2858
time/total (s)                        3077.67
Epoch                                  230
----------------------------------  ----------------
2022-09-09 20:44:23.331783 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 231 finished
----------------------------------  ----------------
epoch                                  231
replay_buffer/size                  233000
trainer/num train calls             232000
trainer/QF1 Loss                         5.37802e-07
trainer/QF2 Loss                         2.51541e-06
trainer/Policy Loss                     -0.962248
trainer/Q1 Predictions Mean              0.957326
trainer/Q1 Predictions Std               0.0255708
trainer/Q1 Predictions Max               1.00147
trainer/Q1 Predictions Min               0.928771
trainer/Q2 Predictions Mean              0.95794
trainer/Q2 Predictions Std               0.0253167
trainer/Q2 Predictions Max               1.0026
trainer/Q2 Predictions Min               0.928809
trainer/Q Targets Mean                   0.956941
trainer/Q Targets Std                    0.0254129
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928252
trainer/Log Pis Mean                     2.74779
trainer/Log Pis Std                      1.71705
trainer/Log Pis Max                      8.47353
trainer/Log Pis Min                     -5.74745
trainer/policy/mean Mean                 0.0562187
trainer/policy/mean Std                  0.690393
trainer/policy/mean Max                  0.995806
trainer/policy/mean Min                 -0.994196
trainer/policy/normal/std Mean           0.640165
trainer/policy/normal/std Std            0.197996
trainer/policy/normal/std Max            1.23469
trainer/policy/normal/std Min            0.183523
trainer/policy/normal/log_std Mean      -0.498089
trainer/policy/normal/log_std Std        0.332944
trainer/policy/normal/log_std Max        0.210816
trainer/policy/normal/log_std Min       -1.69542
trainer/Alpha                            0.000132759
trainer/Alpha Loss                      -2.25145
expl/num steps total                233000
expl/num paths total                 27417
expl/path length Mean                    3.861
expl/path length Std                     1.68229
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.259
expl/Rewards Std                         0.438086
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0116312
expl/Actions Std                         0.763354
expl/Actions Max                         0.999479
expl/Actions Min                        -0.999899
expl/Num Paths                         259
expl/Average Returns                     1
eval/num steps total                     1.15292e+06
eval/num paths total                137470
eval/path length Mean                    3.96746
eval/path length Std                     1.67419
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25205
eval/Rewards Std                         0.43419
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.037596
eval/Actions Std                         0.665494
eval/Actions Max                         0.99667
eval/Actions Min                        -0.996301
eval/Num Paths                        1260
eval/Average Returns                     1
time/data storing (s)                    0.00447321
time/evaluation sampling (s)             0.974317
time/exploration sampling (s)            0.381243
time/logging (s)                         0.0180813
time/sac training (s)                   11.5481
time/saving (s)                          0.00464043
time/training (s)                        2.55e-05
time/epoch (s)                          12.9309
time/total (s)                        3090.86
Epoch                                  231
----------------------------------  ----------------
2022-09-09 20:44:36.763522 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 232 finished
----------------------------------  ----------------
epoch                                  232
replay_buffer/size                  234000
trainer/num train calls             233000
trainer/QF1 Loss                         8.69577e-07
trainer/QF2 Loss                         1.39666e-06
trainer/Policy Loss                     -0.961594
trainer/Q1 Predictions Mean              0.957324
trainer/Q1 Predictions Std               0.0247227
trainer/Q1 Predictions Max               1.00052
trainer/Q1 Predictions Min               0.928481
trainer/Q2 Predictions Mean              0.957251
trainer/Q2 Predictions Std               0.0250688
trainer/Q2 Predictions Max               1.00152
trainer/Q2 Predictions Min               0.927402
trainer/Q Targets Mean                   0.957432
trainer/Q Targets Std                    0.0251898
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92734
trainer/Log Pis Mean                     3.14028
trainer/Log Pis Std                      1.82047
trainer/Log Pis Max                      7.89549
trainer/Log Pis Min                     -4.0057
trainer/policy/mean Mean                 0.0822575
trainer/policy/mean Std                  0.675682
trainer/policy/mean Max                  0.995632
trainer/policy/mean Min                 -0.99734
trainer/policy/normal/std Mean           0.602287
trainer/policy/normal/std Std            0.169231
trainer/policy/normal/std Max            1.19944
trainer/policy/normal/std Min            0.182911
trainer/policy/normal/log_std Mean      -0.549728
trainer/policy/normal/log_std Std        0.300607
trainer/policy/normal/log_std Max        0.181855
trainer/policy/normal/log_std Min       -1.69875
trainer/Alpha                            0.000131071
trainer/Alpha Loss                       1.25411
expl/num steps total                234000
expl/num paths total                 27668
expl/path length Mean                    3.98406
expl/path length Std                     1.6983
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.25
expl/Rewards Std                         0.433013
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996016
expl/Returns Std                         0.0629936
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0159088
expl/Actions Std                         0.761878
expl/Actions Max                         0.999442
expl/Actions Min                        -0.999744
expl/Num Paths                         251
expl/Average Returns                     0.996016
eval/num steps total                     1.15792e+06
eval/num paths total                138735
eval/path length Mean                    3.94862
eval/path length Std                     1.70692
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253253
eval/Rewards Std                         0.434875
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0201334
eval/Actions Std                         0.676979
eval/Actions Max                         0.996065
eval/Actions Min                        -0.997239
eval/Num Paths                        1265
eval/Average Returns                     1
time/data storing (s)                    0.00494554
time/evaluation sampling (s)             0.960191
time/exploration sampling (s)            0.318887
time/logging (s)                         0.0182649
time/sac training (s)                   11.8341
time/saving (s)                          0.00467052
time/training (s)                        0.00020177
time/epoch (s)                          13.1413
time/total (s)                        3104.28
Epoch                                  232
----------------------------------  ----------------
2022-09-09 20:44:50.614520 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 233 finished
----------------------------------  ----------------
epoch                                  233
replay_buffer/size                  235000
trainer/num train calls             234000
trainer/QF1 Loss                         8.81885e-07
trainer/QF2 Loss                         3.07675e-06
trainer/Policy Loss                     -0.961431
trainer/Q1 Predictions Mean              0.957406
trainer/Q1 Predictions Std               0.0253324
trainer/Q1 Predictions Max               1.00044
trainer/Q1 Predictions Min               0.927748
trainer/Q2 Predictions Mean              0.956639
trainer/Q2 Predictions Std               0.0252988
trainer/Q2 Predictions Max               1.00086
trainer/Q2 Predictions Min               0.926387
trainer/Q Targets Mean                   0.957937
trainer/Q Targets Std                    0.0254135
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928177
trainer/Log Pis Mean                     3.07962
trainer/Log Pis Std                      1.64647
trainer/Log Pis Max                      7.40007
trainer/Log Pis Min                     -2.42976
trainer/policy/mean Mean                 0.0340496
trainer/policy/mean Std                  0.694818
trainer/policy/mean Max                  0.995194
trainer/policy/mean Min                 -0.995617
trainer/policy/normal/std Mean           0.618786
trainer/policy/normal/std Std            0.197509
trainer/policy/normal/std Max            1.1864
trainer/policy/normal/std Min            0.19126
trainer/policy/normal/log_std Mean      -0.535064
trainer/policy/normal/log_std Std        0.340616
trainer/policy/normal/log_std Max        0.17092
trainer/policy/normal/log_std Min       -1.65412
trainer/Alpha                            0.000131178
trainer/Alpha Loss                       0.711724
expl/num steps total                235000
expl/num paths total                 27918
expl/path length Mean                    4
expl/path length Std                     1.67093
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996
expl/Returns Std                         0.0631189
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0126913
expl/Actions Std                         0.754427
expl/Actions Max                         0.999469
expl/Actions Min                        -0.999654
expl/Num Paths                         250
expl/Average Returns                     0.996
eval/num steps total                     1.16292e+06
eval/num paths total                140011
eval/path length Mean                    3.91771
eval/path length Std                     1.66853
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.255251
eval/Rewards Std                         0.436002
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00211696
eval/Actions Std                         0.670826
eval/Actions Max                         0.996319
eval/Actions Min                        -0.995856
eval/Num Paths                        1276
eval/Average Returns                     1
time/data storing (s)                    0.00623764
time/evaluation sampling (s)             0.967041
time/exploration sampling (s)            0.323556
time/logging (s)                         0.0178152
time/sac training (s)                   12.211
time/saving (s)                          0.00339017
time/training (s)                        1.915e-05
time/epoch (s)                          13.5291
time/total (s)                        3118.12
Epoch                                  233
----------------------------------  ----------------
2022-09-09 20:45:04.977740 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 234 finished
----------------------------------  ----------------
epoch                                  234
replay_buffer/size                  236000
trainer/num train calls             235000
trainer/QF1 Loss                         4.14632e-07
trainer/QF2 Loss                         2.38465e-06
trainer/Policy Loss                     -0.962554
trainer/Q1 Predictions Mean              0.957722
trainer/Q1 Predictions Std               0.0245441
trainer/Q1 Predictions Max               1.00066
trainer/Q1 Predictions Min               0.929317
trainer/Q2 Predictions Mean              0.958718
trainer/Q2 Predictions Std               0.0244276
trainer/Q2 Predictions Max               1.00264
trainer/Q2 Predictions Min               0.929212
trainer/Q Targets Mean                   0.95758
trainer/Q Targets Std                    0.0245725
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928542
trainer/Log Pis Mean                     3.26269
trainer/Log Pis Std                      1.72084
trainer/Log Pis Max                      8.16287
trainer/Log Pis Min                     -4.63433
trainer/policy/mean Mean                 0.0573238
trainer/policy/mean Std                  0.679782
trainer/policy/mean Max                  0.996557
trainer/policy/mean Min                 -0.997308
trainer/policy/normal/std Mean           0.580404
trainer/policy/normal/std Std            0.190869
trainer/policy/normal/std Max            1.14883
trainer/policy/normal/std Min            0.135888
trainer/policy/normal/log_std Mean      -0.604266
trainer/policy/normal/log_std Std        0.360231
trainer/policy/normal/log_std Max        0.138742
trainer/policy/normal/log_std Min       -1.99592
trainer/Alpha                            0.000132163
trainer/Alpha Loss                       2.3462
expl/num steps total                236000
expl/num paths total                 28157
expl/path length Mean                    4.1841
expl/path length Std                     1.58431
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.238
expl/Rewards Std                         0.425859
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995816
expl/Returns Std                         0.0645492
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0609141
expl/Actions Std                         0.755484
expl/Actions Max                         0.999892
expl/Actions Min                        -0.999507
expl/Num Paths                         239
expl/Average Returns                     0.995816
eval/num steps total                     1.16792e+06
eval/num paths total                141282
eval/path length Mean                    3.93312
eval/path length Std                     1.68795
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254251
eval/Rewards Std                         0.435439
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.000647074
eval/Actions Std                         0.672554
eval/Actions Max                         0.997177
eval/Actions Min                        -0.99725
eval/Num Paths                        1271
eval/Average Returns                     1
time/data storing (s)                    0.00612919
time/evaluation sampling (s)             0.978376
time/exploration sampling (s)            0.320367
time/logging (s)                         0.0185126
time/sac training (s)                   12.6667
time/saving (s)                          0.00386352
time/training (s)                        2.142e-05
time/epoch (s)                          13.9939
time/total (s)                        3132.47
Epoch                                  234
----------------------------------  ----------------
2022-09-09 20:45:18.836654 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 235 finished
----------------------------------  ----------------
epoch                                  235
replay_buffer/size                  237000
trainer/num train calls             236000
trainer/QF1 Loss                         1.00357e-06
trainer/QF2 Loss                         1.39389e-06
trainer/Policy Loss                     -0.961821
trainer/Q1 Predictions Mean              0.956756
trainer/Q1 Predictions Std               0.0250457
trainer/Q1 Predictions Max               1.00029
trainer/Q1 Predictions Min               0.927728
trainer/Q2 Predictions Mean              0.957392
trainer/Q2 Predictions Std               0.0250373
trainer/Q2 Predictions Max               1.00201
trainer/Q2 Predictions Min               0.92829
trainer/Q Targets Mean                   0.957174
trainer/Q Targets Std                    0.0251526
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92798
trainer/Log Pis Mean                     3.04905
trainer/Log Pis Std                      1.76252
trainer/Log Pis Max                      7.84726
trainer/Log Pis Min                     -3.26398
trainer/policy/mean Mean                 0.0426488
trainer/policy/mean Std                  0.690647
trainer/policy/mean Max                  0.995635
trainer/policy/mean Min                 -0.994743
trainer/policy/normal/std Mean           0.600994
trainer/policy/normal/std Std            0.176386
trainer/policy/normal/std Max            1.21764
trainer/policy/normal/std Min            0.219716
trainer/policy/normal/log_std Mean      -0.55395
trainer/policy/normal/log_std Std        0.303397
trainer/policy/normal/log_std Max        0.196918
trainer/policy/normal/log_std Min       -1.51542
trainer/Alpha                            0.000135145
trainer/Alpha Loss                       0.437009
expl/num steps total                237000
expl/num paths total                 28417
expl/path length Mean                    3.84615
expl/path length Std                     1.74515
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.26
expl/Rewards Std                         0.438634
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0148277
expl/Actions Std                         0.75911
expl/Actions Max                         0.999648
expl/Actions Min                        -0.999385
expl/Num Paths                         260
expl/Average Returns                     1
eval/num steps total                     1.17292e+06
eval/num paths total                142529
eval/path length Mean                    4.00962
eval/path length Std                     1.63165
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2494
eval/Rewards Std                         0.432666
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0184812
eval/Actions Std                         0.680213
eval/Actions Max                         0.996512
eval/Actions Min                        -0.996408
eval/Num Paths                        1247
eval/Average Returns                     1
time/data storing (s)                    0.00394336
time/evaluation sampling (s)             0.985677
time/exploration sampling (s)            0.306357
time/logging (s)                         0.0197539
time/sac training (s)                   12.1979
time/saving (s)                          0.00500774
time/training (s)                        3.458e-05
time/epoch (s)                          13.5186
time/total (s)                        3146.31
Epoch                                  235
----------------------------------  ----------------
2022-09-09 20:45:32.521033 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 236 finished
----------------------------------  ----------------
epoch                                  236
replay_buffer/size                  238000
trainer/num train calls             237000
trainer/QF1 Loss                         6.30398e-07
trainer/QF2 Loss                         1.9796e-06
trainer/Policy Loss                     -0.961539
trainer/Q1 Predictions Mean              0.956956
trainer/Q1 Predictions Std               0.0256077
trainer/Q1 Predictions Max               1.00135
trainer/Q1 Predictions Min               0.928148
trainer/Q2 Predictions Mean              0.956785
trainer/Q2 Predictions Std               0.025738
trainer/Q2 Predictions Max               1.0015
trainer/Q2 Predictions Min               0.926939
trainer/Q Targets Mean                   0.956895
trainer/Q Targets Std                    0.0255764
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928385
trainer/Log Pis Mean                     2.96463
trainer/Log Pis Std                      1.91459
trainer/Log Pis Max                      7.43834
trainer/Log Pis Min                     -3.64335
trainer/policy/mean Mean                 0.0456816
trainer/policy/mean Std                  0.689461
trainer/policy/mean Max                  0.995649
trainer/policy/mean Min                 -0.995807
trainer/policy/normal/std Mean           0.606031
trainer/policy/normal/std Std            0.17027
trainer/policy/normal/std Max            0.990259
trainer/policy/normal/std Min            0.185952
trainer/policy/normal/log_std Mean      -0.543631
trainer/policy/normal/log_std Std        0.300213
trainer/policy/normal/log_std Max       -0.0097884
trainer/policy/normal/log_std Min       -1.68226
trainer/Alpha                            0.000129754
trainer/Alpha Loss                      -0.316595
expl/num steps total                238000
expl/num paths total                 28668
expl/path length Mean                    3.98406
expl/path length Std                     1.75823
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.25
expl/Rewards Std                         0.433013
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996016
expl/Returns Std                         0.0629936
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0597199
expl/Actions Std                         0.757113
expl/Actions Max                         0.999537
expl/Actions Min                        -0.999628
expl/Num Paths                         251
expl/Average Returns                     0.996016
eval/num steps total                     1.17791e+06
eval/num paths total                143788
eval/path length Mean                    3.97061
eval/path length Std                     1.67633
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25185
eval/Rewards Std                         0.434076
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00733123
eval/Actions Std                         0.670931
eval/Actions Max                         0.996364
eval/Actions Min                        -0.995929
eval/Num Paths                        1259
eval/Average Returns                     1
time/data storing (s)                    0.00610847
time/evaluation sampling (s)             0.990869
time/exploration sampling (s)            0.328379
time/logging (s)                         0.0195151
time/sac training (s)                   12.0224
time/saving (s)                          0.00338655
time/training (s)                        0.00010149
time/epoch (s)                          13.3707
time/total (s)                        3159.99
Epoch                                  236
----------------------------------  ----------------
2022-09-09 20:45:46.637350 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 237 finished
----------------------------------  ----------------
epoch                                  237
replay_buffer/size                  239000
trainer/num train calls             238000
trainer/QF1 Loss                         8.0452e-07
trainer/QF2 Loss                         1.5446e-06
trainer/Policy Loss                     -0.96376
trainer/Q1 Predictions Mean              0.959559
trainer/Q1 Predictions Std               0.0256415
trainer/Q1 Predictions Max               1.00098
trainer/Q1 Predictions Min               0.928606
trainer/Q2 Predictions Mean              0.959472
trainer/Q2 Predictions Std               0.0255922
trainer/Q2 Predictions Max               1.00149
trainer/Q2 Predictions Min               0.928127
trainer/Q Targets Mean                   0.959222
trainer/Q Targets Std                    0.0257067
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927861
trainer/Log Pis Mean                     2.84639
trainer/Log Pis Std                      1.78418
trainer/Log Pis Max                      7.29643
trainer/Log Pis Min                     -3.79766
trainer/policy/mean Mean                 0.0774032
trainer/policy/mean Std                  0.676733
trainer/policy/mean Max                  0.995434
trainer/policy/mean Min                 -0.99528
trainer/policy/normal/std Mean           0.604301
trainer/policy/normal/std Std            0.20017
trainer/policy/normal/std Max            1.21528
trainer/policy/normal/std Min            0.195452
trainer/policy/normal/log_std Mean      -0.563588
trainer/policy/normal/log_std Std        0.356012
trainer/policy/normal/log_std Max        0.194975
trainer/policy/normal/log_std Min       -1.63244
trainer/Alpha                            0.000130408
trainer/Alpha Loss                      -1.37401
expl/num steps total                239000
expl/num paths total                 28918
expl/path length Mean                    4
expl/path length Std                     1.61988
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.25
expl/Rewards Std                         0.433013
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0410856
expl/Actions Std                         0.758677
expl/Actions Max                         0.999518
expl/Actions Min                        -0.999509
expl/Num Paths                         250
expl/Average Returns                     1
eval/num steps total                     1.18291e+06
eval/num paths total                145054
eval/path length Mean                    3.94787
eval/path length Std                     1.67798
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253301
eval/Rewards Std                         0.434902
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0367223
eval/Actions Std                         0.667189
eval/Actions Max                         0.995862
eval/Actions Min                        -0.996112
eval/Num Paths                        1266
eval/Average Returns                     1
time/data storing (s)                    0.00433876
time/evaluation sampling (s)             1.03476
time/exploration sampling (s)            0.299935
time/logging (s)                         0.0187096
time/sac training (s)                   12.4103
time/saving (s)                          0.00466052
time/training (s)                        3.219e-05
time/epoch (s)                          13.7727
time/total (s)                        3174.09
Epoch                                  237
----------------------------------  ----------------
2022-09-09 20:46:01.053182 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 238 finished
----------------------------------  ----------------
epoch                                  238
replay_buffer/size                  240000
trainer/num train calls             239000
trainer/QF1 Loss                         1.11028e-06
trainer/QF2 Loss                         1.81747e-06
trainer/Policy Loss                     -0.963552
trainer/Q1 Predictions Mean              0.959237
trainer/Q1 Predictions Std               0.0246968
trainer/Q1 Predictions Max               1.00108
trainer/Q1 Predictions Min               0.928561
trainer/Q2 Predictions Mean              0.958669
trainer/Q2 Predictions Std               0.0249663
trainer/Q2 Predictions Max               1.00275
trainer/Q2 Predictions Min               0.927676
trainer/Q Targets Mean                   0.95849
trainer/Q Targets Std                    0.0248276
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928434
trainer/Log Pis Mean                     3.05829
trainer/Log Pis Std                      1.87172
trainer/Log Pis Max                      7.63339
trainer/Log Pis Min                     -4.55373
trainer/policy/mean Mean                 0.0773938
trainer/policy/mean Std                  0.684067
trainer/policy/mean Max                  0.995173
trainer/policy/mean Min                 -0.994816
trainer/policy/normal/std Mean           0.601491
trainer/policy/normal/std Std            0.202963
trainer/policy/normal/std Max            1.06239
trainer/policy/normal/std Min            0.2029
trainer/policy/normal/log_std Mean      -0.56968
trainer/policy/normal/log_std Std        0.358491
trainer/policy/normal/log_std Max        0.0605204
trainer/policy/normal/log_std Min       -1.59504
trainer/Alpha                            0.000127901
trainer/Alpha Loss                       0.522546
expl/num steps total                240000
expl/num paths total                 29166
expl/path length Mean                    4.03226
expl/path length Std                     1.6917
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.247
expl/Rewards Std                         0.431267
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995968
expl/Returns Std                         0.0633719
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0377052
expl/Actions Std                         0.759089
expl/Actions Max                         0.999728
expl/Actions Min                        -0.999432
expl/Num Paths                         248
expl/Average Returns                     0.995968
eval/num steps total                     1.18791e+06
eval/num paths total                146327
eval/path length Mean                    3.92773
eval/path length Std                     1.65988
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2546
eval/Rewards Std                         0.435636
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00470888
eval/Actions Std                         0.668384
eval/Actions Max                         0.996205
eval/Actions Min                        -0.995768
eval/Num Paths                        1273
eval/Average Returns                     1
time/data storing (s)                    0.00612614
time/evaluation sampling (s)             0.972965
time/exploration sampling (s)            0.315452
time/logging (s)                         0.0181727
time/sac training (s)                   12.7399
time/saving (s)                          0.00384697
time/training (s)                        2.128e-05
time/epoch (s)                          14.0565
time/total (s)                        3188.49
Epoch                                  238
----------------------------------  ----------------
2022-09-09 20:46:15.198196 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 239 finished
----------------------------------  ----------------
epoch                                  239
replay_buffer/size                  241000
trainer/num train calls             240000
trainer/QF1 Loss                         1.04255e-06
trainer/QF2 Loss                         2.59266e-06
trainer/Policy Loss                     -0.9611
trainer/Q1 Predictions Mean              0.956778
trainer/Q1 Predictions Std               0.0253877
trainer/Q1 Predictions Max               0.99992
trainer/Q1 Predictions Min               0.927831
trainer/Q2 Predictions Mean              0.956283
trainer/Q2 Predictions Std               0.0252579
trainer/Q2 Predictions Max               1.00026
trainer/Q2 Predictions Min               0.927059
trainer/Q Targets Mean                   0.957072
trainer/Q Targets Std                    0.0254655
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928447
trainer/Log Pis Mean                     2.84256
trainer/Log Pis Std                      1.89827
trainer/Log Pis Max                      7.36167
trainer/Log Pis Min                     -3.76251
trainer/policy/mean Mean                 0.029274
trainer/policy/mean Std                  0.689632
trainer/policy/mean Max                  0.997001
trainer/policy/mean Min                 -0.996741
trainer/policy/normal/std Mean           0.598441
trainer/policy/normal/std Std            0.184798
trainer/policy/normal/std Max            1.27351
trainer/policy/normal/std Min            0.179041
trainer/policy/normal/log_std Mean      -0.566489
trainer/policy/normal/log_std Std        0.33717
trainer/policy/normal/log_std Max        0.241775
trainer/policy/normal/log_std Min       -1.72014
trainer/Alpha                            0.000128112
trainer/Alpha Loss                      -1.41105
expl/num steps total                241000
expl/num paths total                 29429
expl/path length Mean                    3.80228
expl/path length Std                     1.66571
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.263
expl/Rewards Std                         0.440262
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.00760815
expl/Actions Std                         0.757702
expl/Actions Max                         0.999591
expl/Actions Min                        -0.999421
expl/Num Paths                         263
expl/Average Returns                     1
eval/num steps total                     1.19291e+06
eval/num paths total                147586
eval/path length Mean                    3.96982
eval/path length Std                     1.64837
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251901
eval/Rewards Std                         0.434105
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0244199
eval/Actions Std                         0.681584
eval/Actions Max                         0.996286
eval/Actions Min                        -0.997119
eval/Num Paths                        1259
eval/Average Returns                     1
time/data storing (s)                    0.00394539
time/evaluation sampling (s)             0.993744
time/exploration sampling (s)            0.326418
time/logging (s)                         0.0277292
time/sac training (s)                   12.4629
time/saving (s)                          0.00457046
time/training (s)                        0.00020297
time/epoch (s)                          13.8195
time/total (s)                        3202.63
Epoch                                  239
----------------------------------  ----------------
2022-09-09 20:46:30.221995 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 240 finished
----------------------------------  ----------------
epoch                                  240
replay_buffer/size                  242000
trainer/num train calls             241000
trainer/QF1 Loss                         1.0643e-06
trainer/QF2 Loss                         4.52612e-06
trainer/Policy Loss                     -0.963443
trainer/Q1 Predictions Mean              0.958339
trainer/Q1 Predictions Std               0.026136
trainer/Q1 Predictions Max               1.00147
trainer/Q1 Predictions Min               0.928019
trainer/Q2 Predictions Mean              0.959398
trainer/Q2 Predictions Std               0.0260082
trainer/Q2 Predictions Max               1.00264
trainer/Q2 Predictions Min               0.929949
trainer/Q Targets Mean                   0.957792
trainer/Q Targets Std                    0.0259468
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928163
trainer/Log Pis Mean                     3.20458
trainer/Log Pis Std                      1.87634
trainer/Log Pis Max                      8.83615
trainer/Log Pis Min                     -3.68392
trainer/policy/mean Mean                 0.106765
trainer/policy/mean Std                  0.679264
trainer/policy/mean Max                  0.99536
trainer/policy/mean Min                 -0.997089
trainer/policy/normal/std Mean           0.592262
trainer/policy/normal/std Std            0.198693
trainer/policy/normal/std Max            0.924156
trainer/policy/normal/std Min            0.169754
trainer/policy/normal/log_std Mean      -0.584866
trainer/policy/normal/log_std Std        0.359042
trainer/policy/normal/log_std Max       -0.0788746
trainer/policy/normal/log_std Min       -1.7734
trainer/Alpha                            0.000129731
trainer/Alpha Loss                       1.83102
expl/num steps total                242000
expl/num paths total                 29690
expl/path length Mean                    3.83142
expl/path length Std                     1.71603
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.26
expl/Rewards Std                         0.438634
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996169
expl/Returns Std                         0.0617798
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.000227694
expl/Actions Std                         0.748608
expl/Actions Max                         0.999754
expl/Actions Min                        -0.999627
expl/Num Paths                         261
expl/Average Returns                     0.996169
eval/num steps total                     1.19791e+06
eval/num paths total                148855
eval/path length Mean                    3.93775
eval/path length Std                     1.65649
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253952
eval/Rewards Std                         0.435271
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0167641
eval/Actions Std                         0.670315
eval/Actions Max                         0.995937
eval/Actions Min                        -0.997216
eval/Num Paths                        1269
eval/Average Returns                     1
time/data storing (s)                    0.00406492
time/evaluation sampling (s)             1.00868
time/exploration sampling (s)            0.311709
time/logging (s)                         0.0199619
time/sac training (s)                   13.2489
time/saving (s)                          0.00347953
time/training (s)                        2.47e-05
time/epoch (s)                          14.5968
time/total (s)                        3217.63
Epoch                                  240
----------------------------------  ----------------
2022-09-09 20:46:44.380517 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 241 finished
----------------------------------  ----------------
epoch                                  241
replay_buffer/size                  243000
trainer/num train calls             242000
trainer/QF1 Loss                         1.62576e-06
trainer/QF2 Loss                         2.68321e-06
trainer/Policy Loss                     -0.96487
trainer/Q1 Predictions Mean              0.960635
trainer/Q1 Predictions Std               0.0246974
trainer/Q1 Predictions Max               1.00253
trainer/Q1 Predictions Min               0.929472
trainer/Q2 Predictions Mean              0.960623
trainer/Q2 Predictions Std               0.0247449
trainer/Q2 Predictions Max               1.00298
trainer/Q2 Predictions Min               0.929165
trainer/Q Targets Mean                   0.959593
trainer/Q Targets Std                    0.0246744
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928227
trainer/Log Pis Mean                     2.82721
trainer/Log Pis Std                      1.80118
trainer/Log Pis Max                      7.12098
trainer/Log Pis Min                     -4.00121
trainer/policy/mean Mean                 0.107771
trainer/policy/mean Std                  0.661843
trainer/policy/mean Max                  0.996079
trainer/policy/mean Min                 -0.995518
trainer/policy/normal/std Mean           0.609883
trainer/policy/normal/std Std            0.20347
trainer/policy/normal/std Max            1.23356
trainer/policy/normal/std Min            0.21785
trainer/policy/normal/log_std Mean      -0.553271
trainer/policy/normal/log_std Std        0.349291
trainer/policy/normal/log_std Max        0.209904
trainer/policy/normal/log_std Min       -1.52395
trainer/Alpha                            0.000130249
trainer/Alpha Loss                      -1.54574
expl/num steps total                243000
expl/num paths total                 29947
expl/path length Mean                    3.89105
expl/path length Std                     1.6061
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.256
expl/Rewards Std                         0.436422
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996109
expl/Returns Std                         0.0622568
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.052628
expl/Actions Std                         0.755623
expl/Actions Max                         0.999786
expl/Actions Min                        -0.999547
expl/Num Paths                         257
expl/Average Returns                     0.996109
eval/num steps total                     1.20291e+06
eval/num paths total                150128
eval/path length Mean                    3.92694
eval/path length Std                     1.71501
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254651
eval/Rewards Std                         0.435665
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00428181
eval/Actions Std                         0.665194
eval/Actions Max                         0.996384
eval/Actions Min                        -0.995785
eval/Num Paths                        1273
eval/Average Returns                     1
time/data storing (s)                    0.00478838
time/evaluation sampling (s)             0.978678
time/exploration sampling (s)            0.317806
time/logging (s)                         0.0207926
time/sac training (s)                   12.5219
time/saving (s)                          0.00370857
time/training (s)                        2.87e-05
time/epoch (s)                          13.8477
time/total (s)                        3231.78
Epoch                                  241
----------------------------------  ----------------
2022-09-09 20:46:58.323880 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 242 finished
----------------------------------  ----------------
epoch                                  242
replay_buffer/size                  244000
trainer/num train calls             243000
trainer/QF1 Loss                         1.5551e-06
trainer/QF2 Loss                         3.25044e-06
trainer/Policy Loss                     -0.964552
trainer/Q1 Predictions Mean              0.960086
trainer/Q1 Predictions Std               0.0249227
trainer/Q1 Predictions Max               1.00241
trainer/Q1 Predictions Min               0.928778
trainer/Q2 Predictions Mean              0.960961
trainer/Q2 Predictions Std               0.024675
trainer/Q2 Predictions Max               1.00115
trainer/Q2 Predictions Min               0.929783
trainer/Q Targets Mean                   0.959915
trainer/Q Targets Std                    0.0251333
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928107
trainer/Log Pis Mean                     3.12827
trainer/Log Pis Std                      1.62682
trainer/Log Pis Max                      8.03074
trainer/Log Pis Min                     -3.75492
trainer/policy/mean Mean                 0.126946
trainer/policy/mean Std                  0.665278
trainer/policy/mean Max                  0.995566
trainer/policy/mean Min                 -0.99557
trainer/policy/normal/std Mean           0.59437
trainer/policy/normal/std Std            0.17846
trainer/policy/normal/std Max            1.10051
trainer/policy/normal/std Min            0.155418
trainer/policy/normal/log_std Mean      -0.567934
trainer/policy/normal/log_std Std        0.31509
trainer/policy/normal/log_std Max        0.09577
trainer/policy/normal/log_std Min       -1.86164
trainer/Alpha                            0.000128062
trainer/Alpha Loss                       1.14972
expl/num steps total                244000
expl/num paths total                 30201
expl/path length Mean                    3.93701
expl/path length Std                     1.68246
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.254
expl/Rewards Std                         0.435298
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.032391
expl/Actions Std                         0.754968
expl/Actions Max                         0.999707
expl/Actions Min                        -0.999725
expl/Num Paths                         254
expl/Average Returns                     1
eval/num steps total                     1.2079e+06
eval/num paths total                151423
eval/path length Mean                    3.85946
eval/path length Std                     1.68583
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.259104
eval/Rewards Std                         0.438143
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0381795
eval/Actions Std                         0.664468
eval/Actions Max                         0.996187
eval/Actions Min                        -0.995767
eval/Num Paths                        1295
eval/Average Returns                     1
time/data storing (s)                    0.00621748
time/evaluation sampling (s)             1.0196
time/exploration sampling (s)            0.307807
time/logging (s)                         0.0200648
time/sac training (s)                   12.2907
time/saving (s)                          0.00468102
time/training (s)                        2.813e-05
time/epoch (s)                          13.6491
time/total (s)                        3245.71
Epoch                                  242
----------------------------------  ----------------
2022-09-09 20:47:12.222238 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 243 finished
----------------------------------  ----------------
epoch                                  243
replay_buffer/size                  245000
trainer/num train calls             244000
trainer/QF1 Loss                         7.47928e-07
trainer/QF2 Loss                         1.60903e-06
trainer/Policy Loss                     -0.96291
trainer/Q1 Predictions Mean              0.958254
trainer/Q1 Predictions Std               0.0254706
trainer/Q1 Predictions Max               1.0009
trainer/Q1 Predictions Min               0.927878
trainer/Q2 Predictions Mean              0.958445
trainer/Q2 Predictions Std               0.0253188
trainer/Q2 Predictions Max               1.00104
trainer/Q2 Predictions Min               0.92767
trainer/Q Targets Mean                   0.958611
trainer/Q Targets Std                    0.0252936
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928549
trainer/Log Pis Mean                     2.9162
trainer/Log Pis Std                      1.83035
trainer/Log Pis Max                      7.20592
trainer/Log Pis Min                     -2.97341
trainer/policy/mean Mean                 0.127417
trainer/policy/mean Std                  0.677824
trainer/policy/mean Max                  0.995122
trainer/policy/mean Min                 -0.995162
trainer/policy/normal/std Mean           0.625569
trainer/policy/normal/std Std            0.196305
trainer/policy/normal/std Max            1.02038
trainer/policy/normal/std Min            0.199896
trainer/policy/normal/log_std Mean      -0.521364
trainer/policy/normal/log_std Std        0.329809
trainer/policy/normal/log_std Max        0.020171
trainer/policy/normal/log_std Min       -1.60996
trainer/Alpha                            0.000130014
trainer/Alpha Loss                      -0.749845
expl/num steps total                245000
expl/num paths total                 30441
expl/path length Mean                    4.16667
expl/path length Std                     1.69967
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.24
expl/Rewards Std                         0.427083
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0206138
expl/Actions Std                         0.757304
expl/Actions Max                         0.99953
expl/Actions Min                        -0.999763
expl/Num Paths                         240
expl/Average Returns                     1
eval/num steps total                     1.2129e+06
eval/num paths total                152702
eval/path length Mean                    3.9093
eval/path length Std                     1.63319
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2558
eval/Rewards Std                         0.43631
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0449536
eval/Actions Std                         0.665116
eval/Actions Max                         0.995572
eval/Actions Min                        -0.995338
eval/Num Paths                        1279
eval/Average Returns                     1
time/data storing (s)                    0.00630403
time/evaluation sampling (s)             0.984144
time/exploration sampling (s)            0.334273
time/logging (s)                         0.0209863
time/sac training (s)                   12.2394
time/saving (s)                          0.00421447
time/training (s)                        2.305e-05
time/epoch (s)                          13.5893
time/total (s)                        3259.6
Epoch                                  243
----------------------------------  ----------------
2022-09-09 20:47:26.383134 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 244 finished
----------------------------------  ----------------
epoch                                  244
replay_buffer/size                  246000
trainer/num train calls             245000
trainer/QF1 Loss                         8.47527e-07
trainer/QF2 Loss                         5.20323e-06
trainer/Policy Loss                     -0.962557
trainer/Q1 Predictions Mean              0.957482
trainer/Q1 Predictions Std               0.0251627
trainer/Q1 Predictions Max               1.00168
trainer/Q1 Predictions Min               0.928878
trainer/Q2 Predictions Mean              0.959108
trainer/Q2 Predictions Std               0.0252497
trainer/Q2 Predictions Max               1.00504
trainer/Q2 Predictions Min               0.929287
trainer/Q Targets Mean                   0.957324
trainer/Q Targets Std                    0.0251983
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928921
trainer/Log Pis Mean                     3.00609
trainer/Log Pis Std                      1.85305
trainer/Log Pis Max                      7.41873
trainer/Log Pis Min                     -3.97277
trainer/policy/mean Mean                 0.0818596
trainer/policy/mean Std                  0.676851
trainer/policy/mean Max                  0.99541
trainer/policy/mean Min                 -0.995551
trainer/policy/normal/std Mean           0.614184
trainer/policy/normal/std Std            0.196002
trainer/policy/normal/std Max            0.987725
trainer/policy/normal/std Min            0.168808
trainer/policy/normal/log_std Mean      -0.541876
trainer/policy/normal/log_std Std        0.336913
trainer/policy/normal/log_std Max       -0.0123506
trainer/policy/normal/log_std Min       -1.77899
trainer/Alpha                            0.000126186
trainer/Alpha Loss                       0.0547076
expl/num steps total                246000
expl/num paths total                 30704
expl/path length Mean                    3.80228
expl/path length Std                     1.69737
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.262
expl/Rewards Std                         0.439723
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996198
expl/Returns Std                         0.0615453
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.020609
expl/Actions Std                         0.753802
expl/Actions Max                         0.999248
expl/Actions Min                        -0.999563
expl/Num Paths                         263
expl/Average Returns                     0.996198
eval/num steps total                     1.2179e+06
eval/num paths total                153968
eval/path length Mean                    3.94945
eval/path length Std                     1.6752
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2532
eval/Rewards Std                         0.434845
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0346281
eval/Actions Std                         0.6621
eval/Actions Max                         0.996064
eval/Actions Min                        -0.995669
eval/Num Paths                        1266
eval/Average Returns                     1
time/data storing (s)                    0.00630135
time/evaluation sampling (s)             0.982776
time/exploration sampling (s)            0.327779
time/logging (s)                         0.0183113
time/sac training (s)                   12.4898
time/saving (s)                          0.00386135
time/training (s)                        1.969e-05
time/epoch (s)                          13.8288
time/total (s)                        3273.74
Epoch                                  244
----------------------------------  ----------------
2022-09-09 20:47:40.261147 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 245 finished
----------------------------------  ----------------
epoch                                  245
replay_buffer/size                  247000
trainer/num train calls             246000
trainer/QF1 Loss                         9.07156e-07
trainer/QF2 Loss                         3.9284e-06
trainer/Policy Loss                     -0.963052
trainer/Q1 Predictions Mean              0.95814
trainer/Q1 Predictions Std               0.0250735
trainer/Q1 Predictions Max               1.00145
trainer/Q1 Predictions Min               0.928819
trainer/Q2 Predictions Mean              0.959473
trainer/Q2 Predictions Std               0.02501
trainer/Q2 Predictions Max               1.0028
trainer/Q2 Predictions Min               0.930246
trainer/Q Targets Mean                   0.95811
trainer/Q Targets Std                    0.0252791
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928609
trainer/Log Pis Mean                     2.90164
trainer/Log Pis Std                      1.74781
trainer/Log Pis Max                      7.99325
trainer/Log Pis Min                     -5.7029
trainer/policy/mean Mean                 0.0951313
trainer/policy/mean Std                  0.667193
trainer/policy/mean Max                  0.995559
trainer/policy/mean Min                 -0.996026
trainer/policy/normal/std Mean           0.599066
trainer/policy/normal/std Std            0.18437
trainer/policy/normal/std Max            0.937609
trainer/policy/normal/std Min            0.182871
trainer/policy/normal/log_std Mean      -0.563389
trainer/policy/normal/log_std Std        0.327124
trainer/policy/normal/log_std Max       -0.0644219
trainer/policy/normal/log_std Min       -1.69897
trainer/Alpha                            0.000124955
trainer/Alpha Loss                      -0.883993
expl/num steps total                247000
expl/num paths total                 30961
expl/path length Mean                    3.89105
expl/path length Std                     1.71166
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.256
expl/Rewards Std                         0.436422
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996109
expl/Returns Std                         0.0622568
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0136904
expl/Actions Std                         0.755981
expl/Actions Max                         0.99975
expl/Actions Min                        -0.999584
expl/Num Paths                         257
expl/Average Returns                     0.996109
eval/num steps total                     1.2229e+06
eval/num paths total                155240
eval/path length Mean                    3.92925
eval/path length Std                     1.7059
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254502
eval/Rewards Std                         0.435581
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0100626
eval/Actions Std                         0.665715
eval/Actions Max                         0.995816
eval/Actions Min                        -0.997109
eval/Num Paths                        1272
eval/Average Returns                     1
time/data storing (s)                    0.00412581
time/evaluation sampling (s)             0.976543
time/exploration sampling (s)            0.35461
time/logging (s)                         0.0204312
time/sac training (s)                   12.2116
time/saving (s)                          0.00334816
time/training (s)                        1.95e-05
time/epoch (s)                          13.5707
time/total (s)                        3287.61
Epoch                                  245
----------------------------------  ----------------
2022-09-09 20:47:54.503080 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 246 finished
----------------------------------  ----------------
epoch                                  246
replay_buffer/size                  248000
trainer/num train calls             247000
trainer/QF1 Loss                         1.13471e-06
trainer/QF2 Loss                         3.52923e-06
trainer/Policy Loss                     -0.961038
trainer/Q1 Predictions Mean              0.958422
trainer/Q1 Predictions Std               0.0254237
trainer/Q1 Predictions Max               1.00114
trainer/Q1 Predictions Min               0.929071
trainer/Q2 Predictions Mean              0.956729
trainer/Q2 Predictions Std               0.0255742
trainer/Q2 Predictions Max               1.00128
trainer/Q2 Predictions Min               0.926802
trainer/Q Targets Mean                   0.958181
trainer/Q Targets Std                    0.0255174
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92862
trainer/Log Pis Mean                     3.04242
trainer/Log Pis Std                      1.8047
trainer/Log Pis Max                      8.90916
trainer/Log Pis Min                     -4.19612
trainer/policy/mean Mean                 0.0603231
trainer/policy/mean Std                  0.67159
trainer/policy/mean Max                  0.995333
trainer/policy/mean Min                 -0.995423
trainer/policy/normal/std Mean           0.598177
trainer/policy/normal/std Std            0.194195
trainer/policy/normal/std Max            1.04916
trainer/policy/normal/std Min            0.179798
trainer/policy/normal/log_std Mean      -0.570596
trainer/policy/normal/log_std Std        0.345184
trainer/policy/normal/log_std Max        0.0479859
trainer/policy/normal/log_std Min       -1.71592
trainer/Alpha                            0.000126678
trainer/Alpha Loss                       0.380647
expl/num steps total                248000
expl/num paths total                 31214
expl/path length Mean                    3.95257
expl/path length Std                     1.71189
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.252
expl/Rewards Std                         0.434161
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996047
expl/Returns Std                         0.0627451
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0476037
expl/Actions Std                         0.75451
expl/Actions Max                         0.9997
expl/Actions Min                        -0.999802
expl/Num Paths                         253
expl/Average Returns                     0.996047
eval/num steps total                     1.2279e+06
eval/num paths total                156523
eval/path length Mean                    3.89634
eval/path length Std                     1.68927
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.256651
eval/Rewards Std                         0.436785
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00667605
eval/Actions Std                         0.667593
eval/Actions Max                         0.995359
eval/Actions Min                        -0.996639
eval/Num Paths                        1283
eval/Average Returns                     1
time/data storing (s)                    0.00390586
time/evaluation sampling (s)             0.99515
time/exploration sampling (s)            0.324753
time/logging (s)                         0.0200423
time/sac training (s)                   12.5086
time/saving (s)                          0.0047497
time/training (s)                        2.666e-05
time/epoch (s)                          13.8572
time/total (s)                        3301.84
Epoch                                  246
----------------------------------  ----------------
2022-09-09 20:48:08.770944 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 247 finished
----------------------------------  ----------------
epoch                                  247
replay_buffer/size                  249000
trainer/num train calls             248000
trainer/QF1 Loss                         1.04572e-06
trainer/QF2 Loss                         2.49074e-06
trainer/Policy Loss                     -0.964792
trainer/Q1 Predictions Mean              0.960368
trainer/Q1 Predictions Std               0.0262372
trainer/Q1 Predictions Max               1.00008
trainer/Q1 Predictions Min               0.928436
trainer/Q2 Predictions Mean              0.961234
trainer/Q2 Predictions Std               0.0259596
trainer/Q2 Predictions Max               1.00056
trainer/Q2 Predictions Min               0.930127
trainer/Q Targets Mean                   0.960582
trainer/Q Targets Std                    0.0264732
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929166
trainer/Log Pis Mean                     2.97206
trainer/Log Pis Std                      2.11439
trainer/Log Pis Max                      8.17314
trainer/Log Pis Min                    -11.5578
trainer/policy/mean Mean                 0.0833632
trainer/policy/mean Std                  0.684731
trainer/policy/mean Max                  0.995341
trainer/policy/mean Min                 -0.996551
trainer/policy/normal/std Mean           0.589656
trainer/policy/normal/std Std            0.196364
trainer/policy/normal/std Max            1.03059
trainer/policy/normal/std Min            0.164626
trainer/policy/normal/log_std Mean      -0.589727
trainer/policy/normal/log_std Std        0.362538
trainer/policy/normal/log_std Max        0.030136
trainer/policy/normal/log_std Min       -1.80408
trainer/Alpha                            0.000125935
trainer/Alpha Loss                      -0.250926
expl/num steps total                249000
expl/num paths total                 31459
expl/path length Mean                    4.08163
expl/path length Std                     1.69075
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.245
expl/Rewards Std                         0.430087
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0325201
expl/Actions Std                         0.748254
expl/Actions Max                         0.999737
expl/Actions Min                        -0.99964
expl/Num Paths                         245
expl/Average Returns                     1
eval/num steps total                     1.2329e+06
eval/num paths total                157778
eval/path length Mean                    3.98167
eval/path length Std                     1.67774
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251151
eval/Rewards Std                         0.433675
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0232404
eval/Actions Std                         0.669262
eval/Actions Max                         0.996219
eval/Actions Min                        -0.996871
eval/Num Paths                        1255
eval/Average Returns                     1
time/data storing (s)                    0.00625413
time/evaluation sampling (s)             0.994463
time/exploration sampling (s)            0.354034
time/logging (s)                         0.0223171
time/sac training (s)                   12.5486
time/saving (s)                          0.00338931
time/training (s)                        0.0001988
time/epoch (s)                          13.9293
time/total (s)                        3316.09
Epoch                                  247
----------------------------------  ----------------
2022-09-09 20:48:23.093393 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 248 finished
----------------------------------  ----------------
epoch                                  248
replay_buffer/size                  250000
trainer/num train calls             249000
trainer/QF1 Loss                         4.17108e-06
trainer/QF2 Loss                         4.33443e-06
trainer/Policy Loss                     -0.961387
trainer/Q1 Predictions Mean              0.957253
trainer/Q1 Predictions Std               0.0250271
trainer/Q1 Predictions Max               0.99993
trainer/Q1 Predictions Min               0.927468
trainer/Q2 Predictions Mean              0.957559
trainer/Q2 Predictions Std               0.0252141
trainer/Q2 Predictions Max               1.00012
trainer/Q2 Predictions Min               0.926855
trainer/Q Targets Mean                   0.958994
trainer/Q Targets Std                    0.0252835
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929266
trainer/Log Pis Mean                     3.03587
trainer/Log Pis Std                      1.79525
trainer/Log Pis Max                      8.89164
trainer/Log Pis Min                     -3.82493
trainer/policy/mean Mean                 0.044711
trainer/policy/mean Std                  0.687647
trainer/policy/mean Max                  0.995941
trainer/policy/mean Min                 -0.996479
trainer/policy/normal/std Mean           0.585104
trainer/policy/normal/std Std            0.193874
trainer/policy/normal/std Max            1.0443
trainer/policy/normal/std Min            0.175197
trainer/policy/normal/log_std Mean      -0.595497
trainer/policy/normal/log_std Std        0.354376
trainer/policy/normal/log_std Max        0.0433502
trainer/policy/normal/log_std Min       -1.74185
trainer/Alpha                            0.000129417
trainer/Alpha Loss                       0.321119
expl/num steps total                250000
expl/num paths total                 31704
expl/path length Mean                    4.08163
expl/path length Std                     1.6492
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.245
expl/Rewards Std                         0.430087
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0240749
expl/Actions Std                         0.751414
expl/Actions Max                         0.999412
expl/Actions Min                        -0.999366
expl/Num Paths                         245
expl/Average Returns                     1
eval/num steps total                     1.2379e+06
eval/num paths total                159064
eval/path length Mean                    3.88569
eval/path length Std                     1.65589
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.257354
eval/Rewards Std                         0.437176
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0198176
eval/Actions Std                         0.667425
eval/Actions Max                         0.996138
eval/Actions Min                        -0.996654
eval/Num Paths                        1286
eval/Average Returns                     1
time/data storing (s)                    0.00439522
time/evaluation sampling (s)             1.01704
time/exploration sampling (s)            0.285855
time/logging (s)                         0.0188655
time/sac training (s)                   12.6144
time/saving (s)                          0.00521193
time/training (s)                        2.962e-05
time/epoch (s)                          13.9458
time/total (s)                        3330.4
Epoch                                  248
----------------------------------  ----------------
2022-09-09 20:48:36.774404 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 249 finished
----------------------------------  ----------------
epoch                                  249
replay_buffer/size                  251000
trainer/num train calls             250000
trainer/QF1 Loss                         1.37172e-06
trainer/QF2 Loss                         1.53267e-06
trainer/Policy Loss                     -0.964182
trainer/Q1 Predictions Mean              0.960165
trainer/Q1 Predictions Std               0.0248102
trainer/Q1 Predictions Max               1.0003
trainer/Q1 Predictions Min               0.928216
trainer/Q2 Predictions Mean              0.960476
trainer/Q2 Predictions Std               0.0249674
trainer/Q2 Predictions Max               1.00135
trainer/Q2 Predictions Min               0.927482
trainer/Q Targets Mean                   0.960791
trainer/Q Targets Std                    0.0247607
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929181
trainer/Log Pis Mean                     2.9233
trainer/Log Pis Std                      1.71574
trainer/Log Pis Max                      7.11214
trainer/Log Pis Min                     -3.43266
trainer/policy/mean Mean                 0.0962175
trainer/policy/mean Std                  0.665588
trainer/policy/mean Max                  0.995758
trainer/policy/mean Min                 -0.99571
trainer/policy/normal/std Mean           0.580558
trainer/policy/normal/std Std            0.185882
trainer/policy/normal/std Max            0.975889
trainer/policy/normal/std Min            0.152945
trainer/policy/normal/log_std Mean      -0.600206
trainer/policy/normal/log_std Std        0.34655
trainer/policy/normal/log_std Max       -0.0244066
trainer/policy/normal/log_std Min       -1.87768
trainer/Alpha                            0.000126474
trainer/Alpha Loss                      -0.68846
expl/num steps total                251000
expl/num paths total                 31947
expl/path length Mean                    4.11523
expl/path length Std                     1.70785
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.242
expl/Rewards Std                         0.428294
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995885
expl/Returns Std                         0.0640179
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0243397
expl/Actions Std                         0.758049
expl/Actions Max                         0.999611
expl/Actions Min                        -0.999445
expl/Num Paths                         243
expl/Average Returns                     0.995885
eval/num steps total                     1.24289e+06
eval/num paths total                160314
eval/path length Mean                    3.9992
eval/path length Std                     1.64706
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25005
eval/Rewards Std                         0.433042
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0276464
eval/Actions Std                         0.668462
eval/Actions Max                         0.995919
eval/Actions Min                        -0.996252
eval/Num Paths                        1250
eval/Average Returns                     1
time/data storing (s)                    0.00391515
time/evaluation sampling (s)             1.0055
time/exploration sampling (s)            0.32325
time/logging (s)                         0.020682
time/sac training (s)                   12.0264
time/saving (s)                          0.00356046
time/training (s)                        0.000167591
time/epoch (s)                          13.3834
time/total (s)                        3344.07
Epoch                                  249
----------------------------------  ----------------
2022-09-09 20:48:50.537350 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 250 finished
----------------------------------  ----------------
epoch                                  250
replay_buffer/size                  252000
trainer/num train calls             251000
trainer/QF1 Loss                         1.7317e-06
trainer/QF2 Loss                         1.60791e-06
trainer/Policy Loss                     -0.961568
trainer/Q1 Predictions Mean              0.957217
trainer/Q1 Predictions Std               0.0243943
trainer/Q1 Predictions Max               1.00038
trainer/Q1 Predictions Min               0.927922
trainer/Q2 Predictions Mean              0.958491
trainer/Q2 Predictions Std               0.0240898
trainer/Q2 Predictions Max               1.00167
trainer/Q2 Predictions Min               0.92908
trainer/Q Targets Mean                   0.958283
trainer/Q Targets Std                    0.0242162
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929228
trainer/Log Pis Mean                     3.07472
trainer/Log Pis Std                      1.67418
trainer/Log Pis Max                      6.72661
trainer/Log Pis Min                     -2.21984
trainer/policy/mean Mean                 0.132072
trainer/policy/mean Std                  0.673382
trainer/policy/mean Max                  0.995987
trainer/policy/mean Min                 -0.995417
trainer/policy/normal/std Mean           0.605116
trainer/policy/normal/std Std            0.185693
trainer/policy/normal/std Max            1.09417
trainer/policy/normal/std Min            0.192674
trainer/policy/normal/log_std Mean      -0.553769
trainer/policy/normal/log_std Std        0.329823
trainer/policy/normal/log_std Max        0.0899915
trainer/policy/normal/log_std Min       -1.64676
trainer/Alpha                            0.000126389
trainer/Alpha Loss                       0.670657
expl/num steps total                252000
expl/num paths total                 32205
expl/path length Mean                    3.87597
expl/path length Std                     1.7276
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.257
expl/Rewards Std                         0.436979
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996124
expl/Returns Std                         0.0621365
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00562787
expl/Actions Std                         0.754829
expl/Actions Max                         0.999802
expl/Actions Min                        -0.999606
expl/Num Paths                         258
expl/Average Returns                     0.996124
eval/num steps total                     1.24789e+06
eval/num paths total                161558
eval/path length Mean                    4.01849
eval/path length Std                     1.67173
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.24885
eval/Rewards Std                         0.432347
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0447083
eval/Actions Std                         0.669183
eval/Actions Max                         0.996644
eval/Actions Min                        -0.996361
eval/Num Paths                        1244
eval/Average Returns                     1
time/data storing (s)                    0.00388738
time/evaluation sampling (s)             1.02063
time/exploration sampling (s)            0.338035
time/logging (s)                         0.0196104
time/sac training (s)                   12.0641
time/saving (s)                          0.00365517
time/training (s)                        2.241e-05
time/epoch (s)                          13.4499
time/total (s)                        3357.82
Epoch                                  250
----------------------------------  ----------------
2022-09-09 20:49:04.996509 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 251 finished
----------------------------------  ----------------
epoch                                  251
replay_buffer/size                  253000
trainer/num train calls             252000
trainer/QF1 Loss                         4.98156e-07
trainer/QF2 Loss                         1.40067e-06
trainer/Policy Loss                     -0.963617
trainer/Q1 Predictions Mean              0.959583
trainer/Q1 Predictions Std               0.0255098
trainer/Q1 Predictions Max               1.00093
trainer/Q1 Predictions Min               0.927668
trainer/Q2 Predictions Mean              0.95952
trainer/Q2 Predictions Std               0.0252088
trainer/Q2 Predictions Max               1.00036
trainer/Q2 Predictions Min               0.928295
trainer/Q Targets Mean                   0.959498
trainer/Q Targets Std                    0.0254047
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927371
trainer/Log Pis Mean                     2.9555
trainer/Log Pis Std                      1.64437
trainer/Log Pis Max                      7.35945
trainer/Log Pis Min                     -1.87564
trainer/policy/mean Mean                 0.0803931
trainer/policy/mean Std                  0.679722
trainer/policy/mean Max                  0.996336
trainer/policy/mean Min                 -0.995618
trainer/policy/normal/std Mean           0.603195
trainer/policy/normal/std Std            0.195897
trainer/policy/normal/std Max            1.14274
trainer/policy/normal/std Min            0.196085
trainer/policy/normal/log_std Mean      -0.562242
trainer/policy/normal/log_std Std        0.345043
trainer/policy/normal/log_std Max        0.133426
trainer/policy/normal/log_std Min       -1.62921
trainer/Alpha                            0.000125624
trainer/Alpha Loss                      -0.399722
expl/num steps total                253000
expl/num paths total                 32455
expl/path length Mean                    4
expl/path length Std                     1.61741
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996
expl/Returns Std                         0.0631189
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00777765
expl/Actions Std                         0.759234
expl/Actions Max                         0.999899
expl/Actions Min                        -0.999764
expl/Num Paths                         250
expl/Average Returns                     0.996
eval/num steps total                     1.25289e+06
eval/num paths total                162822
eval/path length Mean                    3.95491
eval/path length Std                     1.72574
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252851
eval/Rewards Std                         0.434646
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0278657
eval/Actions Std                         0.672959
eval/Actions Max                         0.996712
eval/Actions Min                        -0.996722
eval/Num Paths                        1264
eval/Average Returns                     1
time/data storing (s)                    0.00447564
time/evaluation sampling (s)             0.983429
time/exploration sampling (s)            0.336333
time/logging (s)                         0.0206719
time/sac training (s)                   12.7695
time/saving (s)                          0.00399697
time/training (s)                        2.178e-05
time/epoch (s)                          14.1185
time/total (s)                        3372.27
Epoch                                  251
----------------------------------  ----------------
2022-09-09 20:49:19.938172 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 252 finished
----------------------------------  ----------------
epoch                                  252
replay_buffer/size                  254000
trainer/num train calls             253000
trainer/QF1 Loss                         6.01945e-07
trainer/QF2 Loss                         1.06832e-06
trainer/Policy Loss                     -0.96198
trainer/Q1 Predictions Mean              0.957796
trainer/Q1 Predictions Std               0.0249693
trainer/Q1 Predictions Max               1.00153
trainer/Q1 Predictions Min               0.928495
trainer/Q2 Predictions Mean              0.957123
trainer/Q2 Predictions Std               0.0250591
trainer/Q2 Predictions Max               1.00109
trainer/Q2 Predictions Min               0.927865
trainer/Q Targets Mean                   0.957489
trainer/Q Targets Std                    0.0250057
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928947
trainer/Log Pis Mean                     3.09579
trainer/Log Pis Std                      1.781
trainer/Log Pis Max                      7.50345
trainer/Log Pis Min                     -4.5126
trainer/policy/mean Mean                 0.0762798
trainer/policy/mean Std                  0.679064
trainer/policy/mean Max                  0.995783
trainer/policy/mean Min                 -0.995226
trainer/policy/normal/std Mean           0.606892
trainer/policy/normal/std Std            0.196761
trainer/policy/normal/std Max            1.09193
trainer/policy/normal/std Min            0.195788
trainer/policy/normal/log_std Mean      -0.555992
trainer/policy/normal/log_std Std        0.344446
trainer/policy/normal/log_std Max        0.0879487
trainer/policy/normal/log_std Min       -1.63072
trainer/Alpha                            0.000124741
trainer/Alpha Loss                       0.861084
expl/num steps total                254000
expl/num paths total                 32684
expl/path length Mean                    4.36681
expl/path length Std                     1.63636
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.229
expl/Rewards Std                         0.420189
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0241371
expl/Actions Std                         0.75483
expl/Actions Max                         0.999574
expl/Actions Min                        -0.999353
expl/Num Paths                         229
expl/Average Returns                     1
eval/num steps total                     1.25789e+06
eval/num paths total                164089
eval/path length Mean                    3.94554
eval/path length Std                     1.71654
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253451
eval/Rewards Std                         0.434987
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0358974
eval/Actions Std                         0.667929
eval/Actions Max                         0.996039
eval/Actions Min                        -0.995022
eval/Num Paths                        1267
eval/Average Returns                     1
time/data storing (s)                    0.00376032
time/evaluation sampling (s)             0.980339
time/exploration sampling (s)            0.304678
time/logging (s)                         0.0200753
time/sac training (s)                   13.2488
time/saving (s)                          0.00464326
time/training (s)                        2.711e-05
time/epoch (s)                          14.5623
time/total (s)                        3387.19
Epoch                                  252
----------------------------------  ----------------
2022-09-09 20:49:33.668248 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 253 finished
----------------------------------  ----------------
epoch                                  253
replay_buffer/size                  255000
trainer/num train calls             254000
trainer/QF1 Loss                         1.29877e-06
trainer/QF2 Loss                         1.34497e-06
trainer/Policy Loss                     -0.961915
trainer/Q1 Predictions Mean              0.957219
trainer/Q1 Predictions Std               0.0251144
trainer/Q1 Predictions Max               1.00191
trainer/Q1 Predictions Min               0.928993
trainer/Q2 Predictions Mean              0.956952
trainer/Q2 Predictions Std               0.0250288
trainer/Q2 Predictions Max               1.00159
trainer/Q2 Predictions Min               0.928858
trainer/Q Targets Mean                   0.956445
trainer/Q Targets Std                    0.0251111
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928381
trainer/Log Pis Mean                     3.15775
trainer/Log Pis Std                      1.66556
trainer/Log Pis Max                      7.80856
trainer/Log Pis Min                     -1.02724
trainer/policy/mean Mean                 0.0659755
trainer/policy/mean Std                  0.684873
trainer/policy/mean Max                  0.995338
trainer/policy/mean Min                 -0.996333
trainer/policy/normal/std Mean           0.596007
trainer/policy/normal/std Std            0.192602
trainer/policy/normal/std Max            0.974524
trainer/policy/normal/std Min            0.220003
trainer/policy/normal/log_std Mean      -0.572254
trainer/policy/normal/log_std Std        0.33632
trainer/policy/normal/log_std Max       -0.0258063
trainer/policy/normal/log_std Min       -1.51411
trainer/Alpha                            0.000123936
trainer/Alpha Loss                       1.41908
expl/num steps total                255000
expl/num paths total                 32943
expl/path length Mean                    3.861
expl/path length Std                     1.69145
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.258
expl/Rewards Std                         0.437534
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996139
expl/Returns Std                         0.0620169
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.018906
expl/Actions Std                         0.7497
expl/Actions Max                         0.999558
expl/Actions Min                        -0.999502
expl/Num Paths                         259
expl/Average Returns                     0.996139
eval/num steps total                     1.26289e+06
eval/num paths total                165383
eval/path length Mean                    3.86012
eval/path length Std                     1.70817
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.259059
eval/Rewards Std                         0.438118
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00398605
eval/Actions Std                         0.665233
eval/Actions Max                         0.996139
eval/Actions Min                        -0.99727
eval/Num Paths                        1294
eval/Average Returns                     1
time/data storing (s)                    0.00620919
time/evaluation sampling (s)             0.97917
time/exploration sampling (s)            0.312728
time/logging (s)                         0.019227
time/sac training (s)                   12.0873
time/saving (s)                          0.00418271
time/training (s)                        5.419e-05
time/epoch (s)                          13.4089
time/total (s)                        3400.91
Epoch                                  253
----------------------------------  ----------------
2022-09-09 20:49:48.272313 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 254 finished
----------------------------------  ----------------
epoch                                  254
replay_buffer/size                  256000
trainer/num train calls             255000
trainer/QF1 Loss                         1.43128e-06
trainer/QF2 Loss                         1.59616e-06
trainer/Policy Loss                     -0.963369
trainer/Q1 Predictions Mean              0.958803
trainer/Q1 Predictions Std               0.0263994
trainer/Q1 Predictions Max               1.00244
trainer/Q1 Predictions Min               0.929481
trainer/Q2 Predictions Mean              0.95819
trainer/Q2 Predictions Std               0.0258567
trainer/Q2 Predictions Max               1.00157
trainer/Q2 Predictions Min               0.929154
trainer/Q Targets Mean                   0.958026
trainer/Q Targets Std                    0.0259815
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928949
trainer/Log Pis Mean                     2.84559
trainer/Log Pis Std                      1.82272
trainer/Log Pis Max                      6.96286
trainer/Log Pis Min                     -6.29594
trainer/policy/mean Mean                 0.0382851
trainer/policy/mean Std                  0.683072
trainer/policy/mean Max                  0.995939
trainer/policy/mean Min                 -0.99595
trainer/policy/normal/std Mean           0.620962
trainer/policy/normal/std Std            0.189335
trainer/policy/normal/std Max            1.11778
trainer/policy/normal/std Min            0.218791
trainer/policy/normal/log_std Mean      -0.527147
trainer/policy/normal/log_std Std        0.327021
trainer/policy/normal/log_std Max        0.111348
trainer/policy/normal/log_std Min       -1.51964
trainer/Alpha                            0.000122953
trainer/Alpha Loss                      -1.39026
expl/num steps total                256000
expl/num paths total                 33196
expl/path length Mean                    3.95257
expl/path length Std                     1.65555
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.252
expl/Rewards Std                         0.434161
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996047
expl/Returns Std                         0.0627451
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0200444
expl/Actions Std                         0.760551
expl/Actions Max                         0.999721
expl/Actions Min                        -0.999612
expl/Num Paths                         253
expl/Average Returns                     0.996047
eval/num steps total                     1.26788e+06
eval/num paths total                166659
eval/path length Mean                    3.91458
eval/path length Std                     1.71881
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.255455
eval/Rewards Std                         0.436117
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0239467
eval/Actions Std                         0.665692
eval/Actions Max                         0.996543
eval/Actions Min                        -0.996287
eval/Num Paths                        1276
eval/Average Returns                     1
time/data storing (s)                    0.00503253
time/evaluation sampling (s)             1.03518
time/exploration sampling (s)            0.317807
time/logging (s)                         0.023006
time/sac training (s)                   12.8476
time/saving (s)                          0.00485994
time/training (s)                        6.019e-05
time/epoch (s)                          14.2335
time/total (s)                        3415.5
Epoch                                  254
----------------------------------  ----------------
2022-09-09 20:50:02.144510 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 255 finished
----------------------------------  ----------------
epoch                                  255
replay_buffer/size                  257000
trainer/num train calls             256000
trainer/QF1 Loss                         9.30325e-07
trainer/QF2 Loss                         1.95447e-06
trainer/Policy Loss                     -0.962165
trainer/Q1 Predictions Mean              0.958551
trainer/Q1 Predictions Std               0.0249391
trainer/Q1 Predictions Max               1.00093
trainer/Q1 Predictions Min               0.929191
trainer/Q2 Predictions Mean              0.957437
trainer/Q2 Predictions Std               0.0253092
trainer/Q2 Predictions Max               1.00088
trainer/Q2 Predictions Min               0.928442
trainer/Q Targets Mean                   0.95811
trainer/Q Targets Std                    0.0251167
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928853
trainer/Log Pis Mean                     3.00605
trainer/Log Pis Std                      1.76654
trainer/Log Pis Max                      6.95694
trainer/Log Pis Min                     -4.5403
trainer/policy/mean Mean                 0.0564519
trainer/policy/mean Std                  0.68207
trainer/policy/mean Max                  0.995175
trainer/policy/mean Min                 -0.995681
trainer/policy/normal/std Mean           0.61208
trainer/policy/normal/std Std            0.185713
trainer/policy/normal/std Max            1.19809
trainer/policy/normal/std Min            0.194216
trainer/policy/normal/log_std Mean      -0.54091
trainer/policy/normal/log_std Std        0.325008
trainer/policy/normal/log_std Max        0.180731
trainer/policy/normal/log_std Min       -1.63879
trainer/Alpha                            0.000122984
trainer/Alpha Loss                       0.0544578
expl/num steps total                257000
expl/num paths total                 33447
expl/path length Mean                    3.98406
expl/path length Std                     1.75369
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0717365
expl/Actions Std                         0.753655
expl/Actions Max                         0.999682
expl/Actions Min                        -0.999665
expl/Num Paths                         251
expl/Average Returns                     1
eval/num steps total                     1.27288e+06
eval/num paths total                167943
eval/path length Mean                    3.89408
eval/path length Std                     1.70659
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2568
eval/Rewards Std                         0.436868
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00833678
eval/Actions Std                         0.663702
eval/Actions Max                         0.996308
eval/Actions Min                        -0.996877
eval/Num Paths                        1284
eval/Average Returns                     1
time/data storing (s)                    0.00629048
time/evaluation sampling (s)             1.02758
time/exploration sampling (s)            0.332543
time/logging (s)                         0.0215724
time/sac training (s)                   12.153
time/saving (s)                          0.00470569
time/training (s)                        2.969e-05
time/epoch (s)                          13.5457
time/total (s)                        3429.36
Epoch                                  255
----------------------------------  ----------------
2022-09-09 20:50:15.671762 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 256 finished
----------------------------------  ----------------
epoch                                  256
replay_buffer/size                  258000
trainer/num train calls             257000
trainer/QF1 Loss                         1.64658e-06
trainer/QF2 Loss                         2.46399e-06
trainer/Policy Loss                     -0.964244
trainer/Q1 Predictions Mean              0.959868
trainer/Q1 Predictions Std               0.0247408
trainer/Q1 Predictions Max               1.00212
trainer/Q1 Predictions Min               0.928797
trainer/Q2 Predictions Mean              0.95976
trainer/Q2 Predictions Std               0.0252256
trainer/Q2 Predictions Max               1.00301
trainer/Q2 Predictions Min               0.927344
trainer/Q Targets Mean                   0.958987
trainer/Q Targets Std                    0.024567
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928439
trainer/Log Pis Mean                     3.1808
trainer/Log Pis Std                      1.8845
trainer/Log Pis Max                      9.07597
trainer/Log Pis Min                     -2.93211
trainer/policy/mean Mean                 0.0437995
trainer/policy/mean Std                  0.69741
trainer/policy/mean Max                  0.995951
trainer/policy/mean Min                 -0.996402
trainer/policy/normal/std Mean           0.582639
trainer/policy/normal/std Std            0.163095
trainer/policy/normal/std Max            1.03304
trainer/policy/normal/std Min            0.218216
trainer/policy/normal/log_std Mean      -0.581968
trainer/policy/normal/log_std Std        0.295073
trainer/policy/normal/log_std Max        0.032509
trainer/policy/normal/log_std Min       -1.52227
trainer/Alpha                            0.000123134
trainer/Alpha Loss                       1.62759
expl/num steps total                258000
expl/num paths total                 33698
expl/path length Mean                    3.98406
expl/path length Std                     1.63129
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.00560565
expl/Actions Std                         0.752772
expl/Actions Max                         0.999638
expl/Actions Min                        -0.99973
expl/Num Paths                         251
expl/Average Returns                     1
eval/num steps total                     1.27788e+06
eval/num paths total                169215
eval/path length Mean                    3.92925
eval/path length Std                     1.7256
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254502
eval/Rewards Std                         0.435581
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00656907
eval/Actions Std                         0.676818
eval/Actions Max                         0.996337
eval/Actions Min                        -0.996899
eval/Num Paths                        1272
eval/Average Returns                     1
time/data storing (s)                    0.00420737
time/evaluation sampling (s)             0.990281
time/exploration sampling (s)            0.3241
time/logging (s)                         0.0195472
time/sac training (s)                   11.8948
time/saving (s)                          0.00461796
time/training (s)                        0.00027477
time/epoch (s)                          13.2378
time/total (s)                        3442.87
Epoch                                  256
----------------------------------  ----------------
2022-09-09 20:50:29.821455 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 257 finished
----------------------------------  ----------------
epoch                                  257
replay_buffer/size                  259000
trainer/num train calls             258000
trainer/QF1 Loss                         8.93025e-07
trainer/QF2 Loss                         1.6302e-06
trainer/Policy Loss                     -0.963682
trainer/Q1 Predictions Mean              0.959398
trainer/Q1 Predictions Std               0.0250606
trainer/Q1 Predictions Max               1.00058
trainer/Q1 Predictions Min               0.928133
trainer/Q2 Predictions Mean              0.959818
trainer/Q2 Predictions Std               0.0247815
trainer/Q2 Predictions Max               1.00042
trainer/Q2 Predictions Min               0.92753
trainer/Q Targets Mean                   0.960026
trainer/Q Targets Std                    0.0250038
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928828
trainer/Log Pis Mean                     2.91693
trainer/Log Pis Std                      1.78491
trainer/Log Pis Max                      7.69002
trainer/Log Pis Min                     -2.76783
trainer/policy/mean Mean                 0.0761668
trainer/policy/mean Std                  0.670391
trainer/policy/mean Max                  0.995775
trainer/policy/mean Min                 -0.996147
trainer/policy/normal/std Mean           0.586365
trainer/policy/normal/std Std            0.172712
trainer/policy/normal/std Max            1.03599
trainer/policy/normal/std Min            0.206927
trainer/policy/normal/log_std Mean      -0.580075
trainer/policy/normal/log_std Std        0.310496
trainer/policy/normal/log_std Max        0.0353561
trainer/policy/normal/log_std Min       -1.57539
trainer/Alpha                            0.000121456
trainer/Alpha Loss                      -0.748923
expl/num steps total                259000
expl/num paths total                 33953
expl/path length Mean                    3.92157
expl/path length Std                     1.72687
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.255
expl/Rewards Std                         0.435861
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0332965
expl/Actions Std                         0.752951
expl/Actions Max                         0.999546
expl/Actions Min                        -0.999418
expl/Num Paths                         255
expl/Average Returns                     1
eval/num steps total                     1.28288e+06
eval/num paths total                170498
eval/path length Mean                    3.89712
eval/path length Std                     1.65929
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2566
eval/Rewards Std                         0.436757
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.020562
eval/Actions Std                         0.66353
eval/Actions Max                         0.996086
eval/Actions Min                        -0.996731
eval/Num Paths                        1283
eval/Average Returns                     1
time/data storing (s)                    0.00635491
time/evaluation sampling (s)             1.01957
time/exploration sampling (s)            0.354635
time/logging (s)                         0.0202779
time/sac training (s)                   12.4053
time/saving (s)                          0.00615082
time/training (s)                        3.508e-05
time/epoch (s)                          13.8123
time/total (s)                        3457.01
Epoch                                  257
----------------------------------  ----------------
2022-09-09 20:50:44.481595 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 258 finished
----------------------------------  ----------------
epoch                                  258
replay_buffer/size                  260000
trainer/num train calls             259000
trainer/QF1 Loss                         9.59461e-07
trainer/QF2 Loss                         2.96762e-06
trainer/Policy Loss                     -0.966593
trainer/Q1 Predictions Mean              0.964279
trainer/Q1 Predictions Std               0.0250042
trainer/Q1 Predictions Max               1.00138
trainer/Q1 Predictions Min               0.928969
trainer/Q2 Predictions Mean              0.963131
trainer/Q2 Predictions Std               0.0250879
trainer/Q2 Predictions Max               1.00038
trainer/Q2 Predictions Min               0.926937
trainer/Q Targets Mean                   0.964144
trainer/Q Targets Std                    0.0251282
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928901
trainer/Log Pis Mean                     3.10437
trainer/Log Pis Std                      1.76896
trainer/Log Pis Max                      7.37181
trainer/Log Pis Min                     -2.67532
trainer/policy/mean Mean                 0.0627348
trainer/policy/mean Std                  0.685157
trainer/policy/mean Max                  0.995596
trainer/policy/mean Min                 -0.996062
trainer/policy/normal/std Mean           0.620006
trainer/policy/normal/std Std            0.196017
trainer/policy/normal/std Max            1.10261
trainer/policy/normal/std Min            0.232478
trainer/policy/normal/log_std Mean      -0.531318
trainer/policy/normal/log_std Std        0.333095
trainer/policy/normal/log_std Max        0.0976833
trainer/policy/normal/log_std Min       -1.45896
trainer/Alpha                            0.00012014
trainer/Alpha Loss                       0.942167
expl/num steps total                260000
expl/num paths total                 34208
expl/path length Mean                    3.92157
expl/path length Std                     1.69246
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.255
expl/Rewards Std                         0.435861
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0397673
expl/Actions Std                         0.753108
expl/Actions Max                         0.999609
expl/Actions Min                        -0.999711
expl/Num Paths                         255
expl/Average Returns                     1
eval/num steps total                     1.28788e+06
eval/num paths total                171737
eval/path length Mean                    4.03309
eval/path length Std                     1.67198
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.247949
eval/Rewards Std                         0.431822
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.015208
eval/Actions Std                         0.665793
eval/Actions Max                         0.996232
eval/Actions Min                        -0.996688
eval/Num Paths                        1239
eval/Average Returns                     1
time/data storing (s)                    0.00607293
time/evaluation sampling (s)             1.04513
time/exploration sampling (s)            0.297382
time/logging (s)                         0.019577
time/sac training (s)                   12.9291
time/saving (s)                          0.00470036
time/training (s)                        2.671e-05
time/epoch (s)                          14.302
time/total (s)                        3471.65
Epoch                                  258
----------------------------------  ----------------
2022-09-09 20:50:58.612124 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 259 finished
----------------------------------  ----------------
epoch                                  259
replay_buffer/size                  261000
trainer/num train calls             260000
trainer/QF1 Loss                         5.95569e-07
trainer/QF2 Loss                         1.55611e-06
trainer/Policy Loss                     -0.964081
trainer/Q1 Predictions Mean              0.959854
trainer/Q1 Predictions Std               0.0261194
trainer/Q1 Predictions Max               1.0012
trainer/Q1 Predictions Min               0.928948
trainer/Q2 Predictions Mean              0.959655
trainer/Q2 Predictions Std               0.0258618
trainer/Q2 Predictions Max               1.00046
trainer/Q2 Predictions Min               0.928731
trainer/Q Targets Mean                   0.959836
trainer/Q Targets Std                    0.0261595
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92911
trainer/Log Pis Mean                     2.95423
trainer/Log Pis Std                      1.7852
trainer/Log Pis Max                      7.40426
trainer/Log Pis Min                     -4.19319
trainer/policy/mean Mean                 0.10746
trainer/policy/mean Std                  0.672134
trainer/policy/mean Max                  0.996142
trainer/policy/mean Min                 -0.995505
trainer/policy/normal/std Mean           0.610982
trainer/policy/normal/std Std            0.187135
trainer/policy/normal/std Max            1.05346
trainer/policy/normal/std Min            0.207575
trainer/policy/normal/log_std Mean      -0.543776
trainer/policy/normal/log_std Std        0.328185
trainer/policy/normal/log_std Max        0.0520781
trainer/policy/normal/log_std Min       -1.57226
trainer/Alpha                            0.000122745
trainer/Alpha Loss                      -0.412208
expl/num steps total                261000
expl/num paths total                 34464
expl/path length Mean                    3.90625
expl/path length Std                     1.66976
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.256
expl/Rewards Std                         0.436422
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0218867
expl/Actions Std                         0.752622
expl/Actions Max                         0.999785
expl/Actions Min                        -0.999765
expl/Num Paths                         256
expl/Average Returns                     1
eval/num steps total                     1.29288e+06
eval/num paths total                172987
eval/path length Mean                    3.9992
eval/path length Std                     1.63731
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25005
eval/Rewards Std                         0.433042
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00617221
eval/Actions Std                         0.666143
eval/Actions Max                         0.99654
eval/Actions Min                        -0.996798
eval/Num Paths                        1250
eval/Average Returns                     1
time/data storing (s)                    0.00405495
time/evaluation sampling (s)             0.989465
time/exploration sampling (s)            0.312282
time/logging (s)                         0.0195984
time/sac training (s)                   12.465
time/saving (s)                          0.00511368
time/training (s)                        0.000337041
time/epoch (s)                          13.7959
time/total (s)                        3485.77
Epoch                                  259
----------------------------------  ----------------
2022-09-09 20:51:13.026275 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 260 finished
----------------------------------  ----------------
epoch                                  260
replay_buffer/size                  262000
trainer/num train calls             261000
trainer/QF1 Loss                         2.16761e-06
trainer/QF2 Loss                         3.34961e-06
trainer/Policy Loss                     -0.962064
trainer/Q1 Predictions Mean              0.958024
trainer/Q1 Predictions Std               0.0253924
trainer/Q1 Predictions Max               0.999337
trainer/Q1 Predictions Min               0.92818
trainer/Q2 Predictions Mean              0.958444
trainer/Q2 Predictions Std               0.0250059
trainer/Q2 Predictions Max               0.999576
trainer/Q2 Predictions Min               0.927645
trainer/Q Targets Mean                   0.959141
trainer/Q Targets Std                    0.0254026
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928892
trainer/Log Pis Mean                     2.99437
trainer/Log Pis Std                      2.06462
trainer/Log Pis Max                      8.51061
trainer/Log Pis Min                     -9.13878
trainer/policy/mean Mean                 0.0287051
trainer/policy/mean Std                  0.679626
trainer/policy/mean Max                  0.996683
trainer/policy/mean Min                 -0.99569
trainer/policy/normal/std Mean           0.609112
trainer/policy/normal/std Std            0.18919
trainer/policy/normal/std Max            1.23427
trainer/policy/normal/std Min            0.209003
trainer/policy/normal/log_std Mean      -0.547424
trainer/policy/normal/log_std Std        0.3288
trainer/policy/normal/log_std Max        0.210476
trainer/policy/normal/log_std Min       -1.5654
trainer/Alpha                            0.000120067
trainer/Alpha Loss                      -0.0508146
expl/num steps total                262000
expl/num paths total                 34724
expl/path length Mean                    3.84615
expl/path length Std                     1.67773
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.26
expl/Rewards Std                         0.438634
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.00179474
expl/Actions Std                         0.756634
expl/Actions Max                         0.999724
expl/Actions Min                        -0.999749
expl/Num Paths                         260
expl/Average Returns                     1
eval/num steps total                     1.29787e+06
eval/num paths total                174248
eval/path length Mean                    3.96193
eval/path length Std                     1.69951
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252402
eval/Rewards Std                         0.434391
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0212227
eval/Actions Std                         0.667407
eval/Actions Max                         0.996111
eval/Actions Min                        -0.996153
eval/Num Paths                        1261
eval/Average Returns                     1
time/data storing (s)                    0.00509433
time/evaluation sampling (s)             0.981337
time/exploration sampling (s)            0.345043
time/logging (s)                         0.019385
time/sac training (s)                   12.7022
time/saving (s)                          0.00471175
time/training (s)                        2.917e-05
time/epoch (s)                          14.0578
time/total (s)                        3500.17
Epoch                                  260
----------------------------------  ----------------
2022-09-09 20:51:26.896170 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 261 finished
----------------------------------  ----------------
epoch                                  261
replay_buffer/size                  263000
trainer/num train calls             262000
trainer/QF1 Loss                         6.64182e-07
trainer/QF2 Loss                         1.79094e-06
trainer/Policy Loss                     -0.965576
trainer/Q1 Predictions Mean              0.961991
trainer/Q1 Predictions Std               0.0255105
trainer/Q1 Predictions Max               1.00169
trainer/Q1 Predictions Min               0.92895
trainer/Q2 Predictions Mean              0.962198
trainer/Q2 Predictions Std               0.0257258
trainer/Q2 Predictions Max               1.00217
trainer/Q2 Predictions Min               0.928491
trainer/Q Targets Mean                   0.961874
trainer/Q Targets Std                    0.025364
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929241
trainer/Log Pis Mean                     2.96245
trainer/Log Pis Std                      1.97678
trainer/Log Pis Max                      7.49721
trainer/Log Pis Min                     -5.48948
trainer/policy/mean Mean                 0.0420049
trainer/policy/mean Std                  0.682317
trainer/policy/mean Max                  0.996104
trainer/policy/mean Min                 -0.997883
trainer/policy/normal/std Mean           0.587785
trainer/policy/normal/std Std            0.180827
trainer/policy/normal/std Max            1.05423
trainer/policy/normal/std Min            0.190776
trainer/policy/normal/log_std Mean      -0.583096
trainer/policy/normal/log_std Std        0.330576
trainer/policy/normal/log_std Max        0.0528147
trainer/policy/normal/log_std Min       -1.65666
trainer/Alpha                            0.000117767
trainer/Alpha Loss                      -0.339673
expl/num steps total                263000
expl/num paths total                 34966
expl/path length Mean                    4.13223
expl/path length Std                     1.71016
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.241
expl/Rewards Std                         0.42769
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995868
expl/Returns Std                         0.0641495
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.000486294
expl/Actions Std                         0.752697
expl/Actions Max                         0.999553
expl/Actions Min                        -0.999781
expl/Num Paths                         242
expl/Average Returns                     0.995868
eval/num steps total                     1.30287e+06
eval/num paths total                175505
eval/path length Mean                    3.97613
eval/path length Std                     1.63282
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251501
eval/Rewards Std                         0.433876
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00189891
eval/Actions Std                         0.67135
eval/Actions Max                         0.996281
eval/Actions Min                        -0.997923
eval/Num Paths                        1257
eval/Average Returns                     1
time/data storing (s)                    0.00404385
time/evaluation sampling (s)             1.00687
time/exploration sampling (s)            0.304182
time/logging (s)                         0.0205222
time/sac training (s)                   12.2124
time/saving (s)                          0.00362056
time/training (s)                        2.12e-05
time/epoch (s)                          13.5517
time/total (s)                        3514.03
Epoch                                  261
----------------------------------  ----------------
2022-09-09 20:51:40.837275 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 262 finished
----------------------------------  ----------------
epoch                                  262
replay_buffer/size                  264000
trainer/num train calls             263000
trainer/QF1 Loss                         1.9471e-06
trainer/QF2 Loss                         4.70047e-06
trainer/Policy Loss                     -0.967826
trainer/Q1 Predictions Mean              0.963705
trainer/Q1 Predictions Std               0.0262315
trainer/Q1 Predictions Max               1.00185
trainer/Q1 Predictions Min               0.929944
trainer/Q2 Predictions Mean              0.964312
trainer/Q2 Predictions Std               0.0261153
trainer/Q2 Predictions Max               1.00373
trainer/Q2 Predictions Min               0.930011
trainer/Q Targets Mean                   0.962582
trainer/Q Targets Std                    0.0261234
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928885
trainer/Log Pis Mean                     3.10098
trainer/Log Pis Std                      1.65702
trainer/Log Pis Max                      7.00643
trainer/Log Pis Min                     -2.04111
trainer/policy/mean Mean                 0.0629187
trainer/policy/mean Std                  0.690785
trainer/policy/mean Max                  0.996209
trainer/policy/mean Min                 -0.99556
trainer/policy/normal/std Mean           0.607929
trainer/policy/normal/std Std            0.192542
trainer/policy/normal/std Max            1.22747
trainer/policy/normal/std Min            0.192135
trainer/policy/normal/log_std Mean      -0.551234
trainer/policy/normal/log_std Std        0.334383
trainer/policy/normal/log_std Max        0.204953
trainer/policy/normal/log_std Min       -1.64956
trainer/Alpha                            0.000123418
trainer/Alpha Loss                       0.908855
expl/num steps total                264000
expl/num paths total                 35216
expl/path length Mean                    4
expl/path length Std                     1.62234
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996
expl/Returns Std                         0.0631189
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00837232
expl/Actions Std                         0.748755
expl/Actions Max                         0.999931
expl/Actions Min                        -0.999662
expl/Num Paths                         250
expl/Average Returns                     0.996
eval/num steps total                     1.30787e+06
eval/num paths total                176767
eval/path length Mean                    3.96038
eval/path length Std                     1.64717
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252501
eval/Rewards Std                         0.434447
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0245396
eval/Actions Std                         0.670718
eval/Actions Max                         0.996023
eval/Actions Min                        -0.995377
eval/Num Paths                        1262
eval/Average Returns                     1
time/data storing (s)                    0.00395567
time/evaluation sampling (s)             0.98007
time/exploration sampling (s)            0.317887
time/logging (s)                         0.0180987
time/sac training (s)                   12.3131
time/saving (s)                          0.00475146
time/training (s)                        1.947e-05
time/epoch (s)                          13.6379
time/total (s)                        3527.96
Epoch                                  262
----------------------------------  ----------------
2022-09-09 20:51:54.949417 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 263 finished
----------------------------------  ----------------
epoch                                  263
replay_buffer/size                  265000
trainer/num train calls             264000
trainer/QF1 Loss                         3.24363e-06
trainer/QF2 Loss                         5.03478e-06
trainer/Policy Loss                     -0.966442
trainer/Q1 Predictions Mean              0.962326
trainer/Q1 Predictions Std               0.0259398
trainer/Q1 Predictions Max               1.00302
trainer/Q1 Predictions Min               0.929908
trainer/Q2 Predictions Mean              0.962579
trainer/Q2 Predictions Std               0.0257976
trainer/Q2 Predictions Max               1.00258
trainer/Q2 Predictions Min               0.929459
trainer/Q Targets Mean                   0.960761
trainer/Q Targets Std                    0.0256754
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.927737
trainer/Log Pis Mean                     3.03666
trainer/Log Pis Std                      1.67484
trainer/Log Pis Max                      7.3404
trainer/Log Pis Min                     -2.79862
trainer/policy/mean Mean                 0.00989085
trainer/policy/mean Std                  0.685852
trainer/policy/mean Max                  0.995243
trainer/policy/mean Min                 -0.99721
trainer/policy/normal/std Mean           0.606325
trainer/policy/normal/std Std            0.178554
trainer/policy/normal/std Max            0.994282
trainer/policy/normal/std Min            0.215541
trainer/policy/normal/log_std Mean      -0.548188
trainer/policy/normal/log_std Std        0.318675
trainer/policy/normal/log_std Max       -0.0057341
trainer/policy/normal/log_std Min       -1.53461
trainer/Alpha                            0.000122291
trainer/Alpha Loss                       0.330294
expl/num steps total                265000
expl/num paths total                 35463
expl/path length Mean                    4.04858
expl/path length Std                     1.74882
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.246
expl/Rewards Std                         0.430679
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995951
expl/Returns Std                         0.0634995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0101083
expl/Actions Std                         0.757886
expl/Actions Max                         0.999581
expl/Actions Min                        -0.999531
expl/Num Paths                         247
expl/Average Returns                     0.995951
eval/num steps total                     1.31286e+06
eval/num paths total                178007
eval/path length Mean                    4.03065
eval/path length Std                     1.6271
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.248099
eval/Rewards Std                         0.43191
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00613551
eval/Actions Std                         0.668452
eval/Actions Max                         0.995808
eval/Actions Min                        -0.997847
eval/Num Paths                        1240
eval/Average Returns                     1
time/data storing (s)                    0.0066163
time/evaluation sampling (s)             0.976964
time/exploration sampling (s)            0.323135
time/logging (s)                         0.0184755
time/sac training (s)                   12.4656
time/saving (s)                          0.00467227
time/training (s)                        2.582e-05
time/epoch (s)                          13.7955
time/total (s)                        3542.05
Epoch                                  263
----------------------------------  ----------------
2022-09-09 20:52:09.520861 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 264 finished
----------------------------------  ----------------
epoch                                  264
replay_buffer/size                  266000
trainer/num train calls             265000
trainer/QF1 Loss                         7.82258e-07
trainer/QF2 Loss                         3.87607e-06
trainer/Policy Loss                     -0.963406
trainer/Q1 Predictions Mean              0.959065
trainer/Q1 Predictions Std               0.0256077
trainer/Q1 Predictions Max               1.00077
trainer/Q1 Predictions Min               0.928676
trainer/Q2 Predictions Mean              0.961049
trainer/Q2 Predictions Std               0.0255477
trainer/Q2 Predictions Max               1.00339
trainer/Q2 Predictions Min               0.929039
trainer/Q Targets Mean                   0.959552
trainer/Q Targets Std                    0.0255226
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929214
trainer/Log Pis Mean                     3.25038
trainer/Log Pis Std                      1.68188
trainer/Log Pis Max                      8.40082
trainer/Log Pis Min                     -3.18382
trainer/policy/mean Mean                 0.0664195
trainer/policy/mean Std                  0.686357
trainer/policy/mean Max                  0.995999
trainer/policy/mean Min                 -0.996927
trainer/policy/normal/std Mean           0.603195
trainer/policy/normal/std Std            0.202129
trainer/policy/normal/std Max            1.37277
trainer/policy/normal/std Min            0.199991
trainer/policy/normal/log_std Mean      -0.565534
trainer/policy/normal/log_std Std        0.354384
trainer/policy/normal/log_std Max        0.316828
trainer/policy/normal/log_std Min       -1.60949
trainer/Alpha                            0.000122349
trainer/Alpha Loss                       2.25559
expl/num steps total                266000
expl/num paths total                 35729
expl/path length Mean                    3.7594
expl/path length Std                     1.67982
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.265
expl/Rewards Std                         0.441333
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996241
expl/Returns Std                         0.0611986
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00710684
expl/Actions Std                         0.758023
expl/Actions Max                         0.999835
expl/Actions Min                        -0.999622
expl/Num Paths                         266
expl/Average Returns                     0.996241
eval/num steps total                     1.31786e+06
eval/num paths total                179300
eval/path length Mean                    3.8662
eval/path length Std                     1.68471
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.258652
eval/Rewards Std                         0.437894
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0227314
eval/Actions Std                         0.674576
eval/Actions Max                         0.99606
eval/Actions Min                        -0.997419
eval/Num Paths                        1293
eval/Average Returns                     1
time/data storing (s)                    0.00627497
time/evaluation sampling (s)             0.981376
time/exploration sampling (s)            0.340573
time/logging (s)                         0.0207318
time/sac training (s)                   12.8705
time/saving (s)                          0.00422504
time/training (s)                        4.707e-05
time/epoch (s)                          14.2237
time/total (s)                        3556.61
Epoch                                  264
----------------------------------  ----------------
2022-09-09 20:52:23.194818 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 265 finished
----------------------------------  ----------------
epoch                                  265
replay_buffer/size                  267000
trainer/num train calls             266000
trainer/QF1 Loss                         4.84299e-07
trainer/QF2 Loss                         1.49128e-06
trainer/Policy Loss                     -0.962082
trainer/Q1 Predictions Mean              0.958004
trainer/Q1 Predictions Std               0.0251863
trainer/Q1 Predictions Max               1.00058
trainer/Q1 Predictions Min               0.928904
trainer/Q2 Predictions Mean              0.958392
trainer/Q2 Predictions Std               0.0251429
trainer/Q2 Predictions Max               1.00133
trainer/Q2 Predictions Min               0.929371
trainer/Q Targets Mean                   0.958196
trainer/Q Targets Std                    0.025182
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929301
trainer/Log Pis Mean                     3.05209
trainer/Log Pis Std                      1.76079
trainer/Log Pis Max                      7.76488
trainer/Log Pis Min                     -2.40671
trainer/policy/mean Mean                 0.0565369
trainer/policy/mean Std                  0.688598
trainer/policy/mean Max                  0.995471
trainer/policy/mean Min                 -0.996214
trainer/policy/normal/std Mean           0.604056
trainer/policy/normal/std Std            0.182598
trainer/policy/normal/std Max            1.12163
trainer/policy/normal/std Min            0.203972
trainer/policy/normal/log_std Mean      -0.554077
trainer/policy/normal/log_std Std        0.325312
trainer/policy/normal/log_std Max        0.114786
trainer/policy/normal/log_std Min       -1.58977
trainer/Alpha                            0.00012143
trainer/Alpha Loss                       0.469684
expl/num steps total                267000
expl/num paths total                 35976
expl/path length Mean                    4.04858
expl/path length Std                     1.69712
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.246
expl/Rewards Std                         0.430679
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995951
expl/Returns Std                         0.0634995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0306945
expl/Actions Std                         0.752604
expl/Actions Max                         0.999691
expl/Actions Min                        -0.99986
expl/Num Paths                         247
expl/Average Returns                     0.995951
eval/num steps total                     1.32286e+06
eval/num paths total                180562
eval/path length Mean                    3.958
eval/path length Std                     1.67596
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252653
eval/Rewards Std                         0.434533
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0139277
eval/Actions Std                         0.673574
eval/Actions Max                         0.995519
eval/Actions Min                        -0.99737
eval/Num Paths                        1262
eval/Average Returns                     1
time/data storing (s)                    0.00603817
time/evaluation sampling (s)             0.96509
time/exploration sampling (s)            0.318091
time/logging (s)                         0.0201421
time/sac training (s)                   12.0645
time/saving (s)                          0.00477072
time/training (s)                        2.533e-05
time/epoch (s)                          13.3787
time/total (s)                        3570.28
Epoch                                  265
----------------------------------  ----------------
2022-09-09 20:52:36.955141 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 266 finished
----------------------------------  ----------------
epoch                                  266
replay_buffer/size                  268000
trainer/num train calls             267000
trainer/QF1 Loss                         4.73601e-07
trainer/QF2 Loss                         1.40525e-06
trainer/Policy Loss                     -0.963466
trainer/Q1 Predictions Mean              0.959482
trainer/Q1 Predictions Std               0.0255807
trainer/Q1 Predictions Max               1.00038
trainer/Q1 Predictions Min               0.9287
trainer/Q2 Predictions Mean              0.959352
trainer/Q2 Predictions Std               0.0254559
trainer/Q2 Predictions Max               1.00109
trainer/Q2 Predictions Min               0.927516
trainer/Q Targets Mean                   0.959639
trainer/Q Targets Std                    0.0255548
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929263
trainer/Log Pis Mean                     2.64278
trainer/Log Pis Std                      1.802
trainer/Log Pis Max                      6.76387
trainer/Log Pis Min                     -3.53783
trainer/policy/mean Mean                 0.128365
trainer/policy/mean Std                  0.675275
trainer/policy/mean Max                  0.994737
trainer/policy/mean Min                 -0.994945
trainer/policy/normal/std Mean           0.609177
trainer/policy/normal/std Std            0.188282
trainer/policy/normal/std Max            1.01834
trainer/policy/normal/std Min            0.194731
trainer/policy/normal/log_std Mean      -0.547586
trainer/policy/normal/log_std Std        0.330867
trainer/policy/normal/log_std Max        0.0181712
trainer/policy/normal/log_std Min       -1.63613
trainer/Alpha                            0.000122911
trainer/Alpha Loss                      -3.21644
expl/num steps total                268000
expl/num paths total                 36241
expl/path length Mean                    3.77358
expl/path length Std                     1.74444
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.264
expl/Rewards Std                         0.440799
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996226
expl/Returns Std                         0.0613135
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00199766
expl/Actions Std                         0.757528
expl/Actions Max                         0.999632
expl/Actions Min                        -0.999804
expl/Num Paths                         265
expl/Average Returns                     0.996226
eval/num steps total                     1.32786e+06
eval/num paths total                181805
eval/path length Mean                    4.02253
eval/path length Std                     1.64544
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2486
eval/Rewards Std                         0.432201
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -1.93347e-05
eval/Actions Std                         0.668812
eval/Actions Max                         0.995896
eval/Actions Min                        -0.996288
eval/Num Paths                        1243
eval/Average Returns                     1
time/data storing (s)                    0.00592544
time/evaluation sampling (s)             0.964284
time/exploration sampling (s)            0.302986
time/logging (s)                         0.0177857
time/sac training (s)                   12.1519
time/saving (s)                          0.00477629
time/training (s)                        1.928e-05
time/epoch (s)                          13.4477
time/total (s)                        3584.02
Epoch                                  266
----------------------------------  ----------------
2022-09-09 20:52:51.116820 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 267 finished
----------------------------------  ----------------
epoch                                  267
replay_buffer/size                  269000
trainer/num train calls             268000
trainer/QF1 Loss                         7.06701e-07
trainer/QF2 Loss                         2.90612e-06
trainer/Policy Loss                     -0.965487
trainer/Q1 Predictions Mean              0.961086
trainer/Q1 Predictions Std               0.0256556
trainer/Q1 Predictions Max               1.00127
trainer/Q1 Predictions Min               0.929006
trainer/Q2 Predictions Mean              0.962068
trainer/Q2 Predictions Std               0.0257586
trainer/Q2 Predictions Max               1.00303
trainer/Q2 Predictions Min               0.930196
trainer/Q Targets Mean                   0.960784
trainer/Q Targets Std                    0.0255552
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929057
trainer/Log Pis Mean                     3.00678
trainer/Log Pis Std                      1.67078
trainer/Log Pis Max                      7.92319
trainer/Log Pis Min                     -2.59407
trainer/policy/mean Mean                 0.0593154
trainer/policy/mean Std                  0.675454
trainer/policy/mean Max                  0.995537
trainer/policy/mean Min                 -0.996435
trainer/policy/normal/std Mean           0.605943
trainer/policy/normal/std Std            0.168214
trainer/policy/normal/std Max            1.05709
trainer/policy/normal/std Min            0.224779
trainer/policy/normal/log_std Mean      -0.541917
trainer/policy/normal/log_std Std        0.291834
trainer/policy/normal/log_std Max        0.0555238
trainer/policy/normal/log_std Min       -1.49264
trainer/Alpha                            0.000122372
trainer/Alpha Loss                       0.0610352
expl/num steps total                269000
expl/num paths total                 36502
expl/path length Mean                    3.83142
expl/path length Std                     1.68448
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.261
expl/Rewards Std                         0.43918
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0176193
expl/Actions Std                         0.758503
expl/Actions Max                         0.99961
expl/Actions Min                        -0.99961
expl/Num Paths                         261
expl/Average Returns                     1
eval/num steps total                     1.33286e+06
eval/num paths total                183082
eval/path length Mean                    3.91543
eval/path length Std                     1.67876
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2554
eval/Rewards Std                         0.436086
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0114532
eval/Actions Std                         0.674202
eval/Actions Max                         0.996235
eval/Actions Min                        -0.996579
eval/Num Paths                        1277
eval/Average Returns                     1
time/data storing (s)                    0.00614288
time/evaluation sampling (s)             1.00275
time/exploration sampling (s)            0.313947
time/logging (s)                         0.0193824
time/sac training (s)                   12.4964
time/saving (s)                          0.00340297
time/training (s)                        1.963e-05
time/epoch (s)                          13.8421
time/total (s)                        3598.18
Epoch                                  267
----------------------------------  ----------------
2022-09-09 20:53:05.122893 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 268 finished
----------------------------------  ----------------
epoch                                  268
replay_buffer/size                  270000
trainer/num train calls             269000
trainer/QF1 Loss                         7.16998e-07
trainer/QF2 Loss                         2.68279e-06
trainer/Policy Loss                     -0.967601
trainer/Q1 Predictions Mean              0.963765
trainer/Q1 Predictions Std               0.0248399
trainer/Q1 Predictions Max               1.00073
trainer/Q1 Predictions Min               0.929002
trainer/Q2 Predictions Mean              0.964672
trainer/Q2 Predictions Std               0.025055
trainer/Q2 Predictions Max               1.00286
trainer/Q2 Predictions Min               0.929123
trainer/Q Targets Mean                   0.963653
trainer/Q Targets Std                    0.0246407
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929141
trainer/Log Pis Mean                     2.96839
trainer/Log Pis Std                      1.99736
trainer/Log Pis Max                      8.35403
trainer/Log Pis Min                     -4.89552
trainer/policy/mean Mean                 0.0363493
trainer/policy/mean Std                  0.674625
trainer/policy/mean Max                  0.995335
trainer/policy/mean Min                 -0.995703
trainer/policy/normal/std Mean           0.601805
trainer/policy/normal/std Std            0.190974
trainer/policy/normal/std Max            1.02785
trainer/policy/normal/std Min            0.199734
trainer/policy/normal/log_std Mean      -0.560403
trainer/policy/normal/log_std Std        0.328784
trainer/policy/normal/log_std Max        0.02747
trainer/policy/normal/log_std Min       -1.61077
trainer/Alpha                            0.000120248
trainer/Alpha Loss                      -0.285337
expl/num steps total                270000
expl/num paths total                 36752
expl/path length Mean                    4
expl/path length Std                     1.63218
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.25
expl/Rewards Std                         0.433013
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0123259
expl/Actions Std                         0.75424
expl/Actions Max                         0.999607
expl/Actions Min                        -0.999643
expl/Num Paths                         250
expl/Average Returns                     1
eval/num steps total                     1.33786e+06
eval/num paths total                184314
eval/path length Mean                    4.05601
eval/path length Std                     1.66055
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.246548
eval/Rewards Std                         0.431001
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0186303
eval/Actions Std                         0.670261
eval/Actions Max                         0.99646
eval/Actions Min                        -0.996028
eval/Num Paths                        1232
eval/Average Returns                     1
time/data storing (s)                    0.00482162
time/evaluation sampling (s)             1.02367
time/exploration sampling (s)            0.309059
time/logging (s)                         0.0179921
time/sac training (s)                   12.3234
time/saving (s)                          0.00489414
time/training (s)                        2.768e-05
time/epoch (s)                          13.6839
time/total (s)                        3612.17
Epoch                                  268
----------------------------------  ----------------
2022-09-09 20:53:18.820481 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 269 finished
----------------------------------  ----------------
epoch                                  269
replay_buffer/size                  271000
trainer/num train calls             270000
trainer/QF1 Loss                         1.51323e-06
trainer/QF2 Loss                         2.94107e-06
trainer/Policy Loss                     -0.964032
trainer/Q1 Predictions Mean              0.960405
trainer/Q1 Predictions Std               0.0261367
trainer/Q1 Predictions Max               1.00105
trainer/Q1 Predictions Min               0.928526
trainer/Q2 Predictions Mean              0.959224
trainer/Q2 Predictions Std               0.0263302
trainer/Q2 Predictions Max               1.00119
trainer/Q2 Predictions Min               0.926839
trainer/Q Targets Mean                   0.960223
trainer/Q Targets Std                    0.0261851
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928911
trainer/Log Pis Mean                     2.86483
trainer/Log Pis Std                      2.01068
trainer/Log Pis Max                      7.82628
trainer/Log Pis Min                     -3.93512
trainer/policy/mean Mean                 0.0869225
trainer/policy/mean Std                  0.680656
trainer/policy/mean Max                  0.995658
trainer/policy/mean Min                 -0.995203
trainer/policy/normal/std Mean           0.587413
trainer/policy/normal/std Std            0.180985
trainer/policy/normal/std Max            1.15433
trainer/policy/normal/std Min            0.200901
trainer/policy/normal/log_std Mean      -0.582121
trainer/policy/normal/log_std Std        0.322287
trainer/policy/normal/log_std Max        0.143524
trainer/policy/normal/log_std Min       -1.60494
trainer/Alpha                            0.00012033
trainer/Alpha Loss                      -1.21994
expl/num steps total                271000
expl/num paths total                 37007
expl/path length Mean                    3.92157
expl/path length Std                     1.65498
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.254
expl/Rewards Std                         0.435298
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996078
expl/Returns Std                         0.0624995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00838663
expl/Actions Std                         0.756579
expl/Actions Max                         0.999848
expl/Actions Min                        -0.999449
expl/Num Paths                         255
expl/Average Returns                     0.996078
eval/num steps total                     1.34285e+06
eval/num paths total                185598
eval/path length Mean                    3.89097
eval/path length Std                     1.6774
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.257006
eval/Rewards Std                         0.436983
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0249304
eval/Actions Std                         0.668614
eval/Actions Max                         0.99655
eval/Actions Min                        -0.9957
eval/Num Paths                        1284
eval/Average Returns                     1
time/data storing (s)                    0.00404617
time/evaluation sampling (s)             0.959377
time/exploration sampling (s)            0.305665
time/logging (s)                         0.018571
time/sac training (s)                   12.1086
time/saving (s)                          0.00465071
time/training (s)                        0.00014614
time/epoch (s)                          13.4011
time/total (s)                        3625.85
Epoch                                  269
----------------------------------  ----------------
2022-09-09 20:53:33.630136 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 270 finished
----------------------------------  ----------------
epoch                                  270
replay_buffer/size                  272000
trainer/num train calls             271000
trainer/QF1 Loss                         1.17425e-06
trainer/QF2 Loss                         3.23624e-06
trainer/Policy Loss                     -0.967215
trainer/Q1 Predictions Mean              0.964143
trainer/Q1 Predictions Std               0.0258747
trainer/Q1 Predictions Max               0.999939
trainer/Q1 Predictions Min               0.928581
trainer/Q2 Predictions Mean              0.963636
trainer/Q2 Predictions Std               0.0257925
trainer/Q2 Predictions Max               0.999556
trainer/Q2 Predictions Min               0.926967
trainer/Q Targets Mean                   0.964845
trainer/Q Targets Std                    0.0259651
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928985
trainer/Log Pis Mean                     2.83215
trainer/Log Pis Std                      1.97294
trainer/Log Pis Max                      7.28113
trainer/Log Pis Min                     -5.08272
trainer/policy/mean Mean                 0.0802146
trainer/policy/mean Std                  0.671656
trainer/policy/mean Max                  0.997225
trainer/policy/mean Min                 -0.996244
trainer/policy/normal/std Mean           0.598733
trainer/policy/normal/std Std            0.181735
trainer/policy/normal/std Max            1.0066
trainer/policy/normal/std Min            0.21406
trainer/policy/normal/log_std Mean      -0.562317
trainer/policy/normal/log_std Std        0.321233
trainer/policy/normal/log_std Max        0.00657976
trainer/policy/normal/log_std Min       -1.5415
trainer/Alpha                            0.000120571
trainer/Alpha Loss                      -1.51452
expl/num steps total                272000
expl/num paths total                 37256
expl/path length Mean                    4.01606
expl/path length Std                     1.64272
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.248
expl/Rewards Std                         0.431852
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995984
expl/Returns Std                         0.063245
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00815124
expl/Actions Std                         0.7529
expl/Actions Max                         0.999442
expl/Actions Min                        -0.999835
expl/Num Paths                         249
expl/Average Returns                     0.995984
eval/num steps total                     1.34785e+06
eval/num paths total                186853
eval/path length Mean                    3.98008
eval/path length Std                     1.68766
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251251
eval/Rewards Std                         0.433733
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00550822
eval/Actions Std                         0.668955
eval/Actions Max                         0.996531
eval/Actions Min                        -0.99624
eval/Num Paths                        1255
eval/Average Returns                     1
time/data storing (s)                    0.00387231
time/evaluation sampling (s)             0.951599
time/exploration sampling (s)            0.311781
time/logging (s)                         0.0179949
time/sac training (s)                   13.1506
time/saving (s)                          0.00465687
time/training (s)                        3.199e-05
time/epoch (s)                          14.4406
time/total (s)                        3640.65
Epoch                                  270
----------------------------------  ----------------
2022-09-09 20:53:47.290852 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 271 finished
----------------------------------  ----------------
epoch                                  271
replay_buffer/size                  273000
trainer/num train calls             272000
trainer/QF1 Loss                         7.61195e-07
trainer/QF2 Loss                         1.44098e-06
trainer/Policy Loss                     -0.963174
trainer/Q1 Predictions Mean              0.959294
trainer/Q1 Predictions Std               0.0253856
trainer/Q1 Predictions Max               1.00158
trainer/Q1 Predictions Min               0.929433
trainer/Q2 Predictions Mean              0.95873
trainer/Q2 Predictions Std               0.0255071
trainer/Q2 Predictions Max               1.0015
trainer/Q2 Predictions Min               0.927694
trainer/Q Targets Mean                   0.959042
trainer/Q Targets Std                    0.02539
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929532
trainer/Log Pis Mean                     2.89487
trainer/Log Pis Std                      1.98266
trainer/Log Pis Max                      7.50592
trainer/Log Pis Min                     -5.56714
trainer/policy/mean Mean                 0.0347831
trainer/policy/mean Std                  0.687031
trainer/policy/mean Max                  0.995776
trainer/policy/mean Min                 -0.99617
trainer/policy/normal/std Mean           0.600053
trainer/policy/normal/std Std            0.180701
trainer/policy/normal/std Max            0.913148
trainer/policy/normal/std Min            0.223355
trainer/policy/normal/log_std Mean      -0.559979
trainer/policy/normal/log_std Std        0.321831
trainer/policy/normal/log_std Max       -0.0908572
trainer/policy/normal/log_std Min       -1.49899
trainer/Alpha                            0.000117254
trainer/Alpha Loss                      -0.951542
expl/num steps total                273000
expl/num paths total                 37498
expl/path length Mean                    4.13223
expl/path length Std                     1.62594
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.241
expl/Rewards Std                         0.42769
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995868
expl/Returns Std                         0.0641495
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0127777
expl/Actions Std                         0.75048
expl/Actions Max                         0.999803
expl/Actions Min                        -0.999708
expl/Num Paths                         242
expl/Average Returns                     0.995868
eval/num steps total                     1.35284e+06
eval/num paths total                188133
eval/path length Mean                    3.90234
eval/path length Std                     1.6632
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.256256
eval/Rewards Std                         0.436565
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0291944
eval/Actions Std                         0.665686
eval/Actions Max                         0.996372
eval/Actions Min                        -0.99651
eval/Num Paths                        1280
eval/Average Returns                     1
time/data storing (s)                    0.00621034
time/evaluation sampling (s)             0.964249
time/exploration sampling (s)            0.329019
time/logging (s)                         0.0183707
time/sac training (s)                   12.0597
time/saving (s)                          0.00472349
time/training (s)                        2.508e-05
time/epoch (s)                          13.3823
time/total (s)                        3654.3
Epoch                                  271
----------------------------------  ----------------
2022-09-09 20:54:01.160833 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 272 finished
----------------------------------  ----------------
epoch                                  272
replay_buffer/size                  274000
trainer/num train calls             273000
trainer/QF1 Loss                         5.88827e-07
trainer/QF2 Loss                         2.15648e-06
trainer/Policy Loss                     -0.963324
trainer/Q1 Predictions Mean              0.959269
trainer/Q1 Predictions Std               0.0243651
trainer/Q1 Predictions Max               1.00104
trainer/Q1 Predictions Min               0.929615
trainer/Q2 Predictions Mean              0.95987
trainer/Q2 Predictions Std               0.0244492
trainer/Q2 Predictions Max               1.0015
trainer/Q2 Predictions Min               0.929727
trainer/Q Targets Mean                   0.959053
trainer/Q Targets Std                    0.0243532
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929406
trainer/Log Pis Mean                     2.79365
trainer/Log Pis Std                      1.79603
trainer/Log Pis Max                      7.25017
trainer/Log Pis Min                     -6.80849
trainer/policy/mean Mean                 0.0653675
trainer/policy/mean Std                  0.67826
trainer/policy/mean Max                  0.995801
trainer/policy/mean Min                 -0.996853
trainer/policy/normal/std Mean           0.611792
trainer/policy/normal/std Std            0.182091
trainer/policy/normal/std Max            1.11253
trainer/policy/normal/std Min            0.201643
trainer/policy/normal/log_std Mean      -0.53904
trainer/policy/normal/log_std Std        0.316391
trainer/policy/normal/log_std Max        0.106635
trainer/policy/normal/log_std Min       -1.60126
trainer/Alpha                            0.000115593
trainer/Alpha Loss                      -1.87067
expl/num steps total                274000
expl/num paths total                 37736
expl/path length Mean                    4.20168
expl/path length Std                     1.61963
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.237
expl/Rewards Std                         0.425242
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995798
expl/Returns Std                         0.0646841
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0291928
expl/Actions Std                         0.751651
expl/Actions Max                         0.99981
expl/Actions Min                        -0.999672
expl/Num Paths                         238
expl/Average Returns                     0.995798
eval/num steps total                     1.35784e+06
eval/num paths total                189396
eval/path length Mean                    3.95804
eval/path length Std                     1.65629
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252651
eval/Rewards Std                         0.434532
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0241992
eval/Actions Std                         0.664981
eval/Actions Max                         0.996477
eval/Actions Min                        -0.998074
eval/Num Paths                        1263
eval/Average Returns                     1
time/data storing (s)                    0.00398651
time/evaluation sampling (s)             0.967234
time/exploration sampling (s)            0.303913
time/logging (s)                         0.0299448
time/sac training (s)                   12.2521
time/saving (s)                          0.00498604
time/training (s)                        1.981e-05
time/epoch (s)                          13.5621
time/total (s)                        3668.17
Epoch                                  272
----------------------------------  ----------------
2022-09-09 20:54:15.057884 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 273 finished
----------------------------------  ----------------
epoch                                  273
replay_buffer/size                  275000
trainer/num train calls             274000
trainer/QF1 Loss                         1.90632e-06
trainer/QF2 Loss                         1.2571e-06
trainer/Policy Loss                     -0.965416
trainer/Q1 Predictions Mean              0.962724
trainer/Q1 Predictions Std               0.0258847
trainer/Q1 Predictions Max               1.0022
trainer/Q1 Predictions Min               0.929739
trainer/Q2 Predictions Mean              0.961221
trainer/Q2 Predictions Std               0.0256276
trainer/Q2 Predictions Max               1.00098
trainer/Q2 Predictions Min               0.928709
trainer/Q Targets Mean                   0.961561
trainer/Q Targets Std                    0.0256861
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928338
trainer/Log Pis Mean                     3.14282
trainer/Log Pis Std                      1.87472
trainer/Log Pis Max                      8.49774
trainer/Log Pis Min                     -2.9626
trainer/policy/mean Mean                 0.0392863
trainer/policy/mean Std                  0.684661
trainer/policy/mean Max                  0.99585
trainer/policy/mean Min                 -0.996903
trainer/policy/normal/std Mean           0.586157
trainer/policy/normal/std Std            0.189841
trainer/policy/normal/std Max            0.956308
trainer/policy/normal/std Min            0.196068
trainer/policy/normal/log_std Mean      -0.589872
trainer/policy/normal/log_std Std        0.340374
trainer/policy/normal/log_std Max       -0.0446752
trainer/policy/normal/log_std Min       -1.62929
trainer/Alpha                            0.000116179
trainer/Alpha Loss                       1.294
expl/num steps total                275000
expl/num paths total                 37985
expl/path length Mean                    4.01606
expl/path length Std                     1.6694
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0059453
expl/Actions Std                         0.748272
expl/Actions Max                         0.999614
expl/Actions Min                        -0.999586
expl/Num Paths                         249
expl/Average Returns                     1
eval/num steps total                     1.36284e+06
eval/num paths total                190682
eval/path length Mean                    3.88802
eval/path length Std                     1.6745
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2572
eval/Rewards Std                         0.437091
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00576972
eval/Actions Std                         0.66543
eval/Actions Max                         0.996364
eval/Actions Min                        -0.9971
eval/Num Paths                        1286
eval/Average Returns                     1
time/data storing (s)                    0.0045305
time/evaluation sampling (s)             1.01156
time/exploration sampling (s)            0.301366
time/logging (s)                         0.0205926
time/sac training (s)                   12.2485
time/saving (s)                          0.0034303
time/training (s)                        2.199e-05
time/epoch (s)                          13.59
time/total (s)                        3682.04
Epoch                                  273
----------------------------------  ----------------
2022-09-09 20:54:29.274843 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 274 finished
----------------------------------  ----------------
epoch                                  274
replay_buffer/size                  276000
trainer/num train calls             275000
trainer/QF1 Loss                         5.61735e-07
trainer/QF2 Loss                         1.56936e-06
trainer/Policy Loss                     -0.965157
trainer/Q1 Predictions Mean              0.961077
trainer/Q1 Predictions Std               0.024839
trainer/Q1 Predictions Max               0.999851
trainer/Q1 Predictions Min               0.928835
trainer/Q2 Predictions Mean              0.96133
trainer/Q2 Predictions Std               0.0246435
trainer/Q2 Predictions Max               1.00009
trainer/Q2 Predictions Min               0.929131
trainer/Q Targets Mean                   0.961324
trainer/Q Targets Std                    0.0249706
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929336
trainer/Log Pis Mean                     2.99087
trainer/Log Pis Std                      1.76373
trainer/Log Pis Max                      7.76237
trainer/Log Pis Min                     -3.48484
trainer/policy/mean Mean                 0.0228548
trainer/policy/mean Std                  0.668102
trainer/policy/mean Max                  0.996053
trainer/policy/mean Min                 -0.995545
trainer/policy/normal/std Mean           0.632345
trainer/policy/normal/std Std            0.195016
trainer/policy/normal/std Max            1.345
trainer/policy/normal/std Min            0.208175
trainer/policy/normal/log_std Mean      -0.507729
trainer/policy/normal/log_std Std        0.319014
trainer/policy/normal/log_std Max        0.296392
trainer/policy/normal/log_std Min       -1.56938
trainer/Alpha                            0.000113474
trainer/Alpha Loss                      -0.0829045
expl/num steps total                276000
expl/num paths total                 38240
expl/path length Mean                    3.92157
expl/path length Std                     1.61662
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.254
expl/Rewards Std                         0.435298
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996078
expl/Returns Std                         0.0624995
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0448993
expl/Actions Std                         0.761179
expl/Actions Max                         0.999748
expl/Actions Min                        -0.999691
expl/Num Paths                         255
expl/Average Returns                     0.996078
eval/num steps total                     1.36784e+06
eval/num paths total                191962
eval/path length Mean                    3.90391
eval/path length Std                     1.67593
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.256154
eval/Rewards Std                         0.436508
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0346032
eval/Actions Std                         0.665441
eval/Actions Max                         0.996114
eval/Actions Min                        -0.996026
eval/Num Paths                        1280
eval/Average Returns                     1
time/data storing (s)                    0.00577104
time/evaluation sampling (s)             0.95932
time/exploration sampling (s)            0.327365
time/logging (s)                         0.0222581
time/sac training (s)                   12.5736
time/saving (s)                          0.00431608
time/training (s)                        7.456e-05
time/epoch (s)                          13.8927
time/total (s)                        3696.25
Epoch                                  274
----------------------------------  ----------------
2022-09-09 20:54:43.136294 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 275 finished
----------------------------------  ----------------
epoch                                  275
replay_buffer/size                  277000
trainer/num train calls             276000
trainer/QF1 Loss                         1.06734e-06
trainer/QF2 Loss                         1.17469e-06
trainer/Policy Loss                     -0.966313
trainer/Q1 Predictions Mean              0.96238
trainer/Q1 Predictions Std               0.0256651
trainer/Q1 Predictions Max               0.99992
trainer/Q1 Predictions Min               0.928054
trainer/Q2 Predictions Mean              0.96288
trainer/Q2 Predictions Std               0.0256389
trainer/Q2 Predictions Max               1.00127
trainer/Q2 Predictions Min               0.928442
trainer/Q Targets Mean                   0.963022
trainer/Q Targets Std                    0.0256473
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929357
trainer/Log Pis Mean                     2.79102
trainer/Log Pis Std                      1.84706
trainer/Log Pis Max                      7.59805
trainer/Log Pis Min                     -4.07558
trainer/policy/mean Mean                 0.038271
trainer/policy/mean Std                  0.676999
trainer/policy/mean Max                  0.995433
trainer/policy/mean Min                 -0.995944
trainer/policy/normal/std Mean           0.598114
trainer/policy/normal/std Std            0.188593
trainer/policy/normal/std Max            1.2414
trainer/policy/normal/std Min            0.19736
trainer/policy/normal/log_std Mean      -0.566662
trainer/policy/normal/log_std Std        0.331037
trainer/policy/normal/log_std Max        0.216239
trainer/policy/normal/log_std Min       -1.62273
trainer/Alpha                            0.000114991
trainer/Alpha Loss                      -1.89562
expl/num steps total                277000
expl/num paths total                 38503
expl/path length Mean                    3.80228
expl/path length Std                     1.68838
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.262
expl/Rewards Std                         0.439723
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996198
expl/Returns Std                         0.0615453
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00445312
expl/Actions Std                         0.752677
expl/Actions Max                         0.999575
expl/Actions Min                        -0.99963
expl/Num Paths                         263
expl/Average Returns                     0.996198
eval/num steps total                     1.37284e+06
eval/num paths total                193228
eval/path length Mean                    3.94866
eval/path length Std                     1.66832
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253251
eval/Rewards Std                         0.434873
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0248778
eval/Actions Std                         0.662783
eval/Actions Max                         0.996213
eval/Actions Min                        -0.997149
eval/Num Paths                        1266
eval/Average Returns                     1
time/data storing (s)                    0.00392053
time/evaluation sampling (s)             0.963366
time/exploration sampling (s)            0.339044
time/logging (s)                         0.0199546
time/sac training (s)                   12.2192
time/saving (s)                          0.00471869
time/training (s)                        0.00013518
time/epoch (s)                          13.5504
time/total (s)                        3710.1
Epoch                                  275
----------------------------------  ----------------
2022-09-09 20:54:56.827063 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 276 finished
----------------------------------  ----------------
epoch                                  276
replay_buffer/size                  278000
trainer/num train calls             277000
trainer/QF1 Loss                         3.97251e-06
trainer/QF2 Loss                         1.5066e-06
trainer/Policy Loss                     -0.96713
trainer/Q1 Predictions Mean              0.964187
trainer/Q1 Predictions Std               0.0260168
trainer/Q1 Predictions Max               1.00307
trainer/Q1 Predictions Min               0.931189
trainer/Q2 Predictions Mean              0.962852
trainer/Q2 Predictions Std               0.0261097
trainer/Q2 Predictions Max               1.00246
trainer/Q2 Predictions Min               0.928664
trainer/Q Targets Mean                   0.962306
trainer/Q Targets Std                    0.025834
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929439
trainer/Log Pis Mean                     2.81846
trainer/Log Pis Std                      1.88341
trainer/Log Pis Max                      7.33387
trainer/Log Pis Min                     -3.29404
trainer/policy/mean Mean                 0.06623
trainer/policy/mean Std                  0.676178
trainer/policy/mean Max                  0.995168
trainer/policy/mean Min                 -0.997898
trainer/policy/normal/std Mean           0.61593
trainer/policy/normal/std Std            0.208144
trainer/policy/normal/std Max            1.31963
trainer/policy/normal/std Min            0.235845
trainer/policy/normal/log_std Mean      -0.545794
trainer/policy/normal/log_std Std        0.357501
trainer/policy/normal/log_std Max        0.277351
trainer/policy/normal/log_std Min       -1.44458
trainer/Alpha                            0.000115384
trainer/Alpha Loss                      -1.64611
expl/num steps total                278000
expl/num paths total                 38763
expl/path length Mean                    3.84615
expl/path length Std                     1.69371
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.259
expl/Rewards Std                         0.438086
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996154
expl/Returns Std                         0.061898
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0188765
expl/Actions Std                         0.764892
expl/Actions Max                         0.999477
expl/Actions Min                        -0.999375
expl/Num Paths                         260
expl/Average Returns                     0.996154
eval/num steps total                     1.37784e+06
eval/num paths total                194482
eval/path length Mean                    3.98565
eval/path length Std                     1.67726
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2509
eval/Rewards Std                         0.433531
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0342243
eval/Actions Std                         0.672879
eval/Actions Max                         0.996619
eval/Actions Min                        -0.998077
eval/Num Paths                        1254
eval/Average Returns                     1
time/data storing (s)                    0.00402293
time/evaluation sampling (s)             0.95306
time/exploration sampling (s)            0.30834
time/logging (s)                         0.0184014
time/sac training (s)                   12.0879
time/saving (s)                          0.00472816
time/training (s)                        2.574e-05
time/epoch (s)                          13.3765
time/total (s)                        3723.78
Epoch                                  276
----------------------------------  ----------------
2022-09-09 20:55:10.406666 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 277 finished
----------------------------------  ----------------
epoch                                  277
replay_buffer/size                  279000
trainer/num train calls             278000
trainer/QF1 Loss                         1.99559e-06
trainer/QF2 Loss                         2.02427e-06
trainer/Policy Loss                     -0.9649
trainer/Q1 Predictions Mean              0.961373
trainer/Q1 Predictions Std               0.0250895
trainer/Q1 Predictions Max               1.00455
trainer/Q1 Predictions Min               0.930254
trainer/Q2 Predictions Mean              0.960849
trainer/Q2 Predictions Std               0.0250593
trainer/Q2 Predictions Max               1.00406
trainer/Q2 Predictions Min               0.929084
trainer/Q Targets Mean                   0.960399
trainer/Q Targets Std                    0.0249412
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929416
trainer/Log Pis Mean                     3.25896
trainer/Log Pis Std                      1.79389
trainer/Log Pis Max                      7.52224
trainer/Log Pis Min                     -4.10665
trainer/policy/mean Mean                 0.031019
trainer/policy/mean Std                  0.699622
trainer/policy/mean Max                  0.995867
trainer/policy/mean Min                 -0.996559
trainer/policy/normal/std Mean           0.603835
trainer/policy/normal/std Std            0.189678
trainer/policy/normal/std Max            1.6775
trainer/policy/normal/std Min            0.255401
trainer/policy/normal/log_std Mean      -0.553389
trainer/policy/normal/log_std Std        0.314027
trainer/policy/normal/log_std Max        0.517307
trainer/policy/normal/log_std Min       -1.36492
trainer/Alpha                            0.000115846
trainer/Alpha Loss                       2.34702
expl/num steps total                279000
expl/num paths total                 39015
expl/path length Mean                    3.96825
expl/path length Std                     1.65201
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996032
expl/Returns Std                         0.062869
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0222609
expl/Actions Std                         0.75992
expl/Actions Max                         0.999864
expl/Actions Min                        -0.99973
expl/Num Paths                         252
expl/Average Returns                     0.996032
eval/num steps total                     1.38284e+06
eval/num paths total                195735
eval/path length Mean                    3.99042
eval/path length Std                     1.64966
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2506
eval/Rewards Std                         0.433359
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0130279
eval/Actions Std                         0.674234
eval/Actions Max                         0.996415
eval/Actions Min                        -0.997811
eval/Num Paths                        1253
eval/Average Returns                     1
time/data storing (s)                    0.00617995
time/evaluation sampling (s)             0.955604
time/exploration sampling (s)            0.320302
time/logging (s)                         0.0176078
time/sac training (s)                   11.9692
time/saving (s)                          0.00345156
time/training (s)                        9.842e-05
time/epoch (s)                          13.2725
time/total (s)                        3737.35
Epoch                                  277
----------------------------------  ----------------
2022-09-09 20:55:24.081802 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 278 finished
----------------------------------  ----------------
epoch                                  278
replay_buffer/size                  280000
trainer/num train calls             279000
trainer/QF1 Loss                         7.1582e-07
trainer/QF2 Loss                         1.11055e-06
trainer/Policy Loss                     -0.964195
trainer/Q1 Predictions Mean              0.960128
trainer/Q1 Predictions Std               0.0251854
trainer/Q1 Predictions Max               1.00049
trainer/Q1 Predictions Min               0.929169
trainer/Q2 Predictions Mean              0.960465
trainer/Q2 Predictions Std               0.0251632
trainer/Q2 Predictions Max               1.00094
trainer/Q2 Predictions Min               0.929234
trainer/Q Targets Mean                   0.960569
trainer/Q Targets Std                    0.0251582
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929971
trainer/Log Pis Mean                     2.8571
trainer/Log Pis Std                      1.63819
trainer/Log Pis Max                      7.43991
trainer/Log Pis Min                     -3.4389
trainer/policy/mean Mean                 0.0987299
trainer/policy/mean Std                  0.658398
trainer/policy/mean Max                  0.994954
trainer/policy/mean Min                 -0.99613
trainer/policy/normal/std Mean           0.604511
trainer/policy/normal/std Std            0.187334
trainer/policy/normal/std Max            1.49453
trainer/policy/normal/std Min            0.222763
trainer/policy/normal/log_std Mean      -0.554533
trainer/policy/normal/log_std Std        0.327389
trainer/policy/normal/log_std Max        0.40181
trainer/policy/normal/log_std Min       -1.50165
trainer/Alpha                            0.000112589
trainer/Alpha Loss                      -1.29919
expl/num steps total                280000
expl/num paths total                 39281
expl/path length Mean                    3.7594
expl/path length Std                     1.71964
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.265
expl/Rewards Std                         0.441333
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996241
expl/Returns Std                         0.0611986
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00120679
expl/Actions Std                         0.759029
expl/Actions Max                         0.99965
expl/Actions Min                        -0.999614
expl/Num Paths                         266
expl/Average Returns                     0.996241
eval/num steps total                     1.38783e+06
eval/num paths total                197000
eval/path length Mean                    3.95178
eval/path length Std                     1.70284
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253051
eval/Rewards Std                         0.43476
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0457535
eval/Actions Std                         0.663927
eval/Actions Max                         0.996022
eval/Actions Min                        -0.996971
eval/Num Paths                        1265
eval/Average Returns                     1
time/data storing (s)                    0.00400094
time/evaluation sampling (s)             0.953597
time/exploration sampling (s)            0.314426
time/logging (s)                         0.0193238
time/sac training (s)                   12.0731
time/saving (s)                          0.00474099
time/training (s)                        2.546e-05
time/epoch (s)                          13.3693
time/total (s)                        3751.01
Epoch                                  278
----------------------------------  ----------------
2022-09-09 20:55:37.900245 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 279 finished
----------------------------------  ----------------
epoch                                  279
replay_buffer/size                  281000
trainer/num train calls             280000
trainer/QF1 Loss                         9.21259e-07
trainer/QF2 Loss                         1.79135e-06
trainer/Policy Loss                     -0.965401
trainer/Q1 Predictions Mean              0.961844
trainer/Q1 Predictions Std               0.0253902
trainer/Q1 Predictions Max               1.00068
trainer/Q1 Predictions Min               0.928604
trainer/Q2 Predictions Mean              0.963003
trainer/Q2 Predictions Std               0.025688
trainer/Q2 Predictions Max               1.00332
trainer/Q2 Predictions Min               0.929283
trainer/Q Targets Mean                   0.96224
trainer/Q Targets Std                    0.0254124
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929446
trainer/Log Pis Mean                     2.86293
trainer/Log Pis Std                      1.85356
trainer/Log Pis Max                      7.86703
trainer/Log Pis Min                     -6.16186
trainer/policy/mean Mean                 0.00465781
trainer/policy/mean Std                  0.673827
trainer/policy/mean Max                  0.996221
trainer/policy/mean Min                 -0.996412
trainer/policy/normal/std Mean           0.602107
trainer/policy/normal/std Std            0.197559
trainer/policy/normal/std Max            1.31274
trainer/policy/normal/std Min            0.218019
trainer/policy/normal/log_std Mean      -0.564367
trainer/policy/normal/log_std Std        0.344123
trainer/policy/normal/log_std Max        0.272116
trainer/policy/normal/log_std Min       -1.52317
trainer/Alpha                            0.000112801
trainer/Alpha Loss                      -1.24591
expl/num steps total                281000
expl/num paths total                 39533
expl/path length Mean                    3.96825
expl/path length Std                     1.68766
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996032
expl/Returns Std                         0.062869
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.052973
expl/Actions Std                         0.755775
expl/Actions Max                         0.999505
expl/Actions Min                        -0.999773
expl/Num Paths                         252
expl/Average Returns                     0.996032
eval/num steps total                     1.39283e+06
eval/num paths total                198248
eval/path length Mean                    4.0024
eval/path length Std                     1.63275
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.24985
eval/Rewards Std                         0.432926
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0265023
eval/Actions Std                         0.669058
eval/Actions Max                         0.996876
eval/Actions Min                        -0.997308
eval/Num Paths                        1248
eval/Average Returns                     1
time/data storing (s)                    0.00387814
time/evaluation sampling (s)             0.999243
time/exploration sampling (s)            0.332895
time/logging (s)                         0.0199714
time/sac training (s)                   12.1194
time/saving (s)                          0.00333158
time/training (s)                        0.00011166
time/epoch (s)                          13.4788
time/total (s)                        3764.82
Epoch                                  279
----------------------------------  ----------------
2022-09-09 20:55:51.560367 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 280 finished
----------------------------------  ----------------
epoch                                  280
replay_buffer/size                  282000
trainer/num train calls             281000
trainer/QF1 Loss                         1.57021e-06
trainer/QF2 Loss                         2.36471e-06
trainer/Policy Loss                     -0.963516
trainer/Q1 Predictions Mean              0.959399
trainer/Q1 Predictions Std               0.0252164
trainer/Q1 Predictions Max               0.998894
trainer/Q1 Predictions Min               0.928469
trainer/Q2 Predictions Mean              0.959267
trainer/Q2 Predictions Std               0.0253257
trainer/Q2 Predictions Max               0.999914
trainer/Q2 Predictions Min               0.927631
trainer/Q Targets Mean                   0.960413
trainer/Q Targets Std                    0.0255771
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929284
trainer/Log Pis Mean                     2.87711
trainer/Log Pis Std                      1.80523
trainer/Log Pis Max                      7.60687
trainer/Log Pis Min                     -2.9376
trainer/policy/mean Mean                 0.0320757
trainer/policy/mean Std                  0.673668
trainer/policy/mean Max                  0.995162
trainer/policy/mean Min                 -0.99573
trainer/policy/normal/std Mean           0.602207
trainer/policy/normal/std Std            0.204115
trainer/policy/normal/std Max            1.09831
trainer/policy/normal/std Min            0.198325
trainer/policy/normal/log_std Mean      -0.568954
trainer/policy/normal/log_std Std        0.359882
trainer/policy/normal/log_std Max        0.0937769
trainer/policy/normal/log_std Min       -1.61785
trainer/Alpha                            0.000113244
trainer/Alpha Loss                      -1.11657
expl/num steps total                282000
expl/num paths total                 39777
expl/path length Mean                    4.09836
expl/path length Std                     1.66157
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.243
expl/Rewards Std                         0.428895
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995902
expl/Returns Std                         0.0638871
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0372257
expl/Actions Std                         0.763862
expl/Actions Max                         0.999617
expl/Actions Min                        -0.999551
expl/Num Paths                         244
expl/Average Returns                     0.995902
eval/num steps total                     1.39783e+06
eval/num paths total                199500
eval/path length Mean                    3.99281
eval/path length Std                     1.66551
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25045
eval/Rewards Std                         0.433272
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0150592
eval/Actions Std                         0.662948
eval/Actions Max                         0.996403
eval/Actions Min                        -0.99651
eval/Num Paths                        1252
eval/Average Returns                     1
time/data storing (s)                    0.0063833
time/evaluation sampling (s)             0.960864
time/exploration sampling (s)            0.318688
time/logging (s)                         0.0183548
time/sac training (s)                   12.0519
time/saving (s)                          0.00471889
time/training (s)                        2.817e-05
time/epoch (s)                          13.3609
time/total (s)                        3778.47
Epoch                                  280
----------------------------------  ----------------
2022-09-09 20:56:05.148042 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 281 finished
----------------------------------  ----------------
epoch                                  281
replay_buffer/size                  283000
trainer/num train calls             282000
trainer/QF1 Loss                         1.07477e-06
trainer/QF2 Loss                         3.44959e-06
trainer/Policy Loss                     -0.967367
trainer/Q1 Predictions Mean              0.963521
trainer/Q1 Predictions Std               0.0253822
trainer/Q1 Predictions Max               1.00107
trainer/Q1 Predictions Min               0.929685
trainer/Q2 Predictions Mean              0.964402
trainer/Q2 Predictions Std               0.0252513
trainer/Q2 Predictions Max               1.00267
trainer/Q2 Predictions Min               0.929894
trainer/Q Targets Mean                   0.963215
trainer/Q Targets Std                    0.0254333
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928031
trainer/Log Pis Mean                     2.91658
trainer/Log Pis Std                      1.5635
trainer/Log Pis Max                      7.64115
trainer/Log Pis Min                     -2.50669
trainer/policy/mean Mean                 0.0281665
trainer/policy/mean Std                  0.672045
trainer/policy/mean Max                  0.99612
trainer/policy/mean Min                 -0.995981
trainer/policy/normal/std Mean           0.606783
trainer/policy/normal/std Std            0.186585
trainer/policy/normal/std Max            1.04893
trainer/policy/normal/std Min            0.212144
trainer/policy/normal/log_std Mean      -0.550475
trainer/policy/normal/log_std Std        0.326741
trainer/policy/normal/log_std Max        0.0477729
trainer/policy/normal/log_std Min       -1.55049
trainer/Alpha                            0.000113059
trainer/Alpha Loss                      -0.758132
expl/num steps total                283000
expl/num paths total                 40018
expl/path length Mean                    4.14938
expl/path length Std                     1.71958
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.241
expl/Rewards Std                         0.42769
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0297107
expl/Actions Std                         0.752962
expl/Actions Max                         0.999817
expl/Actions Min                        -0.999541
expl/Num Paths                         241
expl/Average Returns                     1
eval/num steps total                     1.40282e+06
eval/num paths total                200750
eval/path length Mean                    3.9968
eval/path length Std                     1.68949
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2502
eval/Rewards Std                         0.433128
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00420168
eval/Actions Std                         0.667383
eval/Actions Max                         0.99589
eval/Actions Min                        -0.99679
eval/Num Paths                        1250
eval/Average Returns                     1
time/data storing (s)                    0.00383849
time/evaluation sampling (s)             0.954268
time/exploration sampling (s)            0.314016
time/logging (s)                         0.0186327
time/sac training (s)                   11.9916
time/saving (s)                          0.00474129
time/training (s)                        2.632e-05
time/epoch (s)                          13.2872
time/total (s)                        3792.05
Epoch                                  281
----------------------------------  ----------------
2022-09-09 20:56:19.032281 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 282 finished
----------------------------------  ----------------
epoch                                  282
replay_buffer/size                  284000
trainer/num train calls             283000
trainer/QF1 Loss                         6.96388e-07
trainer/QF2 Loss                         2.35552e-06
trainer/Policy Loss                     -0.967717
trainer/Q1 Predictions Mean              0.963798
trainer/Q1 Predictions Std               0.0262944
trainer/Q1 Predictions Max               1.00066
trainer/Q1 Predictions Min               0.928264
trainer/Q2 Predictions Mean              0.964042
trainer/Q2 Predictions Std               0.0266123
trainer/Q2 Predictions Max               1.00193
trainer/Q2 Predictions Min               0.927177
trainer/Q Targets Mean                   0.963943
trainer/Q Targets Std                    0.0261723
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929098
trainer/Log Pis Mean                     2.75801
trainer/Log Pis Std                      1.84477
trainer/Log Pis Max                      7.49887
trainer/Log Pis Min                     -7.21581
trainer/policy/mean Mean                 0.0571133
trainer/policy/mean Std                  0.667133
trainer/policy/mean Max                  0.996701
trainer/policy/mean Min                 -0.997002
trainer/policy/normal/std Mean           0.61963
trainer/policy/normal/std Std            0.187549
trainer/policy/normal/std Max            1.10862
trainer/policy/normal/std Min            0.182709
trainer/policy/normal/log_std Mean      -0.529654
trainer/policy/normal/log_std Std        0.33064
trainer/policy/normal/log_std Max        0.10312
trainer/policy/normal/log_std Min       -1.69986
trainer/Alpha                            0.000114348
trainer/Alpha Loss                      -2.19637
expl/num steps total                284000
expl/num paths total                 40272
expl/path length Mean                    3.93701
expl/path length Std                     1.7445
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.253
expl/Rewards Std                         0.434731
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996063
expl/Returns Std                         0.0626219
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00180292
expl/Actions Std                         0.75988
expl/Actions Max                         0.999817
expl/Actions Min                        -0.999799
expl/Num Paths                         254
expl/Average Returns                     0.996063
eval/num steps total                     1.40782e+06
eval/num paths total                202042
eval/path length Mean                    3.86842
eval/path length Std                     1.65191
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.258503
eval/Rewards Std                         0.437812
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00107343
eval/Actions Std                         0.665353
eval/Actions Max                         0.996641
eval/Actions Min                        -0.997112
eval/Num Paths                        1292
eval/Average Returns                     1
time/data storing (s)                    0.00618982
time/evaluation sampling (s)             0.966081
time/exploration sampling (s)            0.314615
time/logging (s)                         0.0180755
time/sac training (s)                   12.2704
time/saving (s)                          0.00333606
time/training (s)                        2.332e-05
time/epoch (s)                          13.5787
time/total (s)                        3805.92
Epoch                                  282
----------------------------------  ----------------
2022-09-09 20:56:32.541843 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 283 finished
----------------------------------  ----------------
epoch                                  283
replay_buffer/size                  285000
trainer/num train calls             284000
trainer/QF1 Loss                         1.21174e-06
trainer/QF2 Loss                         3.46006e-06
trainer/Policy Loss                     -0.966448
trainer/Q1 Predictions Mean              0.962649
trainer/Q1 Predictions Std               0.0261674
trainer/Q1 Predictions Max               1.00117
trainer/Q1 Predictions Min               0.929562
trainer/Q2 Predictions Mean              0.963459
trainer/Q2 Predictions Std               0.0258135
trainer/Q2 Predictions Max               1.00279
trainer/Q2 Predictions Min               0.930185
trainer/Q Targets Mean                   0.962418
trainer/Q Targets Std                    0.0260841
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929561
trainer/Log Pis Mean                     2.91227
trainer/Log Pis Std                      1.79379
trainer/Log Pis Max                      7.37015
trainer/Log Pis Min                     -4.21408
trainer/policy/mean Mean                 0.0345735
trainer/policy/mean Std                  0.668768
trainer/policy/mean Max                  0.995597
trainer/policy/mean Min                 -0.996081
trainer/policy/normal/std Mean           0.593316
trainer/policy/normal/std Std            0.197617
trainer/policy/normal/std Max            1.09247
trainer/policy/normal/std Min            0.193076
trainer/policy/normal/log_std Mean      -0.580808
trainer/policy/normal/log_std Std        0.349738
trainer/policy/normal/log_std Max        0.0884453
trainer/policy/normal/log_std Min       -1.64467
trainer/Alpha                            0.000111707
trainer/Alpha Loss                      -0.798319
expl/num steps total                285000
expl/num paths total                 40520
expl/path length Mean                    4.03226
expl/path length Std                     1.64334
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.247
expl/Rewards Std                         0.431267
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995968
expl/Returns Std                         0.0633719
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0195498
expl/Actions Std                         0.753641
expl/Actions Max                         0.999289
expl/Actions Min                        -0.999755
expl/Num Paths                         248
expl/Average Returns                     0.995968
eval/num steps total                     1.41282e+06
eval/num paths total                203306
eval/path length Mean                    3.9557
eval/path length Std                     1.68517
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2528
eval/Rewards Std                         0.434617
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0344507
eval/Actions Std                         0.662449
eval/Actions Max                         0.996576
eval/Actions Min                        -0.996615
eval/Num Paths                        1264
eval/Average Returns                     1
time/data storing (s)                    0.00541691
time/evaluation sampling (s)             0.9597
time/exploration sampling (s)            0.320489
time/logging (s)                         0.0181476
time/sac training (s)                   11.9276
time/saving (s)                          0.00465024
time/training (s)                        2.686e-05
time/epoch (s)                          13.2361
time/total (s)                        3819.42
Epoch                                  283
----------------------------------  ----------------
2022-09-09 20:56:46.397554 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 284 finished
----------------------------------  ----------------
epoch                                  284
replay_buffer/size                  286000
trainer/num train calls             285000
trainer/QF1 Loss                         1.62478e-06
trainer/QF2 Loss                         1.25883e-06
trainer/Policy Loss                     -0.965408
trainer/Q1 Predictions Mean              0.961816
trainer/Q1 Predictions Std               0.0251883
trainer/Q1 Predictions Max               1.00052
trainer/Q1 Predictions Min               0.928536
trainer/Q2 Predictions Mean              0.963114
trainer/Q2 Predictions Std               0.0252207
trainer/Q2 Predictions Max               1.00146
trainer/Q2 Predictions Min               0.929276
trainer/Q Targets Mean                   0.962755
trainer/Q Targets Std                    0.0251385
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92961
trainer/Log Pis Mean                     2.99076
trainer/Log Pis Std                      1.77392
trainer/Log Pis Max                      7.46397
trainer/Log Pis Min                     -3.18878
trainer/policy/mean Mean                 0.0403107
trainer/policy/mean Std                  0.670693
trainer/policy/mean Max                  0.996276
trainer/policy/mean Min                 -0.995917
trainer/policy/normal/std Mean           0.590069
trainer/policy/normal/std Std            0.174078
trainer/policy/normal/std Max            0.906102
trainer/policy/normal/std Min            0.198756
trainer/policy/normal/log_std Mean      -0.574214
trainer/policy/normal/log_std Std        0.312652
trainer/policy/normal/log_std Max       -0.0986039
trainer/policy/normal/log_std Min       -1.61568
trainer/Alpha                            0.000110715
trainer/Alpha Loss                      -0.0841215
expl/num steps total                286000
expl/num paths total                 40771
expl/path length Mean                    3.98406
expl/path length Std                     1.71231
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.25
expl/Rewards Std                         0.433013
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996016
expl/Returns Std                         0.0629936
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0523503
expl/Actions Std                         0.748013
expl/Actions Max                         0.999583
expl/Actions Min                        -0.999668
expl/Num Paths                         251
expl/Average Returns                     0.996016
eval/num steps total                     1.41782e+06
eval/num paths total                204575
eval/path length Mean                    3.93696
eval/path length Std                     1.69897
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254003
eval/Rewards Std                         0.435299
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00675901
eval/Actions Std                         0.668635
eval/Actions Max                         0.996581
eval/Actions Min                        -0.99724
eval/Num Paths                        1269
eval/Average Returns                     1
time/data storing (s)                    0.006207
time/evaluation sampling (s)             0.949877
time/exploration sampling (s)            0.325949
time/logging (s)                         0.0181666
time/sac training (s)                   12.2589
time/saving (s)                          0.00483323
time/training (s)                        2.619e-05
time/epoch (s)                          13.564
time/total (s)                        3833.26
Epoch                                  284
----------------------------------  ----------------
2022-09-09 20:57:00.325226 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 285 finished
----------------------------------  ----------------
epoch                                  285
replay_buffer/size                  287000
trainer/num train calls             286000
trainer/QF1 Loss                         1.07302e-06
trainer/QF2 Loss                         2.36306e-06
trainer/Policy Loss                     -0.965945
trainer/Q1 Predictions Mean              0.962089
trainer/Q1 Predictions Std               0.0248097
trainer/Q1 Predictions Max               1.00003
trainer/Q1 Predictions Min               0.929055
trainer/Q2 Predictions Mean              0.963731
trainer/Q2 Predictions Std               0.0250829
trainer/Q2 Predictions Max               1.00258
trainer/Q2 Predictions Min               0.930044
trainer/Q Targets Mean                   0.962723
trainer/Q Targets Std                    0.0251419
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928719
trainer/Log Pis Mean                     2.76222
trainer/Log Pis Std                      1.75824
trainer/Log Pis Max                      7.39084
trainer/Log Pis Min                     -4.72207
trainer/policy/mean Mean                 0.062614
trainer/policy/mean Std                  0.664124
trainer/policy/mean Max                  0.995581
trainer/policy/mean Min                 -0.996267
trainer/policy/normal/std Mean           0.590721
trainer/policy/normal/std Std            0.176946
trainer/policy/normal/std Max            0.993208
trainer/policy/normal/std Min            0.21034
trainer/policy/normal/log_std Mean      -0.574652
trainer/policy/normal/log_std Std        0.317928
trainer/policy/normal/log_std Max       -0.00681482
trainer/policy/normal/log_std Min       -1.55903
trainer/Alpha                            0.000109642
trainer/Alpha Loss                      -2.16815
expl/num steps total                287000
expl/num paths total                 41019
expl/path length Mean                    4.03226
expl/path length Std                     1.57826
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.248
expl/Rewards Std                         0.431852
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0515118
expl/Actions Std                         0.753035
expl/Actions Max                         0.999571
expl/Actions Min                        -0.999788
expl/Num Paths                         248
expl/Average Returns                     1
eval/num steps total                     1.42282e+06
eval/num paths total                205851
eval/path length Mean                    3.91771
eval/path length Std                     1.67134
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.255251
eval/Rewards Std                         0.436002
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0196786
eval/Actions Std                         0.663005
eval/Actions Max                         0.996627
eval/Actions Min                        -0.996353
eval/Num Paths                        1276
eval/Average Returns                     1
time/data storing (s)                    0.00494912
time/evaluation sampling (s)             0.955711
time/exploration sampling (s)            0.302931
time/logging (s)                         0.0790439
time/sac training (s)                   12.3564
time/saving (s)                          0.00442416
time/training (s)                        0.00014426
time/epoch (s)                          13.7036
time/total (s)                        3847.24
Epoch                                  285
----------------------------------  ----------------
2022-09-09 20:57:13.829065 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 286 finished
----------------------------------  ----------------
epoch                                  286
replay_buffer/size                  288000
trainer/num train calls             287000
trainer/QF1 Loss                         9.01153e-07
trainer/QF2 Loss                         1.9601e-06
trainer/Policy Loss                     -0.96762
trainer/Q1 Predictions Mean              0.964223
trainer/Q1 Predictions Std               0.0249965
trainer/Q1 Predictions Max               1.00212
trainer/Q1 Predictions Min               0.929166
trainer/Q2 Predictions Mean              0.964425
trainer/Q2 Predictions Std               0.0245219
trainer/Q2 Predictions Max               1.0018
trainer/Q2 Predictions Min               0.929863
trainer/Q Targets Mean                   0.963588
trainer/Q Targets Std                    0.0247183
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929426
trainer/Log Pis Mean                     2.83939
trainer/Log Pis Std                      1.93328
trainer/Log Pis Max                      6.76138
trainer/Log Pis Min                     -7.09452
trainer/policy/mean Mean                 0.00971115
trainer/policy/mean Std                  0.678115
trainer/policy/mean Max                  0.995868
trainer/policy/mean Min                 -0.996488
trainer/policy/normal/std Mean           0.590927
trainer/policy/normal/std Std            0.168162
trainer/policy/normal/std Max            0.927058
trainer/policy/normal/std Min            0.22614
trainer/policy/normal/log_std Mean      -0.570332
trainer/policy/normal/log_std Std        0.305779
trainer/policy/normal/log_std Max       -0.0757394
trainer/policy/normal/log_std Min       -1.4866
trainer/Alpha                            0.000110012
trainer/Alpha Loss                      -1.46396
expl/num steps total                288000
expl/num paths total                 41271
expl/path length Mean                    3.96825
expl/path length Std                     1.67823
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.252
expl/Rewards Std                         0.434161
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0415797
expl/Actions Std                         0.753594
expl/Actions Max                         0.999497
expl/Actions Min                        -0.999613
expl/Num Paths                         252
expl/Average Returns                     1
eval/num steps total                     1.42782e+06
eval/num paths total                207123
eval/path length Mean                    3.92925
eval/path length Std                     1.66059
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254502
eval/Rewards Std                         0.435581
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0165151
eval/Actions Std                         0.671749
eval/Actions Max                         0.996352
eval/Actions Min                        -0.997358
eval/Num Paths                        1272
eval/Average Returns                     1
time/data storing (s)                    0.0063031
time/evaluation sampling (s)             0.9668
time/exploration sampling (s)            0.339957
time/logging (s)                         0.0185479
time/sac training (s)                   11.8138
time/saving (s)                          0.00460123
time/training (s)                        0.00011944
time/epoch (s)                          13.1501
time/total (s)                        3860.67
Epoch                                  286
----------------------------------  ----------------
2022-09-09 20:57:27.410087 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 287 finished
----------------------------------  ----------------
epoch                                  287
replay_buffer/size                  289000
trainer/num train calls             288000
trainer/QF1 Loss                         2.31094e-06
trainer/QF2 Loss                         2.31499e-06
trainer/Policy Loss                     -0.967409
trainer/Q1 Predictions Mean              0.96398
trainer/Q1 Predictions Std               0.0243644
trainer/Q1 Predictions Max               0.999261
trainer/Q1 Predictions Min               0.928156
trainer/Q2 Predictions Mean              0.965807
trainer/Q2 Predictions Std               0.0247441
trainer/Q2 Predictions Max               1.00205
trainer/Q2 Predictions Min               0.929287
trainer/Q Targets Mean                   0.96516
trainer/Q Targets Std                    0.0245992
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929527
trainer/Log Pis Mean                     2.84112
trainer/Log Pis Std                      1.87543
trainer/Log Pis Max                      8.01965
trainer/Log Pis Min                     -2.49513
trainer/policy/mean Mean                 0.0689771
trainer/policy/mean Std                  0.66766
trainer/policy/mean Max                  0.996109
trainer/policy/mean Min                 -0.996901
trainer/policy/normal/std Mean           0.615688
trainer/policy/normal/std Std            0.200193
trainer/policy/normal/std Max            0.942331
trainer/policy/normal/std Min            0.195692
trainer/policy/normal/log_std Mean      -0.541805
trainer/policy/normal/log_std Std        0.344753
trainer/policy/normal/log_std Max       -0.059399
trainer/policy/normal/log_std Min       -1.63122
trainer/Alpha                            0.000110702
trainer/Alpha Loss                      -1.44719
expl/num steps total                289000
expl/num paths total                 41528
expl/path length Mean                    3.89105
expl/path length Std                     1.74765
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.256
expl/Rewards Std                         0.436422
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996109
expl/Returns Std                         0.0622568
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00156669
expl/Actions Std                         0.761031
expl/Actions Max                         0.99985
expl/Actions Min                        -0.999678
expl/Num Paths                         257
expl/Average Returns                     0.996109
eval/num steps total                     1.43281e+06
eval/num paths total                208376
eval/path length Mean                    3.98803
eval/path length Std                     1.66625
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.25075
eval/Rewards Std                         0.433445
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0216715
eval/Actions Std                         0.667002
eval/Actions Max                         0.99675
eval/Actions Min                        -0.996606
eval/Num Paths                        1253
eval/Average Returns                     1
time/data storing (s)                    0.00614467
time/evaluation sampling (s)             0.955951
time/exploration sampling (s)            0.335136
time/logging (s)                         0.0179123
time/sac training (s)                   11.97
time/saving (s)                          0.00328192
time/training (s)                        2.221e-05
time/epoch (s)                          13.2884
time/total (s)                        3874.24
Epoch                                  287
----------------------------------  ----------------
2022-09-09 20:57:40.858174 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 288 finished
----------------------------------  ----------------
epoch                                  288
replay_buffer/size                  290000
trainer/num train calls             289000
trainer/QF1 Loss                         4.66616e-07
trainer/QF2 Loss                         1.75386e-06
trainer/Policy Loss                     -0.967859
trainer/Q1 Predictions Mean              0.964731
trainer/Q1 Predictions Std               0.0250432
trainer/Q1 Predictions Max               0.999834
trainer/Q1 Predictions Min               0.929902
trainer/Q2 Predictions Mean              0.964745
trainer/Q2 Predictions Std               0.0254355
trainer/Q2 Predictions Max               1.00134
trainer/Q2 Predictions Min               0.928392
trainer/Q Targets Mean                   0.964709
trainer/Q Targets Std                    0.0253375
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.92963
trainer/Log Pis Mean                     2.96062
trainer/Log Pis Std                      1.87755
trainer/Log Pis Max                      8.05435
trainer/Log Pis Min                     -2.5715
trainer/policy/mean Mean                 0.0301531
trainer/policy/mean Std                  0.67488
trainer/policy/mean Max                  0.996733
trainer/policy/mean Min                 -0.996308
trainer/policy/normal/std Mean           0.607409
trainer/policy/normal/std Std            0.190289
trainer/policy/normal/std Max            1.08379
trainer/policy/normal/std Min            0.207846
trainer/policy/normal/log_std Mean      -0.551953
trainer/policy/normal/log_std Std        0.335235
trainer/policy/normal/log_std Max        0.0804672
trainer/policy/normal/log_std Min       -1.57096
trainer/Alpha                            0.000110092
trainer/Alpha Loss                      -0.358873
expl/num steps total                290000
expl/num paths total                 41772
expl/path length Mean                    4.09836
expl/path length Std                     1.66895
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.244
expl/Rewards Std                         0.429493
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.024099
expl/Actions Std                         0.751394
expl/Actions Max                         0.999661
expl/Actions Min                        -0.99972
expl/Num Paths                         244
expl/Average Returns                     1
eval/num steps total                     1.43781e+06
eval/num paths total                209632
eval/path length Mean                    3.9785
eval/path length Std                     1.66703
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251351
eval/Rewards Std                         0.43379
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0389018
eval/Actions Std                         0.661136
eval/Actions Max                         0.997136
eval/Actions Min                        -0.997147
eval/Num Paths                        1256
eval/Average Returns                     1
time/data storing (s)                    0.00471488
time/evaluation sampling (s)             0.955494
time/exploration sampling (s)            0.335671
time/logging (s)                         0.0195488
time/sac training (s)                   11.8514
time/saving (s)                          0.00331132
time/training (s)                        1.913e-05
time/epoch (s)                          13.1701
time/total (s)                        3887.68
Epoch                                  288
----------------------------------  ----------------
2022-09-09 20:57:54.405242 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 289 finished
----------------------------------  ----------------
epoch                                  289
replay_buffer/size                  291000
trainer/num train calls             290000
trainer/QF1 Loss                         5.03996e-07
trainer/QF2 Loss                         1.16665e-06
trainer/Policy Loss                     -0.966275
trainer/Q1 Predictions Mean              0.962162
trainer/Q1 Predictions Std               0.0249369
trainer/Q1 Predictions Max               1.00124
trainer/Q1 Predictions Min               0.930023
trainer/Q2 Predictions Mean              0.962466
trainer/Q2 Predictions Std               0.024878
trainer/Q2 Predictions Max               1.00167
trainer/Q2 Predictions Min               0.930804
trainer/Q Targets Mean                   0.961856
trainer/Q Targets Std                    0.0249322
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929963
trainer/Log Pis Mean                     2.90352
trainer/Log Pis Std                      1.79646
trainer/Log Pis Max                      7.19026
trainer/Log Pis Min                     -3.34568
trainer/policy/mean Mean                 0.124476
trainer/policy/mean Std                  0.666115
trainer/policy/mean Max                  0.995989
trainer/policy/mean Min                 -0.996436
trainer/policy/normal/std Mean           0.602315
trainer/policy/normal/std Std            0.177905
trainer/policy/normal/std Max            0.96175
trainer/policy/normal/std Min            0.213872
trainer/policy/normal/log_std Mean      -0.553676
trainer/policy/normal/log_std Std        0.312446
trainer/policy/normal/log_std Max       -0.0390011
trainer/policy/normal/log_std Min       -1.54238
trainer/Alpha                            0.000108963
trainer/Alpha Loss                      -0.88037
expl/num steps total                291000
expl/num paths total                 42018
expl/path length Mean                    4.06504
expl/path length Std                     1.61164
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.245
expl/Rewards Std                         0.430087
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995935
expl/Returns Std                         0.063628
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0393925
expl/Actions Std                         0.747425
expl/Actions Max                         0.999487
expl/Actions Min                        -0.999706
expl/Num Paths                         246
expl/Average Returns                     0.995935
eval/num steps total                     1.44281e+06
eval/num paths total                210900
eval/path length Mean                    3.94243
eval/path length Std                     1.65493
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.253651
eval/Rewards Std                         0.4351
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0461968
eval/Actions Std                         0.669621
eval/Actions Max                         0.996375
eval/Actions Min                        -0.997228
eval/Num Paths                        1268
eval/Average Returns                     1
time/data storing (s)                    0.0038225
time/evaluation sampling (s)             0.960391
time/exploration sampling (s)            0.312817
time/logging (s)                         0.0186944
time/sac training (s)                   11.9566
time/saving (s)                          0.00475498
time/training (s)                        2.757e-05
time/epoch (s)                          13.2571
time/total (s)                        3901.22
Epoch                                  289
----------------------------------  ----------------
2022-09-09 20:58:08.013449 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 290 finished
----------------------------------  ----------------
epoch                                  290
replay_buffer/size                  292000
trainer/num train calls             291000
trainer/QF1 Loss                         8.87529e-07
trainer/QF2 Loss                         1.66752e-06
trainer/Policy Loss                     -0.965931
trainer/Q1 Predictions Mean              0.962456
trainer/Q1 Predictions Std               0.025441
trainer/Q1 Predictions Max               0.99973
trainer/Q1 Predictions Min               0.9289
trainer/Q2 Predictions Mean              0.963009
trainer/Q2 Predictions Std               0.0254749
trainer/Q2 Predictions Max               1.00047
trainer/Q2 Predictions Min               0.929304
trainer/Q Targets Mean                   0.963051
trainer/Q Targets Std                    0.0255519
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929728
trainer/Log Pis Mean                     2.90424
trainer/Log Pis Std                      1.7611
trainer/Log Pis Max                      7.38621
trainer/Log Pis Min                     -3.16213
trainer/policy/mean Mean                 0.0619096
trainer/policy/mean Std                  0.659727
trainer/policy/mean Max                  0.995938
trainer/policy/mean Min                 -0.996259
trainer/policy/normal/std Mean           0.599359
trainer/policy/normal/std Std            0.186645
trainer/policy/normal/std Max            0.959484
trainer/policy/normal/std Min            0.223476
trainer/policy/normal/log_std Mean      -0.56415
trainer/policy/normal/log_std Std        0.330826
trainer/policy/normal/log_std Max       -0.0413594
trainer/policy/normal/log_std Min       -1.49845
trainer/Alpha                            0.000108441
trainer/Alpha Loss                      -0.874196
expl/num steps total                292000
expl/num paths total                 42265
expl/path length Mean                    4.04858
expl/path length Std                     1.67552
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.247
expl/Rewards Std                         0.431267
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.0112338
expl/Actions Std                         0.75703
expl/Actions Max                         0.999719
expl/Actions Min                        -0.99991
expl/Num Paths                         247
expl/Average Returns                     1
eval/num steps total                     1.4478e+06
eval/num paths total                212154
eval/path length Mean                    3.98405
eval/path length Std                     1.71206
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.251001
eval/Rewards Std                         0.433589
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00377608
eval/Actions Std                         0.666733
eval/Actions Max                         0.996514
eval/Actions Min                        -0.997309
eval/Num Paths                        1254
eval/Average Returns                     1
time/data storing (s)                    0.00620529
time/evaluation sampling (s)             0.962451
time/exploration sampling (s)            0.309511
time/logging (s)                         0.0176725
time/sac training (s)                   12.0087
time/saving (s)                          0.00333446
time/training (s)                        1.944e-05
time/epoch (s)                          13.3079
time/total (s)                        3914.82
Epoch                                  290
----------------------------------  ----------------
2022-09-09 20:58:21.379309 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 291 finished
----------------------------------  ----------------
epoch                                  291
replay_buffer/size                  293000
trainer/num train calls             292000
trainer/QF1 Loss                         9.10992e-07
trainer/QF2 Loss                         1.81625e-06
trainer/Policy Loss                     -0.967287
trainer/Q1 Predictions Mean              0.964085
trainer/Q1 Predictions Std               0.0252294
trainer/Q1 Predictions Max               1.00155
trainer/Q1 Predictions Min               0.929554
trainer/Q2 Predictions Mean              0.964193
trainer/Q2 Predictions Std               0.0247296
trainer/Q2 Predictions Max               1.00163
trainer/Q2 Predictions Min               0.930484
trainer/Q Targets Mean                   0.963586
trainer/Q Targets Std                    0.0248999
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929711
trainer/Log Pis Mean                     3.0327
trainer/Log Pis Std                      1.79666
trainer/Log Pis Max                      8.25197
trainer/Log Pis Min                     -4.53144
trainer/policy/mean Mean                 0.0230592
trainer/policy/mean Std                  0.678228
trainer/policy/mean Max                  0.995971
trainer/policy/mean Min                 -0.997301
trainer/policy/normal/std Mean           0.598426
trainer/policy/normal/std Std            0.197826
trainer/policy/normal/std Max            1.58847
trainer/policy/normal/std Min            0.187337
trainer/policy/normal/log_std Mean      -0.570087
trainer/policy/normal/log_std Std        0.341328
trainer/policy/normal/log_std Max        0.46277
trainer/policy/normal/log_std Min       -1.67485
trainer/Alpha                            0.000107812
trainer/Alpha Loss                       0.298742
expl/num steps total                293000
expl/num paths total                 42538
expl/path length Mean                    3.663
expl/path length Std                     1.65416
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.273
expl/Rewards Std                         0.445501
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                        0.0217001
expl/Actions Std                         0.759721
expl/Actions Max                         0.999724
expl/Actions Min                        -0.999718
expl/Num Paths                         273
expl/Average Returns                     1
eval/num steps total                     1.4528e+06
eval/num paths total                213423
eval/path length Mean                    3.94011
eval/path length Std                     1.66062
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2538
eval/Rewards Std                         0.435185
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0139851
eval/Actions Std                         0.670565
eval/Actions Max                         0.997079
eval/Actions Min                        -0.997392
eval/Num Paths                        1269
eval/Average Returns                     1
time/data storing (s)                    0.00428864
time/evaluation sampling (s)             0.952552
time/exploration sampling (s)            0.328176
time/logging (s)                         0.0210489
time/sac training (s)                   11.7908
time/saving (s)                          0.00339678
time/training (s)                        1.913e-05
time/epoch (s)                          13.1003
time/total (s)                        3928.18
Epoch                                  291
----------------------------------  ----------------
2022-09-09 20:58:35.134529 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 292 finished
----------------------------------  ----------------
epoch                                  292
replay_buffer/size                  294000
trainer/num train calls             293000
trainer/QF1 Loss                         1.69242e-06
trainer/QF2 Loss                         3.71963e-06
trainer/Policy Loss                     -0.967846
trainer/Q1 Predictions Mean              0.964309
trainer/Q1 Predictions Std               0.0260353
trainer/Q1 Predictions Max               1.00239
trainer/Q1 Predictions Min               0.929854
trainer/Q2 Predictions Mean              0.964601
trainer/Q2 Predictions Std               0.0259402
trainer/Q2 Predictions Max               1.00339
trainer/Q2 Predictions Min               0.929458
trainer/Q Targets Mean                   0.963369
trainer/Q Targets Std                    0.0258955
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929654
trainer/Log Pis Mean                     2.93745
trainer/Log Pis Std                      1.92816
trainer/Log Pis Max                      8.32317
trainer/Log Pis Min                     -3.01513
trainer/policy/mean Mean                -0.0024223
trainer/policy/mean Std                  0.671132
trainer/policy/mean Max                  0.995763
trainer/policy/mean Min                 -0.996592
trainer/policy/normal/std Mean           0.573174
trainer/policy/normal/std Std            0.196548
trainer/policy/normal/std Max            0.938066
trainer/policy/normal/std Min            0.188828
trainer/policy/normal/log_std Mean      -0.620611
trainer/policy/normal/log_std Std        0.367756
trainer/policy/normal/log_std Max       -0.0639347
trainer/policy/normal/log_std Min       -1.66692
trainer/Alpha                            0.000110893
trainer/Alpha Loss                      -0.569619
expl/num steps total                294000
expl/num paths total                 42783
expl/path length Mean                    4.08163
expl/path length Std                     1.60149
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.244
expl/Rewards Std                         0.429493
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.995918
expl/Returns Std                         0.0637571
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0104093
expl/Actions Std                         0.744356
expl/Actions Max                         0.999668
expl/Actions Min                        -0.999737
expl/Num Paths                         245
expl/Average Returns                     0.995918
eval/num steps total                     1.4578e+06
eval/num paths total                214698
eval/path length Mean                    3.91922
eval/path length Std                     1.64512
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.255153
eval/Rewards Std                         0.435947
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0048862
eval/Actions Std                         0.663085
eval/Actions Max                         0.996193
eval/Actions Min                        -0.997244
eval/Num Paths                        1275
eval/Average Returns                     1
time/data storing (s)                    0.00388883
time/evaluation sampling (s)             0.954005
time/exploration sampling (s)            0.349393
time/logging (s)                         0.0183625
time/sac training (s)                   12.148
time/saving (s)                          0.00470062
time/training (s)                        2.417e-05
time/epoch (s)                          13.4783
time/total (s)                        3941.92
Epoch                                  292
----------------------------------  ----------------
2022-09-09 20:58:48.520100 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 293 finished
----------------------------------  ----------------
epoch                                  293
replay_buffer/size                  295000
trainer/num train calls             294000
trainer/QF1 Loss                         1.32982e-06
trainer/QF2 Loss                         1.35243e-06
trainer/Policy Loss                     -0.966327
trainer/Q1 Predictions Mean              0.963725
trainer/Q1 Predictions Std               0.0246241
trainer/Q1 Predictions Max               1.00133
trainer/Q1 Predictions Min               0.930196
trainer/Q2 Predictions Mean              0.963064
trainer/Q2 Predictions Std               0.0247941
trainer/Q2 Predictions Max               1.00207
trainer/Q2 Predictions Min               0.929813
trainer/Q Targets Mean                   0.962949
trainer/Q Targets Std                    0.0247844
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929795
trainer/Log Pis Mean                     2.86179
trainer/Log Pis Std                      1.81119
trainer/Log Pis Max                      7.43579
trainer/Log Pis Min                     -7.4341
trainer/policy/mean Mean                 0.0639807
trainer/policy/mean Std                  0.668893
trainer/policy/mean Max                  0.997001
trainer/policy/mean Min                 -0.99566
trainer/policy/normal/std Mean           0.587452
trainer/policy/normal/std Std            0.186786
trainer/policy/normal/std Max            0.918327
trainer/policy/normal/std Min            0.208233
trainer/policy/normal/log_std Mean      -0.587606
trainer/policy/normal/log_std Std        0.343359
trainer/policy/normal/log_std Max       -0.0852013
trainer/policy/normal/log_std Min       -1.5691
trainer/Alpha                            0.000110264
trainer/Alpha Loss                      -1.25942
expl/num steps total                295000
expl/num paths total                 43042
expl/path length Mean                    3.861
expl/path length Std                     1.65452
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.258
expl/Rewards Std                         0.437534
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996139
expl/Returns Std                         0.0620169
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.00186253
expl/Actions Std                         0.751379
expl/Actions Max                         0.999716
expl/Actions Min                        -0.999602
expl/Num Paths                         259
expl/Average Returns                     0.996139
eval/num steps total                     1.4628e+06
eval/num paths total                215968
eval/path length Mean                    3.93465
eval/path length Std                     1.68728
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254152
eval/Rewards Std                         0.435384
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0204668
eval/Actions Std                         0.662099
eval/Actions Max                         0.996999
eval/Actions Min                        -0.995999
eval/Num Paths                        1270
eval/Average Returns                     1
time/data storing (s)                    0.00598581
time/evaluation sampling (s)             0.953521
time/exploration sampling (s)            0.321442
time/logging (s)                         0.0247044
time/sac training (s)                   11.8021
time/saving (s)                          0.00333128
time/training (s)                        1.904e-05
time/epoch (s)                          13.1111
time/total (s)                        3955.3
Epoch                                  293
----------------------------------  ----------------
2022-09-09 20:59:01.803401 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 294 finished
----------------------------------  ----------------
epoch                                  294
replay_buffer/size                  296000
trainer/num train calls             295000
trainer/QF1 Loss                         3.70946e-07
trainer/QF2 Loss                         2.01385e-06
trainer/Policy Loss                     -0.96687
trainer/Q1 Predictions Mean              0.963117
trainer/Q1 Predictions Std               0.024904
trainer/Q1 Predictions Max               1.00154
trainer/Q1 Predictions Min               0.929074
trainer/Q2 Predictions Mean              0.963606
trainer/Q2 Predictions Std               0.0248871
trainer/Q2 Predictions Max               1.00296
trainer/Q2 Predictions Min               0.930042
trainer/Q Targets Mean                   0.962987
trainer/Q Targets Std                    0.0247803
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929623
trainer/Log Pis Mean                     3.10873
trainer/Log Pis Std                      1.92591
trainer/Log Pis Max                      7.9655
trainer/Log Pis Min                     -4.18005
trainer/policy/mean Mean                 0.0446837
trainer/policy/mean Std                  0.675769
trainer/policy/mean Max                  0.996948
trainer/policy/mean Min                 -0.997479
trainer/policy/normal/std Mean           0.589413
trainer/policy/normal/std Std            0.197192
trainer/policy/normal/std Max            1.03659
trainer/policy/normal/std Min            0.190167
trainer/policy/normal/log_std Mean      -0.588587
trainer/policy/normal/log_std Std        0.353921
trainer/policy/normal/log_std Max        0.0359359
trainer/policy/normal/log_std Min       -1.65985
trainer/Alpha                            0.000111058
trainer/Alpha Loss                       0.990074
expl/num steps total                296000
expl/num paths total                 43295
expl/path length Mean                    3.95257
expl/path length Std                     1.65076
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.252
expl/Rewards Std                         0.434161
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996047
expl/Returns Std                         0.0627451
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0011813
expl/Actions Std                         0.751702
expl/Actions Max                         0.999634
expl/Actions Min                        -0.99987
expl/Num Paths                         253
expl/Average Returns                     0.996047
eval/num steps total                     1.4678e+06
eval/num paths total                217243
eval/path length Mean                    3.92157
eval/path length Std                     1.69617
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.255
eval/Rewards Std                         0.435861
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0166412
eval/Actions Std                         0.665287
eval/Actions Max                         0.996886
eval/Actions Min                        -0.997716
eval/Num Paths                        1275
eval/Average Returns                     1
time/data storing (s)                    0.0038527
time/evaluation sampling (s)             0.955513
time/exploration sampling (s)            0.314694
time/logging (s)                         0.0185711
time/sac training (s)                   11.692
time/saving (s)                          0.00483914
time/training (s)                        3.634e-05
time/epoch (s)                          12.9895
time/total (s)                        3968.57
Epoch                                  294
----------------------------------  ----------------
2022-09-09 20:59:15.780372 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 295 finished
----------------------------------  ----------------
epoch                                  295
replay_buffer/size                  297000
trainer/num train calls             296000
trainer/QF1 Loss                         2.80038e-06
trainer/QF2 Loss                         1.87283e-06
trainer/Policy Loss                     -0.96637
trainer/Q1 Predictions Mean              0.962583
trainer/Q1 Predictions Std               0.0254748
trainer/Q1 Predictions Max               0.998918
trainer/Q1 Predictions Min               0.928702
trainer/Q2 Predictions Mean              0.963628
trainer/Q2 Predictions Std               0.0259407
trainer/Q2 Predictions Max               1.00156
trainer/Q2 Predictions Min               0.928796
trainer/Q Targets Mean                   0.964076
trainer/Q Targets Std                    0.0257003
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929726
trainer/Log Pis Mean                     3.12459
trainer/Log Pis Std                      1.77924
trainer/Log Pis Max                      7.99051
trainer/Log Pis Min                     -5.10139
trainer/policy/mean Mean                 0.0885221
trainer/policy/mean Std                  0.667026
trainer/policy/mean Max                  0.99649
trainer/policy/mean Min                 -0.997247
trainer/policy/normal/std Mean           0.588719
trainer/policy/normal/std Std            0.184618
trainer/policy/normal/std Max            1.02636
trainer/policy/normal/std Min            0.194765
trainer/policy/normal/log_std Mean      -0.582826
trainer/policy/normal/log_std Std        0.333601
trainer/policy/normal/log_std Max        0.0260191
trainer/policy/normal/log_std Min       -1.63596
trainer/Alpha                            0.000108089
trainer/Alpha Loss                       1.13783
expl/num steps total                297000
expl/num paths total                 43547
expl/path length Mean                    3.96825
expl/path length Std                     1.56061
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.251
expl/Rewards Std                         0.433589
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996032
expl/Returns Std                         0.062869
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0234395
expl/Actions Std                         0.74588
expl/Actions Max                         0.999678
expl/Actions Min                        -0.999683
expl/Num Paths                         252
expl/Average Returns                     0.996032
eval/num steps total                     1.4728e+06
eval/num paths total                218495
eval/path length Mean                    3.99361
eval/path length Std                     1.64014
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.2504
eval/Rewards Std                         0.433243
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00263114
eval/Actions Std                         0.665507
eval/Actions Max                         0.996884
eval/Actions Min                        -0.997755
eval/Num Paths                        1252
eval/Average Returns                     1
time/data storing (s)                    0.00392285
time/evaluation sampling (s)             0.972163
time/exploration sampling (s)            0.314283
time/logging (s)                         0.019662
time/sac training (s)                   12.329
time/saving (s)                          0.00489512
time/training (s)                        3.167e-05
time/epoch (s)                          13.644
time/total (s)                        3982.53
Epoch                                  295
----------------------------------  ----------------
2022-09-09 20:59:29.213207 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 296 finished
----------------------------------  ----------------
epoch                                  296
replay_buffer/size                  298000
trainer/num train calls             297000
trainer/QF1 Loss                         6.66426e-07
trainer/QF2 Loss                         1.42711e-06
trainer/Policy Loss                     -0.967052
trainer/Q1 Predictions Mean              0.963119
trainer/Q1 Predictions Std               0.0255273
trainer/Q1 Predictions Max               1.00144
trainer/Q1 Predictions Min               0.929734
trainer/Q2 Predictions Mean              0.963181
trainer/Q2 Predictions Std               0.025402
trainer/Q2 Predictions Max               1.00155
trainer/Q2 Predictions Min               0.929441
trainer/Q Targets Mean                   0.962618
trainer/Q Targets Std                    0.0255612
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.928924
trainer/Log Pis Mean                     3.07468
trainer/Log Pis Std                      1.81581
trainer/Log Pis Max                      7.70985
trainer/Log Pis Min                     -2.29404
trainer/policy/mean Mean                 0.0329039
trainer/policy/mean Std                  0.672297
trainer/policy/mean Max                  0.996144
trainer/policy/mean Min                 -0.996894
trainer/policy/normal/std Mean           0.593172
trainer/policy/normal/std Std            0.206191
trainer/policy/normal/std Max            0.981189
trainer/policy/normal/std Min            0.196268
trainer/policy/normal/log_std Mean      -0.586625
trainer/policy/normal/log_std Std        0.36605
trainer/policy/normal/log_std Max       -0.0189904
trainer/policy/normal/log_std Min       -1.62828
trainer/Alpha                            0.000111532
trainer/Alpha Loss                       0.679708
expl/num steps total                298000
expl/num paths total                 43797
expl/path length Mean                    4
expl/path length Std                     1.68523
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996
expl/Returns Std                         0.0631189
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                        0.0603469
expl/Actions Std                         0.752772
expl/Actions Max                         0.99956
expl/Actions Min                        -0.999603
expl/Num Paths                         250
expl/Average Returns                     0.996
eval/num steps total                     1.47779e+06
eval/num paths total                219766
eval/path length Mean                    3.93076
eval/path length Std                     1.67358
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254404
eval/Rewards Std                         0.435525
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.0297751
eval/Actions Std                         0.665316
eval/Actions Max                         0.996745
eval/Actions Min                        -0.997201
eval/Num Paths                        1271
eval/Average Returns                     1
time/data storing (s)                    0.00401711
time/evaluation sampling (s)             0.968166
time/exploration sampling (s)            0.30284
time/logging (s)                         0.0194931
time/sac training (s)                   11.8379
time/saving (s)                          0.00462989
time/training (s)                        0.00013881
time/epoch (s)                          13.1372
time/total (s)                        3995.95
Epoch                                  296
----------------------------------  ----------------
2022-09-09 20:59:42.978920 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 297 finished
----------------------------------  ----------------
epoch                                  297
replay_buffer/size                  299000
trainer/num train calls             298000
trainer/QF1 Loss                         1.10234e-06
trainer/QF2 Loss                         2.0853e-06
trainer/Policy Loss                     -0.967381
trainer/Q1 Predictions Mean              0.964391
trainer/Q1 Predictions Std               0.0243354
trainer/Q1 Predictions Max               1.00149
trainer/Q1 Predictions Min               0.929187
trainer/Q2 Predictions Mean              0.96471
trainer/Q2 Predictions Std               0.0243386
trainer/Q2 Predictions Max               1.00232
trainer/Q2 Predictions Min               0.929246
trainer/Q Targets Mean                   0.963846
trainer/Q Targets Std                    0.0242663
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929033
trainer/Log Pis Mean                     2.90473
trainer/Log Pis Std                      1.86928
trainer/Log Pis Max                      7.10205
trainer/Log Pis Min                     -5.65668
trainer/policy/mean Mean                -0.00168958
trainer/policy/mean Std                  0.681091
trainer/policy/mean Max                  0.995786
trainer/policy/mean Min                 -0.996727
trainer/policy/normal/std Mean           0.607335
trainer/policy/normal/std Std            0.188026
trainer/policy/normal/std Max            1.09161
trainer/policy/normal/std Min            0.202858
trainer/policy/normal/log_std Mean      -0.549801
trainer/policy/normal/log_std Std        0.326547
trainer/policy/normal/log_std Max        0.0876541
trainer/policy/normal/log_std Min       -1.59525
trainer/Alpha                            0.000110031
trainer/Alpha Loss                      -0.868344
expl/num steps total                299000
expl/num paths total                 44047
expl/path length Mean                    4
expl/path length Std                     1.65892
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.249
expl/Rewards Std                         0.432434
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996
expl/Returns Std                         0.0631189
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.0284933
expl/Actions Std                         0.752702
expl/Actions Max                         0.999637
expl/Actions Min                        -0.999622
expl/Num Paths                         250
expl/Average Returns                     0.996
eval/num steps total                     1.48279e+06
eval/num paths total                221054
eval/path length Mean                    3.88121
eval/path length Std                     1.6444
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.257652
eval/Rewards Std                         0.437341
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                        0.00117088
eval/Actions Std                         0.665458
eval/Actions Max                         0.996093
eval/Actions Min                        -0.997826
eval/Num Paths                        1288
eval/Average Returns                     1
time/data storing (s)                    0.00389395
time/evaluation sampling (s)             0.971718
time/exploration sampling (s)            0.333703
time/logging (s)                         0.0211259
time/sac training (s)                   12.1188
time/saving (s)                          0.00477651
time/training (s)                        0.00016435
time/epoch (s)                          13.4542
time/total (s)                        4009.71
Epoch                                  297
----------------------------------  ----------------
2022-09-09 20:59:56.855182 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 298 finished
----------------------------------  ----------------
epoch                                  298
replay_buffer/size                  300000
trainer/num train calls             299000
trainer/QF1 Loss                         1.35038e-06
trainer/QF2 Loss                         3.62502e-06
trainer/Policy Loss                     -0.965307
trainer/Q1 Predictions Mean              0.962472
trainer/Q1 Predictions Std               0.0240582
trainer/Q1 Predictions Max               0.999044
trainer/Q1 Predictions Min               0.92854
trainer/Q2 Predictions Mean              0.961977
trainer/Q2 Predictions Std               0.0241011
trainer/Q2 Predictions Max               1.00036
trainer/Q2 Predictions Min               0.927809
trainer/Q Targets Mean                   0.963337
trainer/Q Targets Std                    0.0241956
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929847
trainer/Log Pis Mean                     3.10166
trainer/Log Pis Std                      1.73985
trainer/Log Pis Max                      7.31058
trainer/Log Pis Min                     -5.18261
trainer/policy/mean Mean                 0.012874
trainer/policy/mean Std                  0.667854
trainer/policy/mean Max                  0.997583
trainer/policy/mean Min                 -0.995917
trainer/policy/normal/std Mean           0.609913
trainer/policy/normal/std Std            0.185937
trainer/policy/normal/std Max            1.22765
trainer/policy/normal/std Min            0.172759
trainer/policy/normal/log_std Mean      -0.54428
trainer/policy/normal/log_std Std        0.323145
trainer/policy/normal/log_std Max        0.205102
trainer/policy/normal/log_std Min       -1.75586
trainer/Alpha                            0.00010772
trainer/Alpha Loss                       0.928726
expl/num steps total                300000
expl/num paths total                 44303
expl/path length Mean                    3.90625
expl/path length Std                     1.72272
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.255
expl/Rewards Std                         0.435861
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        0.996094
expl/Returns Std                         0.0623778
expl/Returns Max                         1
expl/Returns Min                         0
expl/Actions Mean                       -0.00502861
expl/Actions Std                         0.75409
expl/Actions Max                         0.999741
expl/Actions Min                        -0.999653
expl/Num Paths                         256
expl/Average Returns                     0.996094
eval/num steps total                     1.48779e+06
eval/num paths total                222327
eval/path length Mean                    3.92616
eval/path length Std                     1.68237
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.254702
eval/Rewards Std                         0.435694
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.00174936
eval/Actions Std                         0.669783
eval/Actions Max                         0.997382
eval/Actions Min                        -0.996586
eval/Num Paths                        1273
eval/Average Returns                     1
time/data storing (s)                    0.00620883
time/evaluation sampling (s)             0.971951
time/exploration sampling (s)            0.293944
time/logging (s)                         0.0190441
time/sac training (s)                   12.2745
time/saving (s)                          0.00461755
time/training (s)                        2.559e-05
time/epoch (s)                          13.5703
time/total (s)                        4023.57
Epoch                                  298
----------------------------------  ----------------
2022-09-09 21:00:10.751489 +08 | [name-of-experiment_2022_09_09_19_52_49_0000--s-0] Epoch 299 finished
----------------------------------  ----------------
epoch                                  299
replay_buffer/size                  301000
trainer/num train calls             300000
trainer/QF1 Loss                         1.2339e-06
trainer/QF2 Loss                         1.94573e-06
trainer/Policy Loss                     -0.968488
trainer/Q1 Predictions Mean              0.965091
trainer/Q1 Predictions Std               0.0261877
trainer/Q1 Predictions Max               1.00079
trainer/Q1 Predictions Min               0.928957
trainer/Q2 Predictions Mean              0.965391
trainer/Q2 Predictions Std               0.0263739
trainer/Q2 Predictions Max               1.00122
trainer/Q2 Predictions Min               0.929051
trainer/Q Targets Mean                   0.965315
trainer/Q Targets Std                    0.0262647
trainer/Q Targets Max                    1
trainer/Q Targets Min                    0.929581
trainer/Log Pis Mean                     2.95829
trainer/Log Pis Std                      2.14401
trainer/Log Pis Max                      7.53042
trainer/Log Pis Min                     -8.17094
trainer/policy/mean Mean                 0.0156393
trainer/policy/mean Std                  0.673106
trainer/policy/mean Max                  0.9969
trainer/policy/mean Min                 -0.996641
trainer/policy/normal/std Mean           0.581933
trainer/policy/normal/std Std            0.199217
trainer/policy/normal/std Max            1.05954
trainer/policy/normal/std Min            0.209353
trainer/policy/normal/log_std Mean      -0.604237
trainer/policy/normal/log_std Std        0.362525
trainer/policy/normal/log_std Max        0.0578396
trainer/policy/normal/log_std Min       -1.56373
trainer/Alpha                            0.000105344
trainer/Alpha Loss                      -0.38203
expl/num steps total                301000
expl/num paths total                 44553
expl/path length Mean                    4
expl/path length Std                     1.66613
expl/path length Max                     7
expl/path length Min                     1
expl/Rewards Mean                        0.25
expl/Rewards Std                         0.433013
expl/Rewards Max                         1
expl/Rewards Min                         0
expl/Returns Mean                        1
expl/Returns Std                         0
expl/Returns Max                         1
expl/Returns Min                         1
expl/Actions Mean                       -0.015158
expl/Actions Std                         0.752566
expl/Actions Max                         0.999669
expl/Actions Min                        -0.999766
expl/Num Paths                         250
expl/Average Returns                     1
eval/num steps total                     1.49279e+06
eval/num paths total                223587
eval/path length Mean                    3.96667
eval/path length Std                     1.66966
eval/path length Max                     7
eval/path length Min                     1
eval/Rewards Mean                        0.252101
eval/Rewards Std                         0.434219
eval/Rewards Max                         1
eval/Rewards Min                         0
eval/Returns Mean                        1
eval/Returns Std                         0
eval/Returns Max                         1
eval/Returns Min                         1
eval/Actions Mean                       -0.0348316
eval/Actions Std                         0.668904
eval/Actions Max                         0.996698
eval/Actions Min                        -0.997008
eval/Num Paths                        1260
eval/Average Returns                     1
time/data storing (s)                    0.00527486
time/evaluation sampling (s)             0.997693
time/exploration sampling (s)            0.302849
time/logging (s)                         0.0188126
time/sac training (s)                   12.2668
time/saving (s)                          0.00430972
time/training (s)                        1.928e-05
time/epoch (s)                          13.5958
time/total (s)                        4037.45
Epoch                                  299
----------------------------------  ----------------
